This paper addresses the understanding and characterization of residual networks (ResNet), which are among the state-of-the-art deep learning architectures for a variety of supervised learning problems.
We propose a novel zero-shot learning model that takes advantage of clustering structures in the semantic embedding space, using kernel-based regressors from semantic representation-exemplar pairs from labeled data of the seen object categories.
We explore some of the most popular loss functions that are used in deep saliency models. We demonstrate that on a fixed network architecture, modifying the loss function can significantly improve (or depreciate) the results.
We study the generalization error of randomized learning algorithms -- focusing on stochastic gradient descent -- using a novel combination of PAC-Bayes and algorithmic stability.
The idea of Innovation Search was proposed as a data clustering method in which the directions of innovation were utilized to compute the adjacency matrix and it was shown that Innovation Pursuit can notably outperform the self representation based subspace clustering methods.
We show that by encouraging deep message propagation and interactions between local object features and global predicate features, one can achieve compelling performance in recognizing complex relationships without using any linguistic priors.
We propose a robust stereo matching cost algorithm that relies on refined features extracted by a stack auto-encoder. In addition, we smoothed the belief volume with a guided filter to improve the performance of the belief propagation algorithm.
This paper introduces a network architecture to solve the structure-from-motion (SfM) problem via feature-metric bundle adjustment (BA), which explicitly enforces multi-view geometry constraints in the form of feature-Metric error.
Pretrained language models are equally prone to generate facts ("birds can fly") and their negation ("birds cannot fly"). This casts doubt on the claim that pretrained language model have adequately learned factual knowledge.
We introduce a new Zero-Shot Learning problem setting for detecting and localizing unseen objects in a complex scene, adhering to practical issues.
In recent years, stochastic variance reduction algorithms have attracted considerable attention for minimizing the average of a large but finite number of loss functions. This paper proposes a nove...
This paper presents a flexible Virtual Multi-View Synthesis module that can be adopted into 3D object detection methods to improve orientation estimation.
We propose a copy-augmented architecture for the Grammatical Error Correction task by copying the unchanged words from the source sentence to the target sentence.
We develop methods to create efficient MDLSTM-based models for NHR, particularly a method aimed at eliminating computation waste that results from padding.
We propose SRGAN, a generative adversarial network (GAN) for image super-resolution (SR) capable of inferring photo-realistic natural images for 4x upscaling factors.
This paper focuses on large-scale scene recognition and makes two major contributions to tackle these issues. First, we propose a multi-resolution CNN architecture that captures visual content and structure at multiple levels. Second, we design two knowledge guided disambiguation techniques to deal with label ambiguity.
This paper introduces a novel anchor design to support anchor-based face detection for superior scale-invariant performance, especially on tiny faces.
We propose a novel cascaded-regression-based method for automatic facial landmark localization in 3D face data designed specifically to address appearance variability caused by significant pose variations.
This work proposes a neural generation system using a hidden semi-markov model (HSMM) decoder, which learns latent, discrete templates jointly with learning to generate.
We introduce 3D Multi-View Adaptation, a fully self-supervised approach towards learning depth-aware keypoints from unlabeled videos by incorporating a differentiable pose estimation module that jointly optimizes the keypoints and their depths in a Structure-from-Motion setting.
We introduce new aggregation operators that capture more information about the value distributions, by storing meta-data about value distributions and referencing this meta- data when aggregating, and provide theoretical justification.
We propose a novel general framework for estimating and analysing the elliptical mixture model, achieved through Riemannian manifold optimisation, achieved in a simple and stable way.
In this paper we propose a distributed projection free algorithm named Distributed Conditional Gradient Sliding(DCGS), which attains the same communication complexity under realistic assumptions.
We introduce a novel graph convolutional operator, acting directly on the 3D mesh, that explicitly models the inductive bias of the fixed underlying graph, thus breaking the permutation invariance property.
In this paper, we propose Dynamic Linear Flow (DLF), a new family of invertible transformations with partially autoregressive structure.
In this paper, we make the first attempt to let algorithm automatically design neural networks for video action recognition tasks without losing global video information.
We introduce a real-time and online joint-labelling and association algorithm for action detection that can incrementally construct space-time action tubes on the most challenging action videos in which different action categories occur concurrently.
We propose a novel deep learning framework that can relight complex outdoor scenes by transferring realistic shadow, shading, and other lighting effects onto a single image. We show effectiveness of this method on both synthetic and real datasets.
We propose a nonparametric data-driven method for object and part localization, which achieves better results than state-of-the-art approaches.
We propose a learning framework to improve the shape bias property of self-supervised methods by integrating domain diversification and jigsaw puzzles.
We propose a new Heterogeneous Graph Learning (HGL) framework for seamlessly integrating the intra-graph and inter-graph reasoning in order to bridge the vision and language domain.
We propose an unsupervised strategy for the selection of justification sentences for multi-hop question answering (QA) that maximizes relevance of the selected sentences, minimizes the overlap between the selected facts, and maximizes the coverage of both question and answer.
We first explore this condition via simulation using the CIFAR-10 dataset and variants of two popular convolutive neural network architectures. Employing a simplified model of a single ReLU unit trained by error backpropagation, we then perform a statistical convergence analysis to explore the model's evolutionary behavior.
We propose neural network based attention modules, capable of weighting different portions (spatio-temporal blocks of the video based on their respective discriminative power.
We develop an approach that simultaneously achieves both flexibility and tractability in generative models using iterative forward diffusion.
This paper has the objective to introduce the most fundamental concepts of Deep Learning for Computer Vision in particular CNNs, AEs and GANs, including architectures, inner workings and optimization.
In this paper, a self-guiding multimodal LSTM (sg-LSTM) image captioning model is proposed to handle uncontrolled imbalanced real-world image-sentence dataset.
We propose bilinear-loss, a loss function which differentially penalizes the different wrong assignments of the model, without affecting the overall performance of the classifier.
We develop and evaluate a convolutional neural network-based method for Gibbs artifact and noise removal in diffusion MRI.
Deep latent-variable models learn representations of high-dimensional data in an unsupervised manner. We propose a two-level hierarchical objective to control relative degree of statistical independence between blocks of variables and individual variables.
We study the problem of optimizing accuracy-specificity trade-offs in large scale recognition, motivated by the observation that object categories form a semantic hierarchy of many levels of abstraction.
We present a method for extracting depth information from a rectified image pair using a convolutional neural network and a series of post-processing steps.
We propose a new general framework for directly extracting a policy from data, as if it were obtained by reinforcement learning following inverse reinforcement learning. We show that a certain instantiation of our framework draws an analogy between imitation learning and generative adversarial networks.
We propose an end-to-end approach to the natural language object retrieval task, which localizes an object within an image according to the referring expression, i.e., referring expression.
We propose Coordinate Architecture Search to find effective Transformer architectures for language model, including adding additional LSTM layers to better capture the sequential context while still keeping the computation efficient.
We propose a sparse classifier based on a discriminative Gaussian mixture model based on sparse Bayesian learning, which improves the generalization capability by obtaining a sparse solution.
In this paper, we propose a novel approach of learning discriminative features from weakly-supervised data by using visual attention over the parts and a texture encoding network.
We explore the problem of cross-lingual transfer learning for QA, where a source language task with plentiful annotations is utilized to improve the performance of a QA model on a target languagetask with limited available annotations.
We present a deformable generator model to disentangle the appearance and geometric information for both image and video data in a purely unsupervised manner in a general way.
This paper addresses a new issue of multiple relation semantics that a relation may have multiple meanings revealed by the entity pairs associated with the corresponding triples, and proposes a novel Gaussian mixture model for embedding.
We propose to use visual psychophysics to directly leverage the abilities of human subjects to build better machine learning systems.
We propose a novel localization approach based on a Deep Learning architecture that utilizes dual cascaded CNN subnetworks of the same length, where each subnetwork in a cascade refines the accuracy of its predecessor.
SummaryNet employs a two-stream convolutional network to learn spatial (appearance) and temporal (motion) representations.
In this paper, we propose a structure-aware neural architecture which decomposes the semantic parsing process into two stages.
We present a fast algorithm: detection and annotation for vehicles (DAVE), which effectively combines vehicle detection and attributes annotation into a unified framework, with consistent improvements over existing algorithms.
Novel vision sensors such as event cameras provide information that is not available from conventional intensity cameras. This paper proposes a Network Grafting Algorithm (NGA), where a new front end network driven by unconventional visual inputs replaces the pretrained deep network that processes intensity frames.
Real-time Global Inference Network for Referring Expression Comprehension with Adaptive Feature Selection .
This paper aims to accelerate the test-time computation of deep convolutional neural networks (CNNs) using a low-rank constraint which helps to reduce the complexity of filters.
Zero-Shot Learning in a semantic embedding space where the projected class labels (prototypes) are sparse, these distances are suboptimal, resulting in a number of problems including hubness and domain shift.
This paper presents a vision-based people detection system composed of a monocular fisheye camera and a LiDAR.
We propose an approximation search algorithm that uses additive homogeneous kernel mapping to search for an image approximation based on kernelized locality-sensitive hashing.
In this paper, a self-supervised network is proposed for binocular disparity matching, which computes dense disparity maps from stereo image pairs without disparity labels.
We develop a colour normalisation technique where true colours are not important per se but where examples of same classes have photometrically consistent appearance.
We propose a unified holistic and part-based deformable model that achieves state-of-the-art results.
A method to use semantic road scene knowledge by means of semantic masks for a semantic-guided SfM algorithm is proposed to make the calibration more robust.
We study the problem of backdoor attacks, which add a specific trigger ($i.e. a local patch) onto some training images to enforce that the testing images with the same trigger are incorrectly predicted while the natural testing examples are correctly predicted.
In this paper, we propose to modify SDM in three respects: (1) Multi-scale HOG features are applied orderly as a coarse-to-fine feature detector; (2) Global to local constraints of the facial features are considered orderly in regression cascade; (3) Rigid Regularization is applied to obtain stable prediction results.
We introduce DomaIn Alignment Layers to address the domain shift problem through the introduction of regularization terms aiming to promote the alignment of the two representations.
An algorithm inspired by neuromodulatory mechanisms in the human brain that integrates and expands upon Stephen Grossberg’s ground-breaking Adaptive Resonance Theory proposals.
We propose a novel adversarial learning method that facilitates latent structure by disentangling sources of variation based on a novel cost function and encourages learning generalizable, continuous and transferable latent codes that can be utilized for unpaired multi-domain image transfer and synthesis.
We propose a tensor decomposition method which considers spatial consistency and tries to make full use of image feature information in detecting salient objects.
We show that ambiguity in the data bounds performance on this benchmark at 83.4%; there are often multiple answers that cannot be disambiguated from the linguistic signal alone.
A replication study of BERT pretraining (Devlin et al, 2019) that carefully measures the impact of many key hyperparameters and training data size.
This paper proposes a machine learning algorithm that automates the tasks of topology and hyperparameter selection using a neuroevolution technique.
We study domain adaptation applied to image generation with generative adversarial networks.
We present a novel approach to learn representations for sentence-level semantic similarity using conversational data using unsupervised training.
We propose modified gradient descent methods based on momentum term and resilient propagation to reduce sensitivity for local optima and increase the convergence rate.
This paper presents a Functional Regression solution to the least squares problem, which we coin Continuous Regression, resulting in the first real-time incremental face tracker that is shown to operate in real-Time.
We advocate the use of implicit fields for generative models of shapes and introduce an implicit field decoder, called IM-NET, for shape generation, aimed at improving the visual quality of the generated shapes.
Generative compression of data using generative models produces more accurate and visually pleasing reconstructions at much deeper compression levels for both image and video data.
We present a self-supervised approach to ignoring “distractors” in camera images for the purposes of robustly estimating vehicle motion in cluttered urban environments.
We propose a self-supervised learning task for deep learning on raw point cloud data in which a neural network is trained to reconstruct point clouds whose parts have been randomly rearranged.
We introduce DAWN (Dynamic Adversarial Watermarking of Neural Networks), the first approach to use watermarking to deter model extraction IP theft.
We show that sentence embeddings trained using the supervised data of the Stanford Natural Language Inference datasets can consistently outperform unsupervised methods like SkipThought vectors on a wide range of transfer tasks.
We propose an option comparison network (OCN) for MCRC which compares options at word-level to better identify their correlations to help reasoning.
We propose a novel framework of face beautification that integrates style-based beauty representation (extracted from the reference face) and beauty score prediction into the process.
We address a question answering task on real-world images that is set up as a Visual Turing Test. We propose Neural-Image-QA, an end-to-end formulation to this problem for which all parts are trained jointly.
We propose a discriminative-aware channel pruning method for deep model compression, where both an additional loss and the reconstruction error are considered, and we propose a greedy algorithm to make channel selection and parameter optimization more iterative.
The large volume of video content and high viewing frequency demand automatic video summarization algorithms, of which a key property is the capability of modeling diversity. In this paper, we propose a probabilistic model, built upon SeqDPP, to automatically infer how local the local diversity is supposed to be from the input video.
In this work, we study the use of attention mechanisms to enhance the performance of the state-of-the-art deep learning model in Speech Emotion Recognition (SER)
A survey of autonomous driving datasets which have been published up to date.
An effective and efficient person re-identification (ReID) algorithm will alleviate painful video watching, and accelerate the investigation progress.
We propose a novel approach for estimating the difficulty and transferability of supervised classification tasks using an information theoretic approach: treating training labels as random variables.
Comparison of supervised and unsupervised segmentation methods with a publicly available implementation on five public databases with ground truth segmentation of the vessels.
In this paper we present a new robust approach for 3D face registration to an intrinsic coordinate system of the face. In addition, we propose a fusion of many dependent region classifiers for overlapping face regions.
We adress the problem of dueling bandits defined on partially ordered sets, or posets. In this setting, arms may not be comparable, and there may be several optimal arms.
A GPU-based accelerated deep CNN engine for mobile platforms with upto 60X speedup.
We propose a fundus image quality classifier via the analysis of illumination, naturalness, and structure, which use three effective secondary indices (or 5-D feature set) to determine the recommendation indexes of fundus images for further diagnosis.
This paper proposes a novel approach for crowd counting in low to high density scenarios in static images. The proposed solution is based on the observation that detecting and handling such extreme cases in a specialized way leads to better crowd estimation.
We propose an end-to-end solution to jointly reconstruct room layout, 3D object bounding boxes and meshes from a single image.
This paper presents a novel method to predict future human activities from partially observed RGB-D videos. We use a stochastic grammar model to capture the compositional structure of events.
We present a novel two-stream convolutional neural network (CNN) for RGB-D fingertip detection.
We adapt whole word masking in Chinese text, that masking the whole word instead of masking Chinese characters could bring another challenge in Masked Language Model (MLM) pre-training task.
We make full use of the HR information of separate spatial and temporal features to promote LR recognition by acquiring better attention.
We add message-passing between features and predictions and propose a deep unified CRF saliency model that incorporates multi-scale contextual information.
This paper presents a neural network-based end-to-end clustering framework that leverages contrastive criteria for pushing data-forming clusters directly from raw data.
We compare various GAN techniques, both supervised and unsupervised. The effects on training stability of different objective functions are compared.
This paper presents the results of the RepEval 2017 Shared Task, which evaluated neural network sentence representation learning models on the Multi-Genre Natural Language Inference corpus (MultiNLI) recently introduced by Williams et al.
Capsule networks can be used to detect forged images and videos.
We propose a Video Propagation Network that processes video frames in an adaptive manner. The model is applied online: it propagates information forward without the need to access future frames.
This paper instroduces an unsupervised framework to extract semantically rich features for video representation based on motion cues.
We propose a class-agnostic and anchor-free box regressor, dubbed Universal Bounding-Box Regressor (UBBR), which predicts a bounding box of the nearest object from any given box.
We propose a novel weakly supervised framework to simultaneously locate action frames as well as recognize actions in untrimmed videos.
Scale Aware Network that maps the convolutional features from the different scales onto a scale-invariant subspace to make CNN-based detection methods more robust to the scale variation, and also construct a unique learning method which considers purely the relationship between channels without the spatial information.
We identified functional multi-gene modules with significant expression changes between recurrent and recurrence-free tumors, used them as the signatures for predicting colorectal cancer recurrence in multiple datasets that were collected independently and profiled on different microarray platforms.
In this paper, we propose a Typeface Completion Network (TCN) which takes one character as an input, and automatically completes the entire set of characters in the same style.
Sapphire is a system for querying structured data that strikes a middle ground between ambiguous keyword search and difficult-to-use SPARQL.
This study identified potential inhibitors of NS-3 Helicase in silico, and can be helpful in the treatment of Dengue.
We propose a memory network fit for long-term lifelong learning scenario that learns to replace less important memory entries based on retention probability generated on each entry that is learned to identify data instances of generic importance for a given task.
We present a novel architecture called SPatial Awareness Network (SPANet) to incorporate spatial context for crowd counting. The proposed framework can be integrated into existing deep crowd counting methods and is end-to-end trainable.
We develop a multi-task learning framework that performs the three highly related steps of action proposal, action recognition, and action localization refinement in parallel instead of the standard sequential pipeline.
We propose a new method to apply the multi-scale feature pyramid module to further improve the performance of the DLCM, which is named as deeply learned multi-Scale compositional model.
MLtuner automatically tunes settings for training tunables (such as the learning rate, the momentum, the mini-batch size, and the data staleness bound) that have a significant impact on large-scale machine learning (ML) performance.
We propose a simple and general approach that determines the reward of pre-defined events by their rarity alone, enabling the agent to succeed in challenging VizDoom scenarios without access to the extrinsic reward from the environment.
We address a novel, but potentially emerging, problem of discriminating the natural human voices and those played back by any kind of audio devices in the context of interactions with in-house voice user interface.
Depth completion involves estimating a dense depth image from sparse depth measurements, often guided by a color image. We propose a new representation for depth called Depth Coefficients (DC) to address this problem.
This paper addresses a problem of recognizing human actions in video sequences using Brownian covariance, which is a natural extension of classical covariance measure.
This study investigates a new method of feature extraction for classification problems by utilizing class information. The proposed method is an extension of our previous work on binary class problems to multi-class problems.
We introduce a weighted sum-based color filter array interpolation method using Taylor series cubic approximation, and propose a post-processing method that removes zipper artifacts generated during the interpolation process.
We show that there exists an inherent tension between the goal of adversarial robustness and that of standard generalization. Training robust models may not only be more resource-consuming, but also lead to a reduction of standard accuracy.
In this paper we propose a sign-correlation subspace method for the domain partition of global SDM for face alignment.
This paper aims to present a comprehensive survey of advances in texture representation over the last two decades.
We propose TuckER, a relatively straightforward but powerful linear model based on Tucker decomposition of the binary tensor representation of knowledge graph triples.
We tackle the fundamentally ill-posed problem of 3D human localization from monocular RGB images. We address the ambiguity in the task by predicting confidence intervals through a loss function based on the Laplace distribution.
We propose a Dynamic Re-read Network (DRr-Net) approach for sentence semantic matching, which is able to pay close attention to a small region of sentences at each step and re-read the important words for better sentence semantic understanding.
We propose a generic Sensing-Reasoning machine learning pipeline which contains both the sensing (e.g. deep neural networks) and reasoning components enriched with domain knowledge. Can we certify the end-to-end robustness of such an ML pipeline?
We present Hybrid Voxel Network (HVNet), a novel one-stage unified network for point cloud based 3D object detection for autonomous driving.
Recently, there has been an increasing interest on modern machine vision systems for industrial and commercial purposes. More and more products are introduced in the market, which are making use of visual information captured by camera in order to perform a specific task.
This paper is concerned with the problem of how to better exploit 3D geometric information for dense semantic image labeling. We propose a 3D semantic labeling method to label outdoor street scenes whenever a dense depth map is available.
We propose a novel set of techniques which together produce a task-specific hybrid convolutional and transformer model, WaLDORf, that achieves state-of-the-art inference speed while still being more accurate than previous distilled models.
We show the emergence of single and double opponent cells in anatomically constrained convolutional neural networks and characterise how the distribution of these cells changes under the constraint of a retinal bottleneck.
We propose a novel factorized generative model for 3D shape generation that sequentially transitions from coarse to fine scale shape generation.
In this paper, we propose a multi-task learning architecture with four types of recurrent neural layers to fuse information across multiple related tasks.
We propose the Adaptive Capacity Multi-scale convolutional neural networks (ACM-CNN), a novel crowd counting approach which can assign different capacities to different portions of the input.
In this paper, we present a novel and general network structure towards accelerating the inference process of convolutional neural networks, which is more complicated in network structure yet with less inference complexity.
S-OHEM exploits OHEM with stratified sampling, a widely-adopted sampling technique, to choose the training examples according to this influence during hard example mining, and thus enhance the performance of object detectors.
We propose a Spatially and Temporally Efficient Non-local Video Attention Network (STE-NVAN) to reduce the computation complexity by exploring spatial and temporal redundancy in pedestrian videos.
 PARENT correlates with human judgments better than existing text generation metrics when the reference texts diverge.
Hyperband is a non-stochastic infinite-armed hyperparameter optimization problem where a predefined resource like iterations, data samples, or features is allocated to randomly sampled configurations.
We investigate suitable methods for compositional sentiment classification for German in a data-scarce setting, harnessing cross-lingual methods as well as existing general-domain lexical resources.
We propose a resource-aware architecture search algorithm which dynamically selects atomic blocks during training and achieves state-of-the-art performance.
We propose a top-down keypoint estimation method for object detection that performs on-par with region based detection methods.
We present a conditional generative adversarial network-based approach to alleviate the intra-class variations by individually controlling the facial expressions and learning the generative and discriminative representations simultaneously.
We directly apply the attribute labels constraint to the predefined region of the latent feature space for face attribute transfer by exemplars while improving the quality of generated image.
Visual Question Answering (VQA) is a challenging task that has received increasing attention from both the computer vision and the natural language processing communities. Given an image and a question in natural language, it requires reasoning over visual elements of the image and general knowledge to infer the correct answer.
In this paper, we propose a novel matching based tracker by investigating the relationship between template matching and the recent popular correlation filter based trackers.
This paper investigates the ILP of multi-label MRF with exact connectivity priors via a branch-and-cut method, which provably finds globally optimal solutions.
We present an empirical study of this operation, called pack, and end-to-end experiments that suggest significant improvements for hyperparameter search systems that can bring up to 40% performance improvement.
We propose a weakly-supervised salient object detection model to learn saliency from scribble labels, which is on par with state-of-the-art models.
We present MatrixNets, a new deep architecture for object detection. We leverage xNets to enhance single-stage object detection frameworks.
We propose a novel probabilistic technique for modeling and extracting salient structure from large document collections, providing an organizing perspective into otherwise overwhelming amounts of information.
We introduce a weakly supervised system that automatically learns to temporally segment and label actions in a video, where the only supervision that is used are action sets.
We present hu.MAP, the most comprehensive and accurate human protein complex map to date, containing > 4,600 total complexes, > 7,700 proteins, and > 56,000 unique interactions.
A Domain Adaptation method for biomedical image segmentation based on adversarial networks that can learn from both unlabeled and labeled data.
In this paper, we introduce an end-to-end trainable model based on deep neural networks that we call Ctrl-F-Net for segmentation-free query-by-string word spotting.
This paper introduces distributional inclusion vector embedding, a simple-to-implement unsupervised method of hypernym discovery via per-word non-negative vector embeddings learned by modeling diversity of word context with specialized negative sampling.
ZSL attempts to classify unseen 3D point cloud objects in the ZSL setting, similar to the 2D image version of the same problem.
Evidence sentence extraction for multiple-choice MRC tasks, where the majority of answer options cannot be directly extracted from reference documents.
We propose constructing conformal prediction sets which contain a set of labels rather than a single label. We demonstrate the performance on the ImageNet ILSVRC dataset and the CelebA and IMDB-Wiki facial datasets using state of the art convolutional neural networks.
In this paper we give an overview of the Knowledge Base Population track at the 2010 Text Analysis Conference.
In this work, we explore video frame inpainting, a task that lies at the intersection of general video inPainting, frame interpolation, and video prediction, and devise a method specifically designed for the task.
This article presents a novel road damage detection algorithm based on unsupervised disparity map segmentation. The proposed algorithm requires no parameters.
Motion-Nets use a segmentation model to segment the scene, and separate translation and rotation models to identify the relative 6D motion of an object between two consecutive frames.
Learning a joint language-visual embedding has a number of very appealing properties and can result in variety of practical application, including natural language video annotation and search.
Adversarial perturbations can be used to manipulate the behavior (both targeted or non-targeted) of any corresponding trained classifier during test time when facing clean samples.
We investigate the direction of training a 3D object detector for new object classes from only 2D bounding box labels of these new classes, while simultaneously transferring information from 3D Bounding Box labels of the existing classes.
The goal of machine learning is to develop robust predictors that generalize well to test data. In practical learning settings, however, we do not have infinite data and our predictors may overfit. In this paper, we extend the training set with infinitely many artificial training examples that are obtained by corrupting the original training data.
We introduce a new idea of attribute manipulation at the feature level, by matching the distribution of manipulated features with real features.
We present the results of the VarDial Evaluation Campaign on Natural Language Processing (NLP) for Similar Languages, Varieties and Dialects, which we organized as part of the fourth edition of theVarDial workshop at EACL’2017.
We propose a new approach called Robust Local Features for Adversarial Training (RLFAT), which improves both the adversarially robust generalization and the standard generalization of adversarial training.
We propose a new reinforcement learning algorithm that can train general-purpose neural network policies with minimal human engineering, while still allowing for fast, efficient learning in stochastic environments.
We propose an algorithm for view synthesis from an irregular grid of sampled views that first expands each sampled view into a local light field via a multiplane image representation, then renders novel views by blending adjacent local light fields.
This paper presents improvements to the soft attention model by combining a con-volutional Long Short-Term Memory (LSTM) with a hierarchical system architecture to recognize action categories in videos.
We propose constructing a local graph structured knowledge base for query-based open-domain NLP tasks, which compresses the web search information and reduces redundancy.
In this paper, an activity recognition approach is proposed. Motion information is extracted from the dierence image based on Region of Interest (ROI) using 18-Dimensional features.
We propose a new model for speaker naming in movies that leverages visual, textual, and acoustic modalities in an unified optimization framework that achieves state-of-the-art results on MovieQA 2017 Challenge.
We propose a novel loss layer for CNNs, named grid loss, which minimizes the error rate on sub-blocks of a convolution layer independently rather than over the whole feature map.
A novel differentiable projection module, called ‘CAPNet’, is introduced to obtain such 2D masks from a predicted 3D point cloud, and propose a loss formulation termed ‘affinity loss’ to generate outlierfree reconstructions.
Learning to map questions to vectorial feature representations using weak supervision and stochastic gradient descent .
We present SlideImages, a dataset for the task of classifying educational illustrations, and propose a baseline system using a standard deep neural architecture.
We propose a novel approach for person re-identification, which exploits multi-view information of a fisheye camera looking downwards from the ceiling, based on geometric sensor modelling and deep learning.
We propose a reinforcement learning approach called Differentiable Data Selection (DDS) that learns a scorer network as a learnable function of the training data, which can be efficiently updated along with the main model being trained.
Sparsity based face recognition performs well even when the dictionary bases are collected under uncontrolled conditions and only a single sample per classes is available.
This study provides a new understanding of the adversarial attack problem by examining the correlation between adversarial attacks and visual attention change.
We propose to apply deep transfer learning from computer vision to static malware classification. We instrument an interpretation component to the algorithm and provide interpretable explanations to enhance security practitioners' trust.
We extend a previously proposed low-dimensional manifold model for the image patches to surface patches in the point cloud, and seek self-similar patches to denoise them simultaneously using the patch manifold prior.
Unsupervised Adversarial Training using unlabeled data improves robust accuracy by 21.7% and captures over 95% of the improvement from the same number of labeled examples.
We propose TracKlinic, a tracking diagnosis toolkit for diagnosis of challenge factors of tracking algorithms.
This paper introduces a calibrated stochastic gradient descent algorithm for deep neural network optimization. A theorem is developed to prove that an unbiased estimator for the network variables can be obtained in a probabilistic way based on the Lipschitz hypothesis.
We introduce a hybrid framework that combines a 3D Encoder-Decoder Generative Adversarial Network (3D-ED-GAN) and a Long-term Recurrent Convolutional Network (LRCN) for 3D shape completion.
We propose an Auto-Selecting Receptive Field Network (ASRF) to select receptive field information and effective clues dynamically. The proposed ASRF method performs favorably against state-of-the-art trackers.
In this paper, we propose deep architecture to dynamically learn the most discriminative features from data for both single-cell and object tracking in computational biology and computer vision.
Multi-Drone Single Object Tracking (MDOT) dataset and agent sharing network for multi-drone tracking.
In this work, we present a new operator, called Instance Mask Projection (IMP), which projects a predicted Instance Segmentation as a new feature for semantic segmentation.
In this paper, we propose a new way to generate object proposals, introducing an approach based on a discriminative convolutional network.
We use a deep convolutional neural network with SVM as a classifier to help with recognizing the state of a cooking object.
We propose an extension to an LSTM (Long Short-Term Memory) language model for generating conversational text, conditioned on affect categories.
We propose a novel object captioning task where the machine generates descriptions without extra training sentences about the novel object.
This paper is aimed to give an overview of state-of-the-art results regarding monocular visual localization.
We apply attention mechanism to CNN, which aims at enhancing more relevant features that correspond to important keypoints in the input image.
We address the problem of real-time 3D object detection from point clouds in the context of autonomous driving. We utilize the 3D data more efficiently by representing the scene from the Bird's Eye View (BEV), and propose PIXOR, a proposal-free, single-stage detector that outputs oriented3D object estimates decoded from pixel-wise neural network predictions.
This paper aims at improving how machines can answer questions directly from text, with the focus of having models that can answer correctly multiple types of questions and from various types of texts, documents or even from large collections of them.
We present an active learning framework for large dataset segmentation, which iteratively provides the user with new predictions by training new models based on already segmented shapes. We propose an information theory measure to estimate the prediction quality and for ordering subsequent fast and meaningful shape selection.
We propose a new combination of Bayesian optimization and Hyperband for efficient joint neural architecture and hyperparameter search.
We use a metric called miscalibration for measuring how a recommendation algorithm is responsive to users' true preferences and we consider how various algorithms may result in different degrees of miscalibrration.
We present techniques for speeding up the test-time evaluation of large convolutional networks, designed for object recognition tasks.
We tackle the object recognition problem using two data representations, to achieve leading results on the Princeton ModelNet challenge. We combine both representations and exploit them to learn new features.
Adaptive Attention Time (AAT) can adaptively align source to target for image captioning, improving state-of-the-art methods.
In this paper, we propose a weakly supervised landmark-region-based convolutional neural network (LR-CNN) framework to detect facial component and landmark simultaneously.
The Neural Architecture Search (NAS) problem is typically formulated as a graph search problem where agents control a subset of the network and coordinate to reach optimal architectures. In this paper, we address the issue by framing NAS as a multi-agent problem.
We present a multi-task learning-based convolutional neural network able to estimate multiple tags describing face images simultaneously.
We investigate the effect of adversarial training on the geometry of the classification landscape and decision boundaries and propose a new regularizer that directly minimizes curvature of the loss surface, leading to adversarial robustness that is on par with adversarialtraining.
An efficient and novel panoptic data augmentation method which operates exclusively in pixel space, requires no additional data or training, and is computationally cheap to implement.
We propose SPIN (SMPL oPtimization IN the loop), a model-based human pose estimation approach that combines iterative optimization and regression-based methods to achieve state-of-the-art results.
We present an effective and efficient approach for arbitrary style transfer that seamlessly transfers style patterns as well as keep content structure intact in the styled image.
We use the bio-inspired features (BIF) to analyze different facial parts: (a) eye wrinkles, (b) whole internal face (without forehead area) and (c) whole face (with forehead Area) using different feature shape points.
We propose a movie description model which learns to generate description and jointly ground (localize) the mentioned characters as well as do visual co-reference resolution between pairs of consecutive sentences/clips.
A variant of evolutionary firefly algorithm for feature optimization and facial expression recognition.
We present a novel method and analysis to train generative adversarial networks in a stable manner by using different filtered versions of the data distributions.
The objective of this work is to visually search large-scale video datasets for semantic entities specified by a text query, by using an image search engine to source visual training data for the text query.
This work focuses on the ability to control via latent space factors semantic image attributes in generative models, and the faculty to discover mappings from factors to attributes in an unsupervised fashion.
In this paper we propose cross-modal convolutional neural networks, a novel biologically inspired type of CNN architectures, treating gradient descent-specialised CNNs as individual units of processing in a larger-scale network topology, while allowing for unconstrained information flow and/or weight sharing between analogous hidden layers of the network.
We construct a “visual Turing test”: an operator-assisted device that produces a stochastic sequence of binary questions from a given test image. The system is designed to produce streams of questions that follow natural story lines.
We propose a Markov Random Field model for unconstrained video segmentation that relies on tight integration of multiple cues: vertices are defined from contour based superpixels, unary potentials from temporally smooth label likelihood and pairwise potentials for coherent object regions.
This paper presents a Fully Guided Network for few-shot instance segmentation.
In this work, we propose a novel and efficient method for articulated human pose estimation in videos using a convolutional network architecture, which incorporates both color and motion features.
A standard approach to describe an image for classification and retrieval purposes is to extract a set of local patch descriptors, encode them into a high dimensional vector and pool them into an image-level signature. We propose to use the Fisher Kernel framework as an alternative patch encoding strategy.
We introduce a novel representation that gracefully encodes the movement of some semantic keypoints and term our Pose moTion representation PoTion.
In any practical application of the 2-D-to-3-D conversion that involves storage and transmission, representation efficiency has an undisputable importance. In order to address this problem, a novel algorithm, which yields efficient 3-D representations in the rate distortion sense, is proposed.
We explore the idea of modeling the relationships among the proposals for object detection from the graph learning perspective, which empowers the RepGN module to exploit the inter-regional correlation and scene description.
We propose a generative model-based approach which can not only synthesize novel image structures but also explicitly utilize surrounding image features as references during network training to make better predictions.
We propose an extension of the deep over-sampling framework, to exploit automatically-generated abstract-labels, i.e., a type of side-information used in weak-label learning, to enhance deep representation learning against class imbalance.
We propose a generative adversarial network for point clouds, which achieves competitive performance with other unsupervised learning algorithms on object recognition task.
We exploit diverse human commonsense knowledge for reasoning over large-scale object categories and reaching semantic coherency within one image.
We introduce the idea of a form of personalized popularity also considering how its changes over time affect the accuracy of recommendation results.
We show that data augmentation in feature space provides an effective way to improve intent classification performance in few-shot setting beyond traditional transfer learning approaches.
We proposed a Complex-Retina network, a convolution neural network for 3D object detection based on multi-sensor data fusion.
We propose a Style-based Recalibration Module (SRM), a simple yet effective architectural unit, which adaptively recalibrates intermediate feature maps by exploiting their styles.
This chapter provides an overview of approaches to deal with the increasing heterogeneity of Web data, specifically when dealing with traditional knowledge graphs and linked data.
We introduce a new deeply supervised two-branch architecture, the Multimodal Attentional Translation Embeddings, where the visual features of each branch are driven by a multimodal attentional mechanism that exploits spatio-linguistic similarities.
We propose a generic approach called Human Importance-aware Network Tuning (HINT) that effectively leverages human demonstrations to improve visual grounding.
An encoder-decoder based fully convolutional neural network for classification of retinal vasculature into arterioles and venules, without requiring the preliminary step of vessel segmentation.
Adaptive Weighted Super-Resolution Network (AWSRN) for SISR .
We propose a novel loss function that dynamically rescales the cross entropy based on prediction difficulty and penalizes the network to avoid a false prediction being significant.
We propose a simple but effective postprocessing method to render off-the-Shelf feature representations even stronger by eliminating the common mean vector from off- the-shelf feature representation.
We propose to use a less resource demanding non-learning method, guided by a learning-based model, to handle high-resolution images and achieve accurate stereo reconstruction.
We formulate platform-aware NN architecture search in an optimization framework and propose a novel algorithm to search for optimal architectures aided by efficient accuracy and resource (latency and/or energy) predictors.
We analyze the evolution of yearly rankings of top-cited (C-list) authors in the domain of Computer Science and find that the A-list and P-list serve as (unreliable) indicators for appearance on the C-list, but their effect is quick and short-lived.
A challenge in training discriminative models like neural networks is obtaining enough labeled training data. We present Socratic learning, a paradigm that uses feedback from a corresponding generative model to automatically identify latent subsets in the training data in which the supervision sources perform differently than on average.
Learning descriptive spatio-temporal object models from data is paramount for the task of semi-supervised video object segmentation. In this paper, we present an intermediate solution and devise a novel GAN architecture, FaSTGAN, to learn temporal object models over finite temporal windows.
In this work, we present LIBRE: LiDAR Benchmarking and Reference, a first-of-its-kind dataset featuring 12 different LiDar sensors, covering a range of manufacturers, models, and laser configurations.
In this paper, we propose a generative multi-column network for image inpainting.
Vote Goat uses gamification to incentivize movie voting interactions with the 'Greatest Of All Time' (GOAT) movies derived from user ratings.
This paper addresses the challenge of 3D human pose estimation from a single color image. We propose a fine discretization of the 3D space around the subject and train a ConvNet to predict per voxel likelihoods for each joint.
We study how well current language and vision strategies model quantifiers. We show that state-of-the-art attention mechanisms coupled with a traditional linguistic formalisation of quantifiers gives best performance on the task.
We present a novel deep learning solution based on a hierarchical representation of relative saliency and stage-wise refinement to address a problem that is relatively ill-posed.
We propose a Guided Robust and Efficient Defensive Model GRED integrating detection and recovery processes together.
This paper proposes a detector framework based on the conditional generative adversarial networks to improve the segmentation effect of scene text detection, called DGST (Discriminator Guided Scene Text detector).
We propose a novel densely connected convolutional module (DCCM)-based neural network for human pose estimation, which can achieve higher parameter efficiency compared to the state-of-the-art works.
We explore the effects of various pretraining objectives for sentence encoders (e.g., language modeling, CCG supertagging and natural language inference) on the learned representations.
We address the problem of obtaining good part templates by proposing novel, non-linear joint regressors that take dependencies between body parts for joint localization into account.
We proposed an end-to-end framework for automatic retinal vessel segmentation using deep fully convolutional neural networks.
This paper proposes to learn the multifaceted features in a simple unified single-branch neural network that performs substantially better than state-of-the-art methods.
We propose CMM: Cascaded Mutual Modulation as a novel end-to-end visual reasoning model for both question and image answering problem.
We proposed a novel deep learning-based dynamic opinion inference model that can explicitly deal with uncertain opinions and infer unknown opinions based on a rich set of operators of fusing multiple opinions.
In this paper, we propose a new approach which addresses the Positive Unlabeled learning challenge for image classification. Its functioning is based on GAN abilities in order to generate fake images samples whose distribution gets closer to negative samples distribution included in the unlabeled dataset.
The high demand for computational and storage resources severely impede the deployment of deep convolutional neural networks (CNNs) in limited-resource devices. This paper proposes pSConv, a pre-defined sparse 2D kernel-based convolution, which promises significant improvements in the trade-off between complexity and accuracy.
We propose a view-based approach for labeling objects in 3D scenes reconstructed from RGB-D (color+depth) videos using sliding window detectors trained from object views.
We develop MaskRNN, a recurrent neural net approach which fuses in each frame the output of two deep nets for each object instance to capture the temporal coherence of the data.
We propose LAIM: a linear time iterative approach for efficient IM on large-scale networks.
We propose a self residual attention-based convolutional neural network (SRANet) for discriminative face feature embedding.
We use neural network divergences to measure diversity, sample quality, and generalization, while still being perceptually correlated and computable only from samples.
We formalize this approach by defining a quantitative metric for the agent to maximize it. We demonstrate that the metric indeed correlates with the human judgments of engagingness.
In this paper, we propose a novel Deep Residual Reconstruction Network (DR2-Net) to reconstruct the image from its Compressively Sensed measurement.
In this paper, we propose a series of techniques that significantly improve the accuracy of binarized neural networks (i.e networks where both the features and the weights are binary).
This paper handles with this problem from a new perspective of creating a smooth transition and proposes a concise Deep Fusion Network (DFNet), which builds a bridge for structural and texture information.
In this paper, we introduce a novel multi-scale-hierarchical block-matching approach using a pyramidal variant of depth and cost functions which drastically improves the results of standard block matching stereo techniques while preserving the low memory footprint and further reducing the complexity ofstandard block matching.
In this paper, we rethink adversarial training for semantic segmentation and propose to formulate the fake/real discrimination framework with a correct/incorrect training objective.
We propose an improved sparse convolution method for Voxel-based 3D convolutional networks, which significantly increases the speed of both training and inference, while maintaining a fast inference speed.
Neural networks with high performance can still be biased towards non-relevant features. We propose a verification pipeline, which applies layer-wise relevance propagation to create pixel-based explanations.
A deep understanding of human activity is key to successful human-robot interaction (HRI) in a mobile robot.
In this paper, we propose a novel network model introducing GSoP across from lower to higher layers for exploiting holistic image information throughout a network.
We propose to cast the generative process of a graph into a sequential one, relying on a node ordering procedure. We use this sequential process to design a novel generative model composed of two recurrent neural networks that learn to predict the edges of graphs, while retaining structural properties very similar to those in the training sample.
We propose a cascaded multi-scale cross network (CMSC) in which a sequence of subnetworks is cascaded to infer high resolution features in a coarse-to-fine manner.
We propose a triplet label based deep hashing method which performs image feature learning and hash code learning simultaneously by maximizing the likelihood of the given triplet labels.
We propose an algorithm to represent the class-specific manifold structure in Latent Space for classification task, in which way the object-space dimensionality is reduced.
A CNN architecture for classifying modal sense in English and German.
In this paper, we introduce the problem of jointly learning feed-forward neural networks across a set of relevant but diverse datasets to significantly improve the quality of learned networks.
We propose a sparse feature-space adversarial attack method against deep saliency models, able to generate a sparser and more insidious adversarial perturbation.
We propose to incorporate coding with vector of locally aggregated descriptors (VLAD) on spatial pyramid for CNN features of sub-regions in order to generate image representations that better reflect the local information of the images.
We propose a two-step framework based on generative adversarial nets for generating conditioned responses in dialog.
We propose to apply Self-Attention GAN to further improve the performance of human pose estimation.
A scene-adaptive vehicle detection algorithm based on a composite deep structure based on Bagging (Bootstrap aggregating) mechanism.
We study the role of intrinsic motivation as an exploration bias for reinforcement learning in sparse-reward synergistic tasks, which are tasks where multiple agents must work together to achieve a goal they could not individually.
In this paper, we propose a network architecture that computes and integrates the most important visual cues for action recognition: pose, motion, and the raw images.
This paper summarizes the state of the art in FPV video analysis between 1997 and 2014, highlighting, among others, the most commonly used features, methods, challenges, and opportunities within the field.
We study the relationship between catastrophic forgetting and properties of task sequences and propose a new procedure that uses recent developments in task space modeling as well as correlation analysis to specify and analyze the properties we are interested in.
A comparative study of five deep learning frameworks, namely Caffe, Neon, TensorFlow, Theano, and Torch, on three aspects: extensibility, hardware utilization, and speed.
The communication overhead has become a significant bottleneck in data-parallel network with the increasing of model size and data samples. In this work, we propose a new algorithm LPC-SVRG with quantized gradients and its acceleration ALPC- SVRG to effectively reduce the communication complexity while maintaining the same convergence.
We propose a novel algorithm to generate class representatives for few-shot classification tasks using a mixture of von Mises-Fisher distributions which are more expressive than Gaussian.
We introduce a large-scale audio-visual dataset for speaker recognition under noisy and unconstrained conditions. We propose a pipeline based on computer vision techniques to create the dataset from open-source media.
We propose a novel Orientation and Scale adaptive tracker with Regularized Correlation Filters (OSRCF) for visual tracking.
This paper introduces two approaches for improving communication efficiency by dynamic sampling and top-$k$ selective masking for federated learning.
We present a Self-supervised Image to Shape Translation framework that fulfills three tasks: (i) reconstructing the 3D shape from a single image; (ii) learning disentangled representations for shape, appearance and viewpoint; and (iii) generating a realistic RGB image from these independent factors.
In this work, we try to improve visual search based mobile shopping experience by using machine and crowd intelligence.
This paper proposes a method to employ self-supervision directly at the lexical-semantic level language model, without the use of human annotation.
Saliency methods seek to explain the predictions of a model by producing an importance map across each input sample by backpropagating a signal and analyzing the resulting gradient.
In this paper, we propose a unified method to jointly learn optical flow and stereo matching that achieves state-of-the-art performance.
We propose a data manipulation framework to proactively reshape the data distribution towards reliable samples by augmenting and highlighting effective learning samples as well as reducing the effect of inefficient samples simultaneously.
Our paper presents a fast medical image super-resolution (FMISR) method whereby the three hidden layers to complete feature extraction is as same as the super resolution convolution neural network.
We introduce the concept of convnet-based guidance applied to video object segmentation.
We find that skin type is not the driver of gender discrimination in face classification, and that lip and eye makeup are strong predictors.
This paper proposes a learning-based quality evaluation framework for inpainted results that does not require any subjectively annotated training data.
In this paper, we propose a gaze-assisted deep neural network, which performs the action recognition task with the help of human visual attention.
Topological segmentation of retinal images represents blood vessels as connected regions in the continuous image plane, having shape-related analytic and geometric properties.
We propose to bring Convolutional Neural Networks to generic multi-view recognition, by decomposing an image sequence into a set of image pairs, classifying each pair independently, and then learning an object classifier by weighting the contribution of each pair.
A large class of Person Re-identification (ReID) approaches identify pedestrians with the TriHard loss, but pose variance and viewpoint in pedestrians constrain the performance. To address this problem, we introduce a spatial transformer network (STN) module, DenseNet backbone and Tri hard loss.
We propose a greedy algorithm for joint graph partitioning and labeling derived from the efficient Mutex Watershed partitioning algorithm.
We propose a two-layer approach for visual odometry and SLAM with stereo cameras that runs in real-time and combines feature-based matching with semi-dense direct image alignment.
A novel algorithm for image super-resolution with class-specific predictors is proposed in this paper.
We propose a probabilistic parameter pruning method, named Structured Probabilistic Pruning (SPP), which efficiently prunes weights of convolutional layers in a probablistic manner.
Stereo matching algorithms usually consist of four steps, including matching cost calculation, matching cost aggregation, disparity calculation, and disparity refinement. We propose a network architecture to incorporate all steps of stereo matching.
We provide a more sophisticated variational vocabulary dropout based on variational dropout to perform vocabulary selection, which can intelligently select the subset of the vocabulary to achieve the required performance.
Memorability is considered to be an important characteristic of visual content, whereas for advertisement and educational purposes it is often crucial. Despite numerous studies on understanding and predicting image memorability, there are almost no achievements in memorability modification. In this work, we study two approaches to image editing - GAN and classical image processing - and show their impact on memorability.
We introduce a statistical measure for the evaluation of the dynamics of the simulated eye movements. We underline the limits of the current metrics for saliency prediction and scanpath similarity. We find that unsupervised gravitational models outperform all competitors.
Deep Multi-Task Learning (DMTL) approach to jointly estimate multiple heterogeneous attributes from a single face image.
In this paper, we consider an interesting vision problem---salient instance segmentation. Taking into account the category-independent property of each target, we design a single stage salient instance Segmentation framework, with a novel segmentation branch.
We present a dataset derived from DNN feature decoding analyses, which includes fMRI signals of five human subjects during image viewing, decoded feature values of DNNs (AlexNet and VGG19), and decoding accuracies of individual DNN features with their rankings.
In this paper, we recast the continuous problem of depth regression as discrete binary classification, whose output is an un-normalized distribution over possible depths for each pixel. Such output allows one to reliably and efficiently capture multi-modal depth distributions in ambiguous cases.
We propose a novel Multi-scale Gradual Integration Convolutional Neural Network (MGI-CNN), a computer-aided system for pulmonary nodules detection as early as possible on thoracic CT scans.
A solution to hardening DNNs under adversarial attacks through defensive dropout.
We propose a first attempt to unify genre tag systems by leveraging both representation and interpretation diversity.
We propose an application to extracts multiple persons from images and videos for pleasant life scenes to grouping happy moments of people such as family or friends and a community for QOL.
In this work, we evaluate encoders to inverse the mapping of a cGAN, i.e., mapping a real image into a latent space and a conditional representation.
We present a principled framework to capitalize on unlabeled data by training deep generative models on both labeled and unl labeled data.
This paper presents the UPC system proposed for the Multimodal Speaker Diarization task of the 2018 Albayzin Challenge.
Convolutional networks have achieved great success in various vision tasks. This is mainly due to a considerable amount of research on network structure. In this study, instead of focusing on architectures, we focused on the convolution unit itself.
Transfer learning is one of the subjects undergoing intense study in the area of machine learning. We use transfer learning to accelerate the training of SqueezeDet to a new group of classes.
Feature pyramid mechanism has improved the performance of object detectors by a large margin, especially for the objects with small scale.
We propose a novel motion representation for abnormality detection and behavior recognition and apply it to video analysis.
We develop a pseudo ground truth mining (PGTM) procedure to automatically find the missing bounding-boxes for the unlabeled instances, called pseudo ground truths here, in the training data, and then combine the mined pseudoground truths and the labeled annotations to train a fully-supervised object detector.
We propose a WAILS method to solve the problem of weakly supervised image semantic segmentation through image-level labels and watershed pre-segmentation.
We present a generic process flow for text recognition in scanned documents containing mixed handwritten and machine-printed text without the need to classify text in advance.
We propose a self-supervised adversarial hashing approach for cross-modal retrieval that maximizes the semantic correlation and consistency of representations between different modalities.
In this paper we address the abnormality detection problem in crowded scenes using Generative Adversarial Nets (GANs), which are trained using normal frames and corresponding optical-flow images in order to learn an internal representation of the scene normality.
We investigate the empirical Rademacher complexity related to intermediate layers of deep neural networks and propose a feature distortion method (Disout) for addressing the aforementioned problem.
A novel neural modular approach that performs compositional reasoning by automatically inducing a desired sub-task decomposition without relying on strong supervision.
We learn a Neural Architecture Transformer to replace redundant operations with the more computationally efficient ones (e.g., skip connection or directly removing connection).
We propose BSP-Net, a generative network that learns to represent a 3D shape via convex decomposition, without any need for implicit functions.
Near-Infrared Face Recognition at a Distance Database (NFRAD-DB)
We propose a Convolutional Neural Network (CNN)-based model"RotationNet,"which takes multi-view images of an object as input and estimates both its pose and object category and achieves comparable performance to state-of-the-art methods of 3D object classification.
We propose iterative inference models, which learn to perform inference optimization through repeatedly encoding gradients in variational auto-encoders.
We extracted reliable experimental data about which proteins interact (binary) for eight diverse model organisms from public databases and used evolutionary information to develop a PPI prediction method for each organism based solely on sequence-based prediction methods.
We propose the introduction of batch normalisation units into deep feedforward neural networks with piecewise linear activations, which drives a more balanced use of these activation units, where each region of the activation function is trained with a relatively large proportion of training samples.
We study, compare and combine two state-of-the-art approaches to automatic feature engineering: Convolution Tree Kernels (CTKs) and Convolutional Neural Networks (CNNs) for learning to rank answer sentences in a Question Answering (QA) setting.
Zero-Reference Deep Curve Estimation (Zero-DCE) for image enhancement .
In this paper we present a semantics-aware recommendation strategy that uses graph embedding techniques to learn a vector space reresentation of the items to be recommended.
We propose a self-similarity grouping approach for domain adaptation in person re-identification in an unsupervised manner.
We introduce Trinity. RDF, a distributed, memory-based graph engine for web scale RDF data.
We propose a collective decision-based OSR framework for open set recognition while considering correlations among the testing instances.
We propose Emo2Vec which encodes emotional semantics into vectors and achieves competitive performances to state-of-the-art results on emotion-related tasks.
In this paper, we proposed a fast and accurate human pose estimation framework that combines top-down and bottom-up methods.
We present a novel approach to explicit analysis of temporal dynamics of facial actions using the dynamic appearance descriptor Local Phase Quantization from Three Orthogonal Planes (LPQ-TOP)
We propose to improve the cascaded shape regression method by applying gradual training, which improves the localization and gives accurate estimates of pose.
We propose a new framework for segmenting retinal vasculatures with much improved accuracy and efficiency.
We propose a neurobiologically inspired visual simultaneous localization and mapping (SLAM) system based on direction sparse method to real-time build cognitive maps of large-scale environments from a moving stereo camera.
We present a method for instance ranking and retrieval at fine-grained level based on the global features extracted from a multi-attribute recognition model which is not dependent on landmarks information or part-based annotations.
We propose Deep Feature Interpolation (DFI), a data-driven baseline for automatic high-resolution image transformation. As the name suggests, it relies only on simple linear interpolation of deep convolutional features from pre-trained convnets.
We propose a new approach - VarMixup (Variational Mixup) - to better sample mixup images by using the latent manifold underlying the data.
We analyze the impact of cosmetics on automated gender and age estimation algorithms for spoofing, age alteration, and gender spoofing.
A generalized structured regression framework based on Sharma-Mittal divergence, a relative entropy measure, which generalizes over the Twin Gaussian Processes (TGP) without computational penalty.
We propose a Two-stage Multi-teacher Knowledge Distillation method for web Question Answering system, which effectively reduces the overfitting bias in individual teacher models, and transfers more general knowledge to the student model.
We present a new defense against membership inference attacks that preserves the utility of the target machine learning models significantly better than prior defenses.
We introduce a multimodal visual-textual search refinement method for fashion garments, based on a query item image and textual refinement properties.
We propose a novel multi-source Adversarial Domain Aggregation Network for semantic segmentation.
In the large-scale image retrieval task, the two most important requirements are the discriminability of image representations and the efficiency in computation and storage of representations.
We formulate a compact and efficient network for seamless attenuation of different compression artifacts and apply it to low-level vision problems.
An automatic unsupervised blood vessel segmentation method for retinal images using self-organizing map.
A Bayesian network framework to reconstruct a high-confidence whole-genome map of transcriptional cooperativity in Saccharomyces cerevisiae by integrating a comprehensive list of 15 genomic features for optimal TF cooperativity prediction.
We propose an objective that transfers supervision from neighboring examples. We make and test the following hypothesis - for a given input, the annotations of its neighbors may serve as an additional supervisory signal.
We present a transfer learning method that is able to learn a precise face Active Appearance Model only from neutral training data using an instance-weighted transfer technique.
This article proposes several improvements that are enabled by the Alternating Directions Method of Multipliers (ADMM), a well-known optimization method with many application areas.
This work presents an adaptive activation method for neural networks that exploits the interdependency of features.
In this paper a novel rank estimation technique for trajectories motion segmentation within the Local Subspace Affinity framework is presented.
We propose Multi-Center Learning with multiple shape prediction layers for face alignment.
In this paper, inspired by human language recognition, we propose the Paraphrase-Thought model to pursue semantic coherence as much as possible. Experimental results on two paraphrase identification datasets (MS COCO and STS benchmark) show that P-thought models outperform the benchmarked sentence embedding methods.
We explore the hypothesis that strong prior information about scene geometry can be used to improve pose estimation accuracy. We propose two different mechanisms for integrating multi-layer depth information pose estimation.
We define a distinctively new task, namely video re-localization, to address this need. We propose an innovative cross gated bilinear matching model such that every time-step in the reference video is matched against the attentively weighted query video such that the segment semantically corresponds to the query video.
We investigate compressing a BERT-based question answering system by pruning parameters from the underlying BERT model.
We propose a probabilistic Markov Chain Marginal Line Segment Detector that uses the local marginal posterior probabilities to estimate the expected number of correctly labelled points on a line segment.
We propose a simple but novel deep learning architecture for fast and efficient question-answer ranking and retrieval. Our model requires no feature engineering, no similarity matrix matching, no complicated attention mechanisms nor over-parameterized layers.
This paper proposes modifications in the TransR model to address the issue of skewed data which is common in real-world knowledge graphs.
We propose a self-supervised equivariant attention mechanism (SEAM) to discover additional supervision and narrow the gap.
We propose a novel NLP task called ASR post-processing for readability (APR) that aims to transform noisy ASR output into a readable text for humans and downstream tasks while maintaining the semantic meaning of the speaker.
In this paper, we solve the imperfect rectification problems, and propose matching stereo matching methods that based on absolute differences, square differences, normalized cross correlation, zero-mean normalized crossrelation, and rank and census transforms.
We proposed a novel optimized lidar odometry and mapping method using ground plane constraints and SegMatch-based loop detection to optimize global pose.
A hybrid approach that combines logic-based and distributional semantics through probabilistic logic inference in Markov Logic Networks (MLNs).
We propose a novel covariate cognizant framework to deal with the presence of such covariates.
We proposed a hybrid neural network in combination with recurrent neural network and convolutional neural networks for sentence classification.
A transition-based model to jointly perform disease named entity recognition and normalization, casting the output construction process into an incremental state transition process, learning sequences of transition actions globally, which correspond to joint structural outputs.
We propose a multi-level domain adaptive model to simultaneously align the distributions of local-level features and global- level features for object detection.
We propose a novel Graph2Seq based graph-to-sequence based model for natural question generation.
AffectNet contains more than 1,000,000 facial images which manually annotated for the presence of eight discrete facial expressions and the intensity of valence and arousal. Adaptive structural learning method of DBN is positioned as a top Deep learning model of classification capability for some large image benchmark databases. However, the model was not able to classify some test cases correctly.
We propose a novel neural network architecture for discovering shape regions that strongly correlate with user-prescribed tags, without ever observing shape segmentations.
Adversarial training based on the minimax formulation is necessary for obtaining adversarial robustness of trained models. However, it is conservative or even pessimistic so that it sometimes hurts the natural generalization. We propose a novel approach of friendly adversarial training (FAT), in which we search for least adversarial (i.e., friendly) data minimizing the loss.
In this paper, we look back at existing RE methods, analyze key challenges we are facing nowadays, and show promising directions towards more powerful RE.
We revisit Maximum-Entropy learning in the context of fine-grained classification, and provide a training routine that maximizes the entropy of the output probability distribution for training convolutional neural networks on FGVC tasks.
We propose a simple strategy to inspire creators with new generations learned from a dataset of their choice, while providing some control on them.
We propose an interpretable and easy plug-in spatial-temporal attention mechanism for video action recognition that can localize discriminative regions both spatially and temporally.
We propose a GAN model that learns a tree structure implementing a hierarchical clustering with soft splits in the decision nodes and local generators in the leaves.
In this work we focus on confidence modeling for neural semantic parsers which are built upon sequence-to-sequence models.
We propose a simple yet effective foreground attentive neural network (FANN) to learn a discriminative feature representation for person Re-ID, which can adaptively enhance the positive side of foreground and weaken the negative side of background.
Clustering based evolutionary programming to deal with the photomosaic problem.
We propose a one-step person detector for topview omnidirectional indoor scenes based on convolutional neural networks using transfer learning to fine-tune CNNs trained on perspective images.
We propose AutoRTNet, a joint search framework to automate the design of network depth, downsampling strategy, and feature aggregation.
We propose an adversarial contextual model where hypotheses naturally compete with no need for explicit regularization or hyper-parameter tuning.
We discuss methodological issues related to the evaluation of unsupervised binary code construction methods for nearest neighbor search. We explain why when comparing a method whose goal is preserving cosine similarity to one designed for preserving Euclidean distance, the original features should be normalized.
We propose a deep generative feed-forward network which enables efficient synthesis of multiple textures within one single network and meaningful interpolation between them.
We propose a new algorithm, named Customized Adversarial Training (CAT), which adaptively customizes the perturbation level and the corresponding label for each training sample in adversarial training.
We propose Sparse Switchable Normalization (SSN) where the importance ratios are constrained to be sparse.
We develop a generalization theory for our framework based on a number of novel complexity measures, including an adversarial extension of Rademacher complexity and its semi-supervised analogue.
We introduce a deep, differentiable, fully-connected neural network module composed of diagonal matrices of parameters, $\mathbf{A}$ and $\Mathbf{D}$, and the discrete cosine transform $\mathBF{C}$, which can be used in combination with any other types of module.
We use DAG-CNNs to learn a set of multi-scale features that can be effectively shared between coarse and fine-grained classification tasks.
This paper presents the first weakly supervised, end-to-end neural network model to induce such programs on a real-world dataset, and apply it on WikiTableQuestions.
A strategy to combine rejection classifiers into a cascade for face identification is proposed.
We use the output of existing binary classifiers as input features in a new learning stage which optimizes the structured loss corresponding to the robust performance measure.
We propose VideoGraph, a graph-based representation for minutes-long human activities and learn their underlying temporal structure.
Meta-learning, where, in addition to training a source language model, another model learns to select which training instances are the most beneficial, can be used to improve the performance of downstream tasks.
We propose a novel energy efficient model Binary Weight and Hadamard-transformed Image Network, which is a combination of Binary Weight Network (BWN) and HadAmard-Transformed Image network (HIN), which is achieved with a slight sacrifice at classification accuracy.
We propose a new approach for 3D instance segmentation based on sparse convolution and point affinity prediction, which indicates the likelihood of two points belonging to the same instance.
This paper proposes a novel Subdivision-Fusion Model (SFM) to recognize human actions.
We propose a fast algorithm called multi-class learning from label proportions by extreme learning machine (LLP-ELM) with fast learning speed.
We address the showcase scenario of dense homogeneous layouts in which the state-of-the-art datasets for occlusion-aware instance-sensitive segmentation contain few instances and occlusions mostly due to objects occluding the background, unlike dense object layouts.
This paper presents a novel aggregation window method for stereo matching, by combining the disparity hypothesis costs of multiple pixels in a local region more efficiently for increased hypothesis confidence.
We propose a data-driven approach of learning based visual ego-motion estimation for a monocular camera.
We propose a unified solution for multi-view embedding from different visual cues and modalities using the Rayleigh quotient, which is extensible for multiple views, supervised learning, and nonlinear embeddings.
In this paper, a region-filtering correlation tracking (RFCT) algorithm is proposed to address this problem. In this algorithm, we filter training samples by introducing a spatial map.
This paper tackles the supervised evaluation of image segmentation algorithms. First, it surveys and structures the measures used to compare the segmentation results with a ground truth database, and proposes a new measure: the precision-recall for objects and parts.
We present an end-to-end learnable model that exploits a novel contact loss that favors phys- ically plausible hand-object constellations, using RGB images as input.
We have implemented a convolutional neural network designed for processing sparse three-dimensional input data. The world we live in is three dimensional so there are a lot of potential applications.
In this paper, we demonstrate a simple symmetric discriminative baseline, that can be applied to both predicting an answer as well as predicting a question.
We introduce α-Rank, a principled evolutionary dynamics methodology, for the evaluation and ranking of agents in large-scale multi-agent interactions, grounded in a novel dynamical game-theoretic solution concept called Markov-Conley chains.
We investigate the sensitivity of Delta divergence, a novel measure of classifier incongruence, to estimation errors. The results of the analysis provide guidelines on the selection of threshold for classifierincongruences detection based on this measure.
We hypothesize that re-centering invariance in LayerNorm is dispensable and propose root mean square layer normalization, or RMSNorm, giving the model re-scaling invariance property and implicit learning rate adaptation.
Neural networks are vulnerable to a wide range of erroneous inputs such as adversarial, corrupted, out-of-distribution, and misclassified examples. We train a linear SVM classifier to detect these four types of erroneous data using hidden and softmax feature vectors of pre-trained neural networks.
We introduce a framework that leverages group sparsity to identify important facial patches, and learns a multi-label classifier constrained by the likelihood of co-occurring AUs.
We introduce the notion of camera location anonymisation; by combining multiple input images captured from different viewpoints, we produce a single image that appears to have been shot from a randomly chosen angle.
We introduce a general framework for end-to-end optimization of the rate-distortion performance of nonlinear transform codes assuming scalar quantization.
We present three main architectural explorations for the Audio Visual Scene-Aware Dialog (AVSD) task, exploring several multimodal attention mechanisms during response generation and incorporating an end-to-end audio classification ConvNet into our architecture.
In this paper we present a novel approach to integrate feature similarity and spatial consistency of local features to achieve the goal of localizing an object of interest in an image.
We present a novel technique called Hindsight Experience Replay which allows sample-efficient learning from rewards which are sparse and binary and therefore avoid the need for complicated reward engineering.
This paper proposes a simple but powerful feature-driven super-resolution (FDSR) to improve the detection performance of low-resolution images.
We explore how strong color casts caused by incorrectly applied computational color constancy - referred to as white balance (WB) in photography - negatively impact the performance of DNNs targeting image segmentation and classification.
We propose a novel generative adversarial network (ManiGAN), which contains two key components: text-image affine combination module (ACM) and detail correction module (DCM) for semantically edit an image matching a given text that describes desired attributes.
This paper provides, to the best of our knowledge, the first comprehensive and exhaustive study of adversarial attacks on human pose estimation.
In order to ensure the rigor of the paper, I applied to withdraw the manuscript, and then resubmit it after the replacement version. However, this replacement version may take a lot of time, because aA lot of experiments need to be done again, and
We propose a fine-tuning method that utilizes a single-channel attention map which is manually edited by a human expert to obtain an attention map that takes into account human knowledge.
We present an efficient Bayesian CNN, offering better robustness to over-fitting on small data than traditional approaches.
We propose COALA, an answer selection approach that selects appropriate long answers due to an effective comparison of all question-answer aspects, generalizes from a small number of training examples, and makes use of the information about syntactic roles of words.
We propose novel adversarial training strategies to improve GNNs' defensibility against attacks, and propose defense strategies for GNN.
We propose a new method for music detection from broadcasting contents using the convolutional neural networks with a Mel-scale kernel using only one CPU with 4 cores.
We propose a novel approach to learn non-rigid transformation of input point clouds in each layer, and learn feature maps from the transformed point cloud.
We propose a fast and accurate object detector called SaccadeNet, which can attend to different informative object keypoints, and predict the object locations from coarse to fine.
We propose Task Aware Feature Embedding Networks (TAFE-Nets) to learn how to adapt the image representation to a new task in a meta learning fashion.
We propose to complement handcrafted methods with features found using very recent Machine Learning techniques, and we show that even few filters are sufficient to efficiently leverage handcrafted features.
In this paper, we present Stacked Cross Attention to discover the full latent alignments using both image regions and words in a sentence as context and infer image-text similarity.
In this paper, we propose a novel neural network system that consists a Demand Optimization Model based on a passage-attention neural machine translation and a Reader Model that can find the answer given the optimized question.
We present datasets to evaluate the accuracy of frame-free and frame-based approaches for tasks of visual navigation, with synthetic data created with graphics packages, and real data recorded using a mobile robotic platform.
Curriculum DeepSDF organizes the learning task in ascending order of difficulty according to the following two criteria: surface accuracy and sample difficulty.
Feature extraction component of stereo matching architecture can be used to improve the quality of features used to find point correspondences.
Adversarial attacks on machine learning models have seen increasing interest in the past years. The first attacks did this by changing pixel values of an input image slightly to fool a classifier to output the wrong class. Other approaches have tried to learn adversarial patches that can be applied to an object to fool detectors and classifiers.
This paper proposes a Weakly Supervised Local-Global Attention Network (WS-LGAN), which uses the attention mechanism to deal with part location and feature fusion problems.
We present a new predictor combination algorithm that automatically aligns evaluations of heterogeneous predictors across disjoint feature sets.
This paper proposes a CNN-based gaze-detection method that integrates all information acquired from the dual cameras and uses it as an input for the network, thereby increasing the recognition reliability and reducing the computational cost.
We propose a new framework for outfit complementary item retrieval using a category-based subspace attention network and an outfit ranking loss loss.
We develop a novel technique that analyzes inner neuron behaviors by determining how output activations change when we introduce different levels of stimulation to a neuron. Trojan trigger is then reverse-engineered through an optimization procedure using the stimulation analysis results.
We study the effectiveness of a no-code paradigm for designing deep learning models. We conduct user studies of different expertise levels.
This work provides a method to predict the G-Score, that defines how good a video game is, from its trailer (video) and summary (text), based on other information related to the game.
A stable method for document image segmentation based on a new definition of connected color components and a new model of human vision.
We developed an online multimedia event detection (MED) system. However, there are a secure access control issue and a large scale robust representation issue when we want to integrate traditional event detection algorithms into the online environment.
Adaptive batch sizes can improve performance by up to 6.25 on 4 NVIDIA Tesla P100 GPUs while changing accuracy by less than 1% relative to training with fixed batch sizes.
Multi-expert Gender Classification on Age Group (MGA), an end-to-end multi-task learning schemes of age estimation and gender classification.
We introduce a structure-aware tree-structured RvNN architecture that can provide dynamic compositionality by considering comprehensive syntactic information derived from both the structure and linguistic tags.
Facial expression recognition (FER) using a weighted mixture deep neural network .
Higher-Resolution Network to solve the scale variation challenge in bottom-up multi-person pose estimation and localize the keypoints.
We propose a novel pooling method, kernelized rank pooling, that represents a given sequence compactly as the pre-image of the parameters of a hyperplane in a reproducing kernel Hilbert space, projections of data onto which captures their temporal order.
We propose the cascade attribute learning network (CALNet), which can learn attributes in a control task separately and assemble them together.
We propose two scenarios for generating image features via extracting CNN features from different layers for HRRS scene classification.
We propose a forward prediction objective for simultaneously learning embeddings of states and actions in reinforcement learning, enabling efficient policy learning.
This paper addresses the problem of incremental domain adaptation (IDA) in natural language processing (NLP). We assume each domain comes one after another, and that we could only access data in the current domain. The goal of IDA is to build a unified model performing well on all the domains.
We propose the idea of visual distributional representation, which interprets an image set as samples drawn from an unknown distribution in appearance feature space and learn a distributional set distance function between two image sets.
Pseudo-labeling alone can outperform consistency regularization methods for semi-supervised learning. We, conversely, propose to learn from unlabeled data using the network predictions.
We compared the catalytic properties, inhibitor sensitivity and expression profiles of GADL1 and CSAD in brain tissue, indicating divergent physiological roles.
We propose a novel framework for synthesizing naturalistic facial occlusions from an initial dataset of non-occluded faces and separate images of hands, reducing the costly process of data collection and annotation.
We propose a novel Hierarchical Ensemble of CNN’s (HE-CNN) based algorithm for automated DME screening.
This paper introduces a new image-guided non-local dense matching algorithm that focuses on how to solve the following problems: 1) mitigating the influence of vertical parallax to the cost computation in stereo pairs; 2) guaranteeing the performance of dense matching in homogeneous intensity regions with significant disparity changes.
In this paper, we seek to learn compact embeddings for large-vocab sparse features in recommender systems (recsys), improving recommendation performance with compact model sizes.
We propose to use a convolutional neural network for real time semantic segmentation of users' bodies in the stereoscopic RGB video streams acquired from the perspective of the user.
Two approaches are proposed for cross-pose face recognition, one is based on the 3D reconstruction of facial components and the other isbased on the deep Convolutional Neural Network (CNN)
We can further improve the discriminative power of CNN-based features and achieve more accurate classification of texture images.
In video surveillance, pedestrian attributes such as gender, clothing or hair types are useful cues to identify people. The main challenge in pedestrian attribute recognition is the large variation of visual appearance and location of attributes due to different poses and camera views.
A new privacy-aware data disclosure scheme that considers group privacy requirements of individuals in bipartite association graph datasets where even aggregate information about groups of individuals may be sensitive and need protection.
We have shown that the correlation between the currently available quantitative genetic interaction maps in yeast is relatively low, their comparability can be improved by means of our computational matrix approximation procedure, which will enable integrative analysis and detection of a wider spectrum of genetic interactions using data from the complementary screening approaches.
We take a second look at their findings regarding generalization ability of deep models on ObjectNet, a dataset which includes multiple objects in daily life situations.
We introduce a computationally-efficient CNN micro-architecture Slim Module to design a lightweight deep neural network Slim-Net for face attribute prediction.
In this paper, we propose a new decoder where the output summary is generated by conditioning on both the input text and the latent topics of the document. The latent topics reveal more global semantic information that can be used to bias the decoder to generate words.
Deep Co-Training, a deep learning based method inspired by the Co-training framework, learns two classifiers on two different views which are data from different sources that describe the same instances.
We propose a bilateral multi-perspective matching (BiMPM) model under the"matching-aggregation"framework.
Sparsification is an efficient approach to accelerate CNN inference, but it is challenging to take advantage of sparsity in training procedures because the involved gradients are usually dynamically changed. Hence, we consider pruning these very small gradients randomly.
This paper is the first to review the scene flow estimation field, which analyzes and compares methods, technical challenges, evaluation methodologies and performance of scene flow estimators.
We treat projective dependency trees as latent variables in our probabilistic model and induce them in such a way as to be beneficial for a downstream task, without relying on any direct tree supervision.
This paper addresses the problem of human re-identification across non-overlapping cameras in crowds. To solve this problem, we model multiple Personal, Social and Environmental (PSE) constraints.
In silico prediction of site-specific kinase–substrate relationships using PhosNetConstruct, an automated program for predicting target kinases for a substrate protein.
We propose a novel approach for online action detection based on 3D skeleton sequences extracted from depth data.
We derive an optimal policy for adaptively restarting a randomized algorithm, based on observed features of the run-so-far, so as to minimize the expected time required for the algorithm to successfully terminate.
We propose a general optimization framework that allows a rich class of (non-)convex pairwise penalty functions for matrix completion, with theoretical convergence guarantee under mild assumptions.
In this work, we propose a new approach for dense disparity estimation in a global energy minimization framework in an unsupervised way using a deep deconvolutional network.
We propose Dual Attention Networks (DANs) which jointly leverage visual and textual attention mechanisms to capture fine-grained interplay between vision and language.
We present Voxel-Feature Pyramid Network, a novel one-stage 3D object detector that utilizes raw data from LIDAR sensors only.
Polarimetric imaging modality overcomes the classical methods for object detection especially in adverse weather conditions.
We consider the problem of learning general-purpose, paraphrastic sentence embeddings based on supervision from the Paraphrase Database, evaluating six compositional architectures, evaluating them on annotated textual similarity datasets drawn both from the same distribution as training data and from a wide range of other domains.
RGB-D object detection from RGB images: a survey of recent developments in this field.
We propose a meta network to learn context-sensitive convolutional filters for text processing.
The task of unpaired image-to-image translation is highly challenging due to the lack of explicit cross-domain pairs of instances. In this paper, we study the problem of bias in diverse image translation (DIT), an even more challenging setting in which an image can have multiple plausible translations.
We use pixel classification inspired by Semantic Segmentation to get the local extreme points of the four boundaries of an object and then the boundary positions.
A spatiotemporal representation learning model for video-based anomalous human behavior detection.
We propose AutoTableComplete, a framework to complete tables automatically, using a heterogeneous knowledge base (KB) as the main information source.
We introduce a novel approach for embedding logical formulae using DAG LSTMs that achieves state-of-the-art performance on premise selection and proof step classification.
The enhanced MF response based on enhanced images improved the performances of filters to extract fine blood vessels structures.
We introduce Fluid Annotation, an intuitive human-machine collaboration interface for annotating the class label and outline of every object and background region in an image.
We introduce a notion of directed connected operators for hierarchical image processing, by also considering non-symmetric adjacency relations.
A comprehensive survey of instance retrieval over the last decade, including SIFT-based and CNN-based methods.
This paper fills the gap by considering a distributed communication efficient momentum SGD method and proving its linear speedup property.
We introduce Lyceum, a high-performance computational ecosystem for robot learning. The code, tutorials, and demonstration videos can be found at www.lyceum.ml.
We propose NETNet, a scale-aware detector for real-time and accurate object detection.
Grammatical Error Correction (GEC) has been recently modeled using the sequence-to-sequence framework. However, unlike sequence transduction problems such as machine translation, GEC suffers from the lack of plentiful parallel data. We describe two approaches for generating large parallel datasets for GEC using Wikipedia data.
In this paper, we propose a novel multi-task representation learning architecture coupled with the task of supervised node classification for enhanced graph classification.
This work presents a modular architecture for simultaneous mapping and target driven navigation in indoors environments, demonstrating improved performance on both localization and navigation tasks.
We present a LiDAR-based 3D object detection pipeline entailing three stages entailing a novel cell encoding for bird's eye view projection.
We provide an in-depth analysis of end-to-end image captioning by exploring a variety of cues that ::: can be derived from such object detections.
We propose Deep Affinity Net, an effective affinity-based approach accompanied with a new graph partitioning algorithm Cascade-GAEC for instance segmentation.
We propose ASARS, a novel framework that effectively imports the temporal dynamics methodology in CF into session-based RNN system in DL, such that the temporal info can act as scalable weights by a parallel attentional network.
We introduce a weakly supervised coupled convolutional network for automatic assessment of sentiment from visual content, which significantly reduces annotation burden.
We present a novel adversarial detection and correction method for machine learning classifiers. The detector almost completely neutralises powerful attacks like Carlini-Wagner or SLIDE.
Crowd-ML, a privacy-preserving machine learning framework for a crowd of smart devices, which can solve a wide range of learning problems for crowdsensing data with differential privacy guarantees.
We present a framework for learning single-view shape and pose prediction without using direct supervision, using multi-view observations from unknown poses as supervisory signal during training.
We propose a novel neural network framework, PoseNet3D, that takes 2D joints as input and outputs 3D skeletons and SMPL body model parameters, using only 2D poses for training.
In this paper, we study an important but unexplored task: how to train a single universal image embedding model to match the performance of several specialists on each specialist's domain.
We present a new approach for general object tracking based on the fully convolutional network with multi-layer feature fusion that achieves state-of-the-art performance.
We propose a novel Instance Stixels method that combines instance information into the stixel computation itself, rather than as a post-processing step, improving performance with approximately the same number of stixels.
In recent years, stereo correspondence algorithms based on graph cuts have gained popularity due to the significant improvement in accu racy over the local methods.
In this paper, we propose a simple but effective categorical regularization framework for alleviating this issue.
We introduce the Lifted Matrix-Space model, which uses a global transformation to map vector word embeddings to matrices, which can then be composed via an operation based on matrix-matrix multiplication.
Sparse dictionary-based methods for action recognition in videos using a 3D representation based on the use of a dictionary.
In this paper, we propose a novel Deep Joint Semantic-Embedding Hashing (DSEH) approach that consists of LabNet and ImgNet to capture abundant semantic correlation between sample pairs.
The performance and parameters of neural networks have a positive correlation, and there are lot of parameter redundancies in the existing neural network architectures. By exploring the channels relationship of the whole and part of the neural network, the architectures of the convolution network with the tradeoff between the parameters and the performance are obtained.
We propose an algorithm which simultaneously detects and removes the dynamic objects present in multi-view images of a scene.
We propose to align the semantic space that is derived from external information to the model space that concerns itself with recognizing visual features. We propose to tackle this problem from the perspective of manifold learning.
A deep neural network architecture for Visual Question Answering that captures complex interactions between multi-modal features.
We introduce COVER, a novel lexical resource that combines the lexicographic precision characterizing BabelNet and the rich common-sense knowledge featuring ConceptNet, and propose an algorithm devised to build it.
We introduce software and application patterns for explanation techniques that aim to explain individual predictions of neural networks and describe how to embed algorithms in downstream implementations.
Recursively Branched Deconvolutional Neural Network architecture for image-to-image regression.
We propose a set of quality metrics for evaluating and analyzing the vision&language datasets and classify them accordingly.
We investigate the effect of explicitly enforcing the Lipschitz continuity of neural networks with respect to their inputs. We provide a simple technique for computing an upper bound to the LPschitz constant of a neural network composed of commonly used layer types.
 CNN allows us to obtain discriminative features for the input images, and RNN enables us to jointly optimize the classification of coarse and fine labels.
We address this issue by proposing a dense multi-label network module that is able to encourage the region consistency at different levels.
We propose a method for determining semantic textual similarity by combining shallow features with natural deduction proofs of bidirectional entailment relations between sentence pairs.
We propose RNE, a data-efficient Recommendation-based Network Embedding method, to give personalized and diverse items to users on billion-scale scenario.
We propose a novel transformation of user clicks to generate scale-aware guidance maps which provide the network with necessary cues on the whereabouts of the object of interest.
We propose a framework for synthesizing 3D objects, such as pulmonary nodules, in 3D medical images with manipulable properties.
We propose a fast-approximated triplet (FAT) loss, which provably converts the point-wise triplet loss into its upper bound form, consisting of a point-to-set loss term plus cluster compactness regularization.
This paper proposes a new approach, Flat2Layout, for estimating general indoor room layout from a single-view RGB image whereas existing methods can only produce layout topologies captured from box-shaped room.
We propose a novel strategy for solving this task in an almost zero-shot manner by relying on conventional whole image neural net classifiers that were trained using large bounding boxes.
We introduce a novel regularizer that encourages the loss to behave linearly in the vicinity of the training data.
This paper exploits the intrinsic features of urban-scene images and proposes a general add-on module, called height-driven attention networks (HANet), for improving semantic segmentation for urban- scene images.
We present an analysis of embeddings extracted from different pre-trained models for content-based image retrieval. The discriminative power of object detection models is significantly worse than their classification counterparts for the retrieval task.
We introduce the Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion, and achieve state-of-the-art performance on object recognition benchmark tasks.
We present a method for single image 3D cuboid object detection and multi-view object SLAM without prior object model, and demonstrate that the two aspects can benefit each other.
We propose a novel approach for learning multi-label classifiers with the help of privileged information.
Bipartite Graph Network Structured Embedding (BGNSE) combines the current KB embedding methods with bipartite graph network model for knowledge base structure analysis and completion.
Identity DiscriminativE Attention reinforcement Learning to optimise person re-id attention selection within auto-detected person bounding boxes .
We introduce Information Condensing Active Learning (ICAL), a batch mode model agnostic Active Learning method targeted at Deep Bayesian Active Learning that focuses on acquiring labels for points which have as much information as possible about the still unacquired points.
We propose Norm-ranging LSH, which addresses the excessive normalization problem caused by long tails in Simple-LSH by partitioning a dataset into multiple sub-datasets and building a hash index for each sub-Dataset independently.
In this paper, we propose an Interest-Aware Location-Based Recommender system (IALBR), which combines the advantages of both LBSNs and SNs, in order to provide interest-aware location-based recommendations.
We propose a simple and effective training stabilizer based on the notion of Consistency Regularization, which reduces memorization of the training data and increases the robustness of the discriminator to perturbations.
We describe a software toolbox for the configuration of deep neural networks in the domain of skin cancer classification in the context of dermoscopic images.
We evaluated the similarity and differences in self-reported ratings on emotion recognition accuracy as well as parameters of valence, clarity, genuineness, intensity and arousal of emotional expression, by following the same rating procedure as used for the validation of RaFD.
In this paper, we propose an unsupervised method, dubbed Metric Imitation (MI), where metrics over cheap features (target features, TFs) are learned by imitating the standard metrics over more sophisticated, off-the-shelf features (source features, SFs) by transferring view-independent property manifold structures.
We use a single linguistic phenomenon, negative polarity item licensing in English, as a case study for our experiments. We explore five experimental methods inspired by prior work evaluating pretrained sentence representation models.
Proteins are the building blocks, effectors and signal mediators of cellular processes. A protein's function, regulation and localization often depend on its interactions with other proteins. Here, we describe a protocol for the yeast protein-fragment complementation assay (PCA), a powerful method to detect direct and proximal associations between proteins in living cells.
In this paper, we propose a novel image inpainting framework that takes advantage of holistic and structure information of the broken input image, and restore the damaged images.
In this paper we propose a completely novel direction to text classification research, wherein we convert text to a representation very similar to images, such that any deep network able to handle images is equally able tohandle text.
We present a compact but effective CNN model for optical flow, called PWC-Net, which uses pyramidal processing, warping, and the use of a cost volume.
We study the impact of model size in this setting, focusing on Transformer models for NLP tasks that are limited by compute: self-supervised pretraining and high-resource machine translation.
Pre-trains a latent space representation of the data to capture the features in a lower-dimension for the small-data regime input.
We propose a sample efficient DRL-EG (DRL with efficient guidance) algorithm, in which a discriminator and a guider G(s) are modeled by a small number of expert demonstrations. The discriminator will determine the appropriate guidance states and the guider will guide agents to better exploration in the training phase.
In this paper, we revisit the problem and investigate its failure. We propose to adjust the order of the dropout operations to address the conflict; and further, other structurally more suited dropout variants are also examined and introduced for more efficient and effective regularization.
Combining steganography, cryptography, and neural networks to hide an image inside another container image of similar or same size.
In this paper, a novel multiconcavity modeling approach is proposed to handle both healthy and unhealthy retinas simultaneously.
The impressive performance and plasticity of convolutional neural networks to solve different vision problems are shadowed by their black-box nature and its consequent lack of full understanding. To reduce this gap we propose to describe the activity of individual neurons by quantifiyng their inherent selectivity to specific properties.
We investigated the impact of eye images on prosocial behavior, assessed in a laboratory setting. Three independent studies produced somewhat mixed results.
Continuous Bag of Words (CBOW) is a powerful text embedding method. However, CBOW is not capable of capturing the word order. In order to address this shortcoming, we propose a learning algorithm for the Continuous Matrix Space Model (CMOW), which we call Continual Multiplication of Words.
We propose three cost-effective measures to quantify different aspects of similarity between source pretraining and target task data, and demonstrate that these measures are good predictors of the usefulness of pretrained models for Named Entity Recognition.
We propose a new Pose-based Convolutional Neural Network descriptor for action recognition in video.
We propose a new method which leverages Deep Learning as well as model-based methods to overcome the need of a large data set to recognize landmarks in changing environment.
A single-layer RNN can perfectly mimic an arbitrarily deep stacked RNN under specific constraints on its weight matrix and a delay between input and output.
We study text classification under synonym replacements or character flip perturbations, using Interval Bound Propagation to train models that are robust against adversarial attacks.
We propose a novel pooling method, generalized rank pooling (GRP), that takes as input, features from the intermediate layers of a CNN that is trained on tiny sub-sequences, and produces as output the parameters of a subspace which (i) provides a low-rank approximation to the features and (ii) preserves their temporal order.
In order to reduce overfitting, neural networks are typically trained with data augmentation, the practice of artificially generating additional training data via label-preserving transformations of existing training examples. Despite their effectiveness, little is known about why such methods work. In this work, we aim to explore a new, more generalized form of this type ofdata augmentation in order to determine whether such linearity is necessary.
Video description is the automatic generation of natural language sentences that describe the contents of a given video. Numerous methods, datasets, and evaluation metrics have been proposed in the literature, calling the need for a comprehensive survey to focus research efforts in this flourishing new direction.
In traditional image denoising, noise level is an important scalar parameter which decides how much the input noisy image should be smoothed.
In this paper, a dataset, named 3DBodyTex, of static 3D body scans with high-quality texture information is presented along with a fully automatic method for body model fitting to a 3D scan.
This paper presents a novel large-scale dataset and comprehensive baselines for end-to-end pedestrian detection and person recognition in raw video frames.
Boosted Residual Networks combine residual networks and Deep Incremental Boosting to build fast ensemble of networks of increasing depth.
We present an unsupervised representation learning approach using temporally shuffled frames (i.e., in non-chronological order) as a supervisory signal.
We study the performance of the region-based faster R-CNN model for the electrical equipment defect detection by using the UAV images.
We propose Parametric-Noise-Injection (PNI) which involves trainable Gaussian noise injection at each layer on activation or weights through solving the Min-Max optimization problem, embedded with adversarial training to improve DNN robustness against adversarial attack.
We explore new directions for automatic human gesture recognition and human joint angle estimation as applied for human-robot interaction in the context of an actual challenging task of assistive living for real-life elderly subjects.
Event-specific concepts are the semantic concepts specifically designed for the events of interest, which can be used as a mid-level representation of complex events in videos. We propose a large scale event-specific concept library that covers as many real-world events and their concepts as possible.
This paper makes two contributions: (1) We demonstrate that while the apparent spatial resolution of convolutional feature maps is low, the high-dimensional feature representation contains significant sub-pixel localization information.
In this paper, we propose a novel generative model for descriptor learning, trained on semantic scene completion as an auxiliary task, enabling it to succeed under conditions where previous approaches failed.
We propose an approach called quantum-inspired interactive networks (QIN), which leverages the mathematical formalism of quantum theory (QT and the long short term memory (LSTM) network, to learn such interaction dynamics.
This paper presents a method of human motoric feature identification based on image recognition using the Haar Cascade method in conjunction with the classifier training process.
We propose a novel learnable convolution layer for processing 3D point cloud data directly and achieve state-of-the-art results on LiDAR object detection.
We introduce a semi-supervised method that assigns probabilistic relationship labels to a large number of unlabeled images using few labeled examples using a factor graph-based generative model.
We propose a nested CNN-cascade learning algorithm that allows efficient and progressive elimination of negative hypothesis from easy to hard via self-learning discriminative representations from coarse to fine scales.
A theoretical account of the relationship between the geometry of the manifolds and the classification capacity of the neural networks, and the functional roles different levels in the hierarchy play to achieve it.
We propose a novel deep neural network for 6D pose matching that achieves large improvements over state-of-the-art methods.
We present a new method, called locally shared features (LSFs), to model local dependence between pixels. This is achieved by concatenating features around a pixel, including the pixel itself.
We propose the deep hierarchical network (DHN) for the real-time quantitative analysis of facial palsy.
In this paper, we propose a CRF-CNN framework which can simultaneously model structural information in both output and hidden feature layers in a probabilistic way, and it is applied to human pose estimation.
We propose an extension of Convolutional Neural Networks (CNNs) to graph-structured data, including strided convolutions and data augmentation.
We propose a transfer learning scheme from breast histopathology images to improve prostate cancer detection performance.
We improve the mapping efficiency of CNN parameters to FPGA on-chip memories and achieve up to 65% increase in OCM utilization efficiency for deep CNNs.
We present STAR-FC, a novel multi-saccade generator based on a central/peripheral integration of deep learning-based saliency and lower-level feature- based saliency, successfully predicting human patterns of fixation with equivalent accuracy and quality.
Fashion landmark detection and fashion alignment by cascading multiple convolutional neural networks in three stages.
This paper takes an in-depth look at a technique for computing filtered matrix-vector (mat-vec) products which are required in many data analysis applications, including information retrieval and face recognition.
Long Short-Term Memory with Pointing (LSTM-P) improves image captioning by augmenting standard deep captioning architectures with object learners.
This paper proposes a stochastic variance reduced Nesterov's Accelerated Quasi-Newton method in full (SVR-NAQ) and limited memory forms.
We propose an end-to-end Multi-source Adversarial Domain Aggregation Network (MADAN) for multi-source domain adaptation.
In this paper, we propose a novel method, called buffered asynchronous stochastic gradient descent (BASGD), for distributed learning with attack or error. BASGD is theoretically proved to have the ability of resisting against error and malicious attack.
This paper applies a unified framework for single-image saliency and co-saliency detection in a weakly supervised learning paradigm.
We analyze how captioning model architectures and learning objectives contribute to object hallucination, explore when hallucination is likely due to image misclassification or language priors, and assess how well current sentence metrics capture object hallucation.
Zero-shot learning (ZSL) model learned is particularly vulnerable against adversarial attacks. To address it, we design a defensive relation prediction network, which can bridge the seen and unseen class domains via attributes to generalize prediction and defense strategy.
We present the Multitask Neural Model Search (MNMS) controller, a Reinforcement Learning approach that conducts an automated architecture search for multiple tasks simultaneously while still learning well-performing models for each task.
In this paper, we propose a symmetric fully convolutional neural network enhanced by wavelet transform in order to automatically carry out lane-marking segmentation in aerial imagery.
We aimed at developing a framework dedicated to x-ray stereoscopic breast images used to evaluate and rank several stereo matching methods for the generation of disparity maps.
This paper proposes a gradual denoising strategy that iteratively detects the dominating noise in an image, and removes it using a tailored denoiser that can be extended with new noise nature.
We present a new research task and a dataset to understand human social interactions via computational methods, to ultimately endow machines with the ability to encode and decode a broad channel of social signals humans use.
We introduce Dual Rectified Linear Units (DReLUs), a novel type of rectified unit that comes with a positive and negative image that is unbounded.
Data augmentation alone can achieve the same performance or higher as explicit regularization on popular architectures and data sets.
In this paper we propose a novel method, Improved Word Vectors (IWV), which increases the accuracy of pre-trained word embeddings in sentiment analysis.
We propose a deep representation learning procedure named part loss network, to minimize both the empirical classification risk on training person images and the representation learning risk on unseen person images.
Automatically generating a natural language description of an image is a task close to the heart of image understanding.
The bacterial sliding clamp (SC), also known as the DNA polymerase III β subunit, is an emerging antibacterial target that plays a central role in DNA replication, serving as a protein-protein interaction hub with a common binding pocket to recognize linear motifs in the partner proteins.
We use convolutional neural networks (CNN) and boosting techniques on Corn leaf images in different health states in order to achieve plant disease classification.
We propose a semi-supervised approach for 3D pose estimation on low-cost robotic arms on which all decisions are made upon visual recognition.
Multi-View Multidimensional Scaling on multiple input distance matrices by exploring consensus information and complementary nature of views.
We solve the trust region subproblem using a preconditioned stochastic gradient method with a line search scheme to ensure that each step promotes the model function and stays in the Trust region.
This paper proposes a novel technique called Auto DeepVis to dissect catastrophic forgetting in continual learning and propose a new method to deal with catastrophic forgetting named critical freezing.
We propose a cooperative initialization for training the deep network using ReLU activation function to improve the network performance.
M$^2$ - a Meshed Transformer with Memory for Image Captioning.
We further investigate the extent to which pretrained language models such as BERT capture knowledge using a zero-shot fact completion task.
We evaluate the use of several real-time dense stereo algorithms as a passive 3D sensing technology for potential use in automotive applications.
In this paper, we study the problem of designing efficient convolutional neural network architectures with the interest in eliminating the redundancy in convolution kernels. We present a modularized building block, {IGCV$2$:} interleaved structured sparse convolutions.
Multi-task learning of multiple tasks results in better generalizable sentence representations by conducting extensive experiments.
We propose GSLAM, a universal, cross-platform and full open-source SLAM interface for both research and commercial usage, which is aimed to handle interactions with input dataset, SLAM implementation, visualization and applications in an unified framework.
A hybrid segmentation algorithm is proposed is this paper to extract the blood vessels from the fundus image.
We present novel meta-descriptors based on a hierarchical distribution of pixel features for person re-identification.
We present a histogram layer for artificial neural networks (ANNs) that directly computes the spatial distribution of features for texture analysis.
In this paper, we survey the complete state-of-the-art techniques in the action recognition and prediction.
We propose PointSIFT-based framework that encodes information of different orientations and is adaptive to scale of shape.
A novel adaptive fusion approach that leverages the complementary properties of deep and shallow features to improve both robustness and accuracy.
We introduce a diversity loss objective, which maximizes the distance between synthesized image pairs and links the input noise to the semantic segments in the synthesized images.
Pano-RSOD provides a better panoramic image training dataset for object detection tasks, especially for small and deformed objects.
We propose a deep learning architecture for the set-to-set matching that overcomes the above difficulties, including two novel modules: 1) a cross-set transformation and 2) cross-similarity function.
We present a novel discovery platform integrating structure-based modeling with Drosophila biology and organic synthesis to efficiently explore novel kinase inhibitors outside of explored inhibitor chemical space.
We define a novel threat model for adversarial attacks that captures the space of imperceivable adversarial examples, and apply it to adversarial training.
We develop the first hierarchical segmentation of 3D shapes, based on recursive neural networks, showing strong generality and flexibility.
We present an accurate scene flow algorithm that is faster and more generic than any individual benchmark leader.
In this paper, we establish a comprehensive, rigorous, and coherent benchmark to evaluate adversarial robustness on image classification tasks.
We address the problem of generating paraphrases automatically. We address this problem by conditioning the both, encoder and decoder sides of VAE, on the original sentence, so that it can generate the given sentence's paraphrased.
We present a self-supervised learning approach for optical flow that achieves state-of-the-art results on MPI Sintel, KITTI 2012 and 2015.
This paper describes WiGipedia, a novel tool which provides an alternative to the traditional approach, by supporting editing of structured wiki data through two intuitive and interactive interfaces, facilitating user input on both tabular and graph-based representations of structured data.
We propose a pose guided method to synthesize human videos in a disentangled way: plausible motion prediction and coherent appearance generation.
We propose a Large MiniBatch Object Detector to enable the training with much larger mini-batch size than before (e.g. from 16 to 256), so that we can effectively utilize multiple GPUs (up to 128 in our experiments) to significantly shorten the training time.
We propose a memory optimized deep dense network for image super-resolution.
We propose a weakly supervised framework to find when and where the instruments are played in the videos in a music video.
We present a novel technique for the problem of robust camera-pose estimation that is more suitable for dealing with large amount of data while meeting the realtime constraint.
We propose a two-stage process which firstly trains a High-to-Low Generative Adversarial Network (GAN) to learn how to degrade and downsample high-resolution images requiring, during training, only unpaired high and low- resolution images. Once this is achieved, the output of this network is used to train a Low-toHigh GAN for image super-resolution.
We introduce two pre-trained retrieval focused multilingual sentence encoding models, respectively based on the Transformer and CNN model architectures, which provide competitive performance on English transfer learning tasks.
We propose a novel geometric framework for analyzing spontaneous facial expressions, with the specific goal of comparing, matching, and averaging the shapes of landmarks trajectories.
We study the effect of random seeds on the behaviour of attention, gradient-based and surrogate model based (LIME) interpretations.
We present a unified framework which leverages the strengths of multiple machine learning methods, viz deep learning, probabilistic models and kernel methods to obtain state-of-art performance on Microsoft COCO.
In this paper we propose a lighting insensitive face detection method based upon the edge and skin tone information of the input color image.
This paper tackles the problem of reading comprehension over long narratives where documents easily span over thousands of tokens. We propose a curriculum learning (CL) based Pointer-Generator framework for reading/sampling over large documents.
We propose a method to improve the performance of single-image 3D facial reconstruction networks by utilizing the network to synthesize its own training data for fine-tuning, thereby nudging the network towards more uniform performance as a function of the viewing angle of input faces.
We propose an efficient joint classifier learning and feature selection method that discovers sparse, compact representations of input features from a vast sea of candidates, with an almost unsupervised formulation.
We propose a novel evaluation framework for the hierarchies of morphological segmentations, namely the quasi-flat zones hierarchy and watershed hierarchies, and to evaluate their potential in the context of natural image analysis.
This work lays the foundation for a framework of cortical learning based on the idea of a competitive column, which is inspired by the functional organization of neurons in the cortex.
We propose a novel localization-aware meta tracker (LMT) guided with adversarial features to address the above issues.
In this project, we present ShelfNet, a lightweight convolutional neural network for accurate real-time semantic segmentation.
We extend the dynamic filter to a new convolution operation, named PointConv, which can be applied on point clouds to build deep convolutional networks.
In this paper, we attempt to advance the research work done in human action recognition to a rather specialized application namely Indian Classical Dance (ICD) classification. We construct a pose-oblivious shape signature which is fed to a sequence learning framework.
In this work, we propose a novel method termed Frustum ConvNet (F-ConvNet) for amodal 3D object detection from point clouds.
This paper presents a framework for using diverse suboptimal world models to decompose complex task solutions into simpler modular subpolicies.
We conduct an empirical study to test the ability of Convolutional Neural Networks (CNNs) to reduce the effects of nuisance transformations of the input data, such as location, scale and aspect ratio.
A learning framework for sound representation and recognition that combines (i) a self-supervised objective based on a general notion of unimodal and cross-modal coincidence, (ii) a clustering objective that reflects our need to impose categorical structure on our experiences, and (iii) a cluster-based active learning procedure that solicits targeted weak supervision to consolidate categories into relevant semantic classes.
We propose Hard-Aware BackPropagation to make full use of "hard" samples/attributes.
We address the problem of Image Harmonization: Given a spliced image and the mask of the spliced region, we try to harmonize the “style” of the pasted region with the background (non-spliced region).
We provide recovery guarantees for compressible signals that have been corrupted with noise and extend the framework introduced in [1] to defend neural networks against $\ELL_0$-norm and $\ell_2$- norm attacks.
In this paper, we adopt the dynamical systems point of view, and analyze the lesioning properties of ResNet both theoretically and experimentally, and propose a novel method for accelerating ResNet training.
Part-based image classification aims at representing categories by small sets of learned discriminative parts, upon which an image representation is built. In this context, this paper brings two contributions: first, this work proceeds one step further compared to recent part-based models (PBM), focusing on how to learn parts without using any labeled data. This strategy opens the door to the use of PBM in new applications where labeled data are typically not available
We study approaches to improve fine-grained short answer Question Answering models by integrating coarse-Grained data annotated for paragraph-level relevance and show that coarsely annotated data can bring significant performance gains.
In this paper we propose a general framework for distributed Bayesian learning using Bregman Alternating Direction Method of Multipliers.
We propose a framework for subgoal generation and planning, hierarchical visual foresight (HVF), which generates subgoal images conditioned on a goal image, and uses them for planning.
This paper presents a dual-residual-stream-based vessel segmentation network (Vess-Net), which is not as deep as conventional semantic segmentation networks, but provides good segmentation with few trainable parameters and layers.
Cross-media retrieval is designed for the scenarios where the queries and retrieval results are of different media types. To address these issues, we review more than 100 references, give an overview including the concepts, methodologies, major challenges, and open issues, as well as build up the benchmarks.
The study aimed to explore the role of ERBB3 in type 1 diabetes (T1D) and its potential regulators in the β-cells.
We describe a content based video retrieval (CBVR) software system for identifying specific locations of a human action within a full length film, and retrieving similar video shots from a query.
In this paper, we propose a novel Multi-marginal Wasserstein GAN (MWGAN), a new adversarial objective function with inner and inter-domain constraints to exploit cross-domain correlations.
A Multi-Stream Convolutional Neural Network is developed and evaluated in this work.
We proposed PrivRank, a customizable and continuous privacy-preserving social media data publishing framework protecting users against inference attacks while enabling personalized ranking-based recommendations.
An important aspect of human perception is anticipation, which we use extensively in our day-to-day activities when interacting with other humans as well as with our surroundings.
Deep Learning-based image captioning techniques for image classification .
Feature matching is one of the most fundamental and active research areas in computer vision. A comprehensive evaluation of feature matchers is necessary, since it would advance both the development of this field and also high-level applications such as Structure-from-Motion or Visual SLAM.
We introduce the Metropolis-Hastings generative adversarial network (MH-GAN), which combines aspects of Markov chain Monte Carlo and GANs for improved sampling.
We provide an in depth analysis of ten object proposal methods along with four baselines regarding ground truth annotation recall (on Pascal VOC 2007 and ImageNet 2013), repeatability, and impact on DPM detector performance.
We propose Cluster-GCN, a novel GCN algorithm that is suitable for SGD-based training by exploiting the graph clustering structure, which leads to significantly improved memory and computational efficiency while being able to achieve comparable test accuracy with previous algorithms.
We propose a new family of context-dependent random walk graph kernels and tree-pattern graph matching kernels.
We propose a Self-Evaluated Template Network (SETN) to improve the quality of the architecture candidates for evaluation so that it is more likely to cover competitive candidates.
We investigate two formalisms with deep sentiment representations that capture sentiment subtype expressions by latent variables and Gaussian mixture vectors.
We study risk-sensitive imitation learning where the agent's goal is to perform at least as well as the expert in terms of a risk profile, and develop algorithms based on these optimization problems.
We propose a multi-planar pulmonary nodule detection system using convolutional neural networks.
We employ a transductive label propagation method based on the manifold assumption to make predictions on the entire dataset and use these predictions to generate pseudo-labels for the unlabeled data and train a deep neural network.
We present MimicGAN, an unsupervised technique to solve general inverse problems based on image priors in the form of generative adversarial networks (GANs).
We propose a fast and accurate method for disparity maps estimation from stereo pairs that achieves state-of-the-art results on KITTI benchmarks.
We present a decoupled learning strategy for RL that creates a shared representation space where knowledge can be robustly transferred.
We introduce our method and system for face recognition using multiple pose-aware deep learning models to achieve state-of-the-art results.
We develop a tunable deep network architecture that, by means of adapter residual modules, can be steered on the fly to diverse visual domains.
Recovering high-resolution images from limited sensory data typically leads to a serious ill-posed inverse problem, demanding inversion algorithms that effectively capture the prior information. We develop a successful system solving all these challenges, using recurrent application of proximal gradient algorithm.
We identify three major challenges for the translation of chest x-ray algorithms to the clinical setting. We examine the performance of the top 10 performing models on the CheXpert challenge leaderboard on three tasks: (1) TB detection, (2) pathology detection on photos of chest X-rays, and (3) pathology Detection on data from an external institution.
This study considers the task of machine reading at scale (MRS) wherein, given a question, a system first performs the information retrieval (IR) task of finding relevant passages in a knowledge source and then carries out the reading comprehension (RC)task of extracting an answer span from the passages.
We present a new large-scale remote sensing image retrieval benchmark dataset for RSIR. We evaluate over 35 methods to establish extensive baseline results for future RSIR research.
We present RON, an efficient and effective framework for generic object detection. Our motivation is to smartly associate the best of the region-based (e.g., Faster R-CNN) and region-free methodologies.
In this paper, we propose an online ensemble distillation (OED) method to automatically prune blocks/layers of a target network by transferring the knowledge from a strong teacher in an end-to-end manner.
This work evaluates the failures of state-of-the-art models on existing adversarial datasets that test different linguistic phenomena, and find that even though the models perform similarly on MNLI, they differ greatly in their robustness to these attacks.
We propose a convolution neural network model to predict these answer types based on question words and a recurrent neural network to find sentence similarity scores between question and answer sentences.
We propose three density ratio based subsampling methods for GANs based on DRE-F-SP loss, which are suitable for all types of GAN.
We present a simple yet effective approach, object-contextual representations, characterizing a pixel by exploiting the representation of the corresponding object class.
We evaluate various self-supervised algorithms across a comprehensive array of synthetic datasets and downstream tasks. We investigate what factors may play a role in the utility of these pretraining methods for practitioners.
We study fine-grained domain adaptation as a step towards overcoming the dataset shift between easily acquired annotated images and the real world.
This paper introduces supervoxels to represent objects with partial occlusion, even for missing detections, and propose a detection refinement method based on EAS.
We find that scaling degree 2 features has the highest impact on performance, reducing classification error by 5% in best models.
Fine-tuning pretrained contextual word embedding models to supervised downstream tasks has become commonplace in natural language processing. This process, however, is often brittle: even with the same random seeds, distinct random seeds can lead to substantially different results.
We propose AlignFlow, a generative modeling framework that models each domain via a normalizing flow and guarantees exact cycle consistency in mapping datapoints from a source domain to a target domain.
This work incorporates a real-time deep-learned object detector to the monocular SLAM framework for representing generic objects as quadrics that permit detections to be seamlessly integrated while allowing the real-Time performance.
We propose supervised focus from segmentation, where points are converted into binary maps. The binary maps are combined with a network branch and accompanying loss function to focus on areas of interest.
In this paper, we propose a novel deep network for Weakly Supervised Object Detection (WSOD), using multiple streams to learn refined instance classifiers by an iterative process.
In this paper we tackle the problem of instance-level segmentation and depth ordering from a single monocular image. Towards this goal, we take advantage of convolutional neural nets and train them to directly predict instance- level segmentations where the instance ID encodes the depth ordering.
We propose a new regulariza-tion method to encourage diverse sampling in conditionalsynthesis. In addition, we propose a feature pyramid dis-criminator.
We propose a novel bounding box regression loss that improves the localization accuracies of various architectures with nearly no additional computation.
We formalize and review key applications of adversarial techniques and discuss challenges and open problems to be addressed.
We propose an energy minimization framework that leverages large-scale commonsense knowledge bases, such as ConceptNet, to provide contextual cues to establish semantic relationships among entities directly hypothesized from video.
A good response should smoothly connect both the preceding dialogue history and the following conversations. We strengthen this connection through mutual information maximization.
We propose a weakly supervised, domain-agnostic approach based on task sketches, which include only the sequence of sub-tasks performed in each demonstration and learn the required sub-policies.
We propose a novel learning-based visual odometry framework by incorporating two additional components called Memory and Refining. The Memory component preserves global information by employing an adaptive and efficient selection strategy.
We develop a novel GAN called auto-embedding generative adversarial network, which simultaneously encodes the global structure features and captures the fine-grained details for the generated images.
We present the first method to capture the 3D total motion of a target person from a monocular view input from a multiview system.
We show that online planning with deep dynamics models, together with improvements in online model-predictive control, can indeed enable efficient and effective learning of flexible contact-rich dexterous manipulation skills in the real world.
We build on this intuition to develop a novel approach to extract a summary that simultaneously captures both important particularities arising in the given video, as well as, generalities identified from the set of videos.
We propose a novel knowledge transfer method based on mining the knowledge that is most beneficial to a specific target domain, either from a single or multiple pretrained GANs.
We introduce G$^{3}$AN, a novel spatio-temporal generative model, which seeks to capture the distribution of high dimensional video data and to model appearance and motion in disentangled manner.
We propose a freezing technique to learn sentiment-specific vectors from CNN and LSTM and achieve competitive results on Sentiment Analysis.
Adversarial training and weight decay improve robustness to white-box attacks, while weight decay improves robustness.
This work examines the role of reinforcement learning in reducing the severity of on-road collisions by controlling velocity and steering in situations in which contact is imminent.
We propose a new efficient single-shot method for multi-person 3D pose estimation in general scenes from a monocular RGB camera that achieves state-of-the-art performance.
We propose a novel framework based on neural networks that analyzes an uncurated collection of 3D models from the same category and learns two important types of semantic relations among full and partial shapes: complementarity and interchangeability.
We provide formal foundations for evaluating PPs on the Web and propose an alternative query language for Linked Data that captures the distributed, graph-like nature of the data.
We propose a simple idea, WorldFeatures, where each feature at every layer has a spatial transformation, and the feature map is only transformed as needed. We use these WorldFeatures to model eye movements, such as saccades, fixation, and smooth pursuit, even in a batch setting.
In this paper we propose a slanted plane model for jointly recovering an image segmentation, a dense depth estimate and boundary labels from a static scene given two frames of a stereo pair captured from a moving vehicle.
A unified deep neural network for fast multi-scale object detection.
We introduce a new function-preserving transformation for efficient neural architecture search. This network transformation allows reusing previously trained networks and existing successful architectures that improves sample efficiency.
We propose an unsupervised paradigm for deep visual odometry learning that leverages geometry as a self-supervisory signal and uses it to train accurate deep models that do not require ground-truth labels.
We propose a novel multi-level memory network (MMN) to discover multi- level complementary information in the target domain, relying on three memory modules.
We present Firefly Monte Carlo (FlyMC) MCMC algorithm with auxiliary variables that only queries the likelihoods of a subset of the data at each iteration yet simulates from the exact posterior distribution.
We use knowledge distillation to improve a Multi-Task Deep Neural Network (MT-DNN) for learning text representations across multiple natural language understanding tasks.
We propose a scalable benchmarking methodology that uses the combination of one or more data motifs---to represent diversity of big data and AI workloads. Following this methodology, we present a unified benchmark suite---BigDataBench 4.0.
We propose Top-N-Rank, a novel family of list-wise Learning-to-Rank models for reliably recommending the N top-ranked items.
We propose the Sampling-Free mechanism, including three key ingredients: optimal bias initialization, guided loss weights, and class-adaptive threshold, for training deep detectors without sampling heuristics.
In this paper, We propose a pedestrian detection system based on RetinaNet. Our solution has scored 0.4061 mAP.
We demonstrate that embeddings, in addition to encoding generic semantics, often also present a vector that leaks sensitive information about the input data. We develop three classes of attacks to systematically study information that might be leaked.
We propose a novel attribute-guided network (AgNet), which can perform not only IBIR but also text-based image retrieval (TBIR) in zero-shot setting.
Shake-shake regularization improves on the best single shot published results on CIFAR-10 and CIFar-100 by reaching test errors of 2.86% and 15.85%.
We are motivated by the need for an object proposal generation algorithm that achieves a good balance between proposal localization quality, object recall and computational efficiency. BING++ improves BING's proposals by exploiting the fact that edges in images are typically associated with object boundaries.
We introduce a method for efficiently crowdsourcing multiclass annotations in challenging, real world image datasets. It is based on combining models of worker behavior with computer vision.
We propose a Recurrent network for multiple object Video Object Segmentation that is fully end-to-end trainable. We train RVOS for zero-shot video object segmentation.
A novel deep-neural-network-based pulmonary nodule detection system for automated detection of pulmonary nodules.
In this paper, we propose a deep pyramid generative adversarial network with local and nonlocal similarity features for natural motion image deblurring.
A method to identify response-modulated genetic interactions based on the phenotypic impact of environmental perturbations in response to budding yeast.
By augmenting images with dense optical flow map, domain adaptation in semantic segmentation can be improved.
We present a novel method for simultaneous learning of depth, egomotion, object motion, and camera intrinsics from monocular videos, using only consistency across neighboring video frames as supervision signal.
This paper presents a new deep learning architecture where alignment pairs are compared, compressed and then propagated to upper layers for enhanced representation learning.
We propose a novel 15-layer 2D deep convolutional neural network architecture for automatic feature extraction and classification of pulmonary candidates as nodule or nonnodule.
We propose balancing GAN as an augmentation tool to restore balance in imbalanced datasets. We apply class conditioning in the latent space to drive the generation process towards a target class.
This paper proposes a new Generative Partition Network (GPN) to address the challenging multi-person pose estimation problem. Different from existing models that are either completely top-down or bottom-up, the proposed GPN introduces a novel strategy that generates partitions for multiple persons from their global joint candidates and infers instance-specific joint configurations simultaneously.
We propose Convolutional Neural Mixture Models (CNMMs), a probabilistic model embedding a large number of CNNs that can be jointly trained and evaluated in an efficient manner.
A multi-branch convolutional neural network that uses depthwise separable convolution (DSC) layers to solve the pedestrian attribute recognition problem.
In this paper we detail Cortexica's (this https URL) recommendation framework -- particularly, we describe how a hybrid visual recommender system can be created by combining conditional random fields for segmentation and deep neural networks for object localisation and feature representation.
We examine the combination of top-performing state-of-the-art optical flow and stereo disparity algorithms in order to achieve a basic scene flow in an automotive or commercial vehicle context that is sufficiently robust and accurate.
A general acceleration method for model-free, off-policy deep RL algorithms by drawing the idea underlying regularized Anderson acceleration (RAA), which is an effective approach to accelerating the solving of fixed point problems with perturbations.
We proposed a novel single image super resolution method via recursive squeeze and excitation networks (SESR) that achieves state-of-the-art performance.
This paper formulates a multi-order deep cross-distance learning model for vehicle re-identification.
This paper deals with this problem by adding a differentiable latency loss term into optimization, so that the search process can tradeoff between accuracy and latency with a balancing coefficient.
This work proposes novel hyperparameter-free losses for single view 3D reconstruction with morphable models (3DMM) and proposes a novel implicit regularization technique based on random virtual projections.
AttentiveConvNet extends the context scope of the convolution operation, deriving higher-level features for a word not only from local context, but also from information extracted from nonlocal context by the attention mechanism commonly used in RNNs.
This paper leverages a self-explanatory reformulation of sparse representation, i.e., linking the learned dictionary atoms with the original feature spaces explicitly, to extend simultaneous dictionary learning and sparse coding into reproducing kernel Hilbert spaces (RKHS).
We propose an automatic image segmentation algorithm based on superpixels and image-level labels that produces high-precision results compared with the state-of-the-art algorithms.
In this work, we train fully convolutional networks to detect anger in speech using transfer learning.
This paper presents a novel tree-based cost aggregation method for dense stereo matching. Instead of employing the minimum spanning tree (MST), a new tree structure, "Segment-Tree", is proposed for non-local matching cost aggregation.
We propose a modular neural network with a modular architecture, consisting of separate perception, policy, and trajectory parts, for end-to-end deep robot policies.
We propose an algorithm that prunes the architecture search space with a partial order assumption to automatically search for the architectures with the best speed and accuracy trade-off.
We propose an end-to-end method for extracting the neural network architecture of an off-the-shelf Nvidia GPU platform using off-chip memory address traces.
We train standard neural networks with partial cross-entropy loss function for the labeled pixels and proposed Gated CRF loss for the unlabeled pixels and show that our `purist' approach achieves state-of-the-art performance for both click-based and scribble-based annotations.
A Triangle Generative Adversarial Network ($\Delta$-GAN) is developed for semi-supervised cross-domain joint distribution matching.
We develop a theoretical frame-work for model compression, and propose a new method called Spectral-Pruning, based on the theory, which achieves state-of-the-art performance.
We propose a novel training approach, which applies a layer-wise precision-adaptive quantization in deep neural networks and achieve guaranteed accuracy, without changing hyper parameters.
This paper proposes a novel left-right comparative recurrent model to performleft-right consistency checking jointly with disparity estimation.
We propose in this paper a fully automated deep model, which learns to classify human actions without using any prior knowledge.
We propose a new snippet score-based method, named Snippet Relatedness-based Generator (SRG), for temporal action proposal generation.
We investigate learning a ConvNet classifier with class-imbalanced data and propose to incorporate class-dependent temperatures to compensate for the effect of feature deviation in training.
We introduce a drone-based system for 3D human MoCap, which is usable in various indoor and outdoor environments.
We propose a graph theoretic problem for determining the minimum number of (additional) required protein-protein interactions under the constraint that each complex constitutes a connected component in a PPI network.
This work proposes a Domain and Pose Invariant Generative Adversarial Network (DPI-GAN) for person re-identification.
Unsupervised data-dependent hashing method which learns similarity preserving binary codes for image retrieval.
The effects of the number of landmarks on the mean localization error and the recognition performance are studied. Two landmarking methods are explored and compared.
This paper proposes a new framework to regularize the highly ill-posed and non-linear phase retrieval problem through deep generative priors using simple gradient descent algorithm.
We propose a novel spectral clustering method for person re-identification and derive a lightweight re-ranking method for it.
We propose an architecture agnostic self-training method to sample novel MR/text utterance pairs to augment the original training data.
We present Cavs, a vertex-centric programming interface and optimized system implementation for dynamic DL models. Cavs bypasses expensive graph construction and preprocessing overhead, allows the use of static graph optimization techniques on pre-defined operations in $\mathcal{F}$, and naturally exposes batched execution opportunities over different graphs.
A new algorithmic framework for learning autoencoders of data distributions. We minimize the discrepancy between the model and target distributions, with a relational regularization.
We show that the key ingredient of learning a strong embedding-based Transformer model is the set of pre-training tasks for large-scale query-document retrieval problem.
This paper proposes a method for learning joint embeddings of images and text using a two-branch neural network with multiple layers of linear projections followed by nonlinearities.
In goal-oriented dialog systems, belief trackers estimate the probability distribution of slot-values at every dialog turn. In this paper, we propose a new approach to universal and scalable belief tracker, called slot-utterance matching belief tracker (SUMBT)
In this paper, the residual densely connected blocks are proposed to guaranty the deep supervision, efficient gradient flow, and feature reuse abilities of convolutional neural network.
We propose a new multi-round training scheme for the interactive video object segmentation so that the networks can learn how to understand the user's intention and update incorrect estimations during the training.
We explore the problem of handwriting recognition for source code and propose an approach to improve the recognition accuracy by augmenting a handwriting recognizer with the programming language grammar rules.
We propose a novel method for real-time face alignment in videos based on a recurrent encoder–decoder network model, using temporal recurrent learning at both spatial and temporal dimensions.
We present a dataset of 37,921 frontal-facing American high school yearbook photos that allow us to use computation to glimpse into the historical visual record too voluminous to be evaluated manually.
This paper presents the first end-to-end network for exemplar-based video colorization with temporal consistency loss.
We propose a novel nested sparse network, which exploits an n-in-1-type nested structure in a neural network. The proposed framework realizes a resource-aware versatile architecture as the same network can meet diverse resource requirements.
We show how one can learn transformations with no training examples by learning them on another domain and then transfer to the target domain and use them for image retrieval task.
We focus on the challenging task of real-time semantic segmentation in this paper. We propose an image cascade network (ICNet) that incorporates multi-resolution branches under proper label guidance to address this challenge.
This paper proposes a reinterpretation of the Helmholtz Free Energy formula from physics to explain the relationship between content and noise when using sensors (such as cameras or microphones) to capture multimedia data.
We propose a generative unsupervised learning framework that predicts 6-DoF pose camera motion and monocular depth map of the scene from unlabelled RGB image sequences, using deep convolutional Generative Adversarial Networks.
This paper provides the first empirical demonstration that deep convolutional models really need to contain multiple layers of convolution, even when trained with methods such as distillation that allow small or shallow models of high accuracy to be trained.
DeepFix is a first-of-its-kind fully convolutional neural network for accurate saliency prediction.
In this work we introduce a fully end-to-end approach for action detection in videos that learns to directly predict the temporal bounds of actions.
Knowledge distillation is a widely applicable technique for training a student neural network under the guidance of a trained teacher network. In this paper, we propose a new form of knowledge distillation loss that preserves the pairwise similarities in its own representation space.
We propose a feature fusion method and investigate whether a combined feature bank of deep learning and predefined radiomics features can improve the prognostics performance in resectable PDAC patients.
We propose Quantized SGD, a family of compression schemes which allow the compression of gradient updates at each node, while guaranteeing convergence under standard assumptions.
This paper addresses the problem of establishing whether two vector time sequences could have been generated by the same (unknown) linear time invariant system, possibly affected by bounded model uncertainty and measurement noise.
We propose an efficient and scalable method for incrementally building a dense, semantically annotated 3D map in real-time.
We propose a new GZSL method based on multi-modal training and testing processes, where the optimization explicitly promotes a balanced classification accuracy between seen and unseen classes. We explore Bayesian inference for the visual and semantic classifiers.
This paper compares three practical, reliable, and generic systems for multiview video-based human action recognition, namely, the nearest neighbor classifier, Gaussian mixture model classifier and nearest mean classifier.
We benchmark state of art visual attention models and investigate the influence of the viewpoint on those computational models applied on volumetric data and this to get a better understanding of how viewpoint information could be integrated into view-based approaches.
We propose the visual concept-metaconcept learner (VCML) for joint learning of concepts and metaconcepts.
We present a modularized Mixed Link Network (MixNet) which is equipped with flexible inner link and outer link modules and achieve superior efficiency in parameter over state-of-the-art architectures on many competitive datasets like CIFAR-10/100, SVHN and ImageNet.
This paper establishes risk convergence and asymptotic weight matrix alignment of gradient flow and gradient descent when applied to deep linear networks on linearly separable data.
We introduce StructVAE, a variational auto-encoding model for semisupervised semantic parsing, which learns both from limited amounts of parallel data, and readily-available unlabeled NL utterances.
We use Siamese Mask R-CNN to perform one-shot instance segmentation on MS-COCO, demonstrating that it can detect and segment objects of novel categories it was not trained on.
We propose an end-to-end deep learning architecture for word-level visual speech recognition.
The linguistic experiences of a person are an important part of their individuality. In this paper, we show that people can be modelled as vectors in a semantic space, using their personal interaction with specific language data.
In this paper, we present a novel approach for video anomaly detection in crowded and complicated scenes based on a hierarchical activity pattern discovery framework.
A recent paper [arXiv:1609.00344] claims to classify brain processing evoked in subjects watching ImageNet stimuli as measured with EEG and to use a representation derived from this processing to create a novel object classifier. Our novel experiments and analyses demonstrate that their results crucially depend on the block design that they use.
In this paper we tackle the prediction of physical attributes from face images using Convolutional Neural Networks trained on our dataset named FIRW.
In this work, we investigate the use of sparsity-inducing regularizers during training of Convolution Neural Networks (CNNs)
In this paper, we introduce the method of soft labeling, which allows annotators to assign multiple, weighted, labels to data segments. The results show significant improvement over the state-of-the-art approach.
We explore a popular subgroup of CNNs, the Residual Networks (ResNets) and modify them in order to reduce their number of parameters.
We propose a high-performance and tunable stereo disparity estimation method, with a peak frame-rate of 120Hz (VGA resolution, on a single CPU-thread), that can potentially enable robots to quickly reconstruct their immediate surroundings and maneuver at high-speeds.
We propose a sequence-to-sequence framework with attention mechanism, copy mechanism, and coverage mechanism, which can achieve a better performance than the traditional extraction approaches and can also generate absent keyphrases which do not appear in the source text.
In this paper, we propose collaborative processing to actively guide the output of the sensor to improve performance on the end application.
We present a new latent model of natural images that can be learned on large-scale datasets. The learning process provides a latent embedding for every image in the training dataset, as well as a deep convolutional network for image restoration.
In this paper, we have developed a new method of accurate detection of retinal blood vessels based on a deep convolutional neural network model.
In this paper, we show that the seminal, biologically-inspired saliency model by Itti et al. is still competitive with state-of-the-art methods for salient object segmentation if some important adaptions are made.
In this paper, we address the challenging problem of crowd counting in congested scenes. Specifically, we present Inverse Attention Guided Deep Crowd Counting Network (IA-DCCN) that efficiently infuses segmentation information through an inverse attention mechanism into the counting network, resulting in significant improvements.
The Robust Personalized Emotion Recognition Framework with the Adaptive Data Boosting Algorithm to solve the cold-start problem.
This paper proposes a deep CNN model which simultaneously solves for both the 6-DoF absolute camera pose and 2D--3D correspondences.
The visual cortex is able to extract disparity information through the use of binocular cells. In this article, we implemented a trained binocular neuronal population, which encodes disparity information implicitly. This allows the population to learn how to decode disparities.
This paper seeks to highlight the need for explainability methods designed with Video deep learning models, and by association spatio-temporal input in mind, by first illustrating the cutting edge for video deep learning, and then noting the scarcity of research into explanations for these methods.
Co-transcriptional network analysis identified pathways involved in inflammatory processes in the epithelium of asthmatics, including the Toll-like receptor (TLR) and PPAR signaling pathways, providing a link between general inflammatory processes and the actions of GCs.
The advent of online social networks created new prediction opportunities for recommender systems: instead of relying on past rating history through the use of collaborative filtering (CF), they can leverage the social relations among users as a predictor of user tastes similarity.
In this paper we introduce an unsupervised video generation model that learns a prior model of uncertainty in a given environment. Video frames are generated from this prior and combining them with a deterministic estimate of the future frame.
We propose a novel algorithm for promoting cooperation between internal actors in a goal-conditioned hierarchical reinforcement learning (HRL) policy.
We propose a new recurrent neural framework with 15 layers, 7× than conventional RNN networks, but it is still easy to train.
We introduce a perceptual network to provide mid-level guidance, which measures the semantical similarity between the synthesized and original contents in a similarity-enhanced space in an end-to-end manner.
A system that could automatically analyze the facial actions in real time has applications in a wide range of different fields. In this paper, we propose a novel approach that systematically accounts for the relationships among AUs and their temporal evolutions for AU recognition.
We tackle the task of semi-supervised video object segmentation, i.e. segmenting the pixels belonging to an object in the video using the ground truth pixel mask for the first frame.
We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks. We show that a simple CNN with little hyperparameter tuning and static vectors achieves excellent results.
The University of Toronto is one of eight teams competing in the SAE AutoDrive Challenge -- a competition to develop a self-driving car by 2020. For safe operation, it is critical to have an accurate estimate of the position of all objects surrounding the vehicle.
This paper addresses unsupervised domain adaptation, the setting where labeled training data is available on a source domain, but the goal is to have good performance on a target domain with only unlabeled data. The way we accomplish alignment is by learning to perform auxiliary self-supervised tasks on both domains simultaneously.
This paper addresses the problem of handling spatial misalignments due to camera-view changes or human-pose variations in person re-identification. We introduce a boosting-based approach to learn a correspondence structure which indicates the patch-wise matching probabilities between images from a target camera pair.
We introduce the first very large detection dataset for event cameras. The dataset is composed of 39 hours of automotive recordings acquired with a 304x240 ATIS sensor.
In this paper, we take advantage of binocular camera and propose an unsupervised algorithm based on semi-supervised segmentation algorithm and extracting foreground part efficiently.
This paper proposes a multi-adversarial Faster-RCNN framework for unrestricted object detection, which inherently addresses domain disparity minimization for domain adaptation in feature representation.
We propose a simple and effective attention module, named Bottleneck Attention Module (BAM), that can be integrated with any feed-forward convolutional neural networks.
We introduce the PAnDA (Protein And DNA Associations) approach to characterize DNA associations with human TFs using expression profiles, protein–protein interactions and recognition motifs.
We propose a loss component directly related to ability (by a machine) to disambiguate image/caption matches, we obtain systems that produce much more discriminative caption, according to human evaluation.
We present a robust and simple method for the detection of anomalies in surveillance scenarios that avoids any object tracking, making the system suitable for anomaly detection in crowds.
We propose a far more accessible means of increasing training data sizes for face recognition systems: Domain specific data augmentation.
We propose a simpler and effective baseline for the visual commonsense reasoning task, TAB-VCR.
The recursive autoconvolution operator, adopted from physics, boosts existing unsupervised methods by learning more discriminative filters.
We propose a simple yet effective method to endow deep 3D models with rotation invariance by expressing the coordinates in an intrinsic frame determined by the object shape itself.
We present detailed spatio-temporal correlation profiles of neural activity with low-level and high-level features derived from a “deep” (8-layer) neural network pre-trained for object recognition.
We consider the case of a domain expert who wishes to explore the extent to which a particular idea is expressed in a text collection. We propose the task of semantically matching the idea, expressed as a natural language proposition, against a corpus.
We propose a novel adversarial module to learn the steganographic algorithm, and simultaneously train three modules called generator, discriminator and steganalyzer, which acts like an encryption.
We propose an instance-aware detection network (IDNet), which can learn to extract features from candidate regions and measure their similarities and select an optimal subset of candidate bounding boxes using determinantal point processes.
Cross-domain image translation based on Generative Adversarial Networks and cross-domain autoencoders, a novel network component.
We introduce a new data set for visual emotion analysis, which started from 3+ million weakly labeled images of different emotions and ended up 30 times as large as the current largest publicly available visual emotion data set.
We propose a new training strategy which achieves state-of-the-art results across three evaluation datasets while using 20x ~ 100x less annotated data than competing methods.
This work proposes an online hash model to accommodate data coming in stream for online learning.
We introduce a generative ZSL method named KG-GAN by incorporating rich semantics in a knowledge graph (KG) into GANs for generative zero-shot learning.
This paper presents an efficient annotation procedure and an application thereof to end-to-end, rich semantic segmentation of the sensed environment using FMCW scanning radar.
Data-Adaptive Nonparametric Kernel (DANK) learning framework by imposing an adaptive matrix on the kernel/Gram matrix in an entry-wise strategy.
In this paper, we investigate a new deep architecture, Densely Connected Convolutional Networks (DenseNet), to learn optical flow.
Synthesizing realistic images from text descriptions on a dataset like Microsoft Common Objects in Context (MS COCO), where each image can contain several objects, is a challenging task. Prior work has used text captions to generate images.
We present our methods for the MediaEval 2018 Emotional Impact of Movies Task to predict the expected valence and arousal continuously in movies using pre-trained neural networks.
Data loading can dominate deep neural network training time on large-scale systems. We present a comprehensive study on accelerating data loading performance in large- scale distributed training, proposing optimizations that utilize CPU resources to the data loader design.
We propose a method to learn object representations from 3D point clouds using bundles of geometrically interpretable hidden units, which we call geometric Capsule Autoencoder.
We propose a lightweight generator network, which reduces noises in motion vectors and captures fine motion details, achieving a more Discriminative Motion Cue (DMC) representation.
We propose a method called HirHide (Hierarchical Hidden Community Detection), which can be combined with traditional community detection methods to enable them to discover hierarchical hidden communities.
We present a new Long Short-Term Relation Networks, dubbed as LSTR, that novelly aggregates and propagates relation to augment features for video action detection.
We propose a novel feed-forward network for video inpainting. We use a set of sampled video frames as the reference to take visible contents to fill the hole of a target frame.
The finding that very large networks can be trained efficiently and reliably has led to a paradigm shift in computer vision from engineered solutions to synthetically generated data for supervised learning.
In this paper, we propose a radio object detection network (RODNet) to detect objects purely from the processed radar data in the format of range-azimuth frequency heatmaps (RAMaps) in severe autonomous driving scenarios.
MCR-1 catalyzes the transfer of PEA from the PE donor substrate to the 1 (or 4')-phosphate group of the lipid A moiety of lipopolysaccharide, thereby conferring colistin resistance.
We present a new method for training pedestrian detectors on an unannotated set of images, with the annotations generated along with the synthetic agents.
We propose to model the degree of absence and the presence of features via the activation functions via the AF by using piece-wise linear functions, which we refer to as L*ReLU.
The complex multi-stage architecture of cortical visual pathways provides the neural basis for efficient visual object recognition in humans. Here, we compared temporal (magnetoencephalography) and spatial (functional MRI) visual brain representations with representations in an artificial deep neural network tuned to the statistics of real-world visual recognition.
Crowd counting from a single image is a challenging task due to high appearance similarity, perspective changes and severe congestion. In order to tackle them, we propose a Perspective Crowd Counting Network (PCC Net), which consists of three parts: 1) Density Map Estimation (DME), Random High-level Density Classification (R-HDC) and Fore-/Background Segmentation (FBS)
This paper presents a new sequence-to-sequence (seq2seq) pre-training method PoDA (Pre-training of Denoising Autoencoders), which learns representations suitable for text generation tasks.
We propose to learn word embeddings from visual co-occurrences.
We propose a novel approach of correlation based profile building, by exploiting heterogynous web sources. The aim is to generate comprehensive and validated profiles about researchers and experts in computer science domain.
We propose hyper-sphere quantization (HSQ), a general framework that can be configured to achieve a continuum of trade-offs between communication efficiency and gradient accuracy.
We develop a self-supervised approach to place recognition in robots, where the labels for positive and negative examples of loop-closures can be bootstrapped using a GPS-aided navigation solution that the robot already uses.
We propose a novel filter pruning method that solves the problem of violent pruning by incremental method and Filter degradation by means of random walk.
In order to deal with action recognition for large‐scale video data, we present a spatio‐temporal auto‐combination deep network, able to extract deep features from short video segments by making full use of temporal contextual correlation of corresponding pixels among successive video frames.
We propose a new enhancement method which enhances the informative details in the RGB images for discrimination of smoke/non-smoke images for laparoscopic surgery.
We propose a textual inference framework for answering commonsense questions, which effectively utilizes external, structured commonsense knowledge graphs to perform explainable inferences.
We explore the possibility of only wielding one network for bi-directional image synthesis using self-inverse function.
Using ImageNet-trained convolutional neural networks for automatic glaucoma assessment using fundus images improves state-of-the-art works.
Targeting threonyl-tRNA synthetase (ThrRS) of Brucella abortus is a promising approach to developing small-molecule drugs against bovine brucellosis.
We propose a joint framework (i, ii, iii) of diversity and multi-mapping image-to-image translations, using a single generator to conditionally produce countless and unique fake images that hold the underlying characteristics of the source image.
In this paper, we address the problem of weakly supervised object localization (WSL), which trains a detection network on the dataset with only image-level annotations. Several strategies are taken to adaptively eliminate the noisy proposals and generate pseudo object- level annotations for the weakly labeled dataset.
We study the problem of multimodal generative modelling of images based on generative adversarial networks (GANs) using Dirichlet Allocation based GANs.
In this paper, we proposed two modified neural network architectures based on SFANet and SegNet for accurate and efficient crowd counting.
In this paper, we introduce a method to reconstruct 3D facial shapes with high-fidelity textures from single-view images in-the-wild, without the need to capture a large-scale face texture database.
We propose a novel method for first- and third-person video co-analysis using a multi-branch deep network with a triplet loss to extract joint attention.
We propose a novel probabilistic model to formalize how linguistic and perceptual inputs can work in concert to explain the observed word-context pairs in a text corpus.
The paper presents a novel approach, based on deep learning, for diagnosis of Parkinson's disease through medical imaging, using DNNs.
We present a new approach and a novel architecture, termed WSNet, for learning compact and efficient 1D convolutional neural networks.
We propose two Meta learning methods which improve the Meta learner's attention ability by explicitly embedding an attention model into its network, and use the attention mechanism to reduce the dimension of the input data by expressing it into high representations.
We explore the possibility of learning generic latent relational graphs that capture dependencies between pairs of data units (e.g., words or pixels) from large-scale unlabeled data and transferring the graphs to downstream tasks.
We propose an enhanced multi-flow sequence to sequence pre-training and fine-tuning framework named ERNIE-GEN, which bridges the discrepancy between training and inference with an infilling generation mechanism and a noise-aware generation method.
This paper surveys the various algorithms and techniques used in distributed training and presents the current state of the art for a modern distributed training framework.
We propose a novel adversarial sample detection technique based on interpretability of DNN models, based on bi-directional correspondence inference.
We propose the Hard-Aware Deeply Cascaded Embedding(HDC) framework to mine hard examples at multiple levels in cascaded manner.
We propose an approach to discover class-specific pixels for the weakly-supervised semantic segmentation task. We combine these two cues to obtain reliable cues capable of significantly boosting the performance.
First-order factoid question answering assumes that the question can be answered by a single fact in a knowledge base.
We propose an approach that utilises transcripts without bounding box annotations to train segmentation-free query-by-string word spotting models, given a partially trained model.
We present a novel method for converting Fisher Vectors to compact similarity-preserving binary codes that exploits their natural matrix structure to reduce their dimensionality using compact bilinear projections.
We introduce Recipe1M, a new large-scale, structured corpus of over 1m cooking recipes and 800k food images. Using these data, we train a neural network to find a joint embedding of recipes and images that yields impressive results on an image-recipe retrieval task.
VideoCapsuleNet: a unified capsule network for action detection which can jointly perform pixel-wise action segmentation along with action classification.
In this paper, we propose a multiscale hierarchical network (MHNet) for 3D point cloud semantic segmentation.
In this paper, we propose in a novel generative framework the use of Generative Adversarial Networks (GAN) to generate features that provide robustness for object detection on reduced quality images.
We present a unified CNN architecture that uses a range of enhancement filters that can enhance image-specific details via end-to-end dynamic filter learning.
Robust principal component analysis (RPCA) via decomposition into low-rank plus sparse matrices for image processing, video processing, and 3-D computer vision.
We provide a comprehensive survey of more than 120 promising works on biometric recognition (including face, fingerprint, iris, palmprint, ear, voice, signature, and gait recognition), which deploy deep learning models.
We discover human-interpretable rules which give us unique insight into the behavior of Visual Question Answering models, and use them for debugging.
A large-scale study on the quality of user-generated images in peer-to-peer marketplaces and their impact on sales and perceived trustworthiness.
We propose an unorthodox algorithm based on periodic functions for quantization of the model parameters.
We propose a system for city-scale road audit, using some of the most recent developments in deep learning and semantic segmentation.
We propose 3 good practices for improving CNN baseline model for person re-identification.
We introduce a novel framework for learning a manifold representation from collections of local features in images that captures both the local appearance similarity and spatial arrangement variability between images.
We propose a step towards automatic behavior understanding by integrating principles of Organic Computing into the posture estimation cycle, thereby relegating the need for human intervention while simultaneously raising the level of system autonomy.
We propose to use modified Gammatone filterbank with Teager Energy Operator (TEO) for environmental sound classification (ESC) task.
We present a robust and real-time monocular six degree of freedom relocalization system that localizes from high level features and is robust to difficult lighting, motion blur and different camera intrinsics where point based SIFT registration fails.
We propose a two-stage convolutional neural network (TSCNN) architecture for lung nodule detection in CT images.
We summarize the latest developments of application-specific IoTs (ASIoTs) (a term to conceptualize the development of IoTs targeted toward specific domains, communications mediums, and industry sectors) in eight representative studies and propose a use case for a biometrics-based ASIoT.
We propose a systematic approach to train universally slimmable networks (US-Nets) and improved training techniques to enhance training process and boost testing accuracy.
A data-dependent approach to regularizing neural network in the framework of Information Geometry.
Deluge Networks can propagate information across many layers with greater flexibility and utilize network parameters more effectively compared to ResNets, whilst being more efficient than DenseNets.
We introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals.
We propose an iterative residual refinement scheme based on weight sharing that achieves state-of-the-art results for both optical flow and occlusion estimation across several standard datasets.
We address this research issue here by pre-training a CNN offline and then transferring the rich feature hierarchies learned to online tracking.
We propose a novel interactive architecture and a novel training scheme that are both tailored to better exploit the user workflow.
In this paper, we propose ternary neural networks (TNNs) in order to make deep learning more resource-efficient. We train these TNNs using a novel, layer-wise greedy methodology.
We study collaborative machine learning across wireless devices, each with its own local dataset, where the devices share local updates on the model parameters rather than their datasets.
We propose a new method for learning a representation of image motion in an unsupervised fashion that captures semantic regions corresponding to the motion in the scene, and not merely image-level differences.
This paper introduces a novel approach, termed as PSC-Net, for occluded pedestrian detection, which exploits the topological structure of pedestrian and does not require part-based annotations or additional visible bounding-box information to learn part spatial co-occurence.
In order to train deeper networks, we propose to add auxiliary supervision branches after certain intermediate layers during training.
The application of deep learning in robotics leads to very specific problems and research questions that are typically not addressed by the computer vision and machine learning communities. In this paper we discuss a number of robotics-specific learning, reasoning, and embodiment challenges for deep learning.
In this paper, the differentiable formulation of NAS is exploited to search for several repeatable computation cells for 3D shape classification tasks.
DBpedia extracts most of its data from Wikipedia's infoboxes. Manually-created "mappings" link infobbox attributes to DBpedia ontology properties dbo properties producing most used DBpedia triples.
We aim to address the problem of "learning to look around" in the first place, where a system is rewarded for actions that reduce its uncertainty about the unobserved portions of its environment.
Generative models of commonsense knowledge can be used for automatic commonsense KB completion.
We propose two lightweight deep neural networks using depthwise separable convolution for the real-time image super-resolution.
This paper exploits this analogy and proposes to use an architecture developed for machine comprehension for ellipsis and coreference resolution.
We evaluate the effectiveness of different combinations of neural and non-neural encoders with first- and second-order decoders for graph-based dependency parsing and provide a comprehensive analysis about their effectiveness.
An attention mechanism that enables dense, bi-directional interactions between the two modalities contributes to boost accuracy of prediction of answers.
We present a new novel SR approach, which replaces the main building blocks of the classical interpolation pipeline by a flexible, content-adaptive deep neural networks to enhance the image sharpness and naturalness.
We aim at reducing the query complexity of black-box attacks in this category by exploiting gradients of a few reference models which arguably span some promising search subspaces.
Transferable Interactiveness Network to learn general interactiveness knowledge from multiple HOI datasets and perform Non-Interaction Suppression.
In this paper, we propose a graph neural network to detect objects from a LiDAR point cloud efficiently in a near-neighbors graph.
A knowledge base for real-world language processing applications should consist of a large base of facts and reasoning mechanisms that combine them to induce novel and more complex information.
In this paper, we begin by investigating current feature pyramids solutions, and then reformulate the feature pyramid construction as the feature reconfiguration process. Finally, we propose a novel architecture to combine low-level representations with high-level semantic features in a highly-nonlinear yet efficient way.
We combine global and local properties of semantic graphs through the framework of Max-Margin Markov Graph Models (M3GM), a novel extension of Exponential Random Graph Model (ERGM) that scales to large multi-relational graphs.
We address unsupervised optical flow estimation for ego-centric motion, where the point of view is coherent with vehicle motion.
We address the task of text translation on the How2 dataset using a state of the art transformer-based multimodal approach using different types of action features from the videos.
We propose a Graph Biased Temporal Point Process leveraging the structural information from graph representation learning, where the direct influence between nodes and indirect influence from event history is modeled respectively.
We provide an overview of often used techniques and methods in image classification with fewer labels.
Style transfer methods produce a transferred image which is a rendering of a content image in the manner of a style image. The style used has a strong effect on the outcome, for all methods.
We propose a novel reconstruction network in a novel encoder-decoder-reconstructor architecture, which leverages both forward (video to sentence) and backward (sentence to video) flows for video captioning, which significantly boosts the captioning performance.
We present an end-to-end 3D reconstruction method for a scene by directly regressing a truncated signed distance function (TSDF from a set of posed RGB images.
We propose an ensemble of several models, which capture spatial and audio features from videos, and improve on the previous best result on the test set by about 1 %.
We proposed a novel recurrent neural network for video-based pose estimation and it significantly outperforms state-of-the-art methods.
Achromatic low-resolution grayscale images preserve saliency information and are significantly more computationally attractive than HC images.
We propose a novel Relative Local Distance (RLD) method that integrates a relative local distance constraint into convolutional neural networks (CNNs) in an end-to-end way.
We investigate the performance drop phenomenon of state-of-the-art two-stage instance segmentation models when processing extreme long-tail training data based on LVIS dataset, and find a major cause is the inaccurate classification of object proposals. We propose to calibrate the prediction of classification head to improve recognition performance for the tail classes.
We present a distributed algorithm for Distance Metric Learning, and a large-scale implementation on a parameter server architecture.
Machine reading comprehension aims to teach machines to understand a text like a human and is a new challenge in Artificial Intelligence.
We propose Pyramid Attention Mechanism (PAM) that incorporates contextual reasoning into self-attention module for enhancing the discriminative ability of descriptors.
We propose a novel method to benefit from perceptual loss in a more objective way. We optimize a deep network-based decoder with a targeted objective function that penalizes images at different semantic levels.
We propose an innovative paradigm called Consistent Scale Normalization (CSN) to resolve above problem. CSN compresses the scale space of objects into a consistent range.
A common belief in model-free reinforcement learning is that methods based on random search in the parameter space of policies exhibit significantly worse sample complexity than those that explore the space of actions. We dispel such beliefs.
We propose RLMCS, a Graph Neural Network based model for MCS detection through reinforcement learning.
In the context of single-label classification, despite the huge success of deep learning, the commonly used cross-entropy loss function ignores the intricate inter-class relationships that often exist in real-life tasks such as age classification. In this work, we propose to leverage these relationships between classes by training deep nets with the exact squared Earth Mover's Distance (also known as Wasserstein distance) for single label classification.
The authors propose a color extension to the disparity-based Stixel World method, so that the road can be robustly distinguished from obstacles with respect to erroneous disparity measurements.
Privacy enhancing face images using a GAN-based Semi-Adversarial Network for attribute analysis.
We demonstrate that any participant in federated learning can introduce hidden backdoor functionality into the joint global model, e.g., to ensure that an image classifier assigns an attacker-chosen label to images with certain features.
In this paper, we propose a simple but effective network called DSNet for crowd counting, which can be easily trained in an end-to-end fashion.
We present a method for automated dataset generation and rapidly generate a synthetic training dataset of 50,000 depth images and 320,000 object masks. We train a variant of Mask R-CNN with domain randomization on the generated dataset to perform category-agnostic instance segmentation without any hand-labeled data.
We propose PanopticFusion, a novel online volumetric semantic mapping system at the level of stuff and things, able to densely predict class labels of a background region (stuff) and individually segment arbitrary foreground objects.
Unsupervised depth learning takes the appearance difference between a target view and a view synthesized from its adjacent frame as supervisory signal. In order to explore the information contained in high-resolution data, we propose a simple yet effective dual networks architecture, which can directly take high- Resolution images as input and generate high-accuracy depth map efficiently.
We propose a practical framework to address the problem of privacy-aware image sharing in large-scale setups, such that, from one hand, representations are stored in the public domain without paying the huge cost of privacy protection, but ambiguated and hence leaking no discernible content from the images, unless a combinatorially-expensive guessing mechanism is available.
We find that certain examples, which we term pruning identified exemplars (PIEs), and classes are systematically more impacted by the introduction of sparsity.
We present Momentum Contrast (MoCo) for unsupervised visual representation learning. From a perspective on contrastive learning as dictionary look-up, we build a dynamic dictionary with a moving-averaged encoder.
We propose a weakly-supervised, model-based approach for verifying factual consistency and identifying conflicts between source documents and a generated summary.
This paper addresses an image matching methodology designed for correspondence problem in computer vision. Firstly, a novel superpixel segmentation model driven by spatially constrained Student's- $t$ mixture model (SMM) is proposed. Next, by constructing an adaptive superpixel Gaussian filter and a superpixel salient detector, this paper establishes an innovative key-superpixel detection method.
We propose a new object-level RGBD SLAM system that imposes object priors and produces compact, high-fidelity, and dense 3D maps with semantic annotations.
Understanding human actions in visual data is tied to advances in complementary research areas including object recognition, human dynamics, domain adaptation and semantic segmentation.
A robust and efficient anomaly detection technique is proposed, capable of dealing with crowded scenes where traditional tracking based approaches tend to fail.
This paper presents a context-aware natural image matting method for simultaneous foreground and alpha matte estimation.
This paper presents novel methods to predict the surface and volume of the ham through a camera using deep learning features.
This paper addresses the task of learning an image classifier when some categories are defined by semantic descriptions only (e.g. visual attributes) while the others are undefined by exemplar images as well.
This paper proposes a new gate structure with the bivariate Beta distribution, which enables hierarchical probabilistic modeling on the gates within the LSTM cell, so the modelers can customize the cell state flow.
We address the multi-scale person search challenge by proposing a Cross-Level Semantic Alignment deep learning approach capable of learning more discriminative identity feature representations in a unified end-to-end model.
We propose a novel fully convolutional Siamese network to solve visual tracking end-to-end in a per-pixel manner.
A new adaptive filter model that allows variable scale and orientation in a single convolutional layer.
We borrow the concept of channel features to the face detection domain, make a full exploration of feature design, and discover a multiscale version of features with better performance.
We propose a workflow for knowledge discovery on RDF datasets using Markov Logic Networks and state-of-the-art rule mining, grounding, and inference.
We investigate the application of GANs to generate synthetic feature vectors used for speech emotion recognition.
We propose a novel Region Attention Network (RAN), to adaptively capture the importance of facial regions for occlusion and pose variant FER. We validate our RAN and region biased loss on built test datasets and four popular datasets: FERPlus, AffectNet, RAF-DB, and SFEW.
We attempt to solve the Very Low Resolution Recognition (VLRR) problem using deep learning methods.
In this work, a novel human-in-the-loop re-id model based on Human Verification Incremental Learning is formulated which does not require any pre-labelled training data to learn a model, therefore readily scalable to new camera pairs.
We propose a supervised initialization scheme for cascaded face alignment based on explicit head pose estimation, which improves the face alignment performance.
We propose a novel Adversarial Training with Domain Adaptation (ATDA) method that improves the generalization ability on adversarial examples from other attacks.
This paper proposes a deep learning-based framework for improving the performance of image and video recognition models under adverse conditions, using robust adverse pre-training or its aggressive variant.
We examined and compared the performance of a number of Machine Learning algorithms used for age estimation in several previous works. We observed that the face modelling or feature extraction techniques employed significantly impacted the results and of performances of the proposed age estimation approaches.
We found that using the deep-learning object-detection algorithm YOLO v3, underwater sea life and debris floating on the ocean surface can be detected with mean average precision.
We present Progressive Feature Polishing Network (PFPN), a simple yet effective framework to progressively polish the multi-level features to be more accurate and representative.
We propose a novel federated continual learning framework, Federated continual Learning with Adaptive Parameter Communication, which additively decomposes the network weights into global shared parameters and sparse task-specific parameters.
We focus on spatial redundancy of input samples and propose a novel Resolution Adaptive Network (RANet), which is inspired by the intuition that low-resolution representations are sufficient for classifying"easy"inputs containing large objects with prototypical features, while only some"hard"samples need spatially detailed information.
We propose a deep multi-task multi-view learning framework that learns a deep representation for dual-heterogeneity problems.
We propose a new algorithm to detect facial points in frontal and near-frontal face images using a probabilistic graphical model-based face shape model that restricts the search to anthropomorphically consistent regions.
This paper proposes a novel saliency detection method by combining region- level saliency estimation and pixel-level saliency prediction with CNNs (denoted as CRPSD)
This paper proposes f-CNNx, an automated toolflow for the optimised mapping of multiple CNNs on FPGAs, comprising a novel multi-CNN hardware architecture together with an automated design space exploration method that considers the user-specified performance requirements for each model.
We propose a part-feature extraction network to better focus on subtle, unique signatures on the person which are visible across both infrared and colour modalities for re-identification.
We show that it is possible to attack neural networks in a highly restricted threat setting, where attackers have no knowledge of the neural network (i.e., in a black-box setting) and can only modify highly localized adversarial noise in the form of randomly chosen straight lines or scratches.
We propose anew unsupervised domain adaptation algorithm, called SPIGAN, relying on Sim-ulator Privileged Information (PI) and Generative Adversarial Networks (GAN) for semantic segmentation.
We introduce webly labeled learning for sound events in which we aim to remove human supervision altogether from the learning process.
This paper introduces a live object recognition system that serves as a blind aid.
We make a simple observation that questions about images often contain premises - objects and relationships implied by the question - and that reasoning about premises can help Visual Question Answering (VQA) models respond more intelligently to irrelevant or previously unseen questions.
We propose a novel training strategy to restrict greed in training of GAN. With help of our method, generated samples can cover more instance modes with stable training process.
We present an iterative overlap estimation technique to augment existing point cloud registration algorithms that can achieve high performance in difficult real-world situations where large pose displacement and non-overlapping geometry would otherwise cause traditional methods to fail.
In this paper, we propose to learn deep features from body and parts (DFBP) in camera networks which combine the advantages of part-based and body-based features.
We propose an optical convolutional layer based on an optimized diffractive optical element, improving performance on image classification tasks while adding minimal electronic computational cost or processing time.
We propose to exploit natural language description as additional training supervisions for effective visual features for person re-identification.
We propose a novel action recognition method, called WSGN, that can learn to detect actions from "weak supervision", video-level labels.
We propose meta-curvature (MC), a framework to learn curvature information for better generalization and fast model adaptation.
We study a general stochastic ranking problem where an algorithm needs to adaptively select a sequence of elements so as to “cover” a random scenario (drawn from a known distribution) at minimum expected cost.
We propose a simple, yet efficient approach termed mCT-S2R (modified co-teaching with self-supervision and re-labeling) for the training of deep models in the presence of label noise.
A computer-aided fundus image analysis could provide an immediate detection and characterisation of retinal features prior to specialist inspection.
We introduce a novel Adaptive Temporal Encoding Network (ATEN) that simultaneously segments out each person instance and parses each instance into more fine-grained parts (e.g., head, leg, dress).
This paper presents a novel Contextual-Attentional Attribute-Appearance Network for person re-identification.
We propose a novel network architecture producing multiple networks of different configurations, termed deep virtual networks (DVNs), for different tasks. The hierarchical structure, which contains multiple levels of hierarchy corresponding to different numbers of parameters, enables multiple inference for different memory budgets.
We propose DEISTE (deep explorations of inter-sentence interactions for textual entailment) for SciTail, a natural entailment task.
We propose a Convolutional Neural Network (CNN)-based model "RotationNet," which takes multi-view images of an object as input and jointly estimates its pose and object category.
In this paper, we tackle the problem of retrieving videos using complex natural language queries. Towards this goal, we first parse the sentential descriptions into a semantic graph, which is then matched to visual concepts.
This paper compares various network architectures and regularization techniques to analyze the generalization capabilities of the LightNets, a lightweight network with few parameters.
We present a large-scale visual object detection and tracking benchmark, named VisDrone2018, aiming at advancing visual understanding tasks on the drone platform.
We propose a hybrid approach to temporal anomaly detection in access data of users to databases --- or more generally, any kind of subject-object co-occurrence data that also requires fast computation at test time.
This paper proposes a new actor-critic-style algorithm called Dual Actor-Critic or Dual-AC, which is derived in a principled way from the Lagrangian dual form of the Bellman optimality equation.
We investigate the mechanism by which the human brain represents blurred visual stimuli. We present a new approach using deep neural network (DNN) representation to reveal the effects of such integration on degraded visual inputs.
We propose a novel method using an attention model to exploit head locations which are the most important cue for crowd counting.
We present visual-analytics methods to reveal and analyze this hierarchy of similar classes in relation with CNN-internal data, and propose hierarchy-aware CNNs that accelerate model convergence and alleviate overfitting.
In this paper, we propose a network that fine-tunes a state-of-the-art face verification network using a regularized regression loss and additional data with expression labels.
This paper proposes a real-time driving drowsiness detection algorithm that considers the individual differences of driver.
We further exploit the representational power of Haar wavelet and present a novel low-level face representation named Shape Primitives Histogram (SPH) for face recognition.
We propose a multi-agent reinforcement learning framework for frame sampling strategy for video recognition.
We develop an empirical Bayes (EB) algorithm for the matrix completion problems.
We propose a novel long-term, real-time, intelligent system for unmanned aerial system -based vehicle tracking utilizing deep learning techniques.
In this paper, we propose a phrase-based hierarchical Long Short-Term Memory (phi-LSTM) model to generate image caption from phrase to sentence.
Generative models, such as GANs, learn an explicit low-dimensional representation of a particular class of images, and so they may be used as natural image priors for solving inverse problems such as image restoration and compressive sensing.
The present work proposes a solution to the challenging problem of registering two partial point sets of the same object with very limited overlap. We leverage the fact that most objects found in man-made environments contain a plane of symmetry.
In this paper, we propose a general method for simultaneously detecting tampered images, and GANs generated images.
Resource-adaptive framework for distributed loop closure detection in collaborative SLAM .
We introduce a word embedding method that generates a set of real-valued word vectors from a distributional semantic space.
In this paper, we propose an asymmetric user influence model to measure the directed influence between two users and adopt the PageRank algorithm to calculate the global importance value of each user.
We integrate geometric post-processing within a deep architecture, introducing a differentiable and probabilistically sound counterpart to the common geometric voting technique used for evidence accumulation in vision.
We propose Deep Asymmetric Multitask Feature Learning (Deep-AMTFL) which can learn deep representations shared across multiple tasks while effectively preventing negative transfer that may happen in the feature sharing process.
Batch augmentation reduces the number of necessary SGD updates to achieve the same accuracy as the state-of-the-art.
We proposed a CNN-based hashing method, i.e. binarilizing the activations of a fully connected layer with threshold 0 and taking the binary result as hash codes.
We introduce ML-o-scope, an interactive visualization system for exploratory analysis of convolutional neural networks, a prominent type of pipelined model.
We study conditional risk minimization (CRM), i.e. the problem of learning a hypothesis of minimal risk for prediction at the next step of sequentially arriving dependent data.
We propose a novel type of intrinsic reward which encourages the agent to take actions that lead to significant changes in its learned state representation, particularly for procedurally-generated environments.
We introduce a learning-to-adapt framework that enables deep stereo methods to continuously adapt to new target domains in an unsupervised manner in a robust manner.
In this paper, a hierarchical fusion network with adaptive feature re-weighting is proposed for surface normal estimation from RGB-D data.
A computational approach to annotate phenotypes of genes/proteins using HPO.
We explore the role of `topics' as the context of the conversation along with multimodal attention into such an end-to-end audio-visual scene-aware dialog system architecture.
We propose a new training scheme for binary activation networks called BinaryDuo in which two binary activations are coupled into a ternary activation during training.
We address the problem of semantic motion segmentation, and propose an algorithm that jointly infers the semantic class and motion labels of an object.
Person-in-WiFi achieves fine-grained person perception using WiFi antennas.
We present the first sentence simplification model that learns explicit edit operations (ADD, DELETE, and KEEP) via a neural programmer-interpreter approach, resembling the way that humans might perform simplification and revision.
In this paper, we propose a novel deep domain generalization architecture utilizing synthetic data generated by a Generative Adversarial Network (GAN) and a protocol for applying DA methods to a DG scenario.
We present SlowFast networks for video recognition. The Fast pathway can be made very lightweight by reducing its channel capacity, yet can learn useful temporal information.
We address the problem of grounding free-form textual phrases by using weak supervision from image-caption pairs. We propose a novel end-to-end model that uses caption-toimage retrieval as a `downstream' task to guide the process of phrase localization.
We propose an Activity Proposal-based Image-to-Video Retrieval (APIVR) approach, which incorporates multi-instance learning into cross-modal retrieval framework to address the proposal noise issue.
In this paper, we propose a novel method named Discrimination-Aware Integration (DAI) for person re-identification (re-ID) in camera networks, which not only integrates multiple re-ID models but also adaptively learns integration weights for different feature dimensions.
We develop an automatic perturbation analysis algorithm for neural networks which can be used for robust training and certified defense.
We propose an approach to Multitask Learning to make deep learning models faster and lighter for applications in which multiple tasks need to be solved simultaneously, which is particularly useful in embedded, real-time systems.
We propose a method that scales to large image annotation datasets by simultaneously learning to optimize precision at k of the ranked list of annotations for a given image and learning a low-dimensional joint embedding space.
We present a new approximate scheme with two steps dedicated to pose estimation. We cast this as an optimization problem defined on body parts with spatio-temporal links between them.
We address the efficiency issue for the construction of a deep graph neural network (GNN), where the weights of the recurrent units are left untrained under the stability condition introduced in this work.
We propose a hybrid contextual bandit approach, called CascadeHybrid, for solving an online LTR problem that considers both item relevance and topical diversity using two independent functions and simultaneously learns those functions from user click feedback.
We propose a robust and efficient system for unconstrained video-based face recognition from multiple-shot videos and surveillance videos with low-quality frames.
We propose a framework for language learning that relies on multi-agent communi- cation. We study this learning in the context of referential games.
We introduce the Data Visualization Saliency (DVS) model, a saliency model tailored to address some of these weaknesses, and test the performance of existing saliency models by comparing the saliency maps produced by the models to eye tracking data obtained from human viewers.
In this article, I describe the derivation of dependency structures from LFG analyses, with a focus on the Norwegian grammar NorGram.
We propose a simple yet effective regularization term to address the mode collapse issue for conditional generative adversarial networks, improving diversity without loss of quality.
We propose gradient noise convolution (GNC), which effectively smooths sharper minima of the loss function and achieves state-of-the-art generalization performance.
A local adaptive thresholding technique based on gray level cooccurrence matrix- (GLCM-) energy information for retinal vessel segmentation.
We propose a supervised hierarchical approach to object-independent image segmentation, by which we reduce the problem of segmenting image regions to finding a set of label assignment to tree nodes.
This work is a part of ICLR Reproducibility Challenge 2019, we try to reproduce the results in the conference submission PADAM.
We develop a framework for differentiable learning of set-structured latent representations and extend it to downstream tasks such as set matching.
In this paper, we formalize a new model called the Stackelberg budget allocation game with a bipartite influence model by extending a budget allocation problem over a bipARTite graph to a Stackellberg game.
We study deep generative models for directed acyclic graphs, and propose a novel DAG variational autoencoder (D-VAE) that generates novel and valid DAGs, rather than using existing simultaneous message passing schemes to encode local graph structures.
We present a comparative evaluation of various techniques for action recognition while keeping as many variables as possible controlled. We compare against traditional action recognition techniques based on Gaussian mixture models and Fisher vectors FVs.
Self-attentive encoders are better for visual grounding, as they exploit specific words with strong visual associations.
We propose and evaluate a novel loss function based on the $F$ statistic, which describes the separation of two or more distributions, and propose a new paradigm for discovering disentangled representations of class structure.
We propose a training-free monocular 3D event detection system for traffic surveillance, including the detection of both vehicle actions and traffic collisions in a surveillance scenario.
We propose Seq-CVAE which learns a latent space for every word position to capture the 'intention' about how to complete the sentence by mimicking a representation which summarizes the future.
We propose to eliminate stragglers by adapting each worker's training load to its processing capability; that is, slower workers receive a smaller batch of data to process at the same time.
The accuracy of state-of-the-art Faster R-CNN and YOLO object detectors are evaluated and compared on a special masked MS COCO dataset to measure how much their predictions rely on contextual information encoded at object category level.
We propose a method that separately learns the policy and the task belief by taking advantage of various kinds of privileged information in a meta-RL environment.
We propose to learn attention-based word-level interactions between questions and relations to alleviate the bottleneck issue.
We propose Gaussian Temporal Awareness Networks (GTAN), a new architecture that novelly integrates the exploitation of temporal structure into an one-stage action localization framework, achieving state-of-the-art results.
We introduce BayesOD, an uncertainty estimation approach that reformulates the standard object detector inference and Non-Maximum suppression components from a Bayesian perspective, providing better uncertainty estimates that are correlated with the accuracy of detections.
We propose a practical attack using differential evolution for generating effective adversarial perturbations. The attack only requires modifying five pixels with 20.28% non-targeted attack success rates, with 88.07% confidence on three common types of CNNs.
We introduce a defensive mechanism called DeepMask, which limits the capacity an attacker can use generating adversarial samples and therefore increase the robustness against such inputs.
We present an efficient multi-view 3D reconstruction method based on randomization and propagation scheme for reducing the computational complexity.
This paper describes a network that captures multimodal correlations over arbitrary timestamps. The proposed scheme operates as a complementary, extended network over a deep CNN.
We look at the problem of model bias from a mathematical perspective and propose simple additions that help to reduce model decay in long-term tracking.
In this paper, we propose an extension of the encoder-decoder framework by adding a component called guiding network for image captioning.
This paper presents an optimisation technique to select automatically a set of control parameters for a Markov Random Field applied to stereo matching.
We propose a new model, called Augmented CycleGAN, which learns many-to-many mappings between domains.
We formulate the knowledge for resolving the ambiguities in the main three steps of QALD (phrase detection, phrase-tosemantic-item mapping and semantic item grouping) as first-order logic clauses.
We propose a graph convolutional network (GCN) model to adaptively incorporate multi-level semantic context into video features and cast temporal action detection as a sub-graph localization problem.
The purpose of this paper is to explore the advantages of recommender systems based on the matrix factorization to real users through A/B test, as these studies are more significant.
We consider the problem of anomaly detection in images, and present a new detection technique to discriminate between dozens of geometric transformations applied on all the given images.
We develop and investigate several cross-lingual alignment approaches for neural sentence embedding models, such as the supervised inference classifier, InferSent, and sequential encoder-decoder models.
We propose adversarial data augmentation to address this limitation. The key idea is to design a generator (e.g. an augmentation network) that competes against a discriminator by generating hard examples online.
In this paper, we formulate a more realistic and difficult problem setup for the intent detection task in natural language understanding, namely GFSID.
Image segmentation is a popular area of research in computer vision that has many applications in automated image processing. A recent technique called piecewise flat embeddings (PFE) has shown promising results, but its original formulation is not computationally feasible for large images. We propose two improvements to the algorithm for computing PFE.
Face datasets are considered a primary tool for evaluating the efficacy of face recognition methods. Here we show that in many of the commonly used face datasets, face images can be recognized accurately at a rate significantly higher than random even when no face, hair or clothes features appear.
We introduce semantic conditioning to the discriminator of a generative adversarial network, and achieve strong results on image extension with coherent semantics and visually pleasing colors and textures.
This paper investigates the problem of semi-supervised image classification where unlabeled data are not coming from the same distribution as labeled ones, but rather from a random collection of images.
We propose a new method for creating computationally efficient CNNs by using low-rank representations of convolutional filters. To train such networks, a novel weight initialization scheme is used.
We propose a Collaborative Temporal Modeling (CTM) block (Figure 1) to learn temporal information for action recognition.
We used the combined analysis of spontaneous reports (SRs) and predicted drug-target interactions to estimate the cardiovascular ADEs that are induced by DDIs, namely, myocardial infarction, ischemic stroke, ventricular tachycardia, cardiac failure, and arterial hypertension.
In this paper, a novel framework is proposed which transfers fundamental visual features learnt from a generic image dataset to supplement a supervised face recognition model to achieve state of the art results on both the datasets.
We analyse the effectiveness of using deep transfer learning for character recognition tasks. We transfer both parameters and features and analyse their behaviour.
A novel generative adversarial network based approach to address the issues of aging accuracy and identity permanence.
We propose to explore the predictive coding network, a recurrent neural network that propagates predictive coding errors across layers and time steps for action recognition.
This paper presents an actor-critic reinforcement learning agent with experience replay that is stable, sample efficient, and performs remarkably well on challenging environments, including the discrete 57-game Atari domain and several continuous control problems.
We propose a cyclically-trained adversarial network to learn mappings from image space to a latent representation space and back such that the latent representation is invariant to a specified factor of variation (e.g., pose and illumination)
We present the iNaturalist Challenge 2017 dataset, an image classification benchmark consisting of 675,000 images with over 5,000 different species of plants and animals, from all over the world.
A comparison between visible, thermal infra-red and range images of the face for human identification.
We address the performance evaluation practices for developing medical image analysis methods, in particular, how to establish and share databases of medical images with verified ground truth and solid evaluation protocols.
In this paper, we explore the relationships between various factors of image classification algorithms that may affect energy consumption, such as dataset size, image resolution, algorithm type, algorithm phase, and device hardware.
An online two-level vehicle trajectory prediction framework for urban autonomous driving where there are complex contextual factors, such as lane geometries, road constructions, traffic regulations and moving agents.
This paper focuses on the design, deployment and evaluation of Convolutional Neural Network (CNN) architectures for facial affect analysis on mobile devices while minimising storage requirements.
We address the problem of instance-level facial attribute transfer without paired training data, e.g., faithfully transferring the exact mustache from a source face to a target face.
We propose to detect abnormal events via a sparse reconstruction over the normal bases, which is more robust compared to state-of-the-art methods.
We present a hierarchical maximum-margin clustering method for unsupervised data analysis that performs clustering recursively in a top-down manner.
We built a semi-supervised learning based Multi-part Convolutional Neural Network (MP-CNN) that classifies 35,992 animal images from ImageNet into 27 different classes of animals.
We present a system for summarization and interactive exploration of high-valued query answers to make a large set of possible answers more informative to the user.
In this paper, we propose a novel unsupervised deep neural network architecture of a feature embedding for visual loop closure that is fast and reliable enough to close loops in real time with no dimensionality reduction.
We propose a novel VAE semi-parametric modeling framework, named DeepCoder, which combines the modeling power of parametric (convolutional) and non-Parametric VAEs, for joint learning of hierarchical latent representations at multiple levels in a task hierarchy.
Improved dense trajectories (iDT) have shown great performance in action recognition, and their combination with the two-stream approach has achieved state-of-the-art performance.
We propose a vehicle-detection method using a convolutional-neural-network (CNN)-based object detector using a Deeper Receptive Field Block.
We propose a novel global Top-k sparsification mechanism to address the difficulty of aggregating sparse gradients. The gradient aggregation method based on gTop-k Sparsification reduces the communication complexity from O(kP) to O(K log P).
We introduce a novel approach to improve unsupervised hashing. The proposed method, using Gaussian Mixture Model, embeds feature vector into a low-dimensional vector and enhances the discriminative property of features before passing them into hashing.
We propose an ensemble of classifiers at hidden layers to enable energy efficient detection of natural errors.
We propose a multi-task learning framework using CNN followed by a bi-directional long short term memory (Bi-LSTM) to learn to encapsulate both forward and backward temporal dependencies.
We propose a two-step understanding of value estimation from the perspective of future prediction, through decomposing the value function into a reward-independent future dynamics part and a policy-independent trajectory return part.
We demonstrate a novel deep neural network capable of reconstructing human full body pose in real-time from 6 Inertial Measurement Units (IMUs) worn on the user's body.
We use the general formulation of QHM to give a unified analysis of several popular algorithms, covering their asymptotic convergence conditions, stability regions, and properties of their stationary distributions.
We propose the Squeeze-and-Excitation Long-term Recurrent Convolutional Networks (SE-LRCN) for human action recognition.
We use separable component called data calibrator to help the fixed source classifier recover discrimination power in the target domain, while preserving the source domain's performance.
We propose a principled loss function inspired by a metric learning objective for semantic instance segmentation and achieve competitive performance on Cityscapes and CVPPP benchmarks.
Thundervolt enables aggressive voltage underscaling of high-performance DNN accelerators without compromising classification accuracy even in the presence of high timing error rates.
We develop a knowledge projection framework for training deep neural networks on datasets with limited labeled samples using cross-network knowledge projection which is able to improve the network performance while reducing the overall computational complexity.
We introduce a novel accuracy-driven compressive training algorithm that achieves remarkable compression rates with low accuracy loss.
Action, activity and gesture recognition and analysis require various related datasets. In this paper, we present a short survey on the associated important datasets.
In this paper, we introduce deep learning technology to tackle two traditional low-level image processing problems, companding and inverse halftoning, and develop an effective algorithm based on insights into the properties of visual quality of images.
We investigate the problem of learning a probabilistic distribution over three-dimensional shapes given two-dimensional views of multiple objects taken from unknown viewpoints in a completely unsupervised manner.
This paper regards each face image as an instance associated with a label distribution. Two algorithms, named IIS-LLD and CPNN, learn from such label distributions.
In this paper, we propose the idea that the features consist of three orthogonal parts, \emph{namely} sparse strong signals, dense weak signals and random noise, in which both strong and weak signals contribute to the fitting of data.
We propose a novel end-to-end deep semantic edge learning architecture based on ResNet and a new skip-layer architecture where category-wise edge activations at the top convolution layer share and are fused with the same set of bottom layer features.
We propose TapLab, a fast semantic video segmentation framework for compressed videos using fast feature warping using motion vectors for acceleration.
We propose an alternative training process, named SGAN, in which several adversarial"local"pairs of networks are trained independently so that a"global"supervising pair of networks can be trained against them for improved performances in terms of mode coverage.
We provide empirical evaluation of the performance of some common task selection policies in a synthetic bandit-style setting, as well as on the GLUE benchmark for natural language understanding.
We propose a relatively low-dimensional feature set that combines three features: baseline Mel Frequency Cepstral Coefficients (MFCCs), MFCCs derived from Discrete Wavelet Transform (DWT) sub-band coefficients that are denoted as DMFCC, and pitch based features.
We learn a self-supervised, single-view 3D reconstruction model that predicts the 3D mesh shape, texture and camera pose of a target object with a collection of 2D images and silhouettes.
This paper presents a dense matching algorithm by integrating SIFT and Semi-global matching with truncating error propagation.
This paper proposes a supervised learning approach to jointly perform facial Action Unit localisation and intensity estimation, using heatmap regression.
Taking an image and question as the input of our method, it can output the text-based answer of the query question about the given image, so called Visual Question Answering (VQA)
We proposed a less computational unsupervised automated technique with promising results for detection of retinal vasculature by using morphological hessian based approach and region based Otsu thresholding.
We propose a novel loss function that combines the knowledge of positives, offline hard negatives and online hard negatives to improve the model's generalization capability.
The global feature capturing module (GFCM) and Conv Block are proposed in this paper to build a new model to improve segmentation performance.
We measure the gain of CNNs trained for image classification on ImageNet and observe that the best models are also the most sensitive to perturbations of their input.
This paper presents a novel descriptor named Region based Extensive Response Index Pattern (RETRaIN) for facial expression recognition.
In this paper, we use incremental LDA and hashing based search method to deal with these two problems.
We propose the Deep Co-attention based Comparators that fuse the co-dependent representations of the paired images so as to focus on the relevant parts of both images and produce their relative representations.
We propose ROI regularization (ROIreg) as a semi-supervised learning method for image classification, which improves the state-of-the-art on both SVHN and CIFAR-10.
We address the problem of estimating human body pose from a single image with cluttered background using kernel Support Vector Machines (SVM) with pose-dependent feature selection.
We propose an end-to-end, scalable CNN framework that incorporates a sub-pixel motion compensation layer in a CNN framework for video super-resolution.
We study data-driven algorithm selection and metric learning for clustering problems, where the goal is to simultaneously learn the best algorithm and metric for a specific application.
This paper presents final results of ICDAR 2019 Scene Text Visual Question Answering competition (ST-VQA), which introduces an important aspect that is not addressed by any VQA system up to date, namely the incorporation of scene text to answer questions asked about an image.
This paper presents a new model to overcome the occlusion problems coming from wide baseline multiple camera stereo. Rather than explicitly modeling occlusions in the matching cost function, it detects Occlusion in the depth map obtained from regular efficient stereo matching algorithms.
We propose a Bayesian approach to learn discriminative dictionaries for sparse representation of data using a finite approximation of Beta Process.
We propose Video Inference for Body Pose and Shape Estimation (VIBE), which makes use of an existing large-scale motion capture dataset (AMASS) together with unpaired, in-the-wild, 2D keypoint annotations.
Compression via Adaptive Recursive Partitioning (CARP) uses an optimal permutation of the image pixels inferred from a Bayesian probabilistic model on recursive partitions to reduce its effective dimensionality.
We present a novel algorithm that intrinsically improves both the accuracy and the convergence speed of BP.
We propose a novel context-aware variational autoencoder effectively learning event background information to guide the If-Then reasoning.
The clinical significance of HNRNPL (heterogeneous nuclear ribonucleoproteins L) in PC was analyzed. Bioinformatics analysis including pathway enrichment and interactors with HNRnPL was used to elucidate the biological functions of H NRNPL.
This paper provides a novel approach for recognizing human behavior from RGB-D video data. The three-dimensional convolutional restricted Boltzmann machine (3DCRBM) is proposed.
We propose to use semantic segmentation and detection masks as observations obtained by state-of-the-art computer vision algorithms and use a deep network to learn the navigation policy for semantic visual navigation.
A thorough study of human ability on two tasks, face verification and age estimation, for facial images taken at different ages.
We define a methodology to increase the coverage of DBpedia in different languages by extending the population of the classes for the different languages.
An efficient coarse-to-fine algorithm is proposed for moving object detection in dynamic scenes for autonomous driving.
We propose a multi-task network EdgeStereo that is composed of a backbone disparity network and an edge sub-network for stereo matching task.
This paper presents X3D, a family of efficient video networks that progressively expand a tiny 2D image classification architecture along multiple network axes, in space, time, width and depth.
We propose a novel CNN architecture for view synthesis that does not suffer from texture details, shape distortions, or high computational complexity.
BoLTVOS performs VOS using only the firstframe bounding box without the mask. We evaluate our approach on DAVIS 2017 and YouTube-VOS, and show that it outperforms all methods that perform first-frame fine-tuning.
In this paper, we design a new convolutional neural network (CNN) to automatically learn the interaction mechanism for RGBD salient object detection by exploiting the intrinsic structure of the input image.
In this paper, we directly model the dynamics of GANs and adopt the control theory to understand and stabilize it.
Fractioned Adjacent Spatial and Temporal (FAST) 3D convolutions are a natural decomposition of a regular3D convolution.
We introduce a compact network for holistic scene flow estimation, called SENSE, which shares common encoder features among four closely-related tasks: optical flow, disparity estimation from stereo, occlusion estimation and semantic segmentation.
Recurrent neural networks with Long Short-Term memory cells can be improved using dropout, a recently proposed regularization method for deep architectures.
We propose Deep Perceptual Compression (DPC) which uses an encoder-decoder based image compression model to jointly optimize on the deep perceptual metric and MS-SSIM.
A classifier-based detector that is trained with mimicry adversarial examples can be evaded by an adaptive attacker that specifically targets the detector.
This paper explores the problem of learning transforms for image compression via autoencoders and shows that comparable performances can be obtained with a unique transform.
We propose a novel object proposal generation algorithm, BING++, which inherits the virtue of good computational efficiency of BING but significantly improves its proposal localization quality.
We introduce a novel scheme to train binary convolutional neural networks (CNNs) -- CNNs with weights and activations constrained to {-1,+1} at run-time.
We propose a novel Progressive and Selective Instance-Switching (PSIS) method to augment training data for object detection, which preserves contextual coherence in the original images while requiring no external dataset.
In this paper, we propose PointRCNN for 3D object detection from raw point cloud in a bottom-up manner.
SaLite uses both global and local contextual features for salient object detection without compromising on performance.
Learning from demonstration is an effective method for human users to instruct desired robot behaviour. However, for most non-trivial tasks of practical interest, efficient learning from demonstration depends crucially on inductive bias in the chosen structure for rewards/costs and policies.
An expression recognition model based on a joint partial image and deep metric learning method (PI&DML) is proposed to address the problem of high intraclass variations and interclass similarities.
In this paper, we propose a subset selection algorithm that is trainable with gradient-based methods yet achieves near-optimal performance via submodular optimization.
We study the effectiveness of a corpus-based approach to automatically derive the semantic relatedness between words and images and perform empirical evaluations by measuring its correlation with human annotators.
We propose a novel nonlinear metric learning method that uses an iterative, hierarchical variant of semi-supervised max-margin clustering to construct a forest of cluster hierarchies, where each individual hierarchy can be interpreted as a weak metric over the data.
We propose a model that estimates depth from a monocular image and use a simple transformation to reconstruct the image seen from said viewpoint.
We propose a few-shot vid2vid framework, which learns to synthesize videos of previously unseen subjects or scenes by leveraging few example images of the target at test time.
We show that BERT (Devlin et al, 2018) is a Markov random field language model that can generate high-quality, fluent generations.
We introduce a novel framework for image captioning that can produce natural language explicitly grounded in entities that object detectors find in the image.
In this paper, we introduce an effective and interpretable network module, the Temporal Relation Network (TRN), designed to learn and reason about temporal dependencies between video frames at multiple time scales.
We propose the use of a mixture distribution as a prior to make likelihoods assigned by deep generative models sensitive to out-of-distribution inputs.
We unify different broad-coverage semantic parsing tasks under a transduction paradigm, and propose an attention-based neural framework that incrementally builds a meaning representation via a sequence of semantic relations.
We propose a method that estimates the poses of multiple persons in an image in which a person can be occluded by another person or might be truncated.
We propose Meta Filter Pruning, a meta pruning method that prunes unimportant filters in a collaborative way. The pruning criterions can be adaptively switched.
In this survey, we perform a broad and thorough investigation on challenges, techniques and tools for scalable DL on distributed infrastructures.
We propose a novel search space tailored for text representation that outperforms state-of-the-art models on various public datasets on text classification and natural language inference tasks.
We propose to exploit proprioceptive motor signals to provide unsupervised regularization in convolutional neural networks to learn visual representations from egocentric video. We enforce that our learned features exhibit equivariance.
We propose a group convolutional approach to multiple view aggregation where convolutions are performed over a discrete subgroup of the rotation group, enabling, thus, joint reasoning over all views in an equivariant (instead of invariant) fashion, up to the very last layer.
We investigate the interaction between news and prices for the one-day-ahead volatility prediction using state-of-the-art deep learning approaches. We evaluate a broad range of stock market sectors.
A trade-off exists between reconstruction quality and the prior regularisation in the Evidence Lower Bound (ELBO) loss that Variational Autoencoder (VAE) models use for learning. In this paper, we show that the noise variance in the Gaussian likelihood p(x|z) for real-valued data can naturally act to provide such a balance.
In this paper, we show that accurate pedestrian location estimation is achievable using deep neural networks on fixed cameras with limited computing resources.
We build an effective biomedical DR system that relies on relevant answer snippets in the BioASQ training datasets and exploit two auxiliary features for scoring document relevance.
We integrate confidence into efficient large-scale stereo (ELAS) matching to produce an accurate approach to binocular stereo for high-resolution image matching.
We use activation spaces to capture the differences in spatial dynamics between normal and adversarial examples, and form a novel adversarial example detector, which can be augmented with previously suggested defense methods to form a holistic multi-purpose defense mechanism.
We propose a simple text2image method, representing a novel test query by a set of images selected from large-scale query log, for evaluation of multiple cross-media similarity models on three test sets.
In this paper, we present a methodology that can be applied across multiple domains by incorporating corpora-based statistics into a standardized semantic similarity algorithm that achieves a high correlation value.
We first reformulate supervised LDA based on the normalized perspective of LDA. Then we show that such a reformulation is powerful for semi-supervised learning of Lda.
In this paper, we propose a novel approach to dynamic SLAM with dense object-level representations and formulate multi-object tracking as direct alignment of RGB-D images with the SDF representations.
We propose a compressed domain two-stream network IP TSN, where the two streams are represented by the two types of frames (I and P frames) in compressed videos, without needing a separate temporal stream.
The first computational implementation of Jerzy Konorski's theory of gnostic neurons, which can be used for robust object classification.
Detecting individual pedestrians in a crowd remains a challenging problem since the pedestrians often gather together and occlude each other in real-world scenarios. In this paper, we propose a novel bounding box regression loss specifically designed for crowd scenes.
We developed a novel reverse haptic interface to augment forward dynamic simulations with real-world contact forces. This method can implicitly extend computer models of biomechanics and robotic control with complex ground interactions.
This paper aims to learn a discriminative and robust spatial–temporal representation for person re-identification by a two-stage attribute-constraint network (TSAC-Net)
We introduce the Graph Parsing Neural Network (GPNN), a framework that incorporates structural knowledge while being differentiable end-to-end.
We propose the Reversed Two-Stream Networks (Rev2Net) which can learn robust video features by reversing the multi-modality inputs as training supervisions.
We propose a novel network architecture to perform stereoscopic view synthesis at arbitrary camera positions along the X-axis, or Deep 3D Pan, with "t-shaped" adaptive kernels equipped with globally and locally adaptive dilations.
We propose a novel approach to generate multiple feasible hypotheses of the 3D pose from an input of 2D joints based on a multimodal mixture density networks.
We develop a predictive model in the space of fixed-sized convolutional features of the Mask R-CNN instance segmentation model. We apply the "detection head" of the model on the predicted features to produce the instance Segmentation of future frames.
Combining OMP codes with maximum coordinate detection could achieve state-of-the-art performance on the UCSD dataset.
Recovering the 3D representation of an object from single-view or multi-view RGB images by deep neural networks has attracted increasing attention in the past few years. Several mainstream works (e.g., 3D-R2N2) use recurrent neural networks (RNNs) to fuse multiple feature maps extracted from input images sequentially. However, when given the same set of input images with different orders, RNN-based
We propose a generative classifier that generalizes better than DNNs trained on noisy datasets.
We propose the gated bidirectional feature pyramid network (GBFPN), a simple and effective architecture that provides a significant improvement over the baseline model, StairNet, for one-stage detectors.
This work provides theoretical and empirical evidence that invariance-inducing regularizers can increase predictive accuracy for worst-case spatial transformations (spatial robustness) with the same computational budget.
This paper describes InfoGAN, an information-theoretic extension to the Generative Adversarial Network that learns interpretable representations in a completely unsupervised manner.
We formulate the problem of model uncertainty as a continuous Bayes-Adaptive Markov Decision Process (BAMDP), where an agent maintains a posterior distribution over the latent model parameters given a history of observations and maximizes its expected long-term reward with respect to this distribution.
This paper proposes a generic method to revise traditional neural networks for privacy protection.
We propose the use of neuro-symbolism as a way of using knowledge-bases to guide the learning progress of deep neural networks.
We formulate the sparse 3D registration problem based on the constraints from the intersection of line segments from adjacent scans. We propose a new alternating projection algorithm using line intersection constraints.
The encoder-decoder models for unsupervised sentence representation learning tend to discard the decoder after being trained on a large unlabelled corpus, since only the encoder is needed to map the input sentence into a vector representation.
Image inpainting aims to fill missing regions of a damaged image with plausibly synthesized content. In this paper, we present an approach for image inpaintedting.
This paper proposes a fusion of two levels of similarity across media images-text retrieval method, constructed the cross-media two-level network to explore the better matching between images and texts, it contains two subnets for dealing with global features and local characteristics.
We focus on Unsupervised Domain Adaptation (UDA) for the task of semantic segmentation.
We propose a quaternion convolutional neural network, which can be used for color image classification and denoising.
We propose a novel approach, called Bayesian optimized 1-bit CNNs (denoted as BONNs), taking the advantage of Bayesian learning, a well-established strategy for hard problems, to significantly improve the performance of extreme 1- bit CNNs.
We present a novel action recognition method which is based on combining the effective description properties of Local Binary Patterns with the appearance invariance and adaptability of patch matching based methods.
We propose an effective refinement process that employs image transformations and mask matching to increase the accuracy of object segmentation masks.
A hexagonal sampled SIFT feature descriptor with applicability in face recognition tasks.
The objective of this work is to infer the 3D shape of an object from a single image. We use sculptures as our training and test bed, as these have great variety in shape and appearance.
The goal of this paper is to recognize actions in video without the need for examples. Our key contribution is objects2action, a semantic word embedding that is spanned by a skip-gram model of thousands of object categories.
We propose the Mixed High-Order Attention Network (MHN) module to model and utilize the complex and high-order statistics information in attention mechanism.
In this paper, we propose a discriminative block-diagonal low-rank representation (BDLRR) method for recognition.
We present a novel end-to-end coupled Denoising based Saliency Prediction with Generative Adversarial Network (DSAL-GAN) framework to address the problem of salient object detection in noisy images.
Using head pose, gender detection, and skin color estimation techniques, we demonstrate that the gender disparity in TV in Bangladesh exhibits unique characteristics and is sometimes counter-intuitive to popular perception.
In this paper, we present a method to learn a visual representation adapted for e-commerce products and achieve state-of-art results.
Identification of DNA primase inhibitors via a combined fragment-based and virtual screening .
We present a robust prior-model guided depth-enhanced network for RGB-D salient object detection.
We learn to encode the important and distinct information in the background jointly with the foreground relevant to rigid real-world scenarios where objects are static and the camera moves around the scene.
We address the problem of instance-level semantic segmentation, which aims at jointly detecting, segmenting and classifying every individual object in an image. In this context, existing methods typically propose candidate objects, usually as bounding boxes, and directly predict a binary mask within them.
We propose a general unified attention model that captures the intra- and inter-modal interactions of multimodal features and outputs their corresponding attended representations.
We apply computer graphic scripts and Generative Adversarial Networks to generate and augment a large number of annotated, synthesized license plate images with realistic colors, fonts, and character composition from a small number of real, manually labeled data.
Facial micro-expressions are very brief, spontaneous facial expressions that appear on the face of humans when they either deliberately or unconsciously conceal an emotion.
We propose a generative model based on probability flows that does away with the bijectivity requirement on the model and only assumes injectivity.
The ability to fool modern CNN classifiers with tiny perturbations of the input has lead to a large number of candidate defenses and often conflicting explanations. In this paper, we argue for examining adversarial examples from the perspective of Bayes-Optimal classification.
A system that reads news articles in four different languages and detects what happened, who is involved, where and when in an interoperable RDF format.
This paper studies an effective deep learning based strategy to deal with these issues, which comprises of a facial landmark predicting subnet and an image inpainting subnet.
We present a novel algorithm for semantic segmentation and labeling of 3D point clouds of indoor scenes, where objects in point clouds can have significant variations and complex configurations.
Reconstruction of 3D structure from video data goes hand in hand with the reorganization of the scene.Bottom-up grouping generates object candidates, which can be classified top down, following which the segmentations are refined.3D reconstruction benefits from object category-specific priors.
Automatic redaction of diverse private information in the wild .
In this paper we introduce Fisher GAN which fits within the Integral Probability Metrics (IPM) framework for training GANs.
We propose a novel scalable computational approach to unsupervised data fusion, which exploits network representations of the data to identify similarities among the datasets.
DASPfind is a computational method for finding reliable new interactions between drugs and proteins. We show over six different DTI datasets that DASP find outperforms other state-of-the-art methods when the single top-ranked predictions are considered, or when a drug with no known targets or with few known targets is considered.
We combine two of the most popular approaches to automated Grammatical Error Correction (GEC): GEC based on Statistical Machine Translation (SMT) and NMT, achieving state-of-the-art results on CoNLL-2014 and JFLEG benchmarks.
We present PredRNN++, an improved recurrent network for video predictive learning, which captures short-term and long-term dependencies adaptively.
A deep learning network named kernel principal component analysis network (KPCANet) is proposed.
Our main idea is to mathematically understand and describe the hierarchical structure of feedforward neural networks by reparametrization invariant Riemannian metrics by approximating the tangent subspace.
We propose a scalable framework for multi-class classification based on deep metric learning, which aims to classify the generated images finer.
We propose a small feature distilled network (FDN) for visual tracking by imitating the intermediate representations of a much deeper network. The FDN extracts rich visual features with higher speed than the original deep network.
We propose a generalization error bound for a general family of deep neural networks based on the depth and width of the networks, as well as the spectral norm of weight matrices.
This paper proposes a novel tracking-by-detection framework, which uses multiple discriminative correlation filter bank (DCFB), corresponding to different target sub-regions and global region patches to combine and optimize the final correlation output in the frequency domain to mitigate tracker drift and even failure.
We present an approach incorporating a multi-label class balancing algorithm for Action Unit detection at the ABAW challenge.
We propose procedures for evaluating and strengthening contextual embedding alignment and show that they are useful in understanding and improving multilingual BERT.
We introduce a Figure Skating Dataset (FSD-10) for finegrained sports content analysis and evaluate state-of-the-art action recognition methods on it.
IranVScreen provides an intuitive all-in-one GUI to carry out multiple virtual screening tasks in several mouse clicks with minimal requirement of skill.
A novel loss function for DNNs to pay more attention to clean samples via adaptively weighing the traditional cross-entropy loss, and a cross-training strategy to address label noise.
We propose the Dual Adversarial Semantics-Consistent Network (DASCN), which learns primal and dual Generative GANs in a unified framework for GZSL.
We propose a novel method for quantifying the statistical significance of protein complexes in terms of p-values.
This paper explores the use of saliency which is equivalent to the human visual system to classify Age, Gender and Facial Expression soft-biometric for facial images.
We propose a method to synthesize additional points (Sensible Points) to create pose hypotheses for registration under occlusion, and use the Sensible Points to train recurrent policy networks to move them.
This paper investigates the problem of image-caption retrieval using joint visual-semantic embeddings. We introduce a very simple change to the loss function used in the original formulation by Kiros et al. (2014), which leads to drastic improvements in the retrieval performance.
We propose a new framework that models different levels of semantic units (e.g. sememe, word, sentence, and semantic abstraction) on a single Semantic Hilbert Space, which naturally admits a non-linear semantic composition by means of a complexvalued vector word representation.
The goal of video understanding is to develop algorithms that enable machines understand videos at the level of human experts. Towards that, we propose a deep network that embeds videos using their audio-visual content, onto a metric space.
“Based on theoretical reasoning it has been suggested that the reliability of findings published in the scientific literature decreases with the popularity of a research field”
We propose a ranking-based self-localization scheme for cross-season change detection in a novel generalized setting.
We show that the matching problem that underlies optical flow requires multiple strategies depending on the amount of image motion and other factors. We propose a metric learning method, which selects suitable negative samples based on the nature of the true match.
We propose an efficient limited-memory FGD (L-FGD) method for optimizing graph regularized nonnegative matrix factorization based on Kullback-Leibler divergence.
We study a method to learn the model architectures directly on the dataset of interest and then transfer the block to a larger dataset.
We propose DoPa - a fast and comprehensive CNN defense methodology against physical adversarial attacks.
We propose to accelerate semi-supervised learning with Stochastic Weight Averaging and fast-SWA, which accelerate convergence on the consistency loss.
We propose an end-to-end trainable neural architecture for text-driven 3D mouth animations that improves users' comfort for 78% of the candidates significantly.
Automated theorem proving in large theories can be learned via reinforcement learning over an indefinitely growing action space. Here we address the exploration for reinforcement learning in this space.
In order to improve distance based embedding, we propose multi-distance embeddings (MDE) based on the idea that by learning independent embedding vectors for each entity and relation one can aggregate contrasting distance functions.
We propose a two level hierarchical deep learning architecture inspired by divide & conquer principle that decomposes the large scale recognition architecture into root & leaf level model architectures. The proposed architecture classifies objects in two steps.
We present a real-time 3D shape search engine based on the projective images of 3D shapes, which combines GPU acceleration and Inverted File (Twice) for fast retrieval.
We propose SpeechBERT, a cross-modal transformer-based pre-trained language model for end-to-end spoken question answering tasks.
We propose a novel momentum-SGD-based optimization method to reduce the network complexity by on-the-fly pruning.
We present Transflow Learning, a method for transforming a pre-trained generative model so that its outputs more closely resemble data that we provide afterwards.
This paper proposes a modular method that utilises a model of the environment to aid motion prediction of tracked agents in interactive environments.
We propose an efficient confidentiality metric based on the visual saliency diffusion. We show experimentally that this metric is well correlated with a MOS and efficient to evaluate the confidentiality of selective crypto-compressed JPEG images.
We propose an effective active learning algorithm which learns the best possible target classification model from a set of unlabeled data.
We present DeepSeek a natural language processing based deep learning model that allows users to enter a description of the kind of images that they want to search, and in response the system retrieves all the images that semantically and contextually relate to the query.
We propose a new dense-stereo matching algorithm, tMGM, that achieves 6-8\% performance improvement over the baseline SGM in the presence of illumination variations and shadows, untextured or weakly textured regions, and large stereo rectification errors.
We propose a novel algorithm for resource-constrained filter pruning where meta-learning is involved to determine better solutions. The proposed algorithm is superior to prior art in both effectiveness and efficiency.
A genetic programming framework for convolutional neural network architecture search, abbreviated as GP-CNAS, is proposed to automatically search for optimal CNN architectures.
In video understanding, action spotting consists in temporally localizing human-induced events annotated with single timestamps. In this paper, we propose a loss function that specifically considers the temporal context naturally present around each action, rather than focusing on the single annotated frame to spot.
We define the object detection from imagery problem as estimating a very large but extremely sparse bounding box dependent probability distribution. We introduce two novelties, a corner based region-of-interest estimator and a deconvolution based CNN model.
Feature reuse methods increase the number of parameters, but they increase the network performance. We solved the problem and constructed two novel neural networks.
We address the problem of learning vector representations for complex semantic parses that consist of multiple entities and relations. We use Gated Graph Neural Networks to encode the graph structure of the semantic parse.
The paper proposes a robust framework for 3D facial movement tracking in real time using a monocular camera.
This study explores the use of photometric techniques (shape-from-shading and uncalibrated photometric stereo) for upsampling the low-resolution depth map from an RGB-D sensor to the higher resolution of the companion RGB image.
We present a simple-yet-effective gradual channel pruning while training methodology using a novel data driven metric referred as Feature relevance score, which achieves significant model compression while trading off less than $1% accuracy.
This research proposes a distinctive deep learning network architecture for image captioning and description generation.
In academia, scientific research achievements would be inconceivable without academic collaboration and cooperation among researchers. However, it is often difficult and time-consuming for researchers to find the most valuable collaborators (MVCs) from a large volume of big scholarly data. In this paper, we present MVCWalker, an innovative method that stands on the shoulders of random walk with restart (RWR) for recommending collaborators to scholars.
We propose a new action and gesture recognition method based on spatio-temporal covariance descriptors and a weighted Riemannian locality preserving projection approach that takes into account the curved space formed by the descriptors.
A hybrid approach for unsupervised and unrestricted relation discovery between entities using output from linguistic analysis and semantic typing information from a knowledge base.
We present SQUASH (Specificity-controlled Question-Answer Hierarchies), a new text generation task that converts an input document into a hierarchy of question-answer pairs.
In this paper, we introduce the STN-Homography model to directly estimate the homography matrix between image pair.
 modEnrichr leverages existing model organism databases and other resources to facilitate comprehensive hypothesis generation through data integration.
In this paper, we propose a novel Question-Guided Hybrid Convolution (QGHC) network for Visual Question Answering.
We present a deep learning framework, called DuLa-Net, to predict Manhattan-world 3D room layouts from a single RGB panorama, using a novel feature fusion structure.
This paper focuses on the assumption that the singularity of the ratings cast by the users of the group is relevant information for finding suitable neighbors.
Multi-Instance Dictionary Learning (MIDL) for detecting abnormal events in crowded video scenes.
We present function preserving projections (FPP), a scalable linear projection technique for discovering interpretable relationships in high-dimensional data.
We present a modern scalable reinforcement learning agent called SEED (Scalable, Efficient Deep-RL). By effectively utilizing modern accelerators, we show that it not only possible to train on millions of frames per second but also to lower the cost.
We analyze the effect of a Sybil attack on similarity metrics used to identity users with similar tastes in the trade-off between recommendation quality and privacy.
We propose a novel gradient snapping layer to directly regularize the back-propagating gradient towards a neighboring codeword, the generated gradients are un-biased for reducing similarity loss and also propel the learned representations to be accurately quantized.
We improve the robustness of large embeddings by exploiting the independence within ensembles of deep neural networks.
We propose ContCap, a framework for integrating continual learning into image captioning accompanied by tackling catastrophic forgetting.
This work introduces bijective Gated Recurrent Units, a double mapping between the input and output of a GRU layer. This allows for recurrent auto-encoders with state sharing between encoder and decoder, stratifying the sequence representation and helping to prevent capacity problems.
We incorporate regionlets into an end-to-end trainable deep learning framework for accurate generic object detection.
We propose a boosted GAN with semantically interpretable information for image inpainting that can preserve consistency on both attribute and segmentation level.
This paper considers the use of stereo vision in structured environments. Sharp discontinuities and large untextured areas must be anticipated.
We propose a geometry-aware symmetric domain adaptation framework (GASDA) to explore the labels in the synthetic data and epipolar geometry in the real data and generate high-quality depth maps.
We develop an optimal solution named merged-gradient wait-free backpropagation (MG-WFBP) and implement it in our open-source deep learning platform B-Caffe.
In order to better solve the shortcomings of Deep Neural Networks (DNNs) susceptible to adversarial examples, evaluating existing neural network classification performance and increasing training sets to improve the robustness of classification models, we propose two different variants of Partial Swarm Optimization for the targeted and non-targeted attack under conditions of black-box.
Music genre classification is one of the sub-disciplines of music information retrieval (MIR) with growing popularity among researchers, mainly due to the already open challenges.
This paper proposes a novel technique for multiple human action recognition using a new architecture based on 3Dimdenisional deep learning with application to video surveillance systems.
In this survey, according to the main research directions of human body performance capture and animation, we summarize recent advances in key research topics, namely human body surface reconstruction, motion capture and synthesis, as well as physics-based motion simulation, and further discuss future research problems and directions.
This paper describes the system of the team Orange-Deskin, used for the CoNLL 2017 UD Shared Task. We based our approach on an existing open source tool (BistParser), which we modified in or- ::: der to produce the required output.
In this paper, we develop a deep neural network architecture called "CSVideoNet" that can learn visual representations from random measurements for compressive sensing (CS) video reconstruction by leveraging temporal-spatial features.
In this paper we propose an approach to embed multi-dimensional continuous cues in binary feature descriptors used for visual place recognition.
We propose a novel architecture for image captioning with deep reinforcement learning to optimize image Captioning tasks.
We identify a network of subcortical and cortical regions whose collective atrophy is associated with a clinical phenotype encompassing motor and non-motor features.
In this paper, we present Hitachi and Paderborn University's joint effort for automatic speech recognition in a dinner party scenario.
In response to the development of recent efficient dense layers, this paper shows that something as simple as replacing linear components in pointwise convolutions with structured linear decompositions also produces substantial gains in the efficiency/accuracy tradeoff.
We propose a novel optimization formulation LCP2 (low two-hop conductance sets) using the concept of Markov random walk on graphs, which enables simultaneous identification of both dense and sparse modules based on protein interaction patterns in given networks.
We present a novel unsupervised learning method for human action categories. Given a novel video sequence, the algorithm can categorize and localize the human action(s) contained in the video.
This paper proposes a novel model fitting algorithm for 3D facial expression reconstruction from a single image which is robust to scale, rotation and different lighting conditions.
We present a model of visually-grounded language learning based on stacked gated recurrent neural networks which learns to predict visual features given an image description in the form of a sequence of phonemes.
We introduce a natural image prior that directly represents a Gaussian-smoothed version of the natural image distribution. We include our prior in a formulation of image restoration as a Bayes estimator that also allows us to solve noise-blind image restoration problems.
We make a thorough investigation into the decoder of a video captioning model and adopt three techniques to improve the performance of the model.
We introduce a novel loss max-pooling concept for handling imbalanced training data distributions, applicable as alternative loss layer in the context of deep neural networks for semantic segmentation.
We introduce a new loss function which substitutes this hyperparameter by a parameter that automatically adapted during the training progress and controls the amount of focusing on hard training examples.
In this paper, we introduce an attribute-based interactive image search which can leverage human-in the-loop feedback to iteratively refine image search results.
This paper proposes a novel method to capture the shared features between them as the basis for inferring missing relations for Knowledge Base completion.
Learning with non-modular losses is an important problem when sets of predictions are made simultaneously. The main tools for constructing convex surrogate loss functions for set prediction are margin rescaling and slack rescaling, but these strategies lead to tight convex surrogates iff the underlying loss function is increasing in number of incorrect predictions.
We propose a learning-based, multi-view dense depth map and odometry estimation method that uses Recurrent Neural Networks (RNN) and trains utilizing multi-View image reprojection and forward-backward flow-consistency losses.
Stereo correspondence is a computationally intensive algorithm and requires high-end hardware resources in order to achieve real-time processing speed in embedded computer vision systems. This paper presents an overview of the use of edge information as a means to accelerate hardware implementations of stereo correspondence algorithms.
We propose a novel three-phase action localization framework using multi-stage refinement using a novel non-local pyramid feature under various temporal granularities.
We propose a new architecture for dual-sequence modeling that is based on associative memory which achieves competitive results on textual entailment.
We track a wide variety of statistics related to how frequently MEDLINE indexers refer to MTI recommendations, how well MTI performs against human indexing, and how often MTI is used.
Actor-critic methods can achieve incredible performance on difficult reinforcement learning problems, but they are also prone to instability. To avoid such issues, we propose to regularize the learning objective by penalizing the temporal difference (TD) error of the critic.
We propose the MoCHIN model which is applicable to arbitrary forms of HIN motifs and tackle the problem of user-guided clustering in HIN by using motifs.
We propose new kernels based on PPI, domain, phylogenetic profile, and subcellular localization properties to predict heterodimers, using a machine learning-based approach.
In this paper, we focus on studying the appearing time of different kinds of cars on the road. We propose a fully automatic method to carry out this study.
We analyse MixUp, CutMix, and FMix from an information theoretic perspective, characterising learned models in terms of how they progressively compress the input with depth.
We propose a novel instance based softmax embedding learning method, which directly optimizes the `real' instance features on top of the softmax function. The proposed method performs well for both seen and unseen testing categories with cosine similarity.
We propose Visual Query Detection (VQD), a new visual grounding task that localizes a number of objects in an image.
We introduce a method based on quantum theory to reduce the number of layers to a minimum while maximizing the distinguishability between the multilayer network and the corresponding aggregated graph.
Siamese networks can substantially outperform both classification- and existing similarity-based approaches for authorship attribution on large datasets.
We present a framework capable of tackilng the problem of continual object recognition in a setting which resembles that under whichhumans see and learn.
We make case studies of both benchmarks and design protocols that clarify and qualify the results of previous work by analyzing threats to the validity of previous experimental designs.
We introduce a large-scale and diverse traffic sign benchmark dataset of 100K street-level images around the world that encapsulates diverse scenes, wide coverage of geographical locations, and varying weather and lighting conditions.
We show that incorporating contour integration within artificial vi-sual systems can increase their robustness to adversarial attacks.
We propose a framework based on conditional Generative Adversarial Networks (cGANs) to achieve age progression and regression simultaneously, achieving lifelike face images at desired ages.
We present a simple yet powerful end-to-end convolutional neural network for instance level Segmentation.
In this paper, we propose a novel 3D human pose estimation algorithm from a single image based on neural networks.
We aim to build complex humanoid agents that integrate perception, motor control, and memory. We develop an architecture capable of surprisingly flexible, task-directed motor control of a relatively high-DoF humanoid body by combining pre-training of low-level motor controllers with a high-level,task-focused controller.
We study online social networks in which relationships can be either positive (indicating relations such as friendship) or negative (indicators of opposition or antagonism) and find that the signs of links in the underlying social networks can be predicted with high accuracy.
We present a human-guided planner for non-prehensile manipulation in clutter that can solve the problem faster and with higher success rates.
We propose DeepEM, a novel deep 3D ConvNet framework augmented with expectation-maximization (EM), to mine weakly supervised labels in EMRs for pulmonary nodule detection.
Scale-aware Face Detector to handle scale explicitly using CNN, and achieve better performance with less computation cost.
This paper proposes a segregated temporal assembly recurrent (STAR) network for weakly-supervised multiple action detection.
We extend the state-of-the art HPE model of Yang and Ramanan to include appearance sharing cues and demonstrate on the highly challenging Leeds Sports Poses dataset that they lead to better results than traditional single-image pose estimation.
We propose a novel approach which uses image semantics to generate visual multiple choice questions (VMCQs) for young learners, wherein options are presented in the form of images.
In this paper, we propose a novel training procedure for image captioning models based on policy gradient methods, which allows us to directly optimize for metrics of interest, rather than just maximizing likelihood of human generated captions.
This article aims to provide a comprehensive review of the state-of-the-art tracking methods, and classify these methods into different categories, and identify new trends.
In this work, we present X-SQL, a new network architecture for the problem of parsing natural language to SQL query.
We study the problem of injecting knowledge into large pre-trained models like BERT and RoBERTa. We propose K-Adapter, which remains the original parameters of the pre- trained model fixed and supports continual knowledge infusion.
We construct a novel measure of performance of a GAN by comparing geometrical properties of the underlying data manifold and the generated one, which provides both qualitative and quantitative means for evaluation.
We propose a holistic and novel generator-evaluator framework that incorporates the {\it structure} and {\it semantics of the question being generated.
We propose a novel re-identification method to exploit the full information encoded in a deep feature to boost the re-ID performance.
This paper focuses on verifying the robustness and reliability of state-of- the-art deep neural network watermarking schemes.
We propose the contextual multi-scale region convolutional 3D network (CMS-RC3D) for activity detection.
Sequeval is an online evaluation framework for sequence-based recommender systems capable of suggesting sequences of items, and it aims to become a focal point for researchers and practitioners when experimenting with these systems.
We propose an adversarial learning method for domain adaptation in the context of semantic segmentation.
We demonstrate that LTC-CNN models with increased temporal extents improve the accuracy of action recognition.
We propose a novel unsupervised learning approach to build features suitable for object detection and classification. The features are pre-trained on a large dataset without human annotation and later transferred via fine-tuning.
We propose Conditional Similarity Networks that learn embeddings differentiated into semantically distinct subspaces that capture multiple notions of similarities.
Unsupervised domain adaptation enables to alleviate the need for pixel-wise annotation in the semantic segmentation.
We propose to use a network of asynchronous cameras to estimate the motion of the vehicle and to find the 3D structure of the scene around it (for example for obstacle detection).
A novel deep Emotion-Conditional Adaption Network to learn domain-invariant and discriminative feature representations, which can match both the marginal and the conditional distributions across domains simultaneously.
This study proposes an emotion recognition system for a humanoid robot, based on a deep neural network, and it uses this system to recognize users’ emotions and responds appropriately.
We propose to learn a low dimensional and rich feature representation of the environment by training an encoder-decoder deep neural network to predict multiple application relevant factors such as trajectories of other agents.
In this paper, we propose a new task, ie, simultaneously object localization and counting, abbreviated as Locount, which requires algorithms to localize groups of objects of interest with the number of instances.
We explore a variety of nearest neighbor baseline approaches for image captioning. These approaches find a set of nearest Neighbor images in the training set from which a caption may be borrowed for the query image.
This paper proposes a novel framework for optimizing the latent representations with respect to the \textit{analogical} properties of the embedded entities and relations in knowledge graphs.
Compressing word embeddings is important for deploying NLP models in memory-constrained settings. We propose the eigenspace overlap score as a new measure of compression quality, and use it as a selection criterion for a simple uniform quantization compression method, helping explain the strong empirical performance of this method.
This work explores the binarization of the deconvolution-based generator in a GAN for memory saving and speedup of image construction.
We propose a method for augmenting and training CNNs so that their learned features are compositional, improving their performance over non-compositional baselines.
We propose a novel multi-task deep model to learn high-level features from multiple tasks and multiple data sources for pedestrian detection.
This paper presents PreVIous, a methodology to predict the performance of convolutional neural networks (CNNs) in terms of throughput and energy consumption on vision-enabled devices for the Internet of Things.
We propose a novel general framework for estimating and analysing the elliptical mixture model, achieved through the Riemannian manifold optimisation, achieved in a fast and stable way.
We condition this process on language, allowing end users to manipulate a colorized image by feeding in different captions.
This paper proposes Auto-Ensemble to collect checkpoints of deep learning model and ensemble them automatically by adaptive learning rate scheduling algorithm.
This work combines Convolutional Neural Networks (CNNs), clustering via Self-Organizing Maps (SOMs) and Hebbian Learning to propose the building blocks of convolutional self-organizing neural networks (CSNNs), which learn representations in an unsupervised and Backpropagation free manner.
In this paper, we propose FuseInit, a novel method to initialize shallower networks by fusing neighboring layers of deeper networks that are trained with random initialization.
The multi-granularity training algorithm modifies the mechanism by which negative candidate responses are sampled in order to control the granularity of learned latent representations of language.
We introduce a self-supervised strategy for graph representation learning by exploiting natural supervision provided by the data itself.
We propose an end-to-end unsupervised attribute learning approach to efficiently discover and learn semantic attributes at a large scale.
In this paper, we propose a novel record entity topic model for IoT environment that is associated with a set of entities and records and a Gibbs sampling-based algorithm is proposed to learn the model.
We create a new NLI test set that shows the deficiency of state-of-the-art models in inferences that require lexical and world knowledge, failing to capture many simple inferences.
In this paper, we make the first attempt to train an image captioning model in an unsupervised manner, without any caption annotations.
We propose a graph generative model for conditional graph generation that is computationally efficient and enables direct optimisation of the graph.
We develop a cross-species in silico model that assigns likelihood scores to individual protein pairs based on the information entirely extracted from model organisms for protein-protein interaction inference.
Pyramidal RoR network optimization method for image classification.
We propose a depth-aware gating module that adaptively selects the pooling field size in a convolutional network architecture according to the object scale (inversely proportional to the depth) so that small details are preserved for distant objects while larger receptive fields are used for those nearby.
This paper investigates a new research direction in face super-resolution, called Reference based face Super-Resolution (RefSR), in which a reference facial image containing genuine attributes is provided in addition to the low-resolution images for super- resolution.
We propose AutoML for Model Compression (AMC) which leverage reinforcement learning to provide the model compression policy and achieve 1.81x speedup of measured inference latency on an Android phone and 1.43x speed up on Titan XP GPU.
We present a method of filtering dialog datasets by removing generic utterances from training data using a simple entropy-based approach that does not require human supervision, and compare dialog models across 17 evaluation metrics.
We apply a spherical hashing binary code embedding technique, to compactly encode data without significantly losing classification accuracy.
Learning powerful discriminative features for remote sensing image scene classification using attention information encoded CNN models.
In this paper, we propose LCANet, an end-to-end deep neural network based lipreading system which achieves a 1.3% improvement compared to the state-of-the-art methods.
Age estimation is a technique for predicting human ages from digital facial images, which analyzes a person's face image and estimates his/her age based on the year measure. Age synthesis is defined to render a facial image aesthetically with rejuvenating and natural aging effects.
We present a novel depth and depth-color codec aimed at free-viewpoint 3D-TV. The proposed codec uses a shape-adaptive wavelet transform and an explicit encoding of major depth edges.
We propose a new way of incorporating temporal information present in videos into Spatial Convolutional Neural Networks (ConvNets) trained on images, that avoids training Spatio-Temporal ConvNets from scratch.
This paper proposes a novel sample-consensus pixel-based technique for efficient foreground segmentation complemented with faster ghost suppression.
Neural Processes suffer from underfitting, giving inaccurate predictions at inputs of the observed data they condition on. We address this issue by incorporating attention into NPs, allowing each input location to attend to the relevant context points for the prediction.
An elastic architecture transfer mechanism for accelerating large-scale neural architecture search (EAT-NAS)
In recent years, there has been a rapid increase in the number of service robots deployed for aiding people in their daily activities. Unfortunately, most of these robots require human input for training in order to do tasks in indoor environments. Successful domestic navigation often requires access to semantic information about the environment, which can be learned without human guidance. In this paper, we propose a set of DEDUCE1 -Diverse scEne Detection methods
We propose to use preprocessed images to train a forensic CNN model to detect GAN generated face images.
In this paper, we propose the first “in-the-wild” 3DMM by combining a statistical model of facial identity and expression shape with an "in- the-wild" texture model. We show that such an approach allows for the development of a greatly simplified fitting procedure for images and videos.
We propose a novel 3D-RPN framework able to regress and classify whole video subsets, so providing a truly optimal solution of the action detection problem.
Synaptic plasticity does not improve the performance on sensory pattern recognition tasks that include complex, real-world sensory data.
Knowledge distillation is a widely used technique for model compression. We posit that the teacher model used in a distillation setup captures relationships between classes, that extend beyond the original dataset.
We propose a temporal encoder-decoder network architecture that encodes RGB frames from the past and decodes the future semantic segmentation. The network is coupled with a knowledge distillation training framework specifically for the forecasting task.
In this paper, we investigate how to learn the reconstruction function from the data automatically for unsupervised feature selection, and propose a novel reconstruction-based unsuper supervised feature selection framework REFS, which embeds the reconstruction Function learning process into feature selection.
P53 overexpression, and subsequent increase in caspase-3 expression, in dorsal root ganglion neurons led to increased apoptotic changes in these neurons.
Feature pyramid Siamese network for multiple object tracking based on the tracking-by-detection paradigm.
We propose an algorithm to decouple the human reporting bias from the correct visually grounded labels for image classification and captioning.
We investigate and address computational inefficiencies that arise from adding process noise to deterministic simulators that fail to return for certain inputs; a property we describe as"brittle."
We present a variational approximation to the information bottleneck model using a neural network and leverage the reparameterization trick for efficient training.
We consider the problem of training generative models with a Generative Adversarial Network (GAN) as a mixed strategy in a zero-sum game.
We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB) and propose a neural module, DrKIT, that traverses textual data like a virtual KB, softly following paths of relations between mentions of entities in the corpus.
In this paper, a novel encoding scheme combining Fisher vector and bag-of-words encodings has been proposed for recognizing action in videos.
Bayesian optimization over the latent space of a variational autoencoder can produce invalid molecular structures. We propose a constrained Bayesian optimization problem that mitigates the effects of this pathology.
This short paper presents an efficient, flexible implementation of the SRP-PHAT multichannel sound source localization method.
We propose a universal end-to-end mapping from the blurred image to the dense motion flow which allows the model to focus on the cause of the blur, irrespective of the image content.
We present a fine-grained gating mechanism to dynamically combine word-level and character-level representations based on properties of the words for reading comprehension tasks.
Our interactive approach is able to iteratively cluster classes of images and video without tirelessly labelling the content.
We propose a self-updating algorithm, able to keep over time the expressive power of a limited set of templates stored in the system database, which can overcome the problem of manual updating and, in case, stringent computational requirements.
Exploring single image super-resolution using convolutional neural networks for iris recognition.
We propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30% relative to the previous best result on the canonical PASCAL VOC dataset.
We examine Generative Adversarial Networks (GANs) through the lens of deep Energy Based Models (EBMs), with the goal of exploiting the density model that follows from this formulation.
We propose a novel two-stream deep neural network with RGB-grey information, which can effectively fuse RGB and greyscale feature representations to enhance the generalization ability of Re-ID.
An ontology enrichment pipeline that can automatically enrich a domain ontology using: data extracted by a crawler from social media applications, similarity measures, the DBpedia knowledge base, a disambiguation algorithm and several heuristics.
NeuronBlocks is a toolkit encapsulating a suite of neural network modules as building blocks to construct various DNN models with complex architecture.
We propose to solve these tasks jointly using multi-task learning, and show that our models achieve state-of-the-art performance for formality transfer and formality-sensitive translation.
We propose the Simple Recurrent Unit (SRU), a light recurrent unit that balances model capacity and scalability.
This paper proposes a novel Representative Region NMS approach leveraging the less occluded visible parts, effectively removing the redundant boxes without bringing in many false positives.
We have surveyed over 220 works to comprehensively and systematically study the crowd counting models, mainly CNN-based density map estimation methods. We select the top three performers on their crowd counting datasets and analyze their merits and drawbacks.
HAPPI database version 2.0 is a major update to the original HAPPI 1.0 database. It contains 2,922,202 unique protein-protein interactions (PPI) linked by 23,060 human proteins.
We present Label Diffusion Lidar Segmentation (LDLS), a novel approach for 3-D point cloud segmentation, which leverages 2-D segmentation of an RGB image from an aligned camera to avoid the need for training on annotated3-D data.
Detecting human bodies in highly crowded scenes is a challenging problem. Two main reasons result in such a problem: 1). weak visual cues of heavily occluded instances can hardly provide sufficient information for accurate detection; 2). heavily occLuded instances are easier to be suppressed by Non-Maximum-Suppression (NMS)
In this paper, we propose a novel method called multiple deep networks with scatter loss and diversity combination for solving the HFR problem.
We address this problem using a flexible approach that enables existing deep captioning architectures to take advantage of image taggers at test time, without re-training.
We use a multi-level voxel representation for learning from 3D data that captures important features in the data in a memory efficient way in comparison to an octree representation.
Pre-trained Transformer-based auto-regressive language models for the task of open-domain dialogue generation.
We proposed a computational method, GIC (Gene Importance Calculator), which can efficiently predict the essentiality of both protein-coding genes and long noncoding RNAs (lncRNAs) based on only sequence information.
We propose a novel CNN architecture called ACTNET for robust instance image retrieval from large-scale datasets. Our key innovation is a learnable activation layer designed to improve the signal-to-noise ratio of deep convolutional feature maps.
In this paper, we adopt a collaborative filtering-like recommendation approach, which exploits both existing dataset profiles, as well as traditional dataset connectivity measures, in order to link arbitrary, non-profiled datasets into a global dataset-topic graph.
We propose using $\mathcal D_T$ to probe, attend to, and borrow fragments from any large, topic-rich source corpus (such as Wikipedia), which need not be the corpus used to pretrain embeddings.
We propose to use an adversarial examiner in the testing stage to identify the weakness of the model to be evaluated, preventing performance estimates from being overly optimistic.
We propose a general training framework named self distillation, which notably enhances the performance (accuracy) of convolutional neural networks through shrinking the size of the network rather than aggrandizing it.
We propose an approach that jointly tackles object-level image segmentation and semantic region labeling within a conditional random field (CRF) framework for holistic road scene understanding.
We use motifs to capture higher-order relations between nodes in a network and introduce two methods, one linear and one non-linear, to combine PageRank with higher- order relations.
We use the rotations and local square root velocities of local reference frames as the proposed descriptor to characterize the position and orientation changes of the moving points along the motion trajectories.
We formalize a large-scale approach based on a hierarchical tree-like organization of the images computed off-line, and propose a versatile modulation of the exploration/exploitation trade-off based on the consistency of the system internal states.
We establish a formal connection between MTDNN with infinitely-wide hidden layers and multitask Gaussian Process (GP) and propose an adaptive multitask neural network architecture that corresponds to a multitask GP.
We address the problem of recognizing future actions, indeed human intentions, underlying a same initial (and apparently unrelated) motor act, even when different intentions originate from a same class of movements.
In this paper we investigate what can be learnt by looking at a large number of figures and reading their captions, and introduce a figure-caption correspondence learning task that makes use of our observations.
This paper proposes the use of memory slices, a modular building block for scalable memory systems integrated with compute, in which performance scales with memory size.
Data-to-data translation, i.e. learning a mapping from an input domain to a fair target domain, where a fairness definition is being enforced.
We propose a method for selecting home appliances using a smart glass, which facilitates the control of network-connected appliances in a smart house.
Driver decisions and behaviors are essential factors that can affect the driving safety. To understand driver behaviors, a driver activities recognition system is designed based on the deep convolutional neural networks (CNN) in this paper.
In this paper, we propose a single-shot instance segmentation method, which is simple, fast and accurate.
We present an algorithm to directly solve numerous image restoration problems (e.g., image deblurring, image dehazing, image deraining, etc.) using generative adversarial networks.
This paper presents a general overview of automatic RGB, 3D, thermal and multimodal facial expression analysis. We define a new taxonomy for the field, encompassing all steps from face detection to facial expression recognition.
We propose a novel recurrent encoder-decoder network model for real-time video-based face alignment using recurrent learning at both spatial and temporal dimensions.
This paper proposes a new method for interpreting and simplifying a black box model of a deep random forest (RF) using a proposed rule elimination.
Handl expands the notion of homology through explicit measures of functional similarity between proteins in different species, generating new phenologs supported from the biological literature.
We introduce the Hardware-Aware Automated Quantization framework which leverages the reinforcement learning to automatically determine the quantization policy, and we take the hardware accelerator's feedback in the design loop.
Rectified activation units (rectifiers) are essential for state-of-the-art neural networks. In this work, we study rectifier neural networks for image classification from two aspects.
To produce a domain-agnostic question answering model for the Machine Reading Question Answering 2019 Shared Task, we investigate the relative benefits of large pre-trained language models, various data sampling strategies, as well as query and context paraphrases generated by back-translation.
We propose a joint projection and low-rank dictionary learning method using dual graph constraints for object classification of small-sized and high-dimensional data sets.
We show that perceptually-aligned gradients occur under randomized smoothing, an alternative means of constructing adversarially-robust classifiers.
This paper proposes an improved training algorithm for binary neural networks in which both weights and activations are binary numbers and propose several ways of constructing the shape of the scale factors while keeping the computational budget fixed.
In this paper, a new nonlinear subspace learning technique for class-specific data representation based on an optimized class representation is described.
We investigate the use of machine learning to generalize metadata from a subset of labeled data, thus increasing the availability of meaningful metadata for search.
We present an automatic method to detect keypoints on 3D faces, where these keypoints are locally similar to a set of previously learnt shapes, constituting a 'local shape dictionary'.
This paper presents a novel stereo-based visual odometry approach that provides state-of-the-art results in real time, both indoors and outdoors.
We address the new problem of the prediction of human intents by only analysing very similar movements in both training and test phases, where we are able to predict the underlying intent, i.e., the future, never observed action.
We propose a generalized topic modeling approach based on Latent Dirichlet Allocation (LDA) named as Conference Mining (ConMin) which can discover topically related conferences, conferences correlations and conferences temporal topic trends.
The authors propose a new method for sclera quality measure and segmentation under relaxed imaging constraints, using pixel properties of both the sclacea area and the skin around the eye.
We propose a new real-time audio single-source classification method based on a dictionary of sound models (that can be extended to a multi-source setting).
We use keypoint estimation to find center points and regresses to all other object properties, such as size, 3D location, orientation, and even pose.
We propose a small-footprint multiple instance learning (MIL) framework for multi-class AED using weakly labeled labels.
We generalize Key-Value Memory Networks to a multimodal setting, introducing a novel key-addressing mechanism to deal with sequence-to-sequence models.
We propose an iterative algorithm inspired by classic iterative linear solvers that uses a probabilistic model to actively infer a pre-conditioner in situations where Hessian-projections can only be constructed with strong Gaussian noise.
We propose block sub-image annotation as a replacement for full- image annotation. Despite the attention cost of frequent task switching, we find that block annotations can be crowdsourced at higher quality with equal monetary cost.
We propose Deeply-supervised Nonlinear Aggregation (DNA) for better leveraging the complementary information of various side-outputs.
We propose a simple but general neural model composed of fixed-size ordinally forgetting encoding (FOFE) and deep neural networks, called FOFE-net, to solve KB-QA problem at different stages.
We propose a post-processing approach to improve scene text recognition accuracy by using occurrence probabilities of words (unigram language model), and the semantic correlation between scene and text.
This paper proposes a novel non-local fully convolutional network architecture for video salient object detection and investigates its effect on static and dynamic saliency detection in order to exploit both appearance and motion features.
We revisit the Bellman optimality equation and reformulate it into a novel primal-dual optimization problem using Nesterov's smoothing technique and the Legendre-Fenchel transformation, where any differentiable function class may be used.
In this paper, we propose a novel approach for video representation that captures meaningful information including motion and appearance from a sequence of video frames and compacts it into a single image.
In this work, we focus on a challenging task: synthesizing multiple imaginary videos given a single image.
We propose the Aggregated Residual Dilation based Feature Pyramid Network (ARDFPN) to exploit the inherent correlation of regions in feature pyramid.
We propose a novel Multi-Level Recurrent Residual Networks(MRRN) which incorporates three recognition streams and captures spatiotemporal information.
We propose a method with temporal boundary regression based on time series segmentation, which can generate proposals with flexible temporal duration and improve the classification accuracy.
We present FewShotWoz, the first NLG benchmark to simulate the few-shot learning setting in task-oriented dialog systems. Further, we develop the SC-GPT model, which can generalize well with limited labelled data in real applications.
In this paper, we present LidarStereoNet, the first unsupervised LIDar-stereo fusion network, which can be trained in an end-to-end manner without the need of ground truth depth maps.
We introduce an alternative GAN based approach for building a robust classifier, where the idea is to use the GAN to explicitly generate out of distribution samples that the classifier is confident on (low entropy), and maximize the entropy for these samples.
We propose an alternative Wasserstein distance in discrete time based on the conclusion that the Jordan-Kinderlehrer-Otto discrete flow approximates KL discrete flow when the time step size tends to 0.
The goal of this paper is to embed RGB and optical-flow into a single two-in-one stream network with new layers for fast action detection.
We propose a new regularizer called DeCov which encourages diverse or non-redundant representations in Deep Neural Networks by minimizing the cross-covariance of hidden activations.
We propose an instance-aware GAN that incorporates the instance information and improves multi-instance transfiguration in image-to-image translation.
We propose a sequential gating ensemble network for a multiscale noise robust face restoration issue.
We propose an online module with an attention mechanism for offline siamese networks to extract target-specific features under L2 error, and a template update strategy to handle large target deformations for robust learning.
We propose the first method for certifiable (non-)robustness of graph convolutional networks with respect to perturbations of the node attributes and propose a robust semi-supervised training procedure.
In this paper we introduce Chat-crowd, an interactive environment for visual layout composition via conversational interactions.
Adaptive occlusion state behavior recognition based on Markov random field and probabilistic Latent Semantic Analysis for self-occlusion .
In this paper, we design a causal and simple approach for mitigating gender bias in word vector relation by utilizing the statistical dependency between gender-definition word embeddings and gender-biased word embedDings.
This paper proposed a novel automatic retinal segmentation approach based on Gabor wavelet.
This paper presents a new stereo matching algorithm based on inter-regional cooperative optimization. The proposed algorithm uses regions as matching primitives and defines the corresponding region energy functional for matching.
There are some inadequacies in the language description of this paper that require further improvement.
We address the unsupervised learning of several interconnected problems in low-level vision: single view depth prediction, camera motion estimation, optical flow, and segmentation of a video into the static scene and moving regions.
We present a complete mapping and long-term localization system based on pole landmarks extracted from 3-D lidar data for vehicle localization in urban environments.
We propose a new weak supervision approach that does not require modification of the segmentation training procedure and achieves 95% quality.
We propose a novel hand Gesture Generative Adversarial Network (GestureGAN), which learns the gesture-to-gesture mapping through two novel losses, the color loss and the cycle-consistency loss.
In this paper, a method is proposed that selects and evaluates a subset of words from an initially large codebook, without the need for re-coding or re-pooling.
In this work, we introduce VQA 360, a novel task of visual question answering on 360 images, demanding more sophisticated spatial understanding and reasoning.
We present a novel real-time capable machine learning-based method for depth map fusion which efficiently handle sensor-specific noise and outliers.
In the face of the video data deluge, today's expensive clip-level classifiers are increasingly impractical. We propose a framework for efficient action recognition in untrimmed video that uses audio as a preview mechanism to eliminate both short-term and long-term visual redundancies.
We evaluate the insensitivity of different costs for passive binocular stereo methods with respect to radiometric variations of the input images.
We study the effect of using time as a factor in the post training phase and study it further by applying a genre-based filtering mechanism to the system.
We present a Hamming Distance embedding Binary Search Tree approach for binary Descriptor Matching and Image Retrieval in logarithmic time.
We introduce a statistical test for "distribution parity" in the top-K IR results, which assesses whether a given set of recommendations is fair with respect to a specific protected variable.
We propose an end-to-end trainable network for detecting 3D object in point clouds without exploiting their relationships during learning or inference.
In this work we explore how the architecture proposed in [8], which expresses the processing steps of the classical Fisher vector pipeline approaches, i.e. dimensionality reduction by principal component analysis (PCA) projection, Gaussian mixture model (GMM) and Fisher vector descriptor extraction, can be modified into a hybrid network that combines the benefits of both unsupervised and supervised training methods.
Data seems cheap to get, and in many ways it is, but the process of creating a high quality labeled dataset from a mass of data is time-consuming and expensive.
In this paper, we address this problem by introducing a new network comparison methodology that identifies common organizational principles in networks.
We propose a flexible framework that focuses on the language part of VQA that uses semantically relevant questions, dubbed basic questions, acting as controllable noise to evaluate the robustness of V QA models.
We attempt to interpret how adversarially trained convolutional neural networks (AT-CNNs) recognize objects and compare them with normally trained models.
We apply a stage-wise approach to fine tuning BERT on multiple datasets, starting with data that is"furthest"from the test data and ending with the"closest" from test data.
In this paper, we estimate state value without using a parametrized value estimator and extend n-step training for image captioning.
We propose a learning-based method for estimating 2D human pose from a single image, using Dual-Source Deep Convolutional Neural Networks (DS-CNN).
This paper revisits some assumptions proposed in this context regarding the handling of "visual burstiness", and shows that ad-hoc choices are implicitly done which are not desirable.
This paper proposes a strategy for visual prediction in the context of autonomous driving that learns compact representations which are not neutral but oriented to driving tasks, from two distinct perspectives.
We find that fine-tuning a pruned model only gives comparable or worse performance than training that model with randomly initialized weights.
The analysis of facial expression temporal dynamics is of great importance for many real-world applications. Being able to automatically analyse facial muscle actions (Action Units, AUs) in terms of recognising their neutral, onset, apex and offset phases would greatly benefit application areas as diverse as medicine, gaming and security.
We present a novel method for learning the weights in multinomial logistic regression based on the alternating direction method of multipliers (ADMM), which leads to faster convergence.
We introduce the task of scene-aware dialog. Our goal is to generate a complete and natural response to a question about a scene, given video and audio of the scene and the history of previous turns in the dialog, using contextual cues from the dialog history.
We propose Invariant Encoding Generative Adversarial Networks (IVE-GANs), a novel GAN framework that introduces such a mapping for individual samples from the data by utilizing features in the data which are invariant to certain transformations.
In this paper, we describe Hydra, an ensemble of convolutional neural networks for geospatial land classification.
We introduce RecLab, an open source software for evaluating recommender systems in a distributed fashion. The results of all experiments are permanently stored and publicly available.
We propose a 3-D cuboid bi-level Laplacian-of-Gaussian (CBLoG) operator with high speed and invariant space–time scale for detecting abrupt changes of signals in videos.
In this paper we present a compact 3D Convolutional Neural Network (CNN) architecture for long-term activity recognition in egocentric videos.
Data augmentation is conventionally used to inject robustness in Speaker Verification systems. This work analyzes various facets of that approach and asks few novel questions in that context.
We propose a knowledge-enhanced graph neural network (KGNN), which performs reasoning over multiple paragraphs with entities, which is effective and robust with more retrieved paragraphs.
Knowledge graphs are important resources for many artificial intelligence tasks but often suffer from incompleteness.
This study solves the above-mentioned problems by proposing a novel and robust solution for random bin-picking for planar objects in a cluttered environment.
We propose a Compressed Sensing based Output Encoding (CSOE) scheme, which casts detecting pixel coordinates of small objects into a task of signal regression in encoding signal space, which achieves state-of-the-art performance across four mainstream datasets.
We explore the idea of using only pose, without utilizing any temporal information, for human action recognition.
We propose a method for disease localization in the context of weakly supervised learning, where only image-level labels are available during training. We accomplish this through the use of pre-trained deep convolutional networks, feature embedding, as well as learning via top instances and negative evidence.
In this paper, we derive efficient prediction and learning algorithms for supervised learning with the Canonical Polyadic (CP) decomposition, including suitable regularization and initialization schemes.
We propose a novel deep learning method for shadow removal. Inspired by physical models of shadow formation, we use a linear illumination transformation to model the shadow effects in the image that allows the shadow image to be expressed as a combination of the shadow free image, the shadow parameters, and a matte layer.
In this paper, we propose a sequential and fast graph matching algorithm for GPUs based on sparse local features and hypergraph matching.
Instance segmentation requires a large number of training samples to achieve satisfactory performance and benefits from proper data augmentation. We propose a simple and effective method to augment the training set using the existing instance mask annotations.
TASED-Net is a 3D fully-convolutional network architecture for video saliency detection. The proposed approach assumes that the saliency map can be predicted by considering a limited number of past frames.
We present Multitask Soft Option Learning (MSOL), a hierarchical multitask framework based on Planning as Inference, using separate variational posteriors for each task, regularized by a shared prior.
We explore the rich evidence source of attributes in social networks to improve network embedding. We propose a generic Social Network Embedding framework (SNE), which learns representations for social actors by preserving both the structural proximity and attribute proximity.
We propose a Dense Graph Propagation module with carefully designed direct links among distant nodes to exploit the hierarchical graph structure of the knowledge graph through additional connections.
Convolutional Pose Machine is a popular neural network architecture for articulated pose estimation. In this work we explore its empirical receptive field and realize, that it can be enhanced with integration of a global context.
A new task for empathetic dialogue generation and EmpatheticDialogues, a dataset of 25k conversations grounded in emotional contexts to facilitate training and evaluating dialogue systems.
We introduce a principled approach for unsupervised structure learning of deep neural networks where conditional independencies in the input distribution are encoded hierarchically in the network structure.
We propose a simple model that is able to generate descriptive sentences given a sample image using the phrases inferred.
This paper proposes a novel steganography algorithm based on image-to-image translation, adapting to the covert communication and privacy preserving of the IoT.
We propose algorithms for pre-training hierarchical document representations from unlabeled data which integrate contextual information.
A general Empirical Bayes approach to matrix factorization (EBMF), whose key feature is that it uses the observed data to estimate prior distributions on matrix elements.
JUNR is a rule-based method for line junction detection without prior knowledge of curvilinear structure.
We propose a novel Multi-modal Tensor Fusion Network (MTFN-RR) framework that achieves remarkable matching performance with acceptable model complexity.
In this paper, we propose a novel spatio-temporal feature, based on motion history, which can offer an efficient way to encapsulate temporal texture changes.
We propose a two-dimensional CCA(canonical correlation analysis) framework to fuse monocular images and corresponding depth images for basic computer vision tasks like image classification and object detection.
We provide a unified approach to interpreting the existing nonlocal-based blocks, where we view them as a graph filter generated on a fully-connected graph.
The ability to predict depth from a single image - using recent advances in CNNs - is of increasing interest to the vision community. Unsupervised strategies to learning are particularly appealing.
We propose Contextual Lensing, a methodology for inducing context-oriented universal sentence vectors. We show that it is possible to focus notions of language similarity into small number of lens parameters given a core universal matrix representation.
Zero-shot learning (ZSL) models rely on learning a joint embedding space where both textual/semantic description of object classes and visual representation of object images can be projected to for nearest neighbour search.
This paper proposes Directional Local Pairwise Bases (DLPB) that applies sparse coding to learn a compact set of bases capturing correlation between these descriptors, so to avoid the combinatorial explosion.
In this paper, we propose a Trust-Oriented Social Influence evaluation method, called TOSI, with taking the social contexts into account.
We propose a cascaded framework for GAN that addresses the task of imagining a new distribution that combines the base set X and target set Y in high-level feature space.
This paper studies the problem of embedding very large information networks into low-dimensional vector spaces, which is useful in many tasks such as visualization, node classification, and link prediction.
This paper investigates modifying an existing neural network architecture for static saliency prediction using two types of recurrences that integrate information from the temporal domain.
In this paper, we use a deep LSTM encoder from an attentional sequence-to-sequence model trained for machine translation (MT) to contextualize word vectors.
The objective of this paper is the instantaneous computation of time-to-collision (TTC) for potential collision only from the motion information captured with a vehicle borne camera.
Learning the correlation among labels is a standing-problem in the multi-label image recognition task. FAN builds top-down feature fusion mechanism to refine more important features and learn correlations among convolutional features from FAN to indirect learn the label dependencies.
We propose a novel multi-conditional latent variable model for simultaneous facial feature fusion and detection of facial action units, based on Monte Carlo sampling.
We combine the coarse and fine regression output together for a deep network for head pose estimation without facial landmarks.
We evaluate four Czech text processing tasks: part-of-speech tagging, lemmatization, dependency pars ing and named entity recognition.
We propose a novel weighted bilinear coding framework for local feature aggregation in CNN networks to pursue more representative and discriminative feature representations, which can adapt to other state-of-the-art methods and improve their performance.
In this paper, we propose a new stereo matching algorithm able to reconstruct efficiently a dense disparity maps from few sparse disparity measurements.
Image caption generation in a fully zero-shot learning setting, where the goal is to be able to generate captions of test images containing objects that are not seen during training.
Spectral Dropout improves the generalization ability of deep neural networks by eliminating weak and noisy Fourier domain coefficients.
This work proposes a new approach to train deep neural networks using dictionary learning as the basic building block; the idea is to use the features from the shallow layer as inputs for training the next deeper layer.
This paper presents a pyramid histogram-based confidence map that incorporates structure information into appearance statistics for improved video segmentation performance and reduced manual labeling.
We propose two methods for selecting the most relevant data with weak supervision. The first method is designed for finding visually similar images without the need of labels and is based on modeling image representations with a Gaussian Mixture Model.
This paper tackles the problem of real-time semantic segmentation of high definition videos using a hybrid GPU / CPU approach, while achieving much higher frame rates.
We develop a practical detection system that can verify, with high precision, whether each detection of a machine-learning based object detector is correct.
We address the problem of partial face recognition by using a variable-size description which represents each face with a set of keypoint descriptors.
In this paper, we propose novel edge and corner detection algorithms for unorganized point clouds and propose a novel approach towards automatic weld seam detection for robotic welding.
An end-to-end deep learning framework to turn images that show dynamic content, such as vehicles or pedestrians, into realistic static frames.
In this paper, we propose a method for support vector machine classification using indefinite kernels.
This paper presents PixelBNN, a highly efficient deep method for automating the segmentation of fundus morphologies. The model was trained, tested and cross tested on the DRIVE, STARE and CHASE retinal vessel segmentation datasets.
We propose an iterative algorithm, MCP, based on a cutting plane approach that efficiently solves a quadratic semi-infinite programming problem to find the maximum margin solution to classifying data manifolds where each manifold represents invariances.
We propose a framework that combines an encoder and a generator to learn interpretable, disentangled representations which encode meaningful information about the data distribution without the need for any labels.
We address the problem of active visual exploration of large 360° inputs using a sequence of narrow field-of-view glimpses.
We introduce Embedding from Subword-aware Language Models (ESuLMo) which learns word representation from subwords using unsupervised segmentation over words.
We propose a Seed-Extended algorithm based on Density and Modularity with Topological structure and GO annotations, named SE-DMTG to improve the accuracy of protein complex detection.
We propose a novel ConvNet model for predicting 2D human body poses in an image that achieves state of the art performance.
Combining the outputs of base classifiers trained on different feature types can increase the recall of the combination at high precisions, compared to the performance of a single classifier trained on all the feature types.
In this paper, we propose a method for real-time anomaly detection and localization in crowded scenes, using Gaussian classifiers and sparse auto-encoder.
We propose a hierarchical hierarchical approach for temporal-based action recognition that achieves state-of-the-art performance on high-resolution video.
In this paper, we propose a method which is suitable for edge devices while improving the efficiency and effectiveness of inference.
Deep convolutional networks have access to some local shape information in the form of local edge relations, but no access to global object shapes.
In this paper, we propose Order-Aware Network, which infers the probabilities of correspondences being inliers and regresses the relative pose encoded by the essential matrix.
This paper proposes a novel framework for image classification with an entropy based image semantic cycle that achieves higher classification accuracy.
We propose a new spatial attention pyramid network for unsupervised domain adaptation.
In this paper, we provide a method for understanding the internal representations of Convolutional Neural Networks (CNN) trained on objects.
We introduce entropy-based exploration that enables an agent to explore efficiently the unexplored regions of the state space, which ultimately results in faster learning without having to tune hyperparameters.
Training Spiking Neural Networks in the extreme quantization regime results in near full precision accuracies on large-scale datasets like CIFAR-$100$ and ImageNet.
In this paper, we design and evaluate a convolutional autoencoder that perturbs an input face image to impart privacy.
This paper presents a way to learn a semantic-aware transformation which maps detections from a dashboard camera view onto a broader bird’s eye occupancy map of the scene.
A local ensemble kernel learning technique to recognize/classify objects from a large number of diverse categories.
We introduce Bayesian Convolutional Neural Networks (BayesCNNs), a variant of convolutional neural networks which is built upon Bayes by Backprop, a novel reliable variational inference method.
We provide empirical evidence for a new hypothesis that wide minima generalize better than narrow minima, and propose a novel explore-exploit learning rate schedule that can improve upon this.
This paper contributes by a novel framework for incorporating algebraic invariance structure into kernels.
This paper proposes a two-stage framework that first detects and localizes optic disc and then classifies it into healthy or glaucomatous.
We study how randomized simulated environments and domain adaptation methods can be extended to train a grasping system to grasp novel objects from raw monocular RGB images.
We present PatchNet, a method that provides the features indicative of each class in an image using a tradeoff between restricting global image context and classification error.
Variational auto-encoder (VAE) is a powerful unsupervised learning framework for image generation. We propose to generate images in a multi-stage manner from coarse to fine.
Hsp90 is an essential eukaryotic chaperone with a role in folding specific “client” proteins such as kinases and hormone receptors. Previously performed homozygous diploid yeast deletion collection screens uncovered broad requirements for Hsp90 in cellular transport and cell cycle progression.
We propose a novel data-free method to train the Student from the Teacher via knowledge distillation using the original training data samples.
We develop a principled learning strategy by leveraging curriculum learning, with the goal of handling a massive amount of noisy labels and data imbalance effectively.
We present a novel fusion of neural network based state-of-the-art 3D detector and visual semantic segmentation in the context of autonomous driving.
We propose a novel biphasic learning framework for GANs to achieve image-to-image translation in multiple visual domains at $1024^2$ resolution.
We present a synthetic network, including a symmetric equilibrium generative adversarial network (SEGAN), mul-ti-scale features refine blocks (MSFRB), and attention mechanism (AM) to enhance the performance on retinal fundus vessel segmentation especially for thin vessels.
In this paper, we propose a Dual Focal Loss (DFL) function, as a replacement for the standard cross entropy (CE) function to achieve a better treatment of the unbalanced classes in a dataset.
We propose a simple yet effective proposal-based object detector, aiming at detecting highly-overlapped instances in crowded scenes.
We use ResNet-18 FPN with Cascade R-CNN technique to improve the quality of the classifier and improve the detection accuracy.
We propose an algorithm which detects dense protein sub-networks of which proteins share closely located bottleneck proteins and find protein complexes which allow overlapping with each other.
This paper proposes a novel 3D face reconstruction algorithm (PIFR) based on 3D Morphable Model (3DMM) that solves the problem of face reconstruction of a single image of a traditional method in a large pose.
We introduce the variational filtering EM algorithm, a simple, general-purpose method for performing variational inference in dynamical latent variable models using only past and present variables, i.e. filtering.
The research leading to these results received funding from the European Community's Horizon 2020 programme, AIDE project: "Adaptive Multimodal Interfaces to Assist Disabled People in Daily Activities", grant agreement No: 645322.
We present a novel introspective variational autoencoder (IntroVAE) model for synthesizing high-resolution photographic images.
We show that it is possible to bypass these limitations by learning a data-dependent latent generative representation of model parameters, and performing gradient-based meta-learning in low-dimensional latent space.
We propose the Frame Attention Networks (FAN), to automatically highlight some discriminative frames in an end-to-end framework for facial expression recognition.
We propose a framework which validates robustness of any Question Answering model through model explainers.
We consider the problem of amodal instance segmentation, the objective of which is to predict the region encompassing both visible and occluded parts of each object. Thus far, the lack of publicly available amodAL segmentation annotations has stymied the development of a new method to the best of our knowledge.
We propose a series of recurrent and contextual neural network models for multiple choice visual question answering on the Visual7W dataset, achieving state-of-the-art performance.
In this paper, we address the extraction of the fine-grained attributes of an instance as a `multi-attribute classification' problem.
This work introduces a new curriculum-style training approach in the context of generative-based image inpainting.
We study the vulnerability of LResNet100E-IR with ArcFace loss to adversarial attacks in the physical world.
We develop a new optimization based on partial-sampling from a multinomial distribution combined with straight-through gradient updates, which we name PSST for Partial-Sampling Straight-Through. Together, this approach creates descriptions that are both more discriminative and more natural.
Training a deep architecture using a ranking loss has become standard for the person re-identification task. In this paper we adopt a different approach and carefully design each component of a simple deep architecture and, critically, the strategy for training it effectively for the task.
We propose a new dual-level model that combines handcrafted and raw features for audio signals and achieves state-of-the-art accuracy.
We present a functional form which approximates well the generalization error in practice, and provides accurate predictions from small- to large-scale models and data.
The existing approaches for salient motion segmentation are unable to explicitly learn geometric cues and often give false detections on prominent static objects. We exploit multiview geometric constraints to avoid such shortcomings.
Face synthesis has been a fascinating yet challenging problem in computer vision and machine learning. In this paper, we provide a comprehensive review of typical face synthesis works that involve traditional methods as well as advanced deep learning approaches.
We propose the idea of ‘granularityaware’ groupings where semantically related concepts are grouped across different levels of granularity to capture the variation in how different people describe the same image content.
A number of recent studies have shown that a Deep Convolutional Neural Network (DCNN) pretrained on a large dataset can be adopted as a universal image descriptor, and that doing so leads to impressive performance at a range of image classification tasks.
We found that approach–avoidance modification might result in short-lasting effects on implicit approach tendencies towards feared positive stimuli, but this modification may not result in meaningful behavioral change or symptom reduction in individuals with social anxiety disorder.
We introduce a weakly-supervised learning algorithm leveraging off-the-shelf image caption annotations for fine grained textual summarization.
We propose UMTRA, an algorithm that performs meta-learning on an unlabeled dataset in an unsupervised fashion, without putting any constraint on the classifier network architecture.
Visual memory schema (VMS) maps show which regions of an image cause that image to be remembered or falsely remembered, allowing us to evaluate predicted true memorability and false memorability separately.
We propose a deep learning building block for joint upsampling. The proposed layer is composed of a guided filter, which is reformulated as a fully differentiable block.
In order to learn universal sentence representations, previous methods focus on complex recurrent neural networks or supervised learning. In this paper, we propose a mean-max attention autoencoder (mean-max AAE) within the encoder-decoder framework.
We present the first fully convolutional end-to-end solution for instance-aware semantic segmentation task. It performs instance mask prediction and classification jointly.
In the following paper, we present a framework for quickly training 2D object detectors for robotic perception.
We present a federated meta-learning framework for recommendation in which user information is shared at the level of algorithm, instead of model or data adopted in previous approaches.
Unsupervised diverse colorization of grayscale images using conditional generative adversarial networks .
We apply MBSE methods to Resilience Contracts and simulation-based testing methods to develop resilient automated systems.
In this paper, we explore to train object detectors from scratch robustly, while keeping the favourable performance independent to the network architecture.
We propose to use a GPU with a new Siamese deep learning method to speed up the stereo matching algorithm for autonomous vehicle.
We propose to explore the neighborhood in a reinforcement learning setting and find a walk path well-tuned for classifying the unlabelled target nodes.
We train an embedding function to maximize a metric of local aggregation, causing similar data instances to move together in the embedding space, while allowing dissimilar instances to separate.
In this paper, we extend the kernelized correlation filter (CF) for robust tracking by introducing spatial regularization components to penalize the CF coefficients to improve the effectiveness of tracking.
We investigate training methods for quantized neural networks from a theoretical viewpoint. We first explore accuracy guarantees for training methods under convexity assumptions, and then look at the behavior of these algorithms for non-convex problems.
We release Galactic Dependencies 1.0---a large set of synthetic languages not found on Earth, but annotated in Universal Dependencies format.
We present a generalized convolutional neural network that can be made equivariant to a wide range of spatial transformations.
We extend principal component pursuit to the complex and quaternionic cases to account for the missing phase information and propose new algorithms for both cases.
We propose a fast randomized PCA algorithm for processing large sparse data in less than 400 seconds.
We propose two approaches based on these two algorithms: VDSR-ResNeXt, which is a deep multi-branch convolutional network inspired by V DSR, and SRCGAN, a conditional GAN that explicitly passes class labels as input to the GAN.
We introduce a loss function to handle class imbalance both at class and at an instance level and further demonstrate that penalizing attention masks with high prediction variance accounts for the weak supervision of the attention mechanism.
We propose a key-value attention mechanism that produces separate representations for the key and value of a memory, and for a representation that encodes the next-word distribution for memory-augmented neural language models.
We present a large-scale vehicle detection and counting benchmark, named DroneVehicle, aiming at advancing visual analysis tasks on the drone platform.
We utilize self-attention mechanism, previously used in image inpainting fields, to extract more useful information in each layer of convolution so that the complete depth map is enhanced.
We propose a novel end-to-end question-focused multi-factor attention network for answer extraction, achieving state-of-the-art results on three large-scale QA datasets.
We present a novel network structure called Cascaded Pyramid Network (CPN) which targets to relieve the problem from these "hard" keypoints.
We propose a zero-centered gradient penalty for improving the generalization of GANs by pushing it toward the optimal discriminator.
We propose a neural network for blind image deblurring that achieves state-of-the-art performance and interpretability.
We study this problem in another way: we do not use the logic form any more. Instead we only use the schema and answer info.
We propose a compact and flexible structure, namely Block-Term tensor decomposition, which greatly reduces the parameters of RNNs and improves their training efficiency.
In this paper, we propose an anchor-free lesion detector. The anchor mechanism is removed and lesions are formalized as single keypoints.
We aim at further improvement of SGM accuracy without increasing the computational cost. We propose setting the penalty parameters adaptively according to edge detectors.
We propose a novel visual codebook learning approach using the restricted Boltzmann machine (RBM) as our generative model.
A large amount of training data is usually crucial for successful supervised learning. However, the task of providing training samples is often time-consuming, involving a considerable amount of tedious manual work. As an alternative, in this paper, we propose a cascaded collaborative regression algorithm that can overcome the difficulties caused by pose variations, as well as achieving better accuracy when applied to real faces.
We provide a comprehensive survey of recent Convolutional Neural Network (CNN) based approaches that have demonstrated significant improvements over earlier methods that rely largely on hand-crafted representations.
We introduce an Inception- Recurrent Convolutional Neural Network (IRCNN), which utilizes the power of an inception network combined with recurrent layers in DCNN architecture for better recognition accuracy.
In this paper, we first demonstrate that the minimum-mean-square-error solution to image deblurring can be interestingly unfolded into a series of residual components. Based on this analysis, we propose a novel iterative residual deconvolution algorithm.
In this paper, we propose multimodal convolutional neural networks (m-CNNs) for matching image and sentence.
We propose a human-operator guided planning approach to pushing-based manipulation in clutter. We show that with minimal amount of human input, the low-level planner can solve the problem faster and with higher success rates.
We introduce the Action Transformer model for recognizing and localizing human actions in video clips, outperforming the state-of-the-art using only raw RGB frames as input.
Combining items of clothing into an outfit is a major task in fashion retail. Recommending sets of items that are compatible with a particular seed item is useful for providing users with guidance and inspiration, but is currently a manual process.
We develop the Translate Align Retrieve (TAR) method to automatically translate the Stanford Question Answering Dataset (SQuAD) v1.1 to Spanish and use this dataset to train Spanish QA systems.
We explore the benefits of multi-step greedy policies in model-free RL when employed in the framework of Multi-step Dynamic Programming (DP) and derive fully model free algorithms.
We present a sketch-based approach to procedural modeling in which users are set free from manually adjusting procedural model parameters, yet they are still able to create high quality content.
This paper presents metasketches, a general framework for specifying and solving optimal synthesis problems. We provide two cooperating search algorithms to effectively solve metasketch, and an implementation of these algorithms.
We present a comprehensive study and evaluation of existing single-image dehazing algorithms, using a new large-scale benchmark consisting of both synthetic and real-world hazy images, called REalistic Single-Image DEhazing (RESIDE).
We propose a unified architecture based on Sequence to Sequence models and Pointer Generator Network to handle both simple and complex queries.
We propose a novel facial expression-aware face frontalization method aiming at reconstructing the frontal view while maintaining vivid appearances with regards to facial expressions.
This paper introduces a novel framework to obtain dense depth-map solely from a single LIDAR point cloud using local spatial interpolation, using sliding-window technique, and on the Bilateral Filter.
The proposed MKL-DR approach generalizes the framework of multiple kernel learning for dimensionality reduction, and distinguishes itself with the following three main contributions: First, our method provides the convenience of using diverse image descriptors to describe useful characteristics of various aspects about the underlying data. Second, it extends a broad set of existing dimensionality Reduction techniques to consider multiple Kernel learning, and consequently improves their effectiveness. Third, by focusing on the techniques pertaining to
We extensively compare 30+ state-of-the-art super-resolution Convolutional Neural Networks (CNNs) over three classical and three recently introduced challenging datasets to benchmark single image super- resolution. Despite the progress in recent years, we identify several shortcomings of existing techniques.
This work introduces a novel convolutional network architecture for the task of human pose estimation. Features are processed across all scales and consolidated to best capture the various spatial relationships associated with the body.
We reformulate the self-attention mechanism from the view of the high-order graph and propose a novel method, namely Hierarchical Attention Network (HANet), to address the problem of medical image segmentation.
We present an end-to-end method for generating scene graph representations that can be lifted directly from the top layer of a Transformer.
We propose a QA-based evaluation method which measures the QG model's ability to mimic human annotators in generating QA training data. We propose two ways to generate synthetic QA pairs.
We use simple classifiers to investigate the contents encoded by x-vector embeddings for information related to the speaker, channel, transcription (sentence, words, phones), and meta information about the utterance.
We introduce feature-level data fusion to connected autonomous vehicles for the purpose of enhancing object detection and making real-time edge computing on inter-vehicle data feasible.
We present a new explainable AI (XAI) framework aimed at increasing justified human trust and reliance in the AI machine through explanations. We pose explanation as an iterative communication process, between the machine and human user.
Learning Rate Dropout (LRD), a simple gradient descent technique for training related to coordinate descent, accelerates training while preventing overfitting.
We propose NASS, an integrated framework to search for tailored NN architectures designed specifically for secure inference (SI) schemes.
We introduce a self-monitoring agent with two complementary components: (1) visual-textual co-grounding module to locate the instruction completed in the past, the instruction required for the next action, and the next moving direction from surrounding images and (2) progress monitor to ensure the grounded instruction correctly reflects the navigation progress.
 MF2 is a public large-scale set with 672K identities and 4.7M photos created with the goal to level playing field for large scale face recognition.
The human visual system excels at detecting local blur of visual images, but the underlying mechanism is not well understood. We propose the first end-to-end local blur mapping algorithm based on a fully convolutional network.
In the stereo matching task, matching cost aggregation is crucial in both traditional methods and deep neural network models in order to accurately estimate disparities.
We introduce a data-driven approach to complete partial 3D shapes through a combination of volumetric deep neural networks and 3D shape synthesis, and show extensive evaluations on a newly-introduced shape completion benchmark.
We found a gradient of divergence rates over ontogeny, leading to increased divergence in adults, particularly in the case of reproductive tissues.
Feature boosting and suppression (FBS), a new method to predictively amplify salient convolutional channels and skip unimportant ones at run-time, accelerates convolution by dynamically skipping unimportant input and output channels.
This research was supported by competitive funding from King Abdullah University of Science and Technology (KAUST). Further support was received by the Intelligence Advanced Research Projects Activity (IARPA) via D17PC00280.
In this paper, we propose a novel 3D-RecGAN approach, which reconstructs the complete 3D structure of a given object from a single arbitrary depth view using generative adversarial networks.
We formalize the problem of robust distinct elements in the data stream model, and develop space and time-efficient streaming algorithms for datasets in Euclidean space, using a novel technique we call bucket sampling.
A hybrid transfer learning model based on an improved convolution restricted boltzmann machine (CRBM) model and a CNN model can effectively prevent the negative influence of transfer learning features between different data sets.
We address the challenge of applying existing convolutional neural network (CNN) architectures to compressed images. We introduce Localized Compression, a generalization of downgrading in which the original image is divided into blocks and each block is compressed to a smaller size using random-matrix-based techniques.
We propose seed-expansion graph clustering algorithm (SEGC) for protein complexes detection in PPI networks.
Rule-extraction in the context of ultra-high-dimensional and sparse data can be challenging, and has thus far received scant attention. To address this problem, we develop and test a metafeatures approach based on higher-level, less-sparse"metafeatures".
We propose Slice Tuner, a data collection strategy that optimizes the model accuracy and fairness of different slices of data and uses convex optimization to find the best strategy.
Generative Adversarial Imitation Learning on demonstration trajectories that avoids mode collapse.
The Non-Local Network (NLNet) presents a pioneering approach for capturing long-range dependencies, via aggregating query-specific global context to each query position.
We propose a novel feature-encoding approach for Faster Region-based Convolutional Neural Networks, where spatial information is represented through the spatial distributions of visual patterns.
We propose Scalable and Practical Natural Gradient Descent (SP-NGD), a principled approach for training models that allows them to attain similar generalization performance to models trained with first-order optimization methods, but with accelerated convergence.
We propose a novel unsupervised framework that can synthesize photo-realistic rotated faces using only single-view image collections in the wild.
We study the problem of designing models for machine learning tasks defined on sets and provide a family of functions to which any permutation invariant objective function must belong.
We propose a novel way of using out-of-domain textual data to enhance the performance of existing image captioning systems. We evaluate this learning approach on a newly designed model that uses - and improves upon - building blocks from state- of-the-art methods.
This paper proposes a new strategy for learning powerful cross-modal embeddings for audio-to-video synchronisation, where the objective is to find the most relevant audio segment given a short video clip.
In this paper we propose identity preserve transform (IPT) to study this problem. IPT manipulates the nuisance factors (background, viewpoint, etc.) of the data while keeping those factors related to the task (human motion) unchanged.
In this paper we introduce a scalable automated visual recognition pipeline for discovering political meme genres of diverse appearance.
Adaptive local spatiotemporal feature (ALSTF) using fused RGB-D data using adaptive local constraints.
In this paper, a novel descriptor, named pyramid correlogram of oriented gradients (PCOG), is presented for feature representation.
The objective of this paper is to introduce a fully computerized, simple and low-computational cost technique that can be used in the preprocessing stages of digital images. The proposed technique takes its importance from the huge explosion of images that need accurate processing in real time speedy manner.
We propose a cross-modal deep learning method for heterogeneous face recognition.
We propose, DeCom, a simple but effective mechanism to boost the performance of existing link predictors through extracting more expressive features while preventing overfitting by adding just a few extra parameters.
The speeded-up robust features (SURFs) algorithm is the best and most efficient local invariant feature algorithm for application to 2D images and is widely applied in the fields of 2-D image processing and computer vision.
We propose an Architecture-Driven Weight Prediction (ADWP) approach for neural architecture search (NAS) and we first design an architecture-intensive search space and then train a HyperNetwork.
We introduce a new VQA dataset that provides more challenging and general questions about Compositional Reasoning on vIsion and Commonsense, which is named as CRIC, and propose a new compositional model that can answer these questions.
This paper presents a robotic pick-and-place system that is capable of grasping and recognizing both known and novel objects in cluttered environments.
The design, analysis and application of a volumetric convolutional neural network (VCNN) are studied in this work.
As designing appropriate Convolutional Neural Network architecture in the context of a given application usually involves heavy human works or numerous GPU hours, the research community is soliciting the architecture-neutral CNN structures, which can be easily plugged into multiple mature architectures to improve the performance on our real-world applications.
We present an efficient parallel method for optimizing Potts energy based on the extension of hierarchical fusion algorithm, which has optimality bounds even after a single iteration.
We propose a novel method to improve the diversity of top-$N$ recommendation results based on the determinantal point process (DPP), which is an elegant model for characterizing the repulsion phenomenon.
This paper is concerned with the defense of deep models against adversarial attacks. We developan adversarial detection method, inspired by the certificate defense approach, and capturesthe idea of separating class clusters in the embedding space to increase the margin.
In this paper, motivated by that the local information content is spatially variant in an image, we suggest that: (i) the bit rate of the different parts of the image is adapted to local content, and (ii) the content-aware bit rate is allocated under the guidance of a content-weighted importance map.
We propose a novel direct feature odometry framework for depth estimation and hierarchical feature representation learning from monocular videos.
Line-level keyword spotting (KWS) using frame-level word posterior probabilities.
This paper proposes a 3D shape descriptor network, which is a deep convolutional energy-based model, for modeling volumetric shape patterns.
We propose a novel method of dynamically fuse multi-modal features with intra- and inter-modality information flow, which alternatively pass dynamic information between and across the visual and language modalities, thus significantly improves the performance of visual question answering.
We explore adversarial robustness in the setting in which it is acceptable for a classifier to abstain---that is, output no class---on adversarial examples.
We present LS-CRF, a new method for training cyclic Conditional Random Fields from large datasets that is inspired by classical closed-form expressions for the maximum likelihood parameters of a generative graphical model with tree topology.
Attribute-aware CF models aim at rating prediction given not only the historical rating given by users to items but also the information associated with users (e.g., age), items, price, and ratings.
We present a method to analyze images taken from a passive egocentric wearable camera along with the contextual information, such as time and day of week, to learn and predict everyday activities of an individual.
Automatic detection of dynamic object instances to improve the robustness of vision-based localization and mapping.
We present SOSELETO (SOurce SELEction for Target Optimization), a new method for exploiting a source dataset to solve a classification problem on a target dataset.
This work proposes to learn how to perform semantic image edits through the application of smooth warp fields. We demonstrate face editing at very high resolutions (4k images) with a single forward pass of a deep network.
We present DDFlow, a data distillation approach to learning optical flow estimation from unlabeled data, and show that our approach significantly outperforms all existing unsupervised learning methods, while running at real time.
This paper presents a new weighted representation for images and weighted K-Nearest-Neighbors (WKNN) classifier to improve the precision of image classification using the Bag of Visual Words (BOVW) based models.
We propose a caching mechanism which also weighs all the words from the source vocabulary according to their relation to the current decoding context which improves sequence/token-level accuracy on logical form tasks.
We propose a re-scaling rather than re-weighting approach for high-dimensional regression problems that have closed-form solutions, which improves ranking accuracy compared to SLIM.
Autoencoder reconstructions are widely used for the task of unsupervised anomaly localization. To tackle the issue, we propose in this paper a new approach for projecting anomalous data on a autoencoders-learned normal data manifold, by using gradient descent on an energy derived from the autoenCoder's loss function.
This paper proposes a multi-frame pyramid refinement network to effectively use spatio-temporal information contained in multiple frames (more than two).
We give an algorithm for automatically computing the visual concreteness of words and topics within multimodal datasets, enabling explorations of concepts.
In this paper, we study how to incorporate node diversity into influence maximization (IM) and propose two approximation algorithms based on non-monotonic submodular maximization and traditional IM respectively.
We find sparse matches across stereo image pairs that are detected without any prior regularization and perform dense interpolation preserving geometric and motion boundaries by using edge information.
This paper presents an approach for answering fill-in-the-blank multiple choice questions from the Visual Madlibs dataset using a combination of networks trained for specialized tasks such as scene recognition, person activity classification, and attribute prediction.
We address this problem by deriving synergistic modifications to the standard gating mechanism that are easy to implement, introduce no additional hyperparameters, and improve learnability of the gates when they are close to saturation.
We present a large scale hyperbolic recommender system that scales to millions of users and hundreds of thousands of items.
We use the available data, that may be an imbalanced subset of the original training dataset, or a related domain dataset, to retrieve representative samples from a trained classifier, using a novel Data-enriching GAN framework.
This paper describes community rating and tagging as two widely used social web functionalities and motivates their usage in the tele-teaching context. The potential of other social web features is explained afterwards.
In this paper, we propose a 3D ResNets based on residual networks toward a better action representation.
We develop a graph-walking agent called M-Walk, which consists of a deep recurrent neural network (RNN) and Monte Carlo Tree Search (MCTS) and combine MCTS with the neural policy to effectively train from sparse rewards.
We build a twofold Siamese network, named SA-Siam, for real-time object tracking.
This paper contains an attempt to empirically demonstrate the ability of CNNs to ignore dynamic elements, such as pedestrians or cars, through learning.
An overview of face aging, its implications on biometrics, specifically FR systems, and provide an example of our work via relaying results of experiments designed to measure facial age changes and artificially synthesize facial images, all in an effort to improve FR systems.
Multi-Feature Directed Cascaded CNN (MFS-CCNN) for hand position recognition .
NeuralREG uses deep neural networks to make decisions about form and content in one go without explicit feature extraction.
Boosted Random Ferns can be used to rapidly build discriminative classifiers for 2D and 3D detection and multi-view estimation.
We propose a globally optimized dual-pathway system to handle the optimization and precision weaknesses of deep cascaded regression without resorting to high-level inference models or complex stacked architecture.
In this paper, we conduct an in-depth study to investigate important implementation options that may affect the performance of deep nets on video classification, and to arrive at a practical guideline.
We present a bottom-up approach for the task of object instance segmentation using a single-shot model.
Layer-sequential unit-variance initialization - a simple method for weight initialization for deep net learning.
We provide an in-depth analysis of twelve detection proposal methods along with four baselines regarding proposal repeatability, ground truth annotation recall on PASCAL, ImageNet, and MS COCO, and their impact on DPM, R-CNN.
We present the Efficient Maximum Appearance Search (EMAS) model which is an order of magnitude faster than the existing state-of-the-art large-scale object detection approaches, while maintaining comparable accuracy.
We propose an attention-based word-level interaction model (ABWIM) to alleviate the information loss issue caused by aggregating the sequence into a fixed-dimensional vector before the comparison.
This work describes a method to label and cluster automatically a point cloud based on a supervised Deep Learning approach, using a state-of-the-art Neural Network called PointNet++.
This work builds a simple yet effective network for Kindling the Darkness (denoted as KinD), which, inspired by Retinex theory, decomposes images into two components.
We propose Mah\'e, a novel approach to provide Model-agnostic hierarchical explanations of how powerful machine learning models, such as deep neural networks, capture these interactions as either dependent on or free of the context of data instances.
We propose a novel margin-based generalization bound for training with class-imbalance and a simple, yet effective, training schedule that defers re-weighting until after the initial stage.
We propose a supervised manifold learning method that computes a nonlinear embedding while constructing a smooth and regular interpolation function that extends the embedding to the whole data space, achieving satisfactory generalization.
A novel unsupervised video object segmentation approach via distractor-aware online adaptation (DOA)
We demonstrate that incorporating radar data can boost performance in these difficult situations and introduce an efficient automated method for training data generation.
We propose conditional Glow, a generative flow for structured output learning. Learning with c-Glow does not require a surrogate objective or performing inference.
We present a framework for training pose-invariant lip-reading models on synthetic data instead of collecting and annotating non-frontal data.
We explore the simpler, efficient and easy to implement method for frontalization using a single, unmodified 3D surface as an approximation to the shape of all input faces.
We propose LayoutVAE, a variational autoencoder based framework for generating stochastic scene layouts.
We propose a generalization algorithm that generalizes over a large number of discrete actions and can be applied to large-scale learning problems previously intractable.
We propose a novel one-stage object detection network, called adaptively dense feature pyramid network (ADFPNet), to detect objects cross various scales.
We present a learning framework for abstracting complex shapes by learning to assemble objects using 3D volumetric primitives.
In inductive transfer learning, fine-tuning pre-trained convolutional networks substantially outperforms training from scratch, but there is no mechanism for retaining the features learned on the source task.
We present Negative Face Recognition (NFR), a novel face recognition approach that enhances the soft-biometric privacy on the template-level by representing face templates in a complementary (negative) domain.
We present an experimental framework and comparison which uses real-time height map fusion as an accessible platform for fair comparison, opening up the route to further systematic research in this area.
Comparison of Universal Dependencies and UCCA for semantic parsing, showing substantial differences between the schemes.
In this paper, we establish a new PDE interpretation of a class of deep convolutional neural networks (CNN) that are commonly used to learn from speech, image, and video data and derive three new ResNet architectures that fall into two new classes: parabolic and hyperbolic CNNs.
We demonstrate two approaches to reducing unnecessary computation in cases where a fast but weak baseline classier and a stronger, slower model are both available.
We propose an approach that combines different multiple views geometry constraints to achieve moving objects detection using only a monocular camera.
We propose a weakly supervised hierarchical reinforcement learning framework, which decomposes the whole task into several subtasks to enhance the summarization quality.
This paper introduces a Deep Learning Convolutional Neural Network model based on Faster-RCNN for motorcycle detection and classification on urban environments.
We identified a positive allosteric modulator that potentiated the antagonist N-methyl scopolamine (NMS), while sparing the endogenous agonist acetylcholine.
We evaluate the state-of-the-art of facial landmark detection methods on frontal and profile faces and in various regions of the face.
We propose Swarm Optimised Block Architecture Ensembles, a method for automatically designing and ensembling deep CNN models with a central weight repository to avoid work duplication.
We address these issues by proposing a general and conceptually simple regression method with a clear probabilistic interpretation, achieving state-of-the-art results on computer vision regression tasks.
We address the problem of few-shot classification under domain shifts for metric-based methods using feature-wise transformation layers.
We study probabilistic models of natural images and extend the autoregressive family of PixelCNN architectures by incorporating auxiliary variables.
Facial Expression Recognition (FER), as the primary processing method for non-verbal intentions, is an important and promising field of computer vision and artificial intelligence, and one of the subject areas of symmetry.
In recent years, visual saliency estimation in images has attracted much attention in the computer vision community. Inspired by the recent success of deep convolutional neural networks based static saliency mod- els, in this work, we study two different two-stream convo- lutional networks for dynamic saliency prediction.
In this paper, we propose a segment-based scan-matching framework for six degree-of-freedom pose estimation and mapping.
We introduce multigrid Predictive Filter Flow (mgPFF), a framework for unsupervised learning on videos. The mgPFF takes as input a pair of frames and outputs per-pixel filters to warp one frame to the other.
We present an efficient and paralleled method of SPCA using graphics processing units (GPUs), which can process large blocks of data in parallel.
We propose a new information-theory-based regularization scheme named SHADE for SHAnnon DEcay, which explicitly decouples the learning of invariant representations in the regularizer and the data fitting term.
We propose a hierarchical gating network (HGN), integrated with the Bayesian Personalized Ranking (BPR), to capture both the long-term and short-term user interests in sequential recommender systems.
We utilize an adversarial training framework for domain generalization in Question Answering (QA) task.
We propose to pre-train a context-dependent encoder (CoDE) for ULER by learning from unlabeled conversation data.
We evaluate the performance of an ensemble of action learning techniques, each performing the recognition task from a different perspective. In order to improve the recognition performance, a powerful combination strategy is utilized based on the Dempster-Shafer theory, which effectively make use of diversity of base learners trained on different sources of information.
This paper proposes a solution for a particular case study on object recognition of industrial parts based on hierarchical classification, despite being fairly slower.
We formulate tracking as an online decision-making process, where a tracking agent must follow an object despite ambiguous image frames and a limited computational budget. We learn policies with deep reinforcement learning algorithms.
Generative Adversarial Networks (GANs) have been used widely to generate large volumes of synthetic data. This data is being utilized for augmenting with real examples in order to train deep Convolutional Neural Networks (CNNs). Studies have shown that the generated examples lack sufficient realism to training deep CNNs.
We present an extensive empirical study on the utility of initializing large Transformer-based sequence-to-sequence models with the publicly available pre-trained BERT and GPT-2 checkpoints for sequence generation.
In this paper, we propose a two-stage framework that incorporates complex spatio-temporal information for effectively regularizing the re-identification results.
Learning to classify new categories based on just one or a few examples is a long-standing challenge in modern computer vision.
We address the task of learning novel visual concepts, and their interactions with other concepts, from a few images with sentence descriptions.
We present a mapping algorithm that converts 3D structures to 2D and 1D data grids by mapping a traversal of a 3D space-filling curve to the traversal thereof, which allows for decreased CNN training time cost, increased original 3D model rendering resolutions, and supports increased numbers of data channels.
We propose local binary convolution (LBC), an efficient alternative to convolutional neural networks (CNN) that achieves performance parity with regular CNNs on a range of visual datasets.
An ESR paradigm based on feature extraction from pre-trained deep convolutional neural networks (CNN), the derivation of higher-order statistics by compact bilinear pooling and normalisation.
We proposed an ensemble you only look once (YOLO) framework for ship behavior analysis. The experimental results have shown that ships are accurately detected.
This paper proposes a novel local depth and surface normals descriptor to explore the discriminative features on the nasal surface and adjoining cheek regions for expression robust 3D face recognition.
Semantic Textual Similarity (STS) shared task is a venue for assessing the current state-of-the-art.
The requirement of fine-grained perception by autonomous driving systems has resulted in recently increased research in the online semantic segmentation of single-scan LiDAR. The combination of the aforementioned challenges motivates us to propose a newLiDAR-specific, KNN-free segmentation algorithm - PolarNet.
We propose a principle for exploring context in machine learning models, leading to revisions of many existing deep learning models able to achieve significant performance boost.
This paper proposes a Dual Strategy for DST to borrow advantages from both the picklist-based and span-based methods, by classifying over a picklist or finding values from a slot span.
We introduce a novel approach, named ProgressNet, capable of predicting when an action takes place in a video, where it is located within the frames, and how far it has progressed during its execution.
We propose contrastive learning, an alternative objective for knowledge transfer in which we train a student to capture significantly more information in the teacher's representation of the data, which outperforms knowledge distillation.
The goal of this work is to forecast human activities that may require robot assistance. The method allows us to forecast the trajectories of nominally possible motion goals (prognosing of an action).
Dropout Variational Inference, or Dropout Sampling, has been recently proposed as an approximation technique for Bayesian Deep Learning and evaluated for image classification and regression tasks.
We propose a novel Second-order Response Transform Attention Network (SoRTA-Net), a refined second-order response transform module for classification tasks.
This paper introduces the Intentional Unintentional (IU) agent. This agent endows the DDPG agent with the ability to solve several tasks simultaneously.
We investigate how general convolution kernels are composed from base kernels and construct corresponding explicit feature maps. We apply our results to widely used graph kernels and analyze for which kernels and graph properties computation is feasible and actually more efficient.
We introduce Social IQa, the first largescale benchmark for commonsense reasoning about social situations, using a new framework that mitigates stylistic artifacts in incorrect answers by asking workers to provide the right answer.
This paper presents a cascaded regional spatiotemporal feature-routing networks for video object detection.
This paper presents a supervised deep hashing approach that constructs binary hash codes from labeled data for large-scale image search.
We present 3DMV, a novel method for 3D semantic scene segmentation of RGB-D scans in indoor environments using a joint 3D-multi-view prediction network.
We propose a novel RNN model for Natural Language Inference and empirically evaluate the effect of applying dropout at different layers in the model. We also investigate the impact of varying dropout rates at these layers.
A new and robust mapping approach is proposed entitled mapping forests (MFs) for computer vision applications based on regression transformations. Mapping forests relies on learning nonlinear mappings deduced from pairs of source and target training data.
We investigate in-domain representation learning to develop generic remote sensing representations and establish baselines and a common evaluation protocol in this domain.
In this paper, we introduce a new vision-language pre-trained model -- ImageBERT -- for image-text joint embedding.
We introduce an inference technique to produce discriminative context-aware image captions (captions that describe differences between images or visual concepts) using only generic context-agnostic training data.
We propose a framework for answering open domain multi-hop questions in which partial information is read and used to generate followup questions, to finally be answered by a pretrained single-hop answer extractor.
We propose a reformulation of Variational Auto-Encoders eliminating half of the network outputs (the variances) in a deep network setting.
We propose a novel categorical set similarity measure for Author Name Disambiguation, which performs well even when the cardinalities of the two compared sets are small.
We show that adversarial training improves the robustness of image classifiers against such adversarial perturbations, it leaves them sensitive to perturbation on a non-negligible fraction of the inputs.
We investigate BERT in an evidence retrieval and claim verification pipeline for the FEVER fact extraction and verification challenge, achieving a new state of the art recall of 87.1 for retrieving top five sentences.
Autonomous landing of an unmanned aerial vehicle or a drone in a GPS-denied environment using our remote-marker-based tracking algorithm based on a single visible-light-camera sensor using a convolutional neural network.
We propose Graph Convolutional Policy Network (GCPN), a general graph convolutional network based model for goal-directed graph generation through reinforcement learning.
We use a modified form of the natural policy gradient algorithm for reinforcement learning, applied to a carefully identified simulation model, trained entirely in simulation, to transfer control policies learned in simulation to a physical system.
PyTorch-Kaldi aims to bridge the gap between the efficiency of Kaldi and the flexibility of PyTorch for speech recognition and deep learning.
Predicting pharmacodynamic drug-drug interactions using S-score and golden standard positives .
This paper compares contour based and noncontours based techniques for extracting words from unconstrained handwritten text lines. Proposed novel approach is based on contours of words rather only considering threshold for inter-word gaps.
This work proposes a new human-related video processing task named 3D panoramic multi-person localization and tracking that maximizes the 3D trajectory information of tracking targets.
We propose a novel re-identification framework based on a deep convolutional neural network, SOMAnet, that additionally models other discriminative aspects of the human figure (e.g. height, obesity, gender).
We propose a data mining system for inferring transcriptional regulation relationships from RNA expression values from discretized expression data sets.
This work proposes to solve homography estimation using a hybrid framework HomoNetComb which incorporates deep learning method and energy minimization, and achieves state-of-the-art results.
In this paper, we propose an unsupervised technique to solve inverse problems with generative adversarial networks (GANs) using a pre-trained GAN in a `blind' fashion, i.e., without knowledge of the measurement process.
The problem of Knowledge Base Completion can be framed as a 3rd-order binary tensor completion problem. In this light, the Canonical Tensor Decomposition (CP) seems like a natural solution; however, current implementations of CP on standard Knowledge base completion benchmarks are lagging behind their competitors.
We evaluate CenterNet, a state of the art method for real-time 2D object detection, on the VisDrone2019 dataset. We evaluate the performance of the model with different backbone networks.
We address the problem of finding brands in images and deriving corresponding captions by introducing a modified image captioning network. The introduced network improves mean class accuracy by 24.5 percent.
We present a novel knowledge distillation approach, i.e., Self Attention Distillation (SAD), which allows a model to learn from itself and gains substantial improvement without any additional supervision.
We propose a novel fine-grained quantization (FGQ) method to ternarize pre-trained full precision models, while also constraining activations to 8 and 4-bits.
We learn to compute optical flow by combining a classical spatial-pyramid formulation with deep learning. This estimates large motions in a coarse-to-fine approach.
We propose a novel S-shaped rectified linear activation unit (SReLU) to learn both convex and non-convex functions, imitating the multiple function forms given by the two fundamental laws.
We propose a Modality Compensation Network (MCN) to explore the relationships of different modalities, and boost the representations for human action recognition.
We present a novel instance-level embedding adaptation mechanism, aiming at rapidly adapting embedding deep features to improve their generalization ability in recognizing novel categories.
We study the automated canonicalization of string literals, i.e., replacing the literal with an existing entity from the KB or with a new entity that is typed using classes from DBpedia.
We propose DeepEM, a novel deep 3D ConvNet framework augmented with expectation-maximization (EM), to mine weakly supervised labels in EMRs for pulmonary nodule detection.
We propose a novel approach to the problem of dynamic object removal within stereo based scene mapping that is both independent of the underlying stereo approach in use and applicable to varying object and camera motion.
This paper aims to provide a better understanding of a symmetric loss and propose a convex barrier hinge loss that benefits significantly from the symmetric condition.
We propose Multi-Scale Dilated Convolution Network (MSDC-Net), a dilated convolution based deep network for vision based depth estimation.
In this paper, a LiDAR based vehicle detection approach is proposed with the goal of utilizing range information.
In this paper we explore how we can achieve comparable results to these state-of-the-art networks for devices-on-edge.
In this paper, we present a novel framework for introducing declarative knowledge to neural network architectures in order to guide training and prediction.
In this paper, we propose a residual attention module to the one layer convolutional network to inhibit the descent of discriminative ability caused by over fitness.
We proposed a novel Wasserstein generative adversarial network-based method to perform occluded FER. The proposed method is better than state-of-the-art methods.
We propose a data-driven approach for deep convolutional neural network compression that achieves high accuracy with high throughput and low memory requirements.
We explore the possibility of fine-tuning a cross-lingual model with only a small number of samples from the target language, which is of great interest for low-resource languages.
We propose error correction synchronization involving communication (EC-SIC), whose regret is shown to approach that of the centralized stochastic MP-MAB with collision information.
We propose a generative adversarial residual multi-instance neural network based on pooling for human pose estimation task.
We propose an efficient Stereographic Projection Neural Network (SPNet) for learning representations of 3D objects. We first transform a 3D input volume into a 2D planar image using stereographic projection.
In this paper, we propose a novel deep neural network for VQA that integrates both attention mechanisms for effective question answering.
A pair of collaborative Gaussian process models (GP) with different kernels are used to count people by taking the level of occlusion into account.
We present the first and the largest study of all facial behaviour tasks learned jointly in a single multi-task, multi-domain and multi-label network, which we call FaceBehaviorNet.
We introduce"AnnealSGD", a regularized stochastic gradient descent algorithm motivated by an analysis of the energy landscape of a particular class of deep networks with sparse random weights.
This work aims to learn structurally-sparse Long Short-Term Memory by reducing the sizes of basic structures within LSTM units, including input updates, gates, hidden states, cell states and outputs.
Boosting based GADAM can help unit models jump out the local optima and converge to better solutions.
We introduce a novel descriptor based on motion boundary histograms, which is robust to camera motion and robust to fast irregular motions as well as shot boundaries.
In this paper, we propose a center-based feature transfer framework to augment the feature space of under-represented subjects from the regular subjects that have sufficiently diverse samples.
A consistent cross-viewmatching framework for unsupervised person re-identification by exploiting more reliable positive image pairs in a cameranetwork.
We address image captioning without explicit supervision by generating language descriptions of scenes without learning from annotated pairs of images and their captions.
We introduce occlusion mask, a mask that during training can be used to specifically ignore regions that cannot be reconstructed due to occlusions.
We present a generalization of the Cauchy/Lorentzian, Geman-McClure, Welsch/Leclerc, generalized Charbonnier, Char Bonnier/pseudo-Huber, and L2 loss functions.
Unsupervised ensemble hashing is proposed to improve the ranking accuracy by assembling the diverse hash tables independently in this paper.
In this paper, we extend the PPD based Mahalanobis distance metric learning to PSD and SSD based ones, and solve them under a unified optimization framework.
We introduce a novel PN layer that implements PN for non-linear pooling of feature maps and demonstrate state-of-the-art performance.
We present LOGAN, a deep neural network aimed at learning generic shape transforms from unpaired domains. The network is trained on two sets of shapes, but there is neither a pairing between shapes in the two domains to supervise the shape translation nor any point-wise correspondence between any shapes.
We present a new end-to-end generative adversarial network (GAN) for single image motion deblurring, named DeblurGAN-v2, which considerably boosts state-of-the-artdeblurring efficiency, quality, and flexibility.
We propose a machine reading comprehension model based on the compare-aggregate framework with two-staged attention that achieves state-of-the-art results on the MovieQA question answering dataset.
A well-known issue of Batch Normalization is its significantly reduced effectiveness in the case of small mini-batch sizes. To address this problem, we present Cross-Iteration B batch normalization (CBN), in which examples from multiple recent iterations are jointly utilized to enhance estimation quality.
We propose a novel quantization method that generates per-layer hybrid filter banks consisting of full-precision and ternary weight filters for MobileNets and achieve state-of-the-art results.
The last several years have seen intensive interest in exploring neural-network-based models for machine comprehension (MC) and question answering (QA). In this paper, we approach the problems by closely modelling questions in a neural network framework.
We used genetic data and baseline molecular and clinical variables from the PPMI study to predict the annual rate of change in combined scores from the Movement Disorder Society—Unified Parkinson's Disease Rating Scale (MDS-UPDRS) parts II and III.
Convolutional networks trained on large supervised datasets produce visual features which form the basis for the state-of-the-art in many computer-vision problems.
We address the explainable AI problem for deep neural networks with our proposed framework, named IASSA, which generates an importance map indicating how salient each pixel is for the model's prediction with an iterative and adaptive sampling module.
We explore and employ the relationship between shape of kernels which define receptive fields (RFs) in CNNs for learning of feature representations and image classification.
Bilingual speech emotion recognition using i-vectors and deep learning .
In this study, we explore building a two-stage framework for enabling users to directly manipulate high-level attributes of a natural scene.
We introduce an architecture called Cyclic Reverse Generator (CRG), which allows learning the inverse function of the generator accurately via an encoder in an unsupervised setting by utilizing cyclic cost minimization.
We propose a novel neural learning framework that is capable of handling both homogeneous and heterogeneous data while retaining the benefits of traditional CNN successes.
This paper proposes a new CNN-based approach to monocular orientation estimation that advances the state of the art in four different directions.
We describe an end-to-end method for recovering 3D human body mesh from single images and monocular videos. It reduces the complexity and decouples the skeleton from the details.
Adversarial Personalized Ranking (APR) enhances the pairwise ranking method BPR by performing adversarial training and improves its generalization performance.
We present a novel approach, namely, Partially-Connected DARTS, by sampling a small part of super-network to reduce the redundancy in exploring the network space, thereby performing a faster search without comprising the performance.
Generative Autotransporter with explicit distribution optimal transport for generative probabilistic modeling.
We propose to train a model with partial labels i.e. only some labels are known per image.
Fast greedy local search optimization of a clustering objective function with two different objective functions incorporating a resolution parameter: modularity and a function we introduced in a recent work, called w-log-v, for protein-protein interaction (PPI) networks.
We propose a new constraint-based reinforcement learning approach that ensures task success while minimizing auxiliary costs (such as control effort).
We propose a novel wavelet-based VAE that uses the decoder to model the images in the wavelet coefficient space and achieve consistently better FID scores.
Automatic facial action unit (AU) detection in videos using morphological and bilateral filters using local binary patterns .
A novel deep learning model based on faster region-based convolutional neural network for detecting abnormalities in the esophagus from endoscopic images.
We propose a unified framework for simultaneous facial landmark detection, head pose estimation and facial deformation analysis, and the proposed model is robust to facial occlusion.
We propose a novel and unified framework for unsupervised image-to-Image Translation, under such a requirement that n domains are freely transferred to each other in a general setting.
This article introduces a cascaded multitask framework to improve the performance of person search by fully utilizing the combination of pedestrian detection and person re-identification tasks.
In this paper, we propose novel Stacked Cycle-Consistent Adversarial Networks (SCANs) by decomposing a single translation into multi-stage transformations, which not only boost the image translation quality but also enable higher resolution image-to-image translations in a coarse- to-fine manner.
Fine-tuning can improve the ability of a state-of-the-art DNN model for Recognizing Textual Entailment tasks, where a model pre-trained on a large dataset is fine-tuned with a small supplemental training set.
We use optimal transport to characterize the maximum achievable accuracy in an adversarial classification scenario for Gaussian data with norm-bounded adversaries.
In this paper, we propose PointPillars, a novel encoder which utilizes PointNets to learn a representation of point clouds organized in vertical columns (pillars) and propose a lean downstream network.
A CNN-based dual-chain model for knowledge graph learning, which incorporates descriptions of entities and learns a second set of entity embeddings from the descriptions.
Clustering as an unsupervised learning technique using region segmentation based on data density.
We introduce a new approach to make use of several relations as well as both relations and attributes for classification using ensemble methods.
In safety-critical applications a probabilistic model is usually required to be calibrated, i.e., to capture the uncertainty of its predictions accurately. We propose and study calibration measures for multi-class classification that generalize existing measures such as the expected calibration error, the maximum calibration error and the maximum mean calibration error.
We augmented the hierarchical MAX model using an elastic net-regularised dictionary learning approach for object classification task.
This paper proposes an end-to-end noise-weakened person re-ID and tracking model with adaptive partial information.
We propose a coarse-to-fine hierarchical representation of object detection, 3D pose estimation, and sub-category recognition, where each level of the hierarchy represents objects at different level of granularity.
We propose a novel denoising framework for semantic layout-based image synthesizing and improve the loss function of the discriminator by considering the perturbed loss.
We show that increasing the diversity of realizations sampled from a neural network with dropout helps to improve the quality of uncertainty estimation.
We have developed an ensemble technique that improves the accuracy of underage estimation in conjunction with our deep learning model (DS13K) that has been fine-tuned on the Deep Expectation model.
Our study aims to contribute to the design of an expressive virtual human, by identifying and adapting visual factors promoting transcription of emotions.
We present a dataset derived through the DNN feature decoding analyses including fMRI signals of five human subjects during image viewing, decoded feature values of DNNs (AlexNet and VGG19), and decoding accuracies of individual DNN features with their rankings.
In this paper, we propose a novel filter pruning method by exploring the High Rank of feature maps (HRank), a method that is mathematically formulated to prune filters with low-rank feature maps.
Convolutional Neural Network (CNN) is a very powerful approach to extract discriminative local descriptors for effective image search.
We propose a person re-identification method based on deep hash learning, which achieves comparable performances and outperforms other hashing methods with large margins on Rank-1 and mAP value identification rates in pedestrian re-Identification.
We describe a class of temporal models, which we call Temporal Convolutional Networks (TCNs), that use a hierarchy of temporal convolutions to perform fine-grained action segmentation or detection.
We propose a method for joint detection of abnormalities in videos by spatio-temporal video parsing by formulating an optimization problem.
In this paper, we propose an asymmetric occlusion-aware feature matching module, which can learn a rough Occlusion mask that filters useless (occluded) areas immediately after feature warping without any explicit supervision.
Evolution Strategies are a viable method for learning non-differentiable parameters of large supervised models. We show that it is possible to scale ES to more complex tasks and models with millions of parameters.
We look into developing and training compact facial alignment models that feature fast inference speed and small deployment size, making them suitable for applications on resource restricted devices.
We consider a decentralized multi-agent Multi Armed Bandit setup consisting of $N$ agents, solving the same MAB instance to minimize individual cumulative regret. In our model, agents collaborate by exchanging messages through pairwise gossip style communications.
We consider the case in which a robot has to navigate in an unknown environment, but does not have enough on-board power or payload to carry a traditional depth sensor (e.g., a 3D lidar).
In this paper, we propose a novel approach DHNE to learn the representations of nodes in dynamic heterogeneous networks with dynamic characteristics.
We address the instability of the large mini-batch training with batch size control. We address the overhead of the gradient synchronization with 2D-Torus all-reduce.
We propose a general framework for network reduction which combines gradient descent and a one-step k-means update to learn both value dictionaries and assignment matrices iteratively.
We review and systematically evaluate nine task weighting strategies on common grounds on three automotive datasets (KITTI, Cityscapes and WoodScape) and propose a novel method combining evolutionary meta-learning and task-based selective backpropagation, for finding the task weights and training the network reliably.
CNNs have made a tremendous impact on the field of computer vision in the last several years. To include the location cue for feature learning, we propose to augment the color image, the usual input to CNNs, with one or more channels that carry location information.
Convolutional Neural Network model for facial expression recognition .
We present an approach to efficiently detect the 2D pose of multiple people in an image, irrespective of the number of people in the image.
We present a simple and lightweight variant of the Shuffle-Exchange network, which is based on a residual network employing GELU and Layer Normalization.
This paper presents the method that underlies our submission to the untrimmed video classification task of ActivityNet Challenge 2016.
Attention mechanisms play a central role in NLP systems, especially within recurrent neural network (RNN) models. Recently, there has been increasing interest in whether or not the intermediate representations offered by these modules may be used to explain the reasoning for a model's prediction.
Image captioning is an ambiguous problem, with many suitable captions for an image. In this paper, we first predict a meaningful summary of the image, then generate the caption based on that summary.
In this paper, we address the problem of learning robust cross-domain representations for sketch-based image retrieval (SBIR) using cross-paced partial curriculum learning.
We propose a convolutional neural network which can predict the human activity using the joint data.
We present Interactive Gibson, the first comprehensive benchmark for training and evaluating Interactive Navigation: robot navigation strategies where physical interaction with objects is allowed and even encouraged to accomplish a task.
A novel method for extracting the hierarchical structure of Web video groups based on sentiment-aware signed network analysis is presented to realize Web video retrieval.
In this paper, we introduce Differentiable Graph Module (DGM), a learnable function predicting the edge probability in the graph relevant for the task, that can be combined with convolutional graph neural network layers and trained in an end-to-end fashion.
We propose a new method that uses deep learning techniques to solve the inverse problems. The inverse problem is cast in the form of learning an end-to-end mapping from observed data to the ground-truth.
BubbleView is a mouse-contingent, moving-window interface in which participants are presented with a series of blurred images and click to reveal “bubbles” -- small, circular areas of the image at original resolution, similar to having a confined area of focus like the eye fovea.
We propose a fast feed-forward network for arbitrary style transfer, which can generate stylized image for previously unseen content and style image pairs.
In this paper, we propose a novel type of attention module, namely De-Normalized Attention (DNA), which aims at evaluating the importance of features from different locations, channels and resolutions to enhance the network capability for feature representation.
We propose a tree-based classifier which achieves a better trade-off between efficiency and accuracy with a given tree-shaped hierarchy.
We propose a continual pre-training framework named ERNIE 2.0 which builds and learns incrementally pre- training tasks through constant multi-task learning.
We address this fundamental problem in the ubicomp community (not having enough training data) by proposing a knowledge transfer framework, Vision2Sensor, which opportunistically transfers information from an easy to interpret and more advanced sensing modality, vision, to other sensors on mobile devices. We show that transfer learning is also beneficial to identifying the best Convolutional Neural Network for vision based human activity recognition.
We aim to dismantle the prevalent black-box neural architectures used in complex visual reasoning tasks, into the proposed eXplainable and eXplicit Neural Modules, which advance beyond existing neural module networks towards using scene graphs for explainable and explicit reasoning with structured knowledge.
Cdc34-like E2 ubiquitin-conjugating enzymes are characterized by a 12–14 residue insertion in the proximity of the catalytic site, known as the acidic loop, which is one of the key residues for Cdc34 activity.
We propose a new spatio-temporal feature learning method, which can robustly predict the expression with partial (incomplete) expression sequences, on-the-fly.
In this paper, we propose masked non-autoregressive decoding to tackle the issues of both aut-gressive decoding and non-Autoregressive decode, and generate captions parallelly.
Automatic prototype-domain discovery for domain perceptive (adaptive) person re-identification .
In this paper, we prove that hierarchical latent variable models do not take advantage of the hierarchical structure when trained with existing variational methods, and provide some limitations on the kind of features existing models can learn.
SBC combines existing techniques of communication delay and gradient sparsification with a novel binarization method and optimal weight update encoding to push compression gains to new limits.
Facial aging adversely impacts performance of face recognition and face verification and authentication using facial features.
We propose differentiable quantization (DQ) for efficient deep neural network inference where gradient descent is used to learn the quantizer's step size, dynamic range and bitwidth.
We exploit the fact that objects co-occur mostly in typical regular configurations. We exploit such regularity in the form of data-driven scene priors. We aim to construct scene mockups from single images.
Character-level features are currently used in different neural network-based natural language processing algorithms. In this paper, we investigate which character-level patterns neural networks learn and if those patterns coincide with manually-defined word segmentations and annotations.
This paper introduces a new approach to motion segmentation operating on point trajectories, based on an adaptation of recently proposed J-linkage method.
We propose a generic framework to leverage holistic information in the form of a LabelBank for pixel-level segmentation.
We propose a deep random ferns (d-RFs) model, in which extremely randomized f Ferns are connected to multilayers, allowing a high classification performance and a fast structure.
We propose an approach to the spatiotemporal localisation and classification of multiple concurrent actions within temporally untrimmed videos, achieving new state-of-the-art results across the board and significantly increasing detection speed at test time.
In the paper we construct a fully convolutional GAN model: LocoGAN, which latent space is given by noise-like images of possibly different resolutions.
We present CodeBERT, a bimodal pre-trained model for programming language (PL) and nat-ural language (NL) that learns general-purpose representations that support downstream NL-PL applications such as code search, code documentation generation, etc.
We propose to decompose the challenging semantic forecasting task into two subtasks: current frame segmentation and future optical flow prediction, achieving state-of-the-art accuracy and efficiency.
We propose a novel forensic method to distinguish between natural images (NIs) and colorized images (CIs) based on convolutional neural network (CNN). Our method is able to achieve high classification accuracy and cope with the challenging scenario of blind detection.
We build a stable network model through Depthwise Separable Convolution, Densely Connected Convolutional and Lightweight Channel Attention Mechanism for 3D face alignment and reconstruction.
Unsupervised domain adaptation through an in depth evaluation of AlexNet, DenseNet and Residual Transfer Networks (RTN) on multimodal benchmark datasets that shows and identifies which layers more effectively transfer features across different domains.
In this paper, we introduce a novel approach to recognize the human actions. First, we explore Apache spark with in-memory computing, to resolve the task of human action recognition in the distributed environment.
We propose a fast and accurate video object segmentation algorithm that can immediately start the segmentation process once receiving the images.
We showed transfer representation learning is effective for learning good representations from both big data and small data.
This paper addresses the problem of handling spatial misalignments due to camera-view changes or human-pose variations in person re-identification. We first introduce a boosting-based approach to learn a correspondence structure, which indicates the patchwise matching probabilities between images from a target camera pair.
We propose a general framework for image restoration, called deeply aggregated alternating minimization (DeepAM), which uses deep neural network to advance two steps in the conventional AM algorithm.
We propose a novel regularization method called Drop-Activation to reduce overfitting and improve generalization.
The ability to handle very large amounts of image data is important for image analysis, indexing and retrieval applications. In order to achieve scalability, we investigate the optimal combination of hybridisations of the MapReduce distributed computational framework which allows the components of the analysis and indexing pipeline to be effectively mapped and run on modern server hardware.
This paper proposes a novel table cell search framework to address the problem of how to precisely retrieve table cells to answer a user question on the Web.
We formulate counting as a matching problem, enabling us to exploit the image self-similarity property that naturally exists in object counting problems, and propose a generic matching network architecture that can potentially count any object in a class-agnostic manner.
We show that even when face images are unconstrained and arbitrarily paired, face swapping between them is quite simple. We use our segmentations for robust face swapping under unprecedented conditions.
We propose a learning-based approach that reconstructs the scene in 360 x180 from conventional images.
We present AutoSeM, a two-stage MTL pipeline, where the first stage automatically selects the most useful auxiliary tasks via a Beta-Bernoulli multi-armed bandit with Thompson Sampling, and the second stage learns the training mixing ratio of these selected auxiliary tasks, achieving significant performance boosts on several primary tasks.
We propose a novel end-to-end self-supervised learning scheme that effectively exploit unlabeled data to provide more reliable keypoints under various scene conditions.
We propose a tree-based convolutional neural network for speech emotion recognition using path signatures.
In this paper, we introduce two approaches to automatically learn different combinations of base activation functions (such as the identity function, ReLU, and tanh) during the training phase.
We propose an efficient movie recommendation algorithm based on improved k-clique methods which are the best accuracy of the recommendation system.
We formulate video summarization as a sequence labeling problem and propose fully convolutional sequence models to solve the problem.
We propose a principled approach to generate high quality 3D pose ground truth given any in-the-wild image with a person inside. We achieve this by first devising a novel stereo inspired neural network to directly map any 2D pose to 3D counterpart.
We propose a supervised pyramid context network for scene text detection, based on Feature Pyramid Network (FPN) and instance segmentation.
This paper introduces a visual sentiment concept classification method based on deep convolutional neural networks (CNNs)
We present a deep layered architecture that generalizes classical convolutional neural networks (ConvNets).
We present a novel neural architecture for abstractive summarization that combines a sequential decoder with a tree-based decoder in a synchronized manner to generate a summary sentence and its syntactic dependency parse while performing abstraction.
3D point cloud generation by the deep neural network from a single image captured from any viewpoint and complex background.
In this paper, we propose a new approach to construct approximate $k$-NN graphs with emphasis in: efficiency and accuracy.
This paper presents a novel cue combination framework for ground plane estimation using multiple cues like sparse features, dense inter-frame stereo and (when applicable) object detection for monocular autonomous driving.
In this paper, we bring to surface factors that affect CF process in order to identify existing false beliefs. We propose new approaches that substantially improve the performance of CF algorithms.
Contour detection has been a fundamental component in many image segmentation and object detection systems. Contrary to traditional approaches, we show that we can invert the commonly established pipeline: instead of detecting contours with low-level cues for a higher-level recognition task, we exploit object-related features as high- level cues for contour detection.
This paper proposes a multi-class semi-supervised learning algorithm of the graph based method of the Gaussian process.
We propose solutions to both problems: we entirely eliminate the need for column descriptions, by relying solely on their contents, and augment the WikiSQL dataset by paraphrasing them to reduce bias.
Existing sparse representation-based visual tracking methods detect the target positions by minimizing the reconstruction error. However, due to complex background, illumination change, and occlusi
We propose an algorithm utilizing geodesic distances to upsample a low resolution depth image using a registered high resolution color image. We compare our algorithm with state of the art on the benchmark dataset.
We develop a novel matching based algorithm for video object segmentation without fine-tuning.
We present a new and challenging object detection dataset, ParkingSticker, which mimics the type of data available in industry problems more closely than popular existing datasets like PASCAL VOC.
We propose a novel loss named triplet-center loss for 3D object retrieval, which learns more discriminative features than traditional classification loss.
We extend the knowledge distillation approach to allow the training of a student that is deeper and thinner than the teacher, using not only the outputs but also the intermediate representations learned by the teacher as hints to improve the training process and final performance of the student.
In this paper we present ranking algorithms for folksonomy systems that exploit additional contextual information attached to tag assignments.
We study the problem of attributing the prediction of a deep network to its input features, a problem previously studied by several other works, and develop a new attribution method called Integrated Gradients.
This paper proposes an automatic scale-adaptive approach with attention mechanism-based crowd spatial information addressing the crowd counting task.
We propose a new initialization idea that employs task-dependent layer-wise attenuation, which we call selective forgetting, which mitigates the conflicts and provides outstanding performance.
We present an intriguing behavior: pre-trained CNNs can be made to improve their predictions by structurally perturbing the input.
This paper analyzes the overfitting issue from a novel perspective, which separates the primitives of search space into architecture- overfitting related and parameter-overfitting related elements.
We present an integrated approach for perception and control for an autonomous vehicle and demonstrate this approach in a high-fidelity urban driving simulator. We leverage several deep learning algorithms.
A comprehensive comparison of embedding-based LP methods, extending the dimensions of analysis beyond what is commonly available in the literature.
Adversarial examples can be defined as inputs to a model which induce a mistake - where the model output is different than that of an oracle, perhaps in surprising or malicious ways.
We develop a conditional random field based variational auto-encoder formulation which is able to achieve diversity while taking into account structural consistency.
We investigate Factorization Machines (FMs) based on lightweight LOD-enabled features which can be directly obtained via a public SPARQL Endpoint without any additional effort.
In this paper, we introduce the Chainer framework, which intends to provide a flexible, intuitive, and high performance means of implementing the full range of deep learning models needed by researchers and practitioners.
This paper presents a novel deep neural network design for shadow detection and removal by analyzing the spatial image context in a direction-aware manner.
High-resolution representations are essential for position-sensitive vision problems, such as human pose estimation, semantic segmentation, and object detection. Existing state-of-the-art frameworks first encode the input image as a low-resolution representation through a subnetwork that is formed by connecting high-to-low resolution convolutions.
We propose a method for learning disentangled representations to allow for localized image manipulations. The network allows to generate modified images which appear like realistic images.
We provide novel insights into the use of data transformation in self-supervised tasks, specially pertaining to clustering.
We propose to construct the cost volume by group-wise correlation for stereo matching, which improves on previous methods.
We propose Implicit Feature Networks for 3D shape reconstruction and completion from a variety of 3D inputs, which are deficient in some respect: low and high resolution voxels, sparse and dense point clouds, complete or incomplete.
We propose a self-supervised learning method for object recognition across domains that learns the semantic labels in a supervised fashion, and broadens its understanding of the data by learning from self-Supervised signals how to solve a jigsaw puzzle.
SegStereo employs semantic features from segmentation and introduces semantic softmax loss, which helps improve the prediction accuracy of disparity maps.
We propose a new regularization for generative adversarial networks that forces the generated visual features to reconstruct their original semantic features in a multi-modal cycle-consistent manner.
We propose a structured graph Laplacian embedding algorithm, which can take full advantages of the structured distance relationships among training samples, with the constructed complete graph.
In this paper, a novel framework that embeds the manifold constraint into low-rank and sparse decomposition can consistently integrate the manifolds constraint during the non-convex optimization process, and it can contribute a better solution.
We propose a human-interpretable vocabulary of texture attributes to describe common texture patterns, complemented by a new describable texture dataset for benchmarking, developing corresponding benchmarks on top of the recently proposed OpenSurfaces dataset.
We introduce a novel architecture ADRNN (dilated CNN with residual block and BiLSTM based on the attention mechanism) to apply for the speech emotion recognition which can take advantage of the strengths of diverse networks and overcome the shortcomings of utilizing alone, and are evaluated in the popular IEMOCAP database.
Convolutional neural networks are vulnerable to small $\ell^p$ adversarial attacks, while the human visual system is not. Inspired by neural networks in the eye and brain, we developed a novel artificial neural network model that recurrently collects data with a log-polar field of view that is controlled by attention.
In this work, we propose a novel unsupervised deep learning model to address multi-focus image fusion problem.
In this paper we propose an attentive recurrent generative adversarial network (ARGAN) to detect and remove shadows in an image.
We introduce an iterative procedure which adapts the latent representation to the specific content we wish to compress while keeping the parameters of the network and the predictive model fixed, improving rate-distortion performance.
We propose a method that automatically learns feature extractors in an unsupervised fashion by simultaneously learning the filters and the pooling units that combine multiple filter outputs together.
The goal of this paper is to serve as a guide for selecting a detection architecture that achieves the right speed/memory/accuracy balance for a given application and platform.
We propose a regularization scheme for structured output prediction problems using a multi-task framework. The motivation of this work is to learn the output dependencies that may lie in the output data in order to improve the prediction accuracy.
This paper proposes an alternative, context-aware interaction recognition framework. The key to our method is to explicitly construct an interaction classifier which combines the context, and the interaction.
We propose Pyramidal Feature Fusion Network that integrates the top-down mid-level features to provide multi-level feature outputs for person search.
We develop a domain-specific method to tackle deblurring of human faces, henceforth referred to as face deblring.
This paper presents stacked attention networks (SANs) that learn to answer natural language questions from images.
We propose a novel many-to-one traveled distance estimator which uses deep recurrent convolutional neural network to solve the scale ambiguity problem.
We propose a method to perform active learning of object detectors based on convolutional neural networks. The proposed method performs better than random selection.
This paper presents a novel stereo visual odometry (VO) framework based on structure from motion, where a robust keypoint tracking and matching is combined with an effective keyframe selection strategy.
A novel and practical deep architecture for video person re-identification termed self-and-collaborative attention network (SCAN), which adopts the video pairs as the input and outputs their matching scores.
We propose the resource constrained differentiable architecture search (RC-DARTS) method to learn lightweight neural architectures that are significantly smaller and faster while achieving comparable accuracy.
Building on recent work on capsule networks, we propose a general-purpose form of "routing by agreement" that activates output capsules in a layer as a function of their net benefit to use and net cost to ignore input capsules from earlier layers.
We propose a novel Vivid Face Hallucination Generative Adversarial Network (VividGAN) devised for simultaneously super-resolving and frontalizing tiny non-frontal face images.
A number of recent works have proposed attention models for Visual Question Answering (VQA) that generate spatial maps highlighting image regions relevant to answering the question. We present a novel co-attention model for VQA that jointly reasons about image and question attention.
This paper proposes a new framework for RGB-D-based action recognition that takes advantages of hand-designed features from skeleton data and deeply learned features from depth maps, and exploits effectively both the local and global temporal information.
In this paper, we address the problem of estimating the positions of human joints, i.e., articulated pose estimation, together using convolutional neural networks.
Facial expression perception can be affected by adaptation to low-level curves (i.e., the shape of a mouth).
We address the missed contextual cues by exploiting both the accurate human parts and the coarse non-human parts and apply a self-attention mechanism to capture the soft latent (non-human) part masks.
In this paper, we study the nonnegative tensor data and propose an orthogonal nonnegative Tucker decomposition (ONTD) algorithm to solve the optimization problem.
We present Deep Canonical Time Warping (DCTW), a method that automatically learns non-linear representations of multiple time-series that are maximally correlated in a shared subspace, and (ii) temporally aligned.
We explore the use of structured dropout to promote model diversity and improve confidence calibration in Bayesian active learning.
A learned generative model often produces biased statistics relative to the underlying data distribution. A standard technique to correct this bias is importance sampling, where samples from the model are weighted by the likelihood ratio under model and true distributions.
We introduce an extended version of multiple channel features called Convolutional Channel Features (CCF), which transfers low-level features from off-the-shelf ConvNet models to feed the boosting classifiers based on decision trees.
In this paper, we propose a matrix factorization approach for network embedding, inspired by GloVe, that better handles non co-occurrence with a competitive time-complexity.
We propose a new approach for detecting spatiotemporal visual saliency based on the phase spectrum of videos, which is easy to implement and computationally efficient.
We introduce a new self-supervised task called as Space-Time Cubic Puzzles to train 3D CNNs using large scale video dataset.
This paper proposes a novel method to resolve the aforementioned problems of applying convolutional neural networks to omni-directional images to solve classification and detection problems.
We present a system that rewrites a given question into queries that are used to retrieve supporting text from a large corpus of science-related text. We use a generalizable decision methodology over the retrieved evidence and answer candidates to select the best answer.
We identified three PD subtypes and their progression rates using an automated deep learning algorithm on the top of longitudinal clinical records using a multi-dimensional time series.
We propose a novel joint attention person ReID (JA-ReID) architecture that learns two complementary feature representations by combining a soft pixel- level attention mechanism and a hard region-level attention mechanism.
We design a model extraction framework that makes use of active learning and large public datasets to satisfy them, while using only 30% (30,000 samples) of the public dataset at its disposal.
We present a new approach to rendering a geometrically-correct user-perspective view for a magic lens interface, based on leveraging the gradients in the real world scene, with no active depth sensing.
We propose an attention-based attention module that learns to selectively highlight regions in an image conditioned on the appearance of each instance for detecting human-object interactions.
In this paper, we propose several types of residual LSTM methods for our acoustic modeling.
In this paper, we propose a sequential deep learning strategy that combines both shape and texture features. We develop dual deep networks with memorable gated recurrent units (GRUs), and sequentially feed these two types of features into the dual networks, respectively.
We propose a novel attention mechanism that exploits visual attentions in the past to resolve the current reference in the visual dialog scenario, achieving superior performance in situations where visual reference resolution plays an important role.
We explore the problem of referring expression comprehension from the perspective of language-driven visual reasoning, and propose a dynamic graph attention network to perform multi-step reasoning by modeling both the relationships among the objects in the image and the linguistic structure of the referring expression.
In this paper, we enhance the autoencoders ability to learn effective data representations by aligning inner products between codes with respect to a kernel matrix.
We propose to use the state-of-the-art Probabilistic Patch-Based (PPB) denoiser within the framework of an unsupervised retinal vessel segmentation strategy based on the Frangi filter.
This paper shows that a complicated feature set is efficient for A/V classification, especially on the individual vessels where graph-based methods receive limitations.
We present Chameleon, a novel hybrid (mixed-protocol) framework for secure function evaluation (SFE) which enables two parties to jointly compute a function without disclosing their private inputs.
We propose a new deep neural network accuracy predictor, that estimates in fractions of a second classification performance for unseen input datasets, without training.
In this paper, the MIL problem is formulated as a knowledge discovery task for which algorithms seek to discover the witnesses (i.e. identifying positive instances), using the weak supervision provided by bag labels. A new method that clusters data projected in random subspaces is proposed to perform witness identification.
We propose Derivative-Free Recovery (DFR), a two-phase method for generating robust policies from demonstrations in robotic manipulation tasks where the system comes to rest at each time step.
We present a novel method to estimate the motion matrix between overlapping pairs of 3D views in the context of indoor scenes. We use the Manhattan world assumption to introduce lightweight geometric constraints under the form of planes into the problem.
We propose a segmental neural language model that combines the generalization power of neural networks with the ability to discover word-like units that are latent in unsegmented character sequences.
We provide the first algorithmic implementations for sketch-and-solve SVD problems on real-world, large-scale datasets.
A method to deal with the one sample per person face recognition problem based on the process how unfamiliar faces become familiar to people.
We propose an approach running in real-time with stereo camera, which combines an existing feature-based (indirect) and feature-less (direct) method to improve the performance metrics of visual SLAM systems using Umeyama Method.
This study focuses on the topic of image augmentation in training of deep neural network classifiers on satellite images from EuroSAT. The rapid development of computer vision systems could open new horizons to the utilization of satellite data.
In this paper, we describe an ego-motion estimation method using a vision sensor that is widely used in IoT systems. Then, we propose a new fusion method to improve the accuracy of motion estimation with other sensors.
We present an ultrafast technique that requiresless than a second to localize the Optic Disc.
We propose an intensity-free framework that directly models the point process distribution by utilizing normalizing flows, which capture their asynchronous and probabilistic nature.
PICKLE (Protein InteraCtion KnowLedgebasE) 2.0 implements a new architecture for this recently introduced human PPI meta-database. Its main novel feature over the existing meta-databases is its approach to primary PPI dataset integration via genetic information ontology.
We propose Sampling-Free mechanism for object detectors, which addresses the imbalance from aspects of initialization, loss and inference, thus avoiding laborious hyper-parameters tuning in sampling heuristics.
In this paper, we propose a data-efficient semi-supervised learning framework, which effectively combines the existing deep learning network with GAN and self-training ideas.
This review paper presents a comprehensive survey of both handcrafted and learning-based action representations for activity recognition, offering comparison, analysis, and discussions on these approaches.
Feature Distilling Generative Adversarial Network (FD-GAN) for robust person re-identification.
We introduce a self-supervised approach to object detection and segmentation, able to work with monocular images captured with a moving camera.
This paper proposes a novel domain adaptation framework, named Semi-supervised Domain Adaptation with Subspace Learning (SDASL), which jointly explores invariant low-dimensional structures across domains to correct data distribution mismatch and leverages available unlabeled target examples.
In this paper, we propose a cross-reference network (CRNet) for few-shot segmentation.
We address the problem of temporal activity detection in continuous, untrimmed video streams using a three-dimensional fully convolutional network, then generates candidate temporal regions containing activities and finally classifies selected regions into specific activities.
We propose a novel multi-view deep generative framework for multi-modal emotion data that learns the joint deep representation from multiple modalities and evaluates the importance of each modality simultaneously.
We propose to study the problem of few shot graph classification in graph neural networks (GNNs) to recognize unseen classes, given limited labeled graph examples.
A novel grasshopper detection framework that deploys deep learning within RBG images to detect insects. The framework can be deployed not only on desktop computers but also on edge devices without internet connection.
We provide a review of deep learning-based object detection frameworks along with some modifications and useful tricks.
This paper presents a novel 1-D sentiment classifier trained on the benchmark IMDB dataset with a deconvolution technique that is agnostic to architecture types.
In this paper, we present an approach to improve detectors used in medical image processing by fine-tuning their parameters for a certain dataset.
Automatically assessing emotional valence in human speech has historically been a difficult task for machine learning algorithms. In this work we explore a representation learning approach that automatically derives discriminative representations of emotional speech.
We propose to use discrete Fourier transform features to capture temporal information for video emotion classification and action recognition.
We propose a novel semantic tagging task, semtagging, tailored for the purpose of multilingual semantic parsing, and present the first tagger using deep residual networks (ResNets) using both word and character representations and includes a novel residual bypass architecture.
We propose a novel video object segmentation algorithm based on pixel-level matching using Convolutional Neural Networks (CNN) and propose a feature compression technique that drastically reduces the memory requirements while maintaining the capability of feature representation.
We propose an approach to multi-writer word spotting, where the goal is to find a query word in a dataset that is fast to compute and, especially, fast to compare.
We introduce a tree-structured attention neural network for sentences and small phrases and apply it to the problem of sentiment classification.
We propose a quadruplet loss for person ReID, which can lead to a better generalization ability.
The Augment-Reinforce-Merge (ARM), a recently proposed unbiased gradient estimator, is investigated for this binary optimization problem, where each unit of a neural network is attached with a stochastic binary gate, whose parameters are jointly optimized with original network parameters.
We introduce a novel multi-body feature tracker that bypasses the motion assignment step and reduces to solving a series of subproblems with closed-form solutions.
This paper proposes the approach of two-stream collaborative learning with spatial-temporal attention (TCLSTA) for video classification.
We present Point-Voxel CNN (PVCNN) for efficient, fast 3D deep learning, which is both memory and computation efficient.
In this paper, based on the Inception-v3 model of TensorFlow platform, we use transfer learning techniques to retrain facial expression dataset (The Extended Cohn-Kanade dataset), which can keep the accuracy of recognition and greatly reduce the training time.
We introduce Eigen Evolution Pooling, an efficient method to aggregate a sequence of feature vectors, while maximizing the temporal evolution of the features over time.
This paper suggests to generate the recommendations without such additional input data from the users and let them interactively explore the recommended items on their own.
We investigate the problem of cross-dataset adaptation for visual question answering (Visual QA). Our goal is to train a Visual QA model on a source dataset but apply it to another target one.
We propose CLARA, an interactive method that generates reports in a sentence by sentence fashion based on doctors' anchor words and partially completed sentences.
In this paper, we propose a method to reconstruct the complete 3D shape of an object from a single RGB image, with robustness to occlusion.
We introduce a Bayesian meta-learning algorithm that learns a probability distribution of model parameter prior for few-shot learning.
In this paper, we proposed a new framework that involves residual-attention module and joint path-signature feature (JPSF) representation framework for action recognition.
In this paper, we propose a novel self-supervised learning model for estimating continuous ego-motion from video.
We investigate deep generative models, which allow us to use training data from one domain to build a model for another domain. We propose the Variational Bi-domain Triplet Autoencoder that learns a joint distribution of objects from different domains.
We introduce a new inference and learning framework which can learn arbitrary pairwise CRF potentials and integrate them into deep neural networks.
A methodical investigation into differences in face recognition accuracy between African-American and Caucasian image cohorts of the MORPH dataset.
We propose to enhance learning models with world knowledge in the form of Knowledge Graph (KG) fact triples for Natural Language Processing tasks using attention mechanism.
We present a novel unsupervised deep episodic memory model for representing robot experiences in an episodic-like memory which facilitates encoding, recalling, and predicting action experiences.
The skip-thought model has been proven to be effective at learning sentence representations and capturing sentence semantics. In this paper, we propose a suite of techniques to trim and improve it.
We introduce Viewpoint Invariant Change Captioning, and develop models which can both localize and describe via natural language complex changes in an environment.
In this paper, we propose a novel few-shot deep learning approach to video-based person re-identification, to learn comparable representations that are discriminative and view-invariant.
This study presents a novel method to apply the RGB-D (Red Green Blue–Depth) sensors and fuse aligned RGB and NIR images with deep convolutional neural networks (CNN) for fruit detection using imagery obtained from two modalities.
We propose a neural network model that jointly learns entity mentions and their context representation to eliminate use of hand crafted features for FETC.
This paper introduces geometric generalization based zero-shot learning tests to measure the rapid learning ability and the internal consistency of deep generative models.
This paper proposes a novel approach that uses very dense corner features that are spatially and temporally grouped in a hierarchical process to produce an overcomplete compound feature set to achieve state-of-the-art action recognition.
This paper introduces a new content-based, cross-modal retrieval method for video and music that is implemented through deep neural networks.
Language models based on recurrent neural networks have dominated recent image caption generation tasks. We introduce a language CNN model which is suitable for statistical language modeling tasks and shows competitive performance in image captioning.
We present a novel activity recognition CNN which co-learns the object recognition task in an end-to-end multitask learning scheme to improve upon baseline activity recognition performance.
This work presents a large-scale audio-visual speech recognition system based on a recurrent neural network transducer (RNN-T) architecture.
We propose a method to calculate joint loss using dynamic weights to improve the total performance, instead of the individual performance, of tasks.
We constructed time-course protein–protein interaction networks of TNF-α induced regulation of cell cycle in VECs using microarray datasets and genome-wide PPI datasets and analyzed the topological properties of the responsive PPI networks.
We develop a method constructing mid-level motion features which are built from low-level optical flow information and use them to classify input sequences.
In this paper, we propose a principled method for sensibly reducing the learning time, while converging to more accurate link prediction models.
We propose a straightforward method for detecting adversarial image examples, which can be directly deployed into unmodified off-the-shelf DNN models.
In this paper, we present a novel integrated approach for keyphrase generation (KG) that leverages the power of extraction and retrieval to improve the generative model.
Image to image translation is the problem of transferring an image from a source domain to a target domain even when there are geometric changes across the two domains.
This paper introduces an extremely efficient CNN architecture named DFANet for semantic segmentation under resource constraints.
We propose a semi-supervised 3D model-based vision-based control system for low-cost robotic arms that generalizes to real-world tasks.
We present, for the first time, a method for preventing catastrophic forgetting for scenarios with task boundaries that are unknown during training.
We propose a method named snapshot boosting, a boosting-based training framework for deep learning, which can get a balanced trade-off between training expenses and ensemble accuracy.
Learning from demonstrations has gained increasing interest in the recent past, enabling an agent to learn how to make decisions by observing an experienced teacher.
A robust evaluation metric has a profound impact on the development of text generation systems. A desirable metric compares system output against references based on their semantics rather than surface forms.
We present Unicoder, a universal language encoder that is insensitive to different languages. Given an arbitrary NLP task, a model can be trained with Unicoder using training data in one language and directly applied to inputs in other languages.
The autosomal dominant form of retinitis pigmentosa (adRP) is a blindness-causing conformational disease largely linked to mutations of rhodopsin. Molecular simulations coupled to the graph-based protein structure network (PSN) analysis and in vitro experiments were conducted to determine the effects of 33 adRP r Rhodopsin mutations on the structure and routing of the opsin protein.
Autonomous robots often encounter challenging situations where their control policies fail and an expert human operator must briefly intervene, e.g., through teleoperation. Our goal is to automate this decision, thereby enabling users to supervise more robots than their attention would normally allow for.
This paper proposes a way for a robot to recognize every object at an almost human-level accuracy, as long as the robot stays in a closed environment.
We propose the Review-guided Answer Helpfulness Prediction (RAHP) model that not only considers the interactions between QA pairs but also investigates the opinion coherence between the answer and crowds' opinions reflected in the reviews, which is another important factor to identify helpful answers.
Stereo matching algorithms usually consist of four steps, including matching cost calculation, matching cost aggregation, disparity calculation, and disparity refinement. We propose a network architecture to incorporate all steps of stereo matching.
We propose CG-Stereo, a confidence-guided stereo 3D object detection pipeline that uses separate decoders for foreground and background pixels during depth estimation, and leverages the confidence estimation from the depth estimation network as a soft attention mechanism in the3D object detector.
We show that it is possible to predict output quality without generating the captions, based on the probability assigned by the neural model to the reference captions.
This paper introduces DensePoint, a densely sampled and annotated point cloud dataset containing over 10,000 single objects across 16 categories, by merging different kind of information from two existing datasets.
We propose for this task a hierarchical encoder-decoder model which computes a multi-modal embedding of the dialogue context and compute semantic features using pre-trained LSTMs.
A state-of-the-art data collection and information extraction methodology to document infrastructure at high granularity to assess preevent vulnerability and postevent damage in the face of disasters.
The LyS-FASTPARSE team presents BIST-COVINGTON, a neural implementation of the Covington (2001) algorithm for non-projective dependency parsing.
We propose to make use of existing class hierarchies like WordNet to integrate additional domain knowledge into classification. We encode a special label encoding together with a corresponding loss function.
We first extend the analysis supporting this claim and then show that sparseness explicitly contributes to improved classification, hence it should not be completely ignored for computational gains.
We reformulate the problem of ego-motion estimation as a problem of motion estimation of a 3D-scene with respect to a static camera. We provide motion maps as inputs to a deep neural network that predicts 6DoF of scene motion.
We introduce the notion of coarse gradient and propose the blended coarse gradient descent (BCGD) algorithm, for training fully quantized neural networks.
In this paper, we present a learning based approach to depth fusion, i.e., dense 3D reconstruction from multiple depth images that learns to predict an implicit surface representation from the input depth maps.
In this paper, we introduce Clip Alignment with Language (CAL), a model that aligns features for a natural language query to a sequence of short video clips that compose a candidate moment in a video.
To alleviate the problem of data sparsity inherent to recommender systems, we propose a semi-supervised framework that uses abundant unlabelled information to improve the quality of recommendations.
This paper presents a comparative study on five feature selection heuristics applied to a retinal image database called DRIVE.
We explore the transferability of various end-to-end object detection Convolutional Neural Network (CNN) architectures for threat detection within complex and cluttered X-ray security imagery.
In this article, an image feature extraction method based on two-dimensional mel-cepstrum-based Mellin cepstrum is introduced.
In the vision and language navigation task, the agent may encounter ambiguous situations that are hard to interpret by just relying on visual information. We propose an interactive learning framework to endow the agent with the ability to ask for users' help in such situations.
In this paper, we investigate the joint learning of deep representation and model adaptation, where an updater network is introduced for better tracking on future frame.
We propose a learning-based approach for removing the multipath distortions for a Time-of-Flight camera in a robotic arm setup using deep learning.
This paper presents an unsupervised deep learning framework called UnDEMoN for estimating dense depth map and 6-DoF camera pose information directly from monocular images.
This paper proposes an adaptive multi-target future state prediction (position/velocity) method under autonomous driving conditions under changeable scenes.
This data package includes the data, analysis scripts, and relevant documents for the project: Explaining the persistent influence of facial cues in social decision-making.
This paper proposes LRR factorization model based on group norm regularization and uses Augmented Lagrangian Method~(ALM) algorithm to solve this model.
We design and analyse variations of the classical Thompson sampling (TS) procedure for Bayesian optimisation (BO) in settings where function evaluations are expensive, but can be performed in parallel.
We investigate learning a general shape template from data using structured implicit functions.
We proposed a novel way to extract image representations from two consecutive convolutional layers: one layer is utilized for local feature extraction and the other serves as guidance to pool the extracted features.
In this paper, we propose new constraints that are more effective for non-rigid shape recovery and propose a new NRSfM algorithm.
In depth-sensing applications ranging from home robotics to AR/VR, it will be common to acquire 3D scans of interior spaces repeatedly at sparse time intervals (e.g., as part of regular daily use). We propose an algorithm that analyzes these "rescans" to infer a temporal model of a scene with semantic instance information.
A novel boundary refinement architecture to improve localization accuracy by combining coarse-to-fine framework with feature pyramid structure, named as Pyramidal Bounding Box Refinement network(PBRnet)
In this work, we revisit atrous convolution, a powerful tool to explicitly adjust filter's field-of-view as well as control the resolution of feature responses computed by Deep Convolutional Neural Networks, in the application of semantic image segmentation.
End-to-end learning of monocular occupancy grid mapping from weak binocular ground truth using variational encoder–decoder network.
We address the challenging task of video-based person re-identification. Using a learned clip similarity aggregation function allows filtering out hard clip pairs, where the person is not clearly visible, is in a challenging pose, or where the poses in the two clips are too different to be informative.
We propose a novel Attention guided Multi-modal Correlation (AMC) learning method which consists of a jointly learned hierarchy of intra and inter-attention networks for image search by learning their correlation with input query.
We present the first learning-based metric to evaluate image captioning systems that incorporates lexical and semantic information into a single learned metric.
We present a novel training paradigm, Learn from EveryOne (LEO), which leverages multiple instructions (as different views) for the same trajectory to resolve language ambiguity and improve generalization.
We automate the design of counting models with Neural Architecture Search (NAS) and introduce an end-to-end searched encoder-decoder architecture, Automatic Multi-Scale Network (AMSNet), which achieves state-of-the-art results.
This paper uses the IMU measurements to reconstruct the epipolar geometry and it integrates the Epipolar geometry constraint with the brightness constancy assumption in the Lucas-Kanade method.
We propose transductive auxiliary task self-training: training a multi-task model on (i) a combination of main and auxiliary task training data, (ii) test instances with auxiliary task labels which a single-task version of the model has previously generated.
We propose a dynamic graph message passing network, based on the message passing neural network framework, that significantly reduces the computational complexity compared to related works modelling a fully-connected graph.
A unified driver behavior reasoning system toward multi-scale and multi-tasks behavior recognition.
In this paper, a simple but effective instance-level feature representation is presented.
We investigate the effect of precision scaling on both network accuracy and hardware metrics including memory footprint, power and energy consumption, and design area.
SCATTER utilizes a stacked block architecture with intermediate supervision during training, that paves the way to successfully train a deep BiLSTM encoder, thus improving the encoding of contextual dependencies.
A general framework that unifies gradient-based hyperparameter optimization and meta-learning (or learning-to-learn).
In this paper, we propose to guide the video captioning generation with Part-of-Speech (POS) information, based on a gated fusion of multiple representations of input videos.
In this paper, we propose a novel network structure, which allows an arbitrary number of frames as the network input for video-based action recognition.
In this paper, we propose a Deep Conditional Variational Autoencoder based model that synthesizes diverse anatomically plausible 3D-pose samples conditioned on the estimated 2D-POSE.
In this paper, we propose a novel pulmonary nodule detection framework based on a 3D Feature Pyramid Network (3DFPN) to improve the sensitivity of nodule Detection by employing multi-scale features to increase the resolution of nodules, as well as a parallel top-down path to transit the high-level semantic features.
We propose a gradient detach based stacked complementary losses method that uses detection losses as the primary objective, and cuts in several auxiliary losses in different network stages accompanying with gradient detach training to learn more discriminative representations.
We propose a new attention framework by introducing a novel conditional global feature which represents the weak feature descriptor of the current focused object conditional on its previous observations.
Iterate averaging has a rich history in optimisation, but has only very recently been popularised in deep learning. We investigate its effects in a deep learning context, and argue that previous explanations on its efficacy, which place a high importance on the local geometry (flatness vs sharpness of final solutions, are not necessarily relevant.
In this paper, we focus on learning structure-aware document representations from data without recourse to a discourse parser or additional annotations.
We propose a joint optimization framework of learning DNN parameters and estimating true labels. Our framework can correct labels during training.
ContextNet combines a deep network branch at low resolution that captures global context information efficiently with a shallow branch that focuses on high-resolution segmentation details.
We present a latent variable model for predicting the relationship between a pair of text sequences. We extend the cross-sentence generating framework to facilitate semi-supervised training.
In this paper, we explore the potential of more sophisticated language models in GEC and offer some key insights on their strengths and weaknesses.
We investigate questions of scalability, performance and energy efficiency for large-scale capsular endoscopy, investigate means for providing support to doctors in unobtrusive ways, and assist in reporting.
We present a novel training framework for neural sequence models, particularly for grounded dialog generation. Our primary contribution is an end-to-end trainable generative visual dialog model, where G receives gradients from D as a perceptual (not adversarial) loss of G.
We strive to reduce the energy cost during training, by dropping unnecessary computations, from three complementary levels: stochastic mini-batch dropping on the data level; selective layer update on the model level; and sign prediction for low-cost, low-precision back-propagation, on the algorithm level.
We present a multimodal feature representation that encodes all these modalities and use it to infer temporal ordering.
We propose a novel, docking-based pre-screening protocol named Spresso (Speedy PRE-Screening method with Segmented cOmpounds). Partial structures (fragments) are common among many compounds, and the number of fragment variations needed for evaluation is smaller than that of compounds.
We develop a differentiable NAS solution that optimizes both the architecture of a deep network and its parameters in the same round of backward propagation, yielding an end-to-end mechanism of searching network architectures.
We propose a weighted fusion approach that combines the dictionary learning-based sparse representation with collaborative representation for person re-identification.
We first investigate the supervision vanishing issue in existing backpropagation (BP) methods and propose to address it via an effective method, called Multi-way BP (MW-BP), which relies on multiple auxiliary losses added to the intermediate layers of the network.
We propose a novel neural architecture search method with balanced training strategy to ensure fair comparisons and a selective drop mechanism to reduce conflicts among candidate paths.
This paper proposes visual knowledge memory network to address this issue, which seamlessly incorporates structured human knowledge and deep visual features into memory networks in an end-to-end learning framework.
We investigate how different ImageNet models affect transfer accuracy on domain adaptation problems, and explore the architecture of each neural network to find the best layer for feature extraction.
We study the conservative learning problem in the contextual linear bandit setting and introduce a novel algorithm, the Conservative Constrained LinUCB (CLUCB2), which outperforms state-of-the-art conservative bandit algorithms in a number of synthetic and real-world problems.
We propose a joint learning framework that couples re-id learning and data generation end-to-end, leading to state-of-the-art performance on several benchmark datasets.
Small-molecule inhibitors of protein-protein interactions tend to bury a smaller fraction of their surface area upon binding to their protein targets, which can make detection of active compounds from decoy compounds more difficult.
We present a novel parallel approach, parallel nearest neighbor unit PNNU, for finding the nearest member in a learned dictionary of high-dimensional features. This is a computation fundamental to machine learning and data analytics algorithms.
We propose a principled active sample mining (ASM) framework for using unlabeled or partially labeled data for object detection while minimizing user effort.
A simple yet efficient approach for video representation, called Adversarial Video Distillation (AVD).
In this paper, we propose a cost aggregation strategy based on joint bilateral filtering and incremental calculation schemes that allow for efficient and accurate inference of disparity maps.
We investigate the samples derived from generative adversarial networks (GAN) from a classification perspective. We propose architectural and algorithmic changes to reduce this gap.
We propose a new hybrid model of Alpha-Beta Associative memories (Amαβ) with Correlation Matrix (CM) and K-Nearest Neighbors (KNN), where the Amαβ-CMKNN was trained with characteristic biometric vectors generated from images of faces from people who present different facial expressions such as happiness, surprise, anger and sadness.
This paper presents a novel approach, which relies on content-based guided image filtering and weighted semi-global optimization for fast and accurate disparity estimation.
We formulate this intuition as a non-parametric classification problem at the instance-level, and use noise-contrastive estimation to tackle the computational challenges imposed by the large number of instance classes.
This paper attempts to address this very issue through a content aware technique, uses combinations of Chan-Vese segmentation algorithm, two-dimensional Gaussian filter and brute-force nearest neighbor search.
This paper presents a novel deep learning based formulation, termed as Class Specific Mean Autoencoder, to learn the intra-class similarity and extract class-specific features.
A novel CNN architecture with an improved residual convolutional LSTM is proposed for temporally consistent horizon line estimation from video sequences.
A theory for hierarchizing non-hierarchical image segmentation method depending on a region-dissimilarity parameter which controls the desired level of simpli fication.
We propose a privacy-preserving adversarial protector network (PPAPNet) as an image anonymization tool to convert an image into another synthetic image that is both realistic and immune to model inversion attacks.
We propose Escort, an efficient sparse convolutional neural network on GPUs, which improves inference performance (speed) when running models on GPUs.
LEP-CNN allows IoT devices to securely offload over 99% CNN operations, and edge devices to execute CNN inference on encrypted data as efficient as on plaintext.
We compare SNNs to auto-encoders on three visual recognition datasets, and extend the use of SNN-equipped spike-timing dependent plasticity rules to color images.
We review the state of the art algorithms for generating adversarial examples and the countermeasures against adversarial Examples, for the three popular data types, i.e., images, graphs and text.
We show how to boost conditional GAN by augmenting available class labels by clustering in the representation space learned by the same GAN model.
We investigated the efficacy of current state-of-the-art neural embedding models for semantic similarity estimation of sentences from biomedical literature.
This paper proposes a multiple-scaling-based SR (MSSR) method to extend CNN-based single image super-resolution (SR) models from discrete to continuous scale without retraining networks.
We present 3D-BEVIS (3D bird’s-eye-view instance segmentation), a deep learning framework for joint semantic- and instance-segmentation on 3D point clouds.
This work proposes a novel unsupervised domain adaption framework which transfers discriminative representations from the labeled source domain (dataset) to the unlabeled target domain (Dataset), and a novel domain similarity loss based on one-class classification.
In this paper, we introduce the global anchor method for detecting corpus-level language shifts.
We propose an architecture based on Gated Recurrent Unit that supports (i) representation learning of phrases of arbitrary granularity and (ii) task-specific attentive pooling of phrase alignments between two sentences.
Feeding an appropriate feature to the CNN enhances its performance in some face related works such as age/gender estimation, face detection and emotion recognition.
In this paper, we propose a novel regularization method for Generative Adversarial Networks, which allows the model to learn discriminative yet compact binary representations of image patches (image descriptors).
We propose an end-to-end learning architecture with hybrid deep appearance-temporal feature for video-based person re-identification that achieves 79%, 59% and 72% at Rank-1.
We propose an adaptation of the gradient-weighted class activation mapping method for embedding networks and develop an efficient weight-transfer method to explain network decisions.
We present a semi-supervised approach that determines object regions in a completely automatic manner and only requires global labels of training images.
We present a locality preserving loss that improves the alignment between vector space representations (i.e., word or sentence embeddings) while separating (increasing distance between) uncorrelated representations as compared to the standard method that minimizes the mean squared error.
We propose an adaptive exploration/exploitation trade-off that transforms the original framework into a versatile retrieval framework with full searching capabilities.
In this paper, a unified three-layer hierarchical approach for solving tracking problems in multiple non-overlapping cameras is proposed.
We propose a generative model neural network approach for recovering signals from compressed measurements contaminated with sparse outliers, and give an upper bound on the number of outliers allowed for recovery.
We propose a novel neural network framework, neural fashion recommendation (NFR), that simultaneously provides fashion recommendations and generates abstractive comments.
We propose an actor-transformer model able to learn and selectively extract information relevant for group activity recognition. Experiments show what is important to transform and how it should be transformed.
Aging affects left and right half face differently owing to numerous factors such as sleeping habits, exposure to sun light, and weaker face muscles.
We propose a combined and jointly trained convolutional recurrent recurrent neural network architecture that allows the training of an end-to-end to system that attempts to alleviate the aforementioned drawbacks.
We propose Amulet, a generic aggregating multi-level convolutional feature framework for salient object detection.
We perform a comprehensive study to evaluate the effects of different facial regions with state-of-the-art VSR models, including the mouth, the whole face, the upper face, and the cheeks.
We propose an efficient, end-to-end fully convolutional Siamese network that computes the similarities at multiple levels for person re-Identification.
This paper presents an aircraft pose estimation method based on a convolutional neural network through reconstructing the 2D skeleton of an aircraft.
We propose a joint face alignment and 3D face reconstruction method to simultaneously solve these two problems for 2D face images of arbitrary poses and expressions.
In this paper, we develop a novel training method for classifiers so that such inference algorithms can work better.
In order to enjoy the simplicity of anchor-free and one-stage detectors and the accuracy of two-stage ones simultaneously, we propose some adaptations based on a detector, Center and Scale Prediction(CSP)
We introduce a parameterization method called Neural Bayes which allows computing statistical quantities that are in general difficult to compute and opens avenues for formulating new objectives for unsupervised representation learning.
We use hidden Markov models to recover sequences of characters from images of redacted text and use them for text classification.
Unsupervised domain adaptation aims to leverage labeled data from a source domain to learn a classifier for an unlabeled target domain. The key insight lies with exploiting the mutually beneficial information between two networks.
In modern recommender systems, both users and items are associated with rich side information, which can help understand user and items. While side information has been proved to be valuable, the majority of existing systems have exploited only flat side information or only hierarchical side information due to the challenges brought by the heterogeneity.
Point cloud is an important type of geometric data structure. Due to its irregular format, most researchers transform such data to regular 3D voxel grids or collections of images. In this paper, we design a novel type of neural network that directly consumes point clouds, which well respects the permutation invariance of points in the input.
In this paper, we propose Multilinear Compressive Learning, a framework that takes into account the tensorial nature of multi-dimensional signals in the acquisition step and builds the subsequent inference model on the structurally sensed measurements.
Predicting facial attributes from faces in the wild using mid-level CNN features .
This paper presents a novel approach to tackle this stance detection problem, based on the combination of string similarity features with a deep neural network architecture that leverages ideas previously advanced in the context of learning-efficient text representations, document classification, and natural language inference.
We propose a family of Krylov subspace based algorithms (\fasten) to speed up and scale up the computation of Sylvester equation for graph mining.
We present a novel stereo visual odometry system for automotive applications based on advanced monocular techniques.
We propose a probabilistic framework for incorporating quantitative information from AP-MS data into existing PPI inference methods that analyze binary interaction data, extending the existing body of work on PPI analysis using binary experimental data.
We present an Information-theoretic Multi-view Adaptation Model (IMAM) based on a multi-way clustering scheme, where word and link clusters can draw together seemingly unrelated domain-specific features from both sides.
This paper introduces GeneCAI, a novel optimization method that automatically learns how to tune per-layer compression hyper-parameters to capture optimal Pareto front.
This paper tackles the problem of learning brain-visual representations for understanding and neural processes behind human visual perception, with a view towards replicating these processes into machines.
We use the geodesic distance transform to enforce connectivity in local stereo matching and achieve state of the art results.
In this work, we develop a multi-stage progressive structure for deep neural networks which is able to adapt its inference process and complexity for images with different visual recognition complexity.
We investigate completely self-supervised learning of a general image embedding and control primitives, based on finding the shortest time to reach any state.
We propose Guided Attention for Sparsity Learning, a framework based on interpretable attention mechanisms for imposing structured and non-structured sparsity in deep neural networks.
In this paper we introduce a formal definition of robustness which can be viewed as a localized Lipschitz constant of the network function, quantified in the domain of the data to be classified.
We introduce a general framework based on an alternating direction method of multipliers to devise efficient, robust black-box attacks that work with various distortion metrics and feedback settings without incurring high query complexity.
We investigate the utility of hands as a natural interface for including and indicating the object of interest in the camera frame. We propose a deep learning system that jointly models hand segmentation and object localization for object classification.
This survey offers insight into the field of machine learning with Python, taking a tour through important topics to identify some of the core hardware and software paradigms that have enabled it.
A generative deep neural network interacted with a genetic algorithm to evolve stimuli that maximized the firing of neurons in alert macaque inferotemporal cortex without making any assumptions about natural features or categories.
In this paper we extend universal schema to natural language question answering, employing memory networks to attend to the large body of facts in the combination of text and KB.
We address the problem of effectively composing skills to solve sparse-reward tasks in the real world. Our insight is that for many tasks, the learning process can be decomposed into learning a state-independent task schema (a sequence of skills to execute) and a policy to choose the parameterizations of the skills in a state dependent manner.
We propose an abstraction memory based framework for few-shot learning, building upon machine-labeled image annotations, achieving great results.
We consider the design of an image representation that embeds and aggregates a set of local descriptors into a single vector. We formalise this problem and propose two related solutions, both aimed at equalising the individual contributions of the local descriptor in the final representation.
Multidrug combinations that increased the risk of myopathy were identified in the US Food and Drug Administration Adverse Event Reporting System and electronic medical record (EMR) databases by a mixture drug-count response model.
This paper proposes a novel method for factorising the information in the latent space of an autoencoder (AE), to improve the interpretability of the latent Space and facilitate controlled generation.
We propose a new method called MNEW, including multi-domain neighborhood embedding, and attention weighting based on their geometry distance, feature similarity, and neighborhood sparsity, for sparse outdoor point clouds.
We propose a framework to improve over these challenges using adversarial training and impose domain-confusion between natural and synthetic image representations to reduce the distribution gap.
In this paper, a novel Generation-Evaluation framework is developed for multi-turn conversations with the objective of letting both participants know more about each other.
We present a probabilistic variant of the recently introduced maxout unit that is partially invariant to changes in its input, while improving their invariance properties.
This paper derives a theory of Graphon Signal Processing centered on the notions of graphon Fourier transform and linear shift invariant graphon filters.
We propose an iterative discriminative-generative approach for unsupervised segmentation of complex activities from video into multiple steps, or sub-activities, without any textual input.
In this paper, we propose a novel image defogging approach called NIN-DehazeNet combining Network-in-Network with MSCNN for single image.
We present a novel robotic grasp detection system that predicts the best grasping pose of a robotic gripper for novel objects using the RGB-D image of the scene using a deep convolutional neural network.
In this paper, we introduce a"3D as-smooth-as-possible (3D-ASAP)"prior inside the pipeline, which enables joint estimation of edges and 3D scene, yielding significant improvement in accuracy for fine detailed structures.
We present an approach for weakly supervised learning of human actions from video transcriptions without any frame-based annotation.
We present an adaptive importance learning scheme for SISR that trains the network with an easy-to-complex paradigm by dynamically updating the importance of image pixels on the basis of the training loss.
We propose a new quality measure that evaluates how well the superpixel segmentation algorithms cover relevant image boundaries, based on two recently published datasets coming with ground truth optical flow fields.
We propose a new approach to generate a complete image of a person, given an occluded version in input, that should be a) without occlusion b) similar at pixel level to a completely visible people shape c) capable to conserve similar visual attributes (e.g. male/female) of the original one.
We address these questions by exploring the actions and interactions that are detectable in monocular still images of the MS COCO dataset.
This paper introduces a query-adaptive late fusion scheme at the score level, which is able to highlight the good features and suppress the bad ones, is resilient to distractor features, and achieves competitive retrieval accuracy compared with the state of the art.
The complex environment background, lighting conditions, and other action-irrelevant visual information in the video frame bring a lot of redundancy and noise to the action spatial features, which seriously affects the accuracy of action recognition. Aiming at this point, we propose a recurrent region attention cell to capture the action-relevant regional visualinformation in the spatial feature, and according to the temporal sequential natures of the video, a Recurrent Region Attention model (R
TPPII influences a wide network of signaling pathways that are regulated by MAPKs and exerts thereby a pleiotropic effect on biological processes associated with cell survival, proliferation and genomic instability.
We propose an approach towards high-resolution facial image de-identification, called k-Same-Siamese-GAN, which leverages the k Same-Anonymity mechanism, the Generative Adversarial Network, and the hyperparameter tuning methods.
This paper studies the cooperative training of two generative models for image modeling and synthesis.
We propose the use of graph Laplacian regularized logistic regression to integrate biological networks into disease classification and pathway association problems.
We propose a local feature integration framework based on attention clusters for video classification, and introduce a shifting operation to capture more diverse signals.
A general framework based on the perturbation analysis of learning algorithms which consists of convex programming and is able to recover many current adversarial attacks as special cases.
In this paper, we reviewed several modern image labeling methods based on Markov random field and conditional random Field. And we compare the result of these methods with classical image labeling method.
We use a large-scale faces-in-the-wild dataset with human annotations in the form: Expressions A and B are visually more similar when compared to expression C, and train a neural network that produces a compact (16-dimensional) expression embedding.
We propose to inject phrasal paraphrase relations into BERT in order to generate suitable representations for semantic equivalence assessment, which effectively improves a smaller BERT model while maintaining the model size.
We propose an adaptive document retrieval model that learns the optimal candidate number for document retrieval, conditional on the size of the corpus and the query, which improves state-of-the-art methods.
We propose a new descriptor named holons visual representation (HVR), which exploits both global characteristics and the statistic information of local descriptors in the image dataset in an efficient way.
We investigate the problem of identifying adversarial attacks on image-based neural networks and propose a framework which can identify whether a given input is adversarial.
We introduce a novel word vector postprocessing scheme under a causal inference framework, which achieves state-of-the-art performance.
This paper proposes a computationally efficient and numerically stable orthogonalization method using Newton's iteration (ONI), to learn a layer-wise Orthogonal weight matrix in DNNs.
A well-trained Convolutional Neural Network can easily be pruned without significant loss of performance. We attempt to address this problem from another angle - not by changing the network structure but by altering the training method.
We present a connected system consisting of three homogeneous neural semantic matching models that conduct document retrieval, sentence selection, and claim verification jointly for fact extraction and verification.
In logic-based approaches to reasoning tasks such as Recognizing Textual Entailment (RTE), it is important for a system to have a large amount of knowledge data. However, there is a tradeoff between adding more knowledge data for improved RTE performance and maintaining an efficient RTE system.
This paper presents a memory efficient architecture that implements the Multi-Scale Line Detector (MSLD) algorithm for real-time retinal blood vessel detection on a Zynq FPGA.
An evaluation framework to compare various visual features' performance for part based object detection.
We reconsider the training objective of Generative Adversarial Networks (GANs) from the mixed Nash Equilibria (NE) perspective. Inspired by the classical prox methods, we develop a novel algorithmic framework for GANs via an infinite-dimensional two-player game.
This paper tackles the problem of endogenous link prediction for Knowledge Base completion by complementing a high-capacity model with a simpler one that achieves state-of-the-art results on four benchmarks.
A survey on the state-of-the-art DL-based visual tracking methods, benchmark datasets, and evaluation metrics.
We propose a novel group-shuffling random walk network for end-to-end refining the P2G affinities based on G2G affinity information with a simple yet effective matrix operation.
We propose a new feature representation framework based on time series pooling, which captures short-term/long-term changes in feature descriptor elements to represent motion in the activity video.
We propose a unified formulation for the problem of 3D human pose estimation from a single raw RGB image that reasons jointly about 2D joint estimation and 3D pose reconstruction to improve both tasks.
This paper introduces a method to quantify dependency between data series composed of few sample points. The method is used to construct gene co-expression subnetworks of highly significant edges.
In recent years, attention models have been extensively used for person and vehicle re-identification. However, depending on the orientation, the contribution of each key-point varies. In this paper, we propose a novel dual-path adaptive attention model that captures localized discriminative features by focusing attention on the most informative key-points.
We present a new incremental learning framework for realtime object recognition in video streams. We adopt an inductive transfer learning (ITL) approach to warp the video feature space to ImageNet feature space, so enabling incremental updates.
We propose a Deep Reinforcement Learning based method capable of learning sequential reasoning across large collections of documents so as to pass a query-aware, fixed-size context subset to existing models for answer extraction.
A set of experiments that demonstrate that relational features, mainly derived from dependency-syntactic and semantic role structures, can improve the performance of automatic systems for fine-grained opinion analysis tasks: marking up opinion expressions, finding opinion holders, and determining the polarities of opinion expressions.
We propose a new framework, which achieves the balancing between detection accuracy and video processing time by employing two efficient motion techniques, specifically, foreground and optical flow energy.
Unseen Visual Data Synthesis for Zero-shot Learning using only Semantic Attributes .
In this paper we address the problem of building environmental maps that include both semantically meaningful, object-level entities and point- or mesh-based geometrical representations.
The recently proposed panoptic segmentation task segments both "things" (countable object instances) and "stuff" (amorphous regions) within a single output. A common approach involves the fusion of instance segmentation (for "things") and semantic segmentation proposals into a non-overlapping placement of segments, and resolves occlusions (or overlaps) between segments based on confidence scores.
We present Mean Teacher with Object Relations (MTOR) that novelly remolds Mean Teacher under the backbone of Faster R-CNN. The domain gap is thus naturally bridged with consistency regularization in a teacher-student scheme.
We propose an approach involving the introduction of facial landmark information into the task simplifier and landmark heatmap generator constructed before the feed-forward neural network, which can use this information to normalize the face shape into a canonical shape, for enhancing generalization ability in the wild.
We propose CorrReg, a correlation-regularized network layer for multi-view learning in fusion layers of generic DNNs, and apply it to fusion layers in these networks, improving classification performance.
We present a neighborhood adaptive graph convolutional network (NAGCN), a novel method to efficiently learn each node's representations for node classification on the graph.
We propose a lightweight implementation of random shuffling (LIRS) to randomly shuffle the entire training dataset, and the selected training instances are directly accessed from the storage and packed into batches.
A Learning-based Boundary Metric (LBM) is proposed to replace $\chi^2$ difference adopted by the classical algorithm mPb.
This paper studies the dynamic generator model for spatialtemporal processes such as dynamic textures and action sequences in video data.
We propose a method to dynamically apply convolutions conditioned on the input image, at a lower computational complexity.
We introduce RED-NET: A Recursive Encoder-Decoder Network with Skip-Connections for edge detection in natural images.
Generative Adversarial Networks (GANs) can be used to generate synthetic samples for emotion recognition.
We developed a guided filtering scheme for optical flow computation, which is able to preserve the image edges and motion boundaries, and to improve the accuracy and robustness of optical flow estimation under the coarse-to-fine computing scheme.
Combining simple elements from the literature, we define a linear model that is geared toward sparse data, in particular implicit feedback data for recommender systems.
We evaluate S3DCNN on a large-scale 3D Shape benchmark ModelNet40, and measure how it is impacted by voxel resolution of input shape.
Constructing powerful generative models for natural images is a challenging task. Here we introduce PixelVAE++, a VAE with three types of latent variables and a PixelCNN++ for the decoder.
Our goal is to isolate individual speakers from multi-talker simultaneous speech in videos. In this paper, we propose a deep audio-visual speech enhancement network that is able to separate a speaker's voice given lip regions in the corresponding video.
Hierarchical Adaptation Tree for Structural SVM Classifiers .
This paper aims to evaluate the security and accuracy of Multi-Factor Biometric Authentication (MFBA) schemes that are based on applying UserBased Transformations (UBTs) on biometric features.
We trained a generative adversarial network with fMRI data and the corresponding stimulus images to build an end-to-end reconstruction model for brain activity and perception.
We propose Hierarchical Group Convolution (HGC) for creating computationally efficient neural networks that leverage the inter-group information effectively.
A series of computer-aided virtual screening techniques were utilized to discover potential inhibitors of PDKs with favorable interaction energy and predicted to be non-toxic.
We examine the biased embedding values of [CLS] token before the fine tuning phase, and propose several simple yet effective normalization methods to modify the [ CLS] embedding during the fine-tuning.
A novel approach called compressive sequential learning (CSL) is proposed by leveraging the compressive sensing theory and sequential learning to address the problem of action similarity labeling.
A Pyramid Attention Network(PAN) is proposed to exploit the impact of global contextual information in semantic segmentation.
Road scene model construction is an important aspect of intelligent transportation system research. This paper proposes an intelligent framework that can automatically construct road scene models from image sequences.
We propose a principled approach for one-class SVMs (OC-SVM), that draws on the novel insight that these models can be rewritten as distance/pooling neural networks, allowing us to quickly and reliably explain decisions in terms of input features.
We propose a novel unsupervised game-theoretic salient object detection algorithm that does not require labeled training data.
A graph-based recommender system using link prediction techniques incorporating similarity metrics for improving coverage and hits rate of recommender systems.
The ability to predict and therefore to anticipate the future is an important attribute of intelligence. While prediction of the raw RGB pixel values in future video frames has been studied in previous work, we introduce the novel task of predicting semantic segmentations of future frames.
A novel soft softmax-triplet loss is proposed to support learning with soft pseudo triplet labels for achieving the optimal domain adaptation performance.
We introduce a multi-scale framework for low-level vision where the goal is estimating physical scene values from image data—such as depth from stereo image pairs.
We propose to detect scene text by localizing corner points of text bounding boxes and segmenting text regions in relative positions, achieving better results than previous methods.
We present a theoretical framework for robust estimation of multiple motions and structures from perspective views through a car-mounted camera.
An end-to-end trainable neural network model for scene text spotting, which aims at simultaneous text detection and recognition.
Iris recognition is nowadays considered as one of the most accurate biometric recognition techniques. However, the overall performances of such systems can be reduced in non-ideal conditions, such as unconstrained, on-the-move, or non-collaborative setups.
We introduce a hierarchical adjacency dependent network (HadNet) for semantic segmentation and explore the correlation of adjacent pixels in different feature levels to improve the segmentation accuracy.
In this paper, we propose a novel algorithm m ::: ulti-gr ::: a ::: nular r ::: epresentation learning for networks based on the 3-clique lique named Marc. It makes the representations of the current network be formed by both considering the structure of this granular network and inheriting the coarser network representation results.
Answerer in Questioner's Mind (AQM), a novel information theoretic algorithm for goal-oriented dialog.
This paper presents a robust face recognition technique based on the extraction and matching of SIFT features related to independent face areas.
This paper proposes a deep learning encoder-decoder architecture, based on a transfer learning technique, to predict visual saliency.
We propose the single-column counting network (SCNet) for efficient crowd counting without relying on multi-column networks.
The principal component analysis network (PCANet) is an unsupervised parsimonious deep network, utilizing principal components as filters in the layers. We propose Hybrid Network (HybridNet) to simultaneously learn filters from both the views of the data.
In this paper, we propose and study two hierarchical models for the task of question generation from paragraphs.
Adaptive Genetic Algorithm with Adaptive Strategy for Exploiting Outliers .
Using dilated convolutional units for reading comprehension, we achieve state-of-the-art results on two question answering tasks, while at the same time achieving up to two orders of magnitude speedups.
We propose to incorporate a biased PU risk within the standard GAN discriminator loss function, enabling GAN-based PU learning without prior knowledge.
We propose a graph-based representation for describing the geometry information of multiview image representations that is natural and flexible.
We formulate saliency estimation as a quadratic program problem based on robust hypotheses and propose an adaptive center-based bias hypothesis.
We propose a unifying framework that can handle and combine varying types of less-demanding weak supervision with competitive performance.
The emergence of biometric tools and its increased usage in day to day devices has brought simplicity in the authentication process for the users as compared to the passwords and pattern locks. Among different biometric traits, the face is one which can be captured without much cooperation of users.
This paper presents resource-aware algorithms for distributed inter-robot loop closure detection with provable performance guarantees.
We study weakly supervised learning approaches for salient object detection and propose a solution toward jointly addressing salient object existence and detection tasks.
We propose Mask Scoring R-CNN which uses a network block to learn the quality of the predicted instance masks and improve instance segmentation performance.
We propose an online meta-learning setting which captures the spirit and practice of continual lifelong learning and provides an online regret guarantee.
We propose a learned updater based on recurrent neural networks and learn the online learning algorithm itself using large numbers of offline videos , i.e., learning to update .
In this paper, we investigate the robust dictionary learning (DL) to discover the hybrid salient low-rank and sparse representation in a factorized compressed space, which can improve the robustness to outliers and noise in data.
We propose a novel and principled learning formulation that maximizes the information between labels and input data indices for both representation learning and clustering.
We propose mathematically grounded generalizations of graph convolutional networks (GCN) to (products of) constant curvature spaces, according to their discrete curvature.
We introduce SkipNet, a modified residual network that uses a gating network to selectively skip convolutional blocks based on activations of the previous layer.
We propose an adaptive scale selection mechanism to determine a suitable resolution level from which to begin the hierarchical depth estimation process for each pixel.
We propose a reinforcement learning framework to solve the joint content pushing and recommendation problem that maximizes the net profit of a mobile network operator.
Choco-SGD achieves linear speedup in the number of workers for arbitrary high compression ratios on general non-convex functions, and non-IID training data.
We explore the sparsification of CNNs by proposing three model-independent methods. Our methods are applied on thefly and require no retraining.
We learn general and effective models for both audio and video analysis from self-supervised temporal synchronization, achieving state-of-the-art performance.
We propose a deep-learning architecture called ADNet, that automatically detects the presence of advertisements in a video frame, and achieves state-of-the-art results on a public dataset.
An asymmetric 3D-CNN deep model for action recognition.
We explore the task of Canonical Surface Mapping (CSM) by leveraging only foreground mask labels for training and exploiting a geometric cycle consistency loss.
We introduce a motion part regularization framework to mine for discriminative groups of dense trajectories which form important motion parts and use them for action classification.
We develop a novel deep contour detection algorithm with a top-down fully convolutional encoder-decoder network that achieves state-of-the-art performance.
We propose a fast approximate AIB algorithm that can significantly improve the computational efficiency of AIB while well maintaining or even slightly increasing its classification performance.
In this work1, we present a method to represent a video with a sequence of words, and learn the temporal sequencing of such words as the key information for predicting and recognizing human actions.
We first used behavioral methods to discover hundreds of these ‘challenge’ images that require additional recurrent processing beyond the feedforward IT response, demonstrating that recurrent circuits are critical for rapid object identification.
We study methods for learning syntactic sentence embeddings with syntactic structure using a multilingual parallel-corpus augmented by Universal Parts-of-Speech tags.
The Relative Motion Descriptor is an approach to the categorisation of such activity in natural settings, which is based solely on the relative distribution of spatio-temporal interest points.
A convolutional neural network for image classification can be constructed using Runge-Kutta methods.
In this work, the task of pixel-wise semantic segmentation in the context of self-driving with a goal to reduce the inference time is explored.
We explore the use of stereo sequences for learning depth and visual odometry from a monocular sequence.
We propose a novel warp LSTM network, which propagates the spatio-temporal information for a long period and thereby captures the corresponding long-term dependencies.
A probabilistic classifier that can predict smoking vs nonsmoking environments from images of a smoker’s daily life and trigger environment-based interventions.
We use a black-box population-based optimization algorithm to generate semantically and syntactically similar adversarial examples that fool well-trained sentiment analysis and textual entailment models with success rates of 97% and 70%.
A large-scale road damage dataset is prepared, and a state-of-the-art object detection method using convolutional neural networks can be used for road damage detection.
We address the problem of outlier detection for robust motion estimation by using modern sparse-low-rank decompositions, i.e., Robust PCA-like methods, to impose global rank constraints.
We characterize a class of base kernels used to compare parts that guarantees positive semidefinite optimal assignment kernels. We apply these kernels for graph data.
This paper describes our system for SemEval-2018 Task 11: Machine Comprehension using Commonsense Knowledge.
In this paper, we propose an unsupervised learning approach, which is capable of estimating various complex poses well under limited available training data.
We investigate the effectiveness of pre-trained \textit{Inception} model for crowd counting. We propose a novel curriculum learning strategy for more efficient training of crowd counting networks.
We propose Differentiable Soft Quantization (DSQ) to bridge the gap between the full-precision and low-bit networks.
We present a novel language representation model enhanced by knowledge called ERNIE (Enhanced Representation through kNowledge IntEgration) which achieves state-of-the-art results on five Chinese natural language processing tasks.
This paper presents a new deep architecture for actionness estimation, called hybrid fully convolutional network (H-FCN), which leverages the strong capacity of deep models to estimate actionness maps.
We focus on first-person action recognition from egocentric videos. Unlike the state-of-the-art approaches, we show that a regular two stream Convolutional Neural Network (CNN) with Long Short-Term Memory (LSTM) architecture, having separate streams for objects and motion, can generalize to all categories of first- person actions.
We propose a new method to create compact convolutional neural networks (CNNs) by exploiting sparse convolutions. Different from previous works that learn sparsity in models, we directly employ hand-crafted kernels with regular sparse patterns.
We leverage a sequence-to-sequence model to generate synthetic captions that have the same meaning for robust image generation.
A good neural sequence-to-sequence summarization model should have a strong encoder that can distill and memorize important information from long input texts so that the decoder can generate salient summaries based on the encoder's memory.
We propose ISTA-Net, a fast yet accurate algorithm for compressive sensing (CS) reconstruction of natural images, while maintaining fast computational speed.
We propose a cross-lingual framework for fine-grained opinion mining using bitext projection and a novel dependency-based model.
We propose the configurable rendering of massive quantities of photorealistic images with ground truth for the purposes of training, benchmarking, and diagnosing computer vision models.
The aim of this work is to identify seasonal trends in revenue development in a selected e-commerce segment based on the assessment of the applicability of the Facebook Prophet forecasting tool for debugging seasonal tendencies.
We propose a gated texture CNN (GTCNN), which is designed to carefully exclude the texture information from each intermediate feature map of CNN by incorporating gating mechanisms.
We present a novel unsupervised invariance induction framework that learns a split representation of data through competitive training between the prediction task and a reconstruction task coupled with disentanglement, without needing any labeled information about nuisance factors or domain knowledge.
We define a new notion of ensemble diversity in the adversarial setting as the diversity among non-maximal predictions of individual members, and present an adaptive diversity promoting regularizer to encourage the diversity, which leads to globally better robustness for the ensemble by making adversarial examples difficult to transfer among individual members.
This paper presents a novel yet intuitive approach to unsupervised feature learning. Inspired by the human visual system, we explore whether low-level motion-based grouping cues can be used to learn an effective visual representation.
In this paper, we present a novel method for generating composite images for attacking a mentor neural network using a student model and stealing its knowledge.
This paper addresses this task when only partial scanning data are available. We propose a solution for an obstacle categorization problem for partial point clouds without shape modeling.
We further apply a pre-trained language model (BERT) to provide a stronger baseline for document-level relation extraction.
We show that adversarial examples, i.e., the visually imperceptible perturbations that result in Convolutional Neural Networks (CNNs) fail, can be alleviated with a mechanism based on foveations---applying the CNN in different image regions.
Packing naturally penalizes generators with mode collapse, thereby favoring generator distributions with less mode collapse during the training process.
We first revisit and systematically analyze object detectors and many recently developed attacks from the perspective of model robustness. We further develop an adversarial training approach which can leverage the multiple sources of attacks for improving the robustness of detection models.
We propose a two-step, yes and no question answering framework to find specific individuals doing one or multiple specific actions in aerial images.
In this paper, we formulate the task in a weakly-supervised attribute localization framework, where novelly designed detection layers are used to train these layers without the need of bounding box annotations.
We propose an image super resolution(ISR) method using generative adversarial networks (GANs) that takes a low resolution input fundus image and generates a high resolution super resolved (SR) image upto scaling factor of $16$.
We propose a Siamese network which models an action as a transformation which changes the state of the environment before the action happens (precondition) to the state after the action.
We develop a dual motion Generative Adversarial Net (GAN), which learns to explicitly enforce future-frame predictions to be consistent with the pixel-wise flows in the video through a dual learning mechanism.
This paper presents the components and services that are integrated using the qa vocabulary and the Qanary methodology for QA pipelines distributed over the Web.
The self-expressive property of data points, that is, each data point can be linearly represented by the other data points in the same subspace, has proven effective in leading subspace clustering methods. To overcome these problems, in this article, we introduce a scaled simplex representation (SSR) model for the SC problem.
We propose to represent shapes as the deformation and combination of learnt elementary 3D structures. We demonstrate this decomposition in learnt elementary structures is highly interpretable and leads to clear improvements in 3D shape generation and matching.
Convolutional neural networks are designed for dense data, but vision data is often sparse (stereo depth, point clouds, pen stroke, etc.). We present a method to handle sparse depth data with optional dense RGB and accomplish depth completion and semantic segmentation changing only the last layer.
We derive a learning rule that minimizes its empirical error as well as a measure of the model complexity, while improving generalization.
We propose to generate FiLM layers going up the hierarchy of a convolutional network in a multi-hop fashion rather than all at once, as in prior work.
We propose a novel defense solution based on a Deep Denoising Sparse Autoencoder (DDSA), where the adversarial noise of the input samples is removed before feeding the classifier.
We present an approach to indoor scene reconstruction from RGB-D video based on robust global optimization based on line processes.
We present a two-step occlusion detection method to remove false matches in dense matching fields using statistical dense matching method.
We propose a novel online distillation method, which online constructs the teacher network without pre-training and conducts mutual learning between the teacher and student network.
We propose a multi-level self-supervised learning model for domain adaptation of semantic segmentation and achieve state-of-art results.
Multi-Subject Subspace Alignment (MSSA) is proposed in this paper, which takes advantage of subspace alignment solution and multi-subject information in a unified framework to build personalized models without user-specific labeled data.
We provide a novel and systematic approach to trace retinal vessel tree structure from fundus images with the present of crossovers by solving a transductive learning problem on induced undirected graphs.
We propose a hidden-layer LSTM (H-LSTM) that reduces the number of parameters and run-time latency while employing fewer external stacked layers.
We propose an arbitrator model (AM) for saliency integration, which improves the state-of-the-art integration of multiple saliency models.
We show both filtered and unfiltered web action images are complementary to training videos for action recognition in videos.
We present a general and flexible video-level framework for learning action models in videos using temporal segment networks.
We propose StarGAN, a novel and scalable approach that can perform image-to-image translations for multiple domains using only a single model.
The information bottleneck principle (Shwartz-Ziv&Tishby, 2017) suggests that SGD-based training of deep neural networks results in optimally compressed hidden layers, from an information theoretic perspective, even for an autoencoder.
We present a system for concurrent activity recognition. We propose a transformer-network encoder that models independent temporal associations for each activity, and a feature-to-activity attention that maps the extracted global features to sub-features associated with individual activities.
The Flickr30k dataset has become a standard benchmark for sentence-based image description. This paper presents Flickr30K Entities, which augments the 158k captions fromFlickr30k with 244k coreference chains linking mentions of the same entities in images, as well as 276k manually annotated bounding boxes corresponding to each entity.
This paper examines the challenging problem of new user cold starts in subset labelled and extremely sparsely labelled big data. We introduce a new technique, the Transitive Semantic Relationships (TSR) model, which infers potential relationships from user and item text content and few labelled examples.
We propose two FCN architectures for single-image-based view generation, both of which improve accuracy and speed over state of the art.
We develop a tree-based algorithm for considering network autocorrelation in the setting of Hierarchical Multi-label Classification (HMC) that improves the predictive performance of the learned models for predicting gene function.
An empirical evaluation of linear and kernel common vector based approaches that consider directions (attributes) that carry out very little information as if they were null.
In this paper we investigate the problems of class imbalance and irrelevant relationships in Visual Relationship Detection (VRD) and propose modifications to both model and training to alleviate the aforementioned issues.
Deep Convolutional Neural Networks (DCNNs) commonly use generic 'max-pooling' (MP) layers to extract deformation-invariant features, but we argue in favor of a more refined treatment that explicitly accommodates global translation and scaling.
In this paper we propose a GAN-based video generation framework that employs two latent spaces in order to structure the generative process in a more natural way.
In this paper, a high precision detection method of salient objects is presented based on deep convolutional networks with proper combinations of shallow and deep connections.
This paper proposes a novel system to automatically estimate food attributes such as ingredients and nutritional value by classifying the input image of food.
We study efficiency and budget balance for designing mechanisms in general quasi-linear domains. We show that if the valuations are unrestricted, no deterministic mechanism can do asymptotically better than minimizing inefficiency alone.
This paper tackles the task of estimating the topology of road networks from aerial images, inspired by a human delineating a complex network with the tip of their finger.
We propose a generative adversarial network based method to remove microphone object in facial images and fill hole with correct facial semantics and fine details.
Deep neural networks progressively transform their inputs across multiple processing layers. What are the geometrical properties of the representations learned by these networks?
We find that excessive pre-training is not necessary for pruning algorithms. We newly proposed a pruning algorithm that can compress and accelerate in the training stage.
We study large-scale image classification methods that can incorporate new classes and training images continuously over time at negligible cost. We introduce a new metric learning approach for distance-based classifiers and introduce an extension of the NCM classifier to allow richer class representations.
We propose a simple way to improve the capacity of any CNN model having large-scale features, without adding more parameters. We modify a standard convolutional layer to have a new functionality of channel-selectivity.
In this paper, we compare fine-tuning to alternative retraining techniques. Learning rate rewinding (which we propose) trains the unpruned weights from their final trained values using a small fixed learning rate.
We describe a new method based on recurrent neural networks that keeps track of the individual party states throughout the conversation and uses this information for emotion classification.
Recovering correlated and individual components of two, possibly temporally misaligned, sets of data is a fundamental task in disciplines such as image, vision, and behavior computing, with application to problems such as multi-modal fusion, predictive analysis, and clustering.
We analyse the effect of different network architectures, model capacity and multiscale processing on adversarial attacks on modern semantic segmentation models.
We introduce a new dataset, “HiPen”, which tabulates Δ A g a s M M → 3 o b (the free energy associated with switching from an M M to an S C C − D F T B molecular description using the 3ob parameter set in gas phase), calculated for 22 drug-like small molecules.
In this paper, we propose a Switchable Deep Network (SDN) for pedestrian detection.
We propose a new approach to perform object shape retrieval from images, it can handle the shape of the part of the object and combine parts from different sources to find a different 3D shape.
We identified evolutionarily conserved gene modules in meiotic prophase by integrating cross-species and cross-sex expression profiles from budding yeast, mouse, and human, and used the genetically amenable yeast system for experimental validation.
This work aims at disentangling the contributions of the adjectives and nouns in the visual prediction of ANPs.
We solve this problem by projecting patches of the score map to their nearest neighbors in a set of ground truth training patches in a geometrically consistent way.
We present a minimalistic but effective neural network that computes dense facial correspondences in highly unconstrained RGB images. When combined with a facial detection and 3D face fitting step, our approach outperforms the state-of-the-art face alignment methods in terms of accuracy and speed.
We present a domain-aware automatic chest X-Ray radiology report generation system which first predicts what topics will be discussed in the report, then conditionally generates sentences corresponding to these topics. The resulting system is fine-tuned using reinforcement learning, considering both readability and clinical accuracy.
In recent years, supervised machine learning models have demonstrated tremendous success in a variety of application domains. Despite the promising results, these successful models are data hungry and their performance relies heavily on the size of training data. Transfer learning can help overcome this issue by transferring the knowledge from readily available datasets (source) to a new dataset (target) using probabilistic weighting.
This paper aims at overcoming those limitations by proposing a deep neural network, which is designed in a systematic fashion and is interpretable, by integrating multiresolution analysis at the core of theDeep neural network design.
We propose two computation-performance optimization methods to reduce the redundant convolution kernels of a CNN with performance and architecture constraints, and apply it to a network for super resolution (SR).
We present ClearGrasp -- a deep learning approach for estimating accurate 3D geometry of transparent objects from a single RGB-D image for robotic manipulation.
A third approach, synchronous optimization with backup workers, can avoid asynchronous noise while mitigating for the worst stragglers.
In this paper, we explore ways to tackle the instability problem by dualizing the discriminator of generative adversarial nets.
In this paper, we propose Cross Stage Partial Network (CSPNet) to mitigate the problem that previous works require heavy inference computations from the network architecture perspective.
This paper proposes new methods for learning and using embeddings of word pairs that implicitly represent background knowledge about such relationships.
We propose a new layer, named visualization layer, that can be integrated into the CNN architecture and enables joint optimization with different loss functions.
A generalized Higher Order Tucker Articulated Kernels (HOTCAKE) scheme comprising four steps: input channel decomposition, guided Tucker rank selection, higher order Tucker decomposition and fine-tuning.
In this paper, we propose a novel generative adversarial network, RankGAN, for generating high-quality language descriptions.
Learning structural information is critical for producing an ideal result in retinal image segmentation. In this paper, we propose an Attention Guided Network (AG-Net) to preserve the structural information and guide the expanding operation.
This paper proposes an innovative object detector by leveraging deep features learned in high-level layers.
We develop a novel selective sampling algorithm for the drifting setting, analyze it under no assumptions on the mechanism generating the sequence of instances, and derive new mistake bounds that depend on the amount of drift in the problem.
Dilated residual networks outperform their non-dilated counterparts in image classification without increasing the model's depth or complexity.
We explore the challenges of setting the parameters for secure aggregation to achieve communication efficiency in the context of the aggressively quantized inputs enabled by random rotation.
We present PixelVAE, a VAE model with an autoregressive decoder based on PixelCNN, which achieves state-of-the-art performance on binarized MNIST and competitive performance on 64 × 64 ImageNet.
Objects in human environments support various functionalities which govern how people interact with their environments in order to perform tasks. In this work, we discuss how to represent and learn a functional understanding of an environment in terms of object affordances in the form of spatial locations on the object and temporal trajectories.
A novel method, robust to pose, illumination variations, and occlusions is proposed for joint face frontalization and landmark localization and recognition.
We propose a novel framework taking two images as inputs, named dual-reference age synthesis, which approaches the task differently; instead of using"hard"age information, i.e. a fixed number, our model determines the target age in a"soft"way, by employing a second reference image.
We propose STE (stochastically trained ensemble) layers, which enhance the averaging properties of such methods by training an ensemble of weight matrices with stochastic regularization while explicitly averaging outputs.
In this paper, we propose a detection and evaluation method of defect for transmission line inspection based on deep learning.
Image denoising using plain multi layer perceptrons, trained on large image databases, achieves superior results.
The task of associating images and videos with a natural language description has attracted a great amount of attention recently. Instead of proposing new models, this work investigates the possibility of empirically establishing performance upper bounds on various visual captioning datasets without extra data labelling effort or human evaluation.
We propose a novel end-to-end neural network architecture along with a well-designed loss function based on the strong prior knowledge that facial expressions are the result of some facial muscles and components.
The effectiveness of learning-based point cloud upsampling pipelines heavily relies on the upampling modules and feature extractors used therein. We propose three novel point upsampler modules and a novel feature extractor that improve state-of-the-art upsamplings methods.
We address this problem by projecting features in original full-precision networks to high-dimensional quantization features to establish a compact quantization neural network with sufficient representation ability.
We study unsupervised multilingual alignment, the problem of finding word-to-word translations between multiple languages without using any parallel data. Instead of going through a rather arbitrarily chosen pivot language, we use the Wasserstein barycenter as a more informative ''mean'' language.
We introduce a supervised multimodal bitransformer model that fuses information from text and image encoders, and obtain state-of-the-art performance on various multimodAL classification benchmark tasks, outperforming strong baselines, including on hard test sets.
We propose a supervised appearance model (sAM) that improves on AAM by replacing PCA with partial least-squares regression for age and gender classification.
We develop GroupTrust, a dependable trust management scheme to provide reliable trust management in the presence of dishonest ratings, malicious camouflage, and malicious collusive behaviors.
We propose two methods to explore the importance of grammatical categories with respect to the model and the task. We observe that the model pays most attention to head-words, noun subjects and adjectival modifiers and least to determiners.
We propose a novel approach for semantic segmentation that uses an encoder in the reverse direction to decode and use only the 13 convolutional layers from VGG-16 plus one tiny classification layer.
We have formulated a fractional version of max-pooling where is allowed to take non-integer values.
An innovative method for extracting thesauri from wikis using Wikipedia structure.
We introduce three effective methods to control the attention and find that these are producing expected results in up to 28.56% of cases.
We explore the low-level statistics of images generated by state-of-the-art deep generative models, including mean power spectrum, number of connected components in a given image area, distribution of random filter responses, and contrast distribution.
We propose a new method of FER in video sequences via a hybrid deep learning model to extract discriminative spatiotemporal video features.
We address the problem of spatio-temporal person retrieval from multiple videos using a natural language query, in which we output a tube (i.e., a sequence of bounding boxes) which encloses the person described by the query.
We proposed NeuroTreeNet (NTN), a new horizontal extension network through the combination of random forest and Inception Model, for improving network performance.
We propose a novel two-stage approach to learn a video classifier using webly-supervised data and apply domain adaptation to account for potential domain shift present between the source and target domain.
We propose a new ML approach for predicting drug-drug interactions based on multiple data sources using PyTorch-BigGraph.
We propose a new texture descriptor, FV-CNN, obtained by Fisher Vector pooling of a Convolutional Neural Network (CNN) filter bank, which improves the state-of-the-art in texture, material and scene recognition in clutter.
The paucity of videos in current action classification datasets (UCF-101 and HMDB-51) has made it difficult to identify good video architectures, as most methods obtain similar performance on existing small-scale benchmarks. This paper re-evaluates state-of-the-art architectures in light of the new Kinetics Human Action Video dataset.
In this paper, we propose a parallax-based spatial and channel attention stereo SR network (PSCASSRnet) to combine the stereo correspondence with the SR task.
In this paper, we propose a novel multi-stage sample training scheme to reduce sample hardness while preserving sample informativeness.
We propose an unsupervised, simple, and fast alignment and information retrieval baseline that incorporates two novel contributions: a \textit{one-to-many alignment} between query and document terms and a proxy for discriminative information.
We propose a two-stream multi-task network for fashion recognition, which achieves state-of-the-art results.
This paper addresses the problem of Sketch-Based Image Retrieval (SBIR), for which bridge the gap between the data representations of sketch images and photo images is considered as the key. We propose a novel loss function, named Euclidean Margin Softmax (EMS), that not only minimizes intra- class distances but also maximizes inter-class distances simultaneously.
We propose normalized Wasserstein distance for mixture distributions with imbalanced mixture proportions.
Improving upon a simple Recurrent Neural Network for answering"simple"first-order questions (QA-RNN) using the SimpleQuestions dataset.
In this paper, we propose a system for creating diverse image dataset collections from the web with limited manual labeling effort.
We propose a novel architecture that uses a top-down network to modify the main network according to the task in a channel-wise, as well as spatial- wise, image-dependent computation scheme.
A real-time suspicious tracking mechanism across multiple cameras based on correlation filters for intelligent video surveillance .
This paper proposes a 3-layer bio-inspired Convolutional Spiking Neural Network (NatCSNN), for classifying objects extracted from natural images.
We apply a variant of a de-noising autoencoder network to learn higher-order features using simple gradient based optimization.
We introduce a new unsupervised deep neural network architecture called the Visual Inertial Flow (VIFlow) network and demonstrate image correspondence and optical flow estimation by receiving grayscale imagery and extra-visual inertial measurements.
A noiseless image is desirable for many applications. Generally, wavelet-based methods are used to noise reduction. However, due to insufficient performance of wavelet transforms (WT) on images, different multi-resolution analysis methods have been proposed. In this study, one of them is Contourlet Transform (CT) and the Translation-Invariant Contourlets Transform (TICT) are compared using different noises.
We propose a Domain Agnostic Normalization layer for Unsupervised Adversarial Domain Adaption in semantic scene segmentation.
We present the first publicly available open-domain dataset for domain-independent comparative argument mining.
We propose a technique for producing ‘visual explanations’ for decisions from a large class of Convolutional Neural Network (CNN)-based models, making them more transparent and explainable.
We introduce a hierarchical decomposition of the joint posterior distribution, which couples the subset inferences, allowing for embarrassingly parallel computations in a sequence of at most three stages.
We propose a novel knowledge distillation strategy which employs two special teachers for efficient training of student networks.
This work proposes to evaluate the direct metric for efficient neural network architecture design, beyond only considering FLOPs.
Super-resolution (SR) is a technique that allows increasing the resolution of a given image. Currently, the best performing methods are based on convolutional neural networks (CNNs) and require extensive datasets for training. We propose a new framework that joins both approaches and produces images with superior quality than any of the prior methods.
In this paper, we address the problem of person re-identification, which refers to associating persons captured from different cameras. We propose a simple yet effective human part-aligned representation for handling the body part misalignment problem.
Layer-wise Relevance Propagation does not manage normalization layers, in this work we suggest a method to include normalization layer.
In this paper, we address the challenging problem of effi- cient temporal activity detection in untrimmed long videos. We formulate this problem as a Markov decision process, and adopt a recurrent network to model a policy for the frame selec- tion.
Unsupervised pretraining can help NLI inference, and if not, how?
Face expression recognition is still a complex task, particularly due to the presence of head pose variations and facial expressions. In this paper, we compare the performance of recent face alignment approaches to highlight the most appropriate techniques for preserving facial geometry when correcting the head pose variation.
This paper presents a new Heterogeneous Deep Discriminative Model (HDDM) whose parameters are initialized by performing an unsupervised pre-training in a layer-wise fashion using Gaussian Restricted Boltzmann Machines.
We train causal explanation (CXPlain) models that learn to estimate to what degree certain inputs cause outputs in another machine-learning model in little time, and enable quantification of the uncertainty associated with its feature importance estimates.
We use a divide-and-conquer strategy to find reliable relations between training images and use them for learning robust representations.
This paper investigates recently proposed approaches for defending against adversarial examples and evaluating adversarial robustness. We motivate the use of adversarial risk as an objective, although it cannot easily be computed exactly.
We propose a cascade proposal and location anticipation network for frame-level action detection in temporally untrimmed videos.
In this paper we study the use of convolutional neural networks (convnets) for the task of pedestrian detection.
We propose to combine the Grad-CAM visualization method that allows to visualize spatial relevance to popularity with a soft self-attention mechanism to weight the relative importance of frames in time domain.
DRUM uses bidirectional RNNs to share useful information across the tasks of learning probabilistic logical rules for inductive and interpretable link prediction.
We propose an extension of the long short term memory (LSTM) model for image caption generation, which achieves state-of-the-art results on Flickr8K and Flickr30K.
We introduce a novel method to combine the advantages of both multi-task and curriculum learning in a visual attribute classification framework.
We present an approach for learning to translate faces in the wild from the source photo domain to the target caricature domain with different styles, which can also be used for other high-level image-to-image translation tasks.
We propose a question-agnostic attention mechanism that is complementary to the existing question-dependent attention mechanisms, enabling the VQA model to focus on the regions containing objects that are most relevant for answering a question.
This paper investigates various structures of neural network models and various types of stacked ensembles for singing voice detection.
Keyword spotting refers to the process of retrieving all instances of a given keyword from a document. In the present paper, a novel keyword spotting method is described.
HyperKG extends translational models by exploiting hyperbolic space in order to better reflect the topological properties of knowledge bases.
We propose and compare various unsupervised ways to perform cloze-to-natural question translation using synthetic training data.
We introduce Segment-Phrase Table (SPT), a large collection of bijective associations between textual phrases and their corresponding segmentations, enabling state-of-the-art segmentation results on benchmark datasets.
Neural networks using transformer-based architectures have recently demonstrated great power and flexibility in modeling sequences of many types. One of the core components of transformer networks is the attention layer, which allows contextual information to be exchanged among sequence elements. In this work, we present an attention model that has only linear requirements in memory and computation time.
Fusing a filter and a wrapper to measure the relationships among image features, and to select feature clusters based on mutual information for gender classification from face images.
PSceneGAN is a novel dual-condition GAN for multi-domain particular scene generation under the guidance of semantics using only one model.
Meta-graph assessment and combination methods for HIN embedding in an end-to-end manner.
MDL, Multimodal Deep Learning Library, is a deep learning framework that supports multiple models. It depends on OpenCV.
We developed a 3D cascade regression approach in which facial landmarks remain invariant across pose over a range of approximately 60 degrees.
We propose a style-aggregated approach to deal with the large intrinsic variance of image styles for facial landmark detection.
We introduce an effective temporal action proposal generation method, named Boundary-Sensitive Network (BSN), which adopts"local to global"fashion, and improve state-of-the-art temporal action detection.
In this paper, we propose a "Learning with Rethinking" algorithm. By adding a feedback layer and producing emphasis vector, the model is able to recurrently boost the performance based on previous prediction.
We introduce a new inference task - Visual Entailment (VE) - which differs from traditional Textual EntailMENT (TE) tasks whereby a premise is defined by an image, rather than a natural language sentence.
We present a computational imaging framework using deep and ensemble learning for reliable detection of blood vessels in fundus color images.
We show that joint training improves relative performance by 4% to 13% for an end-to-end speech recognition model learned through maximum likelihood.
In this paper, we propose a novel framework of Non-Autoregressive Dialog State Tracking which can factor in potential dependencies among domains and slots to optimize the models towards better prediction of dialogue states as a complete set rather than separate slots.
We present iRefWeb, a web interface to protein interaction data consolidated from 10 public databases: BIND, BioGRID, CORUM, DIP, IntAct, HPRD, MINT, MPact, MPPI and OPHID.
This paper addresses two crucial problems of learning disentangled image representations, namely controlling the degree of disentanglement during image editing, and balancing the disentANGlement strength and the reconstruction quality.
In this paper we formulate structure from motion as a learning problem. We train a convolutional network end-to-end to compute depth and motion from successive, unconstrained image pairs.
We propose a new neural network architecture that combines the two abovementioned approaches for video frame interpolation.
Automatic description generation from natural images is a challenging problem that has recently received a large amount of interest from the computer vision and natural language processing communities. In this survey, we classify the existing approaches based on how they conceptualize this problem.
A longstanding problem in machine learning is to find unsupervised methods that can learn the statistical structure of high dimensional signals. In recent years, GANs have gained much attention as a possible solution to the problem, and in particular have shown the ability to generate remarkably realistic high resolution sampled images. At the same time, many authors have pointed out that GGANs may fail to model the full distribution ("mode collapse") and using the learned models
We propose gradient rescaling for training robust DNNs under label noise, which improves the state-of-the-art noise-tolerant algorithms by a large margin.
We propose a novel flow-based generative model named conditional adversarial generative flow (CAGlow), which can synthesize images with conditional information.
We propose a post-processing approach to improve the accuracy of text spotting by using the semantic relation between the text and its surrounding visual context.
We introduce a novel benchmark FollowMeUp Sports that makes an important advance in terms of specific postures, self-occlusion and class balance, a contribution that we feel is required for future development in human body models.
We propose the MIMLfast approach, which first constructs a low-dimensional subspace shared by all labels, and then trains label specific linear models to optimize approximated ranking loss via stochastic gradient descent.
We present a novel approach, TypeSQL, which views this problem as a slot filling task and converts users' questions to SQL queries automatically.
Deep Reinforcement Learning (DRL) has become increasingly powerful in recent years, with notable achievements such as Deepmind's AlphaGo.
We propose a novel method that combines the multiscale analysis provided by the Stationary Wavelet Transform with a Fully Convolutional Neural Network to cope with the varying width and direction of the vessel structure in the retina.
In recent years, deep learning methods have been successfully applied to image classification tasks. One such model is the ResNeXt model that uses a homogeneous, multi-branch architecture.
Hashing has been widely applied to large-scale multimedia retrieval due to the storage and retrieval efficiency. In this paper, we relax the strong assumption by only requiring heterogeneous relationship in an auxiliary dataset different from the query/database domain.
In this paper, we propose an unpaired SR method using a generative adversarial network that does not require a paired/aligned training dataset.
This paper expands the strength of deep convolutional neural networks (CNNs) to the pedestrian attribute recognition problem by devising a novel attribute aware pooling algorithm.
A complex-valued convolutional network (convnet) implements the repeated application of the following composition of three operations, recursively applying the composition to an input vector of nonnegative real numbers, followed by taking the absolute value of every entry of the resulting vectors.
We investigate the extent to which individual attention heads in pretrained transformer language models, such as BERT and RoBERTa, implicitly capture syntactic dependency relations.
We examine ImageNet, a large-scale ontology of images that has spurred the development of many modern computer vision methods, including offensive prediction results and lower performance for underrepresented groups.
In this paper we propose an approach for multi-modal image retrieval in multi-labelled images that leverages a supervised LSTM-based visual attention model learned from convolutional features.
A novel conditional knock-out model of HuR genetic ablation during CD4+ T activation and Th2 differentiation provides insights into HuR-regulated genes during T cell activation and immune mechanisms.
We propose an approach to embed 3D context into the topology of a neural network trained to perform holistic scene understanding.
This paper presents a new approach to Single Image Super Resolution (SISR), based upon Convolutional Neural Network (CNN) based upon convolutional neural networks.
We propose an efficient yet effective Avatar-Net that enables visually plausible multi-scale style transfer in real-time.
Adversarial examples that strongly transfer across computer vision models influence the classifications made by time-limited human observers.
An algorithm-hardware co-optimization framework to accelerate hardware implementations of deep neural networks.
Deep neural networks with millions of parameters may suffer from poor generalization due to overfitting. To mitigate the issue, we propose a new regularization method that penalizes the predictive distribution between similar samples during training.
This paper presents a data driven approach where citation patterns of scientific papers are analyzed to quantify how much a potential challenger idea shifts an established paradigm.
Progressive Neural Network Learning is a class of algorithms that incrementally construct the network's topology and optimize its parameters based on the training data. In this paper, we propose to speed up this process by exploiting subsets of training data at each incremental training step.
In this work, we propose a learning-based method to denoise and refine disparity maps of a given stereo method.
In this paper, we adapt an architecture with augmented memory capacities called Neural Semantic Encoders for sentence simplification.
We propose a self-supervised proxy task for some regression problems for which unlabeled data can be used as a proxy task.
We construct a Conditional Random Field on a fully-connected spatio-temporal graph that learns adaptive relations conditioned on visual observations.
We present an improved Locality Preserving Projections (LPP) method to preserve both the global and local geometric structures of data, and apply it to face recognition.
SiamVGG combines a Convolutional Neural Network (CNN) backbone and a cross-correlation operator, and takes advantage of the features from exemplary images for accurate object tracking.
In this paper, we propose a model for the Environment Sound Classification Task that consists of multiple feature channels given as input to a Deep Convolutional Neural Network (CNN) with Attention mechanism.
This paper proposes a novel generative adversarial networks, rdAttnGAN, which generate text to fine images by training multi-pair generators and discriminators. Comparing with the conventional models, it pays more attention to the representativeness and diversity of the generated images.
We investigate the vulnerability of DNNs to OoD poses of well-known objects in ImageNet, including natural, non-adversarial ones, which are common in real-world settings.
We propose an appearance-based gaze estimation method that only takes the full face image as input, outperforms state of the art for 2D and 3D gaze estimation.
We propose a statistical framework for investigating long-range dependence in deep sequence modeling, drawing on the well-developed theory of long memory stochastic processes.
We introduce Selective Sharing, a method that learns the inter-task relatedness from secondary latent features while the model trains. Using this insight, we can automatically group tasks and allow them to share knowledge in a mutually beneficial way.
We propose to use intensity particle flow (IPF) in NPF-SMC-PHD filter for multi-speaker tracking.
Prior Networks, a new method of estimating predictive uncertainty, has been shown to outperform Monte-Carlo dropout on a range of adversarial attack detection tasks.
We employ the technique of model distillation (supervising a low-cost student model using the output of a high-cost teacher) to specialize accurate, low- cost semantic segmentation models to a target video stream.
We propose a general targeted attack framework for adversarial text generation which addresses the challenge of discrete input space and is easily adapted to general natural language processing tasks.
We introduce an approach to weakly-supervised semantic segmentation by making use of classifier heatmaps. We then develop a two-stream deep architecture that jointly leverages appearance and motion.
With the popularity of OSNs, finding a set of most influential users (or nodes) so as to trigger the largest influence cascade is of significance.
We present a self-supervised task on point clouds, in order to learn meaningful point-wise features that encode local structure around each point, and generalize well to other datasets.
Memory traffic for accessing intermediate feature maps can be a factor dominating the inference latency, especially in such tasks as real-time object detection and semantic segmentation of high-resolution video.
In this paper we proposed an ordered patch based method using Conditional Random Field in order to encode local properties and their spatial relationship in images to address texture classification, face recognition, and scene classification problems.
We propose the HEER algorithm, which embeds HINs via edge representations that are further coupled with properly-learned heterogeneous metrics. Experiment results demonstrate the effectiveness of the proposed HEER model.
We propose a method to reconstruct, complete and semantically label a 3D scene from a single input depth image. We improve the accuracy of the regressed semantic 3D maps by using adversarial learning.
In this paper, we propose a dictionary-based approach for facialexpression analysis by decomposing expressions in terms of action units and their composition rules.
Compressive sensing CS, as a new theory of signal processing, has found many applications. A novel framework, called projection matrix optimization- PMO- based compressive classification, is proposed for distributed intelligent monitoring systems.
A novel generative deformable model motivated by Pictorial Structures (PS) and Active Appearance Models (AAMs) for object alignment in-the-wild.
This paper proposes a novel binocular stereo matching algorithm based on SAD and improved Census transformation, which produces accurate and complete disparities.
We present a simple, highly modularized network architecture for image classification. The code and models are publicly available online.
The Touchdown dataset (Chen et al, 2019) provides instructions by human annotators for navigation through New York City streets and for resolving spatial descriptions at a given location. To enable the wider research community to work effectively with Touchdown tasks, we are publicly releasing the 29k raw Street View panoramas needed for Touchdown.
Learning a powerful representation for a class with few labeled samples is a challenging problem. In this paper, to accomplish this goal, it proposes to combine the channel attention and spatial attention module (C-SAM), the C-SAM can mine more effective information using samples of different classes that exist in different tasks.
This paper presents a teamed classifier framework for video analytics in heterogeneous many-camera networks with adversarial conditions such as multi-scale, multi-resolution cameras capturing the environment with varying occlusion, blur, and orientations.
We propose FACSCaps architecture to handle multi-view and multi-label facial action unit (AU) detection within a single model that can generalize to novel views.
Satyam leverages a crowdtasking platform, Amazon Mechanical Turk, and automates several challenging aspects of groundtruth collection for machine vision systems.
We derive an alternative variational lower bound from the one common in VAEs, which aims to minimize aggregate information loss. This alternative form of prior constraint allows individual posteriors more flexibility to preserve necessary information for good reconstruction quality.
We propose Slice-based Learning, a new programming model in which the slicing function (SF), a programmer abstraction, is used to specify additional model capacity for each slice.
We present a novel method for image anomaly detection, where algorithms use samples drawn from some distribution of “normal” data, aim to detect out-of-distribution (abnormal) samples.
We present a self-supervised method of training scene flow that matches current state-of-the-art supervised performance using no real world annotations and exceeds state of the art performance using supervised learning on a smaller labeled dataset.
We present a system that achieves state-of-the-art results on the CLEVR dataset without any questions-answers training, utilizes real visual estimators and explains the answer.
We study the problem of alleviating the instability issue in the GAN training procedure via new architecture design. In this work, we give new results on the benefits of multi-generator architecture of GANs.
This paper proposes a crossbar-aware pruning framework based on a formulated $L_{0}$ -norm constrained optimization problem and a new co-design solution for mapping CNNs onto various crossbar devices with much better efficiency.
We propose an explicit audio representation learning framework that disentangles audio sequences into various factors such as phonetic content, emotional tone, background noise and others, which improves the performance of talking head generation from disentangled audio representation perspective.
We present Mmkg, a collection of three knowledge graphs that contain both numerical features and (links to) images for all entities as well as entity alignments between pairs of KGs.
We present an algorithm to generate diverse foreground objects and composite them into background images using a GAN architecture that improves on state-of-the-art object insertion approaches.
We propose an efficient 4-point algorithm for multi-camera relative pose, which admits analytic solutions by solving a polynomial root-finding equation, and runs extremely fast.
In this paper, we propose a unified formulation for learning a deformable convolution filter that improves the baseline method, leading to state-of-the-art performance.
We set ourselves to providing a clear and concise overview on several large pre-trained language models, which achieved state-of-the-art results in the last two years, with respect to their use of new architectures and resources.
We show that models trained on natural language inference dataset drawn from one benchmark fail to perform well in others, even if the notion of inference assumed in these benchmark tasks is same or similar.
We ask when and how one can combine network outputs, when (i) details of the observations are evaluated by learned deep components and (ii) facts and confirmation rules are available.
In this paper, we present the first publicly available dataset for distraction identification with more distraction postures than existing alternatives. In addition, we propose a reliable deep learning-based solution that achieves a 90% accuracy.
We propose Convolutional Occupancy Networks, a more flexible implicit representation for detailed reconstruction of objects and 3D scenes, enabling structured reasoning in 3D space.
A novel algorithm to remove age-related components from features mixed with both identity and age information for age-invariant face recognition.
We introduce a general purpose transfer-learnable NLI with the goal of learning one model that can be used as NLI for any relational database.
We test the hypothesis that scene categories reflect functions, or the possibilities for actions within a scene, and find a strong relationship between ranked category distance and functional distance.
We propose a dynamic texture-based approach to the recognition of facial Action Units (AUs, atomic facial gestures) and their temporal models (i.e., sequences of temporal segments) in near-frontal-view face videos.
In this work we aim to develop a universal sketch grouper that can be applied to sketches of any category in any domain to group constituent strokes/segments into semantically meaningful object parts.
We use feature clustering to effectively detect backdoor-infected robust DNNs.
We introduce a novel convolution operator for point clouds that achieves rotation invariance and generalizes to arbitrary rotations.
Large scale image dataset and deep convolutional neural network (DCNN) are two primary driving forces for the rapid progress made in generic object recognition tasks in recent years. In this paper, we aim to achieve lower error rate by augmenting existing datasets in an automatic manner.
In this paper, we introduce an embedding model, named CapsE, exploring a capsule network to model relationship triples (subject, relation, object) for knowledge graph completion.
In this paper, we propose a novel approach, 3D-RecGAN++, which reconstructs the complete 3D structure of a given object from a single arbitrary depth view using generative adversarial networks.
We trained several deep convolutional object detection models for automated detection of threats that can be found in airports in real time.
In situ-active pharmacological tools for inhibiting alkyl-glycerone phosphate synthase.
Image blur and image noise are common distortions during image acquisition. Re-training and fine-tuning with noisy images can alleviate much effect due to distorted inputs, and is more practical than re-training.
Unsupervised feature learning with convolutional networks in the context of temporally coherent unlabeled data, using the assumption that adjacent video frames contain semantically similar information.
Deep neural networks trained with the negative Pearson correlation coefficient as the loss function are particularly fit for photon-starved phase retrieval problems, which are fundamentally affected by strong Poison noise.
This paper introduces the new color face recognition (FR) method that makes effective use of boosting learning as color-component feature selection framework.
In this work, we present a novel method for blood vessel segmentation in fundus images based on a discriminatively trained, fully connected conditional random field model.
We address the estimation problem for general finite mixture models that is both robust to initialisations and reaches a superior optimum by adaptively optimising along a manifold of an approximate Wasserstein distance.
We propose TransM to leverage the structure of the knowledge graph via pre-calculating the distinct weight for each training triplet according to its relational mapping property.
Double-domain translation generative adversarial network for person re-identification and generalization .
Automated quantification of blood vessels in human retina is the ::: fundamental step in designing any computer-aided diagnosis system ::: for ophthalmic disorders.
The goal of this paper is to embed controllable factors, i.e., natural language descriptions, into image-to-image translation with generative adversarial networks, which allows text descriptions to determine the visual attributes of synthetic images.
We propose a novel robust long-term tracking framework based on continual learning and dynamic sample set modules. We transform the online tracking process into a continual learning process.
Style transfer is a technique for combining two images based on the activations and feature statistics in a deep learning neural network architecture in an image-based framework to generate audio texture.
We propose to generate cross-lingual image captions with self-supervised rewards in the reinforcement learning framework to alleviate these two types of errors.
 Gamma memory, a hierarchical memory unit, forms the central memory of Gamma-LSTM with gates to regulate the information flow into various levels of hierarchy, thus providing the unit with a control to pick the appropriate level of hierarchy to process the input.
We propose a novel alternative adversary-generation algorithm, AddSentDiverse, that significantly increases the variance within the adversarial training data by providing effective examples that punish the model for making certain superficial assumptions.
We study the setting in which an agent must learn to generate programs for diverse scenes conditioned on a given symbolic instruction.
We propose a novel dynamic hidden graph module to model complex object-object interactions in videos, of which two instantiations are considered: a visual graph that captures appearance/motion changes among objects and a location Graph that captures relative spatiotemporal position changes.
We propose a Rotated Region of Interest Transformer to improve the quality of region proposals for oriented object detection.
We propose a novel part-based deep convolutional neural network with feature learning and fusion for person re-identification.
We present a novel and principled solution for modeling both the global absolute positions of words and their order relationships in complex-valued word embeddings.
We investigate the effects of multi-task learning using the recently introduced task of semantic tagging for three different NLP tasks: part-of-speech tagging, Universal Dependency parsing, and Natural Language Inference.
This paper proposes a step toward obtaining general models of knowledge for facial analysis, at an affordable training cost.
This paper makes the attempt in integrating deep learning and hashing into one framework to evaluate the efficiency and accuracy for large-scale person re-id.
We introduce a novel method named Class Regularization that performs class-based regularization of layer activations. We demonstrate that this improves feature search during training, but also allows an explicit assignment of features per class during each stage of the feature extraction process.
This work provides simple and effective baseline methods. State-of-the-art results are achieved on challenging benchmarks.
We investigate the problem of generalized zero-shot learning (GZSL). GZSL relaxes the unrealistic assumption in conventional zero- shot learning (ZSL) that test data belong only to seen and unseen novel classes.
We expand the scope and improve the inference accuracy of generalized relational topic models by exploring data augmentation without making restricting assumptions.
This paper describes a new approach for training generative adversarial networks (GANs) to understand the detailed 3D shape of objects.
We demonstrate that defensive distillation does not significantly increase the robustness of neural networks by introducing three new attack algorithms that are successful on both distilled and undistilled neural networks with 100% probability.
We address the more challenging case of not only using a single camera but also not leveraging markers: going directly from 2D appearance to 3D geometry and account for the uncertainties arising from the discriminative model.
We introduce the concept of spatio-temporal activation reprojection (STAR), an end-to-end architecture based on the proposed STAR framework (which we nickname STAR-Net) is proficient in single-environment and small-scale applications.
This paper investigates a neat model with promising detection accuracy under wild environments e.g., unconstrained pose, expression, lighting, and occlusion conditions.
This paper presents a comprehensive study towards demystifying membership inference attacks from two complimentary perspectives.
We investigate the importance of unsupervised learning in a large-scale setting by augmenting existing neural networks with decoding pathways for reconstruction.
We study in this paper how to initialize the parameters of multinomial logistic regression (a fully connected layer followed with softmax and cross entropy loss), which is widely used in DNN models for classification problems.
We propose a novel methodology for scalable unsupervised data fusion, which exploits network representations of the data in order to identify (and quantify) similarities among the datasets, and perform data fusion.
In this paper, we propose four different strategies to transform continuous and generic sentence embeddings into a binarized form, while preserving their rich semantic information.
Federated Learning is a machine learning setting where the goal is to train a high-quality centralized model while training data remains distributed over a large number of clients each with unreliable and relatively slow network connections. We propose two ways to reduce the uplink communication costs.
In this paper, we propose an inverse reinforcement learning method for architecture search (IRLAS), which trains an agent to learn to search network structures that are topologically inspired by human-designed network.
Learning an encoding of feature vectors in terms of an over-complete dictionary or a information geometric construct is wide-spread in statistical signal processing and computer vision. In content based information retrieval using deep-learning classifiers, such encodings are learnt on the flattened last layer, without adherence to the multi-linear structure of the underlying tensor.
This paper attempts to address the few-shot fine-grained recognition problem. We propose a feature fusion model to explore the largest discriminative features by focusing on key regions. Extensive experiments are carried out to validate the performance of our model.
We propose the first white-box video attack method, which utilizes an l2,1-norm based optimization algorithm to compute the sparse adversarial perturbations for videos.
We propose a novel neural memory network based framework for future action sequence forecasting, in which we effectively map the long-term relationships among individual input sequences.
In this paper, we present a novel framework of transformation-invariant feature learning by incorporating linear transformations into the feature learning algorithms, which achieves invariance of the feature representation.
Object detection remains as one of the most notorious open problems in computer vision. Despite large strides in accuracy in recent years, modern object detectors have started to saturate on popular benchmarks raising the question of how far we can reach with deep learning tools and tricks.
We propose a high speed kernel correlation filter without the boundary effect, which runs at 70 fps on average.
We propose a simple yet powerful temporal interlacing network that combines spatial and temporal information and achieves state-of-the-art performance in video understanding.
This work studies a supervised Nystr\"om method that chooses the critical subsets of samples for the success of the Machine Learning model.
In this paper we propose to perform 3D face matching based on alignments obtained using Simulated Annealing (SA) algorithm guided by Mean Squared Error (MSE) with M-estimator Sample Consensus (MSAC) and the Surface Interpenetration Measure (SIM).
We propose a novel approach named Multi-Channel Attention SelectionGAN that makes it possible to generate images of natural scenes in arbitrary viewpoints, based on an image of the scene and a novel semantic map.
Principal Filter Analysis (PFA) exploits the intrinsic correlation between filter responses within network layers to recommend a smaller network footprint.
In this paper, we propose a Distance-IoU (DIoU) loss by incorporating the normalized distance between the predicted box and the target box, which converges faster in training than IoU and GIoU losses.
In this paper, we propose a novel framework with rules of updating images for person re-identification in real-world surveillance system.
We propose a generative guiding block for realistic looking image synthesis, especially in large change demands.
We propose a unified framework consisting of object proposal, tracking and segmentation components for video object segmentation.
A deep and shallow feature learning network to learn the multi-level same-resolution compressed features for efficient online tracking, in an end-to-end offline manner.
We propose 'Hide-and-Seek' a general purpose data augmentation technique, which is complementary to existing data augmented techniques and is beneficial for various visual recognition tasks.
We propose a conditional GAN that uses mixture of Student's t-distribution with attention mechanism in addition to class information for image generation.
We propose extended feature pyramid network with an extra high-resolution pyramid level specialized for small object detection.
In this paper, we proposed new ways, named "constrained extreme learning machines (CELMs), to randomly select hidden neurons based on sample distribution.
In this paper we explore a novel strategy for training a CNN using an alternation strategy that offers substantial speedups during training. We make the following contributions: (i) replace the ReLU non-linearity within a CNN with positive hard-thresholding, (ii) reinterpret this non- linearity as a binary state vector making the entire CNN linear if the multi-layer support is known.
We propose to model 3D shape variations with a part-aware deep generative network which we call PAGENet, generating plausible, diverse and detailed structure.
We propose a structured pruning method through neuron selection which can remove the independent neuron of RNNs without losing performance.
Two large facial-expression databases depicting challenging real-world conditions were constructed using semi-automatic approach via a recommender system based on subtitles.
We study the problem of privacy-preserving collaborative filtering where the objective is to reconstruct the entire users-items preference matrix using few observed preferences of users for some of the items, without violating privacy of other users.
We developed a robust, automatic method to simultaneously predict KL and OARSI grades in knee radiographs in a multi-task manner.
We address a novel problem called class-distinct and class-mutual image generation, in which the goal is to construct a generator that can capture between-class relationships and generate an image selectively conditioned on the class specificity.
We propose a scalable Principal Component Analysis algorithm that scales well to cope with the ever increasing volumes of data.
We propose trainable filters, which we call COSFIRE (Combination Of Shifted FIlter REsponses), and use to detect vascular bifurcations in retinal images.
We address the challenging problem of generating facial attributes using a dense 3D representation given by UV texture and position maps, resulting in photorealistic, geometrically-consistent and identity-preserving outputs.
In this paper, we propose a novel algorithm named Magnitude Bounded Matrix Factorisation (MBMF), which allows different bounds for individual users/items and performs very fast on large scale recommender systems.
In this paper we propose a polynomial fusion layer that models the joint representation of the encodings by a higher-order polynometric, with the parameters modelled by a tensor decomposition.
We demonstrate in this article that as soon as the category and the strength of the filter used to obscure faces can be (automatically) identified, there exist in the literature ad-hoc powerful approaches enable to partially cancel the impact of such filters with regards to automatic face recognition.
We propose a Sketching-rendering Unconditional Generative Adversarial Network (SkrGAN) to introduce a sketch prior constraint to guide the medical image generation.
Memory augmented neural networks can reduce the effects of vanishing gradients by creating shortcut connections to the past to propagate the gradients more effectively and it helps to learn the temporal dependencies.
The Fisher kernel (FK) is a generic framework which combines the benefits of generative and discriminative approaches. Equipped with this representation, we can now explore image classification on a larger scale.
This paper presents an exemplar-based approach to detecting and localizing human actions, such as running, cycling, and swinging, in realistic videos with dynamic backgrounds, relative to other activity classes.
In this article, we introduce a new mode for training Generative Adversarial Networks (GANs). Rather than minimizing the distance of evidence distribution $\tilde{p}(x)$ and the generative distribution $q(x_f)$, we minimize the distance $(x_r)q(q_f)/q_r$ and use information of real samples during training generator.
We propose a novel local nearest neighbor distance (LNND) descriptor for anomaly detection in crowded scenes.
We introduce a new method to learn approximations of such non-differentiable objective functions in a generative learning framework.
We present SPIRAL, an adversarially trained agent that generates a program which is executed by a graphics engine to interpret and sample images, trained with a distributed reinforcement learning setup.
We propose an effective method to modify a modest amount of pixels in an encoder, changing the attribute strength contin- uously without hindering global information.
We propose an end-to-end training procedure that explicitly accounts for the complex and noisy structure of the image sets returned by Internet image search engines, especially for polysemous queries.
We propose a novel weakly-supervised semantic segmentation algorithm based on Deep Convolutional Neural Network (DCNN) that exploits auxiliary segmentation annotations available for different categories to guide segmentations on images.
We propose an adversarial learning framework, which distills the 3D human pose structures learned from the fully annotated dataset to in-the-wild images with only 2D pose annotations.
Unsupervised image-image translation suffers from the information loss of source-domain labels during translation. We propose a generative adversarial network for domain adaptation and train re-identification models with the translated images by supervised methods.
We propose a novel model Neural Factorization Machine (NFM) for prediction under sparse settings.
This paper proposes using the semantic information associated with concepts and locations such as the type as a mean for identifying these relations. The proposed approach achieves an average precision of 74% across three different datasets.
This paper gives an overview of our current Optical Music Recognition research, aimed at improving usefulness on real-world task and tackling extreme class imbalance.
We present a novel framework to generate images of different age while preserving identity information, which is known as face aging.
Increasing the mini-batch size progressively reduces the range of learning rates that provide stable convergence and acceptable test performance. We adopt a learning rate that corresponds to a constant average weight update per gradient calculation (i.e., per unit cost of computation), and point out that this results in a variance of the weight updates.
We show that the challenges raised by coherent data (i.e., the data with high coherence) could be alleviated by Low-Rank Representation (LRR), provided that the dictionary in LRR is configured appropriately.
We explore the possibilities to generate high-quality labels as proxy labels to supervise the training on target data for domain adaptation.
We formalize the task as Legal Reading Comprehension according to the legal scenario. We propose a novel LRC model, AutoJudge, which captures the complex semantic interactions among facts, pleas, and laws.
We measure and evaluate facial asymmetry across gender and different ethnic groups and investigate the differences in asymmetric facial dimensions among the subjects from two public face datasets, MORPH and FERET.
The problem of multi-view transformation is associated with transforming available source views of a given object into unknown target views. To solve this problem, a Mutual-Encoding InfoGenerative Adversarial Networks-based algorithm is proposed.
We propose a method, which learns the matching function, that automatically finds the space of allowed changes in visual appearance, such as due to the motion blur, chromatic distortions, different colour calibration or seasonal changes.
Stereo matching task is the core of applications linked to the intelligent vehicles. In this paper, we present a new variant function of Census Transform (CT) which is more robust against radiometric changes in real road scenes.
We consider the problem of subspace clustering: given points that lie on or near the union of many low-dimensional linear subspace, recover the subspaces. We propose new algorithms that perform competitively against state-of-the-art algorithms for this problem.
We propose a supervised feature learning approach, Label Consistent Neural Network, which enforces direct supervision in late hidden layers and achieves state-of-the-art performances on several public benchmarks.
We address the problem of instance-level semantic segmentation, which aims at jointly detecting, segmenting and classifying every individual object in an image. In this context, existing methods typically propose candidate objects, usually as bounding boxes, and directly predict a binary mask within such proposal.
We propose a novel regularization-based continual learning method, dubbed as Adaptive Group Sparsity based Continual Learning (AGS-CL), using two group sparsity based penalties.
We propose a new action classification challenge that is performed well by humans, but poorly by state-of-the-art Deep Learning models. We propose a rigorous method to reduce confounds, and when comparing human versus computer vision performance.
We introduce a novel transformer based architecture that jointly learns Continuous Sign Language Recognition and Translation while being trainable in an end-to-end manner.
We propose a context-augmented translation embedding model that can capture both common and rare relations.
A novel open-set semantic instance segmentation approach capable of segmenting all known and unknown object classes in images, based on the output of an object detector trained on known object classes.
Adaptive Instance Selection network architecture for class-agnostic instance segmentation.
We present two metrics for measuring the informativeness of an object hypothesis, which allow us to leverage active learning to reduce the amount of annotated data needed to achieve a target object detection performance.
We define the task of salient structure (SS) detection to unify the saliency-related tasks, such as fixation prediction, salient object detection, and detection of other structures of interest in cluttered environments.
We propose a new evaluation protocol that evaluates the rain removal algorithms on their ability to improve the performance of subsequent segmentation, instance segmentation and feature tracking algorithms under rain and snow.
We present a general and principled Controllable Imitative Reinforcement Learning (CIRL) approach which successfully makes the driving agent achieve higher success rates based on only vision inputs in a high-fidelity car simulator.
We propose Multi-View 3D networks (MV3D), a sensory-fusion framework that takes both LIDAR point cloud and RGB images as input and predicts oriented 3D bounding boxes.
We introduce a novel fully convolutional model of lane detection that learns to decode lane structures instead of delegating structure inference to post-processing.
Word vectors require significant amounts of memory and storage, posing issues to resource limited devices like mobile phones and GPUs. We show that high quality quantized word vectors using 1-2 bits per parameter can be learned using Word2Vec.
We propose an attention based configurable convolutional neural network for visual question answering task (VQA).
We present 3DFaceGAN, the first GAN-based GAN tailored towards modeling the distribution of 3D facial surfaces, while retaining the high frequency details of the 3D face shapes.
The authenticity of images posted on social media is an issue of growing concern. In this paper, we propose several novel methods to predict if an image was captured at one of several noteworthy events.
We propose iterative approach of applying low-rank approximation to compress deep convolutional neural networks. We demonstrate the effectiveness of our approach.
Calibration ensures that the various (past) areas of interest of a user are reflected with their corresponding proportions in a recommender system.
We propose the Reinforced Evolutionary Neural Architecture Search (RENAS), which integrates reinforced mutation into an evolution algorithm for neural architecture exploration, and obtain a powerful network architecture, RENASNet.
We consider uncertainty aware compressive sensing when the prior distribution is defined by an invertible generative model. We develop a variational approach to conditional sampling that composes a new generativeModel with the given generativemodel.
In the context of multi-task learning, neural networks with branched architectures have often been employed to jointly tackle the tasks at hand. Prior works have either relied on ad hoc methods to determine the level of layer sharing, which is suboptimal, or utilized neural architecture search techniques to establish the network design.
In Embodied Question Answering (EmbodiedQA), an agent interacts with an environment to gather necessary information for answering user questions. In this paper, we empirically study this problem and introduce 1) a simple yet effective baseline that achieves promising performance; 2) an easier and practical setting where an agent has a chance to adapt the trained model to a new environment before it answers users questions.
This paper aims to automatically estimate the level of taste liking through facial expression videos by exploiting expression dynamics such as the speed and acceleration of facial movements.
In this paper, we propose an Unstructured Semantic Model (USM) to tackles this challenge by designing a orthogonal base convolution and pooling model which adaptively learn the multi-scale base semantic representation between features supervised by the click label.
We explore the margin between positive and negative pairs of triplets and prove that large margin is beneficial for person re-identification.
We propose a neural network to cope with person tracking using only 3D point cloud, named Point Siamese Network (PSN)
We present a non-end-to-end deep learning classifier for 3D point clouds using multiple sets of input features and compare it with an implementation of PointNet++.
We conduct a quantitative analysis to gauge the efficacy of DL workloads on the latest HPC system and identify viability of next-generation DL-optimized heterogeneous supercomputers for enabling researchers to develop more efficient resource management and distributed DL middleware.
We propose a neural architecture and several extensions for detecting off-topic responses to visual prompts and evaluate it on a dataset of texts written by language learners.
We make a step towards bridging the gap between human and machine learning by introducing a simple regularization technique that allows the learned representation to be decomposable into parts. We demonstrate the value of compositional representations on three datasets.
This study introduces a novel method to optimize ensemble docking-based experiments by reducing the size of an InhA FFR model at docking runtime and scaling docking workflow invocations on cloud virtual machines.
We propose a novel two-stream architecture for joint learning of object detection and motion segmentation. It improves accuracy compared to training them independently.
We propose a novel method for robust facial landmark detection using a loss function based on 2D Wasserstein distance combined with a new landmark coordinate sampling relying on the barycenter of the individual propability distributions.
We present a novel technique, coined implicit affordances, to effectively leverage RL for urban driving thus including lane keeping, pedestrians and vehicles avoidance, and traffic light detection.
We present a new learning-based method for multi-frame depth estimation from a color video, which is a fundamental problem in scene understanding, robot navigation or handheld 3D reconstruction.
We present a generative model of images that explicitly reasons over the set of objects they show.
We propose a self-supervised algorithm for learning robotic skills from raw image observations, using only autonomously collected experience, and demonstrate that even an imperfect model can complete complex tasks if it can continuously retry.
We explore several image and action preprocessing steps, using the discrete expressions: happy, sad, surprised, fearful, angry, disgusted and neutral; with a dataset aligned and normalised by our proposed face model.
We propose a novel model which can predict accurate saliency maps by incorporating neural attentive mechanisms. The core of our solution is a Convolutional LSTM.
In this article, we propose a multimodal perspective to diagrammatic representations by sketching a description of what may be tentatively termed the diagrammatic mode.
This paper describes a dataset containing small images of text from everyday scenes. The purpose of the dataset is to support the development of new automated systems that can detect and analyze text.
In this paper we describe novel neural network architectures for suggesting complementary components and their placement for an incomplete 3D part assembly, where the retrieval network is not a function.
In this paper, we present a method called HODGEPODGE\footnotemark[1] for large-scale detection of sound events using weakly labeled, synthetic, and unlabeled data proposed in the Detection and Classification of Acoustic Scenes and Events (DCASE) 2019 challenge Task 4: Sound event detection in domestic environments.
We define a novel textual entailment task that requires inference over multiple premise sentences. We present a new dataset for this task that minimizes trivial lexical inferences and emphasizes knowledge of everyday events.
We propose a box-driven class-wise masking model (BCM) to remove irrelevant regions of each class from bounding box supervision.
We present a method to forecast actions for the unseen future of video using a neural machine translation technique that uses encoder-decoder architecture.
We propose a method for learning landmark detectors for visual objects (such as the eyes and the nose in a face) without any manual supervision.
We propose a unified formalism for video descriptors and extend all usual descriptors by switching the projection step.
We tackle image question answering (ImageQA) problem by learning a convolutional neural network (CNN) with a dynamic parameter layer whose weights are determined adaptively based on questions.
We propose an automatic human matting algorithm that learns to jointly fit both semantic information and high quality details with deep networks.
We propose a fast and accurate off-target prediction method, REMAP, which is based on a dual regularized one-class collaborative filtering algorithm to explore continuous chemical space, protein space, and their interactome on a large scale.
NeuACF is a neural network based Aspect-level Collaborative Filtering model to exploit different aspect latent factors for recommendation.
This work presents a general Attention Based Convolutional Neural Network (ABCNN) for modeling a pair of sentences.
We present BOLD5000, a human functional MRI (fMRI) study that includes almost 5,000 distinct images depicting real-world scenes.
We introduce MGP-VAE, a variational autoencoder which uses Gaussian processes (GP) to model the latent space distribution for unsupervised learning of video sequences.
In this work, we propose a recurrent neural network that is equivalent to the traditional bag-of-words approach but enables for the application of discriminative training.
We propose a novel model to simultaneously predict scene parsing and motion prediction in unobserved future video frames in a novel way.
Automatic facial expression recognition based on a deep neural network.
We present a convolutional neural network for joint 3D shape prediction and viewpoint estimation from a single input image.
This study explores a simple but strong baseline for person re-identification (ReID) with effective training tricks.
We perform extensive experiments by varying the constituent components of the video captioning framework, and quantify the performance gains that are possible by mere component selection, without major changes to the pipeline itself.
We propose a generative adversarial network to generate novel visual illusions with an artificial neural network, and validate that the outputs of our ANN are indeed visual illusions.
We explicitly optimize a diversity inducing adversarial loss for learning the stochastic latent variables and thereby obtain diversity in the output predictions necessary for modeling multi-modal data.
We propose dual model learning combined with multiple feature selection for accurate visual tracking. The proposed method is better adaptive to various challenges in visual object tracking.
A meta-learning approach for adaptive text-to-speech (TTS) with few data.
We propose a novel adversarial learning framework to train the deep matching network for CISDL using atrous convolution and spatial pyramid pooling.
We introduce the attention mechanism directly to the generative adversarial network (GAN) architecture for image-to-image translation tasks.
This article proposes a novel scheme using the subspace decomposition-based estimation (SDBE) to achieve a robust image classification for occluded images, and achieves 22.25% increase in classification accuracy under 20% occlusion.
We explore to propagate information throughout the image under the control of objects' boundaries, achieving new state-of-the-art segmentation performance.
In this paper, we propose to make NLI models robust by incorporating external knowledge to the attention mechanism using a simple transformation.
We enhance this training with teacher annealing, a novel method that gradually transitions the model from distillation to supervised learning, helping the multi-task model surpass its single-task teachers.
We propose a novel regularization method, called \textit{volumization}, for neural networks. Inspired by physics, we define a physical volume for the weight parameters in neural networks, and we show that this method is an effective way of regularizing neural Networks.
We propose a dynamic memory network to adapt the template to the target’s appearance variations during tracking.
We present a confidence- and margin-based discriminative training approach for model adaptation of a hidden Markov model (HMM)-based handwriting recognition system to handle different handwriting styles and their variations.
We compare learning performance across three tasks (peg insertion, hammering, and pushing), four action spaces (torque, joint PD, inverse dynamics, and impedance control), and two modern reinforcement learning algorithms (Proximal Policy optimization and Soft Actor-Critic).
We propose an end-to-end architecture for one-class classification that learns the target class effectively and is superior to baseline and state-of-the-art methods.
We propose the use of Monte Carlo planning in combination with two different UCT (upper confidence bound applied to trees) derivations to search for network architectures.
We propose a Hessian-based measure for flatness that is invariant to rescaling of the network parameters, and use this measure to confirm the proposition that Large-Batch SGD minima are indeed sharper than Small-batch SGDs.
We propose the SCAN framework for neural networks training and inference, which is orthogonal and complementary to existing acceleration and compression methods.
This paper addresses the problem of learning one unified embedding model for multiple object verticals (e.g. all apparel classes) without sacrificing accuracy.
A novel based unified model for protein interactions data (P-P, G-G, and G-D) by using Apache HBase.
In this paper, we propose a more efficient representation of 3D point clouds and propose SCNet, a single-stage, end-to-end 3D subdivision coding network that learns finer feature representations.
We propose a novel active learning (AL) solution, that does not rely on existing sources of unlabeled data. Using this framework, we look at the instance space as a search space and apply search algorithms in order to create desirable membership queries.
We introduce a novel deep neural network architecture that links visual regions to corresponding textual segments including phrases and words without any supervision.
We present an unsupervised approach for disentangling appearance and shape by learning parts consistently over all instances of a category.
We propose a modularizable component that can predict the boundary shapes and boxes of an image, along with a new masking scheme for improving object detection and instance segmentation.
We propose a conditional non-autoregressive neural sequence model based on iterative refinement that speeds up decoding while maintaining the generation quality comparable to the autoregressive counterpart.
We propose a face alignment framework that relies on the texture model generated by the responses of discriminatively trained part-based filters and show that our framework outperforms state-of-the-art on multiple ”wild” databases.
We propose a novel online multi-target visual tracker based on the recently developed Hypothesized and Independent Stochastic Population (HISP) filter for tracking multiple targets in varying environmental conditions and targets density using a tracking-by-detection approach.
We provide a comprehensive review to categorize and investigate existing DL methods for source code modeling and generation. We introduce recent DL mechanisms suitable to solve such problems.
We propose a robust loss function for convolutional neural networks that achieves robustness to outliers by minimizing Tukey's biweight function.
This paper addresses the problem of dense disparity estimation from a pair of color stereo images using a convex programming problem.
We propose to leverage deep monocular depth prediction to overcome limitations of geometry-based monocular visual odometry, while only using a single camera.
We propose a reinforcement learning-based weakly supervised video summarisation method that exploits easy-to-obtain, video-level category labels and encourages summaries to contain category-related information and maintain category recognisability.
In this paper, we propose a deep cocktail network (DCTN) to battle the domain and category shifts among multiple sources.
We study the essential reasons behind the failure, and accordingly present a simple baseline to addresses the problems. The baseline could inspire and help evaluate new ideas in this field.
We propose a generative adversarial network framework that generates compressed images instead of synthesizing raw RGB images and compressing them separately.
We propose a reinforced random walk that allows prominent topics to absorb tokens from similar and smaller topics, thus enhances the diversity among the top topics extracted.
We propose a novel neural network based approach to address the graph similarity search problem, aiming to alleviate the computational burden while preserving a good performance.
We study the problem of video-to-video synthesis, whose goal is to learn a mapping function from an input source video (e.g., a sequence of semantic segmentation masks) to an output photorealistic video that precisely depicts the content of the source video.
We propose a novel weakly supervised learning method that models the video event (expression, pain etc) as a sequence of automatically mined, discriminative sub-events (eg. onset and offset phase for smile, brow lower and cheek raise for pain).
We propose integrating semantic information into learning locality-aware feature sets for accurate crowd counting.
We study several attack scenarios and show that a malicious agent can force a linear contextual bandit algorithm to pull any desired arm $T - o(T)$ times over a horizon of $T$ steps, while applying adversarial modifications to either rewards or contexts that only grow logarithmically.
We propose Power Normalization (PN), a novel normalization scheme that resolves this issue by relaxing zero-mean normalization in BN, incorporating a running quadratic mean instead of per batch statistics to stabilize fluctuations, and using an approximate backpropagation for incorporating the running statistics in the forward pass.
We introduce a re-weighting scheme that uses the effective number of samples for each class to re-balance the loss, thereby yielding a class-balanced loss.
We propose three different methods for depth error reduction using a modified joint bilateral filtering at the TOF camera side.
We present a novel spatiotemporal saliency detection method to estimate salient regions in videos based on the gradient flow field and energy optimization.
Self-Correction for Human Parsing (SCHP), a cyclically learning scheduler to infer reliable pseudo-masks by iteratively aggregating the current learned model with the former optimal one in an online manner.
Autonomous underwater robots working with teams of human divers may need to distinguish between different divers, e.g. to recognize a lead diver or to follow a specific team member. This paper describes a technique that enables autonomous underwater robots to track divers in real time as well as to reidentify them.
Identity alignment models assume precisely annotated images manually. In this work, we propose to refine images by removing the undesired pixels.
This article introduces a two-dimensional taxonomy to structure the growing literature, understand the ingredients of the main works, clarify their connections and difference, and recognize their merits and limitations.
We present One-Shot Video Object Segmentation, based on a fully-convolutional neural network architecture that is able to successively transfer generic semantic information, learned on ImageNet, to the task of foreground segmentation, and finally to learning the appearance of a single annotated object of the test sequence.
We propose a novel approach which casts gait recognition as a bipartite ranking problem and leverages training samples from different people and even from different datasets, achieving 14-fold increase in recognition rate under the most difficult uncooperative settings.
This paper introduces a novel approach for 3D semantic instance segmentation on point clouds. A 3D convolutional neural network used to generate semantic predictions and instance embeddings simultaneously.
We propose a style-transfer-based data enhancement method, which uses Generative Adversarial Networks (GANs) to generate images in low-light conditions, that increases the environmental adaptability of the lane detector.
A BERT language model for answering clinical why-questions based on patient-specific clinical text.
In this paper, we propose a novel CNN architecture called Fusion Network (FusionNet) to tackle the age estimation problem.
We introduce variability through noise at different levels in a knowledge distillation framework for improving robustness to input variability in the student.
In this paper, a novel {\alpha}-matte boundary defocus model is proposed and trained, aiming to achieve clearer fusion results around the focused/defocused boundary (FDB), especially for areas near the FDB.
We propose Multi-view Concept Learning (MCL), a novel nonnegative latent representation learning algorithm for capturing conceptual factors from multi-view data.
This paper proposes low-complexity algorithms for finding approximate second-order stationary points (SOSPs) of problems with smooth non-convex objective and linear constraints.
We present a novel and general recommendation approach that uses a recurrent network to summarize the history of users' past purchases, with a continuous vectors representing items, and an attention-based recurrent mixture density network, which outputs each mixture component dynamically, to accurate model the predictive distribution of future purchase.
Cross-domain complementary learning to learn multi-person part segmentation on real images without any human-annotated segmentation labels.
In recommender systems based on low-rank factorization of a partially observed user-item matrix, a common phenomenon that plagues many otherwise effective models is the interleaving of good and spurious recommendations in the top-K results.
We propose a gated intercommunication unit to enable transfer and integration of information between global and local branches in hemisphere-inspired artificial neural networks, such that one branch can leverage the other’s learned knowledge and benefit each other.
In this paper, we propose a method for cloud removal from visible light RGB satellite images by extending the conditional Generative Adversarial Networks (cGANs) from RGB images to multispectral images to reduce the effects of clouds.
We propose a benchmark for edge-preserving image smoothing and propose novel loss functions and baseline algorithms that can perform competitively on the benchmark.
An automated method for assessing the consistency of biological assertions, to assist biocurators to perform data cleansing.
Attributes allow us to exchange information between the two modalities and in this way lead to an interaction on a semantic level.
We propose a gated multi-layer convolutional feature extraction method which can adaptively generate discriminative features for candidate pedestrian regions for small-size and occluded pedestrians.
A list of promising compounds displaying high binding characteristics towards MASTL protein is reported.
We present an algorithm to synthetically increase the resolution of a solitary depth image using only a generic database of local patches using only synthetic training data.
We present a principled framework for infusing knowledge of the image formation into deep networks that solve inverse problems in imaging, inspired by classical iterative methods.
We develop a general problem setting for training and testing the ability of agents to gather information efficiently. We combine deep architectures with reinforcement learning to develop agents that solve our tasks.
In this paper, we propose a new object detection model, Mixture-Model-based Object Detector (MMOD), that performs multi-object detection using a mixture model.
Adaptive Affinity Matrix (AdaAM) to learn an adaptive affinity matrix and derive a distance metric from the affinity.
Unsupervised domain adaptation algorithms aim to transfer the knowledge learned from one domain to another (e.g., synthetic to real images) but often capture pixel-level domain shifts that are crucial for dense prediction tasks.
We propose to use the kernel partial least squares (KPLS) regression for age estimation in computer vision and pattern recognition.
We propose a new recommender hybridization method that combines multiple recommendation algorithms into a single ensemble that improves the recommendation quality.
We leverage the specific structure of data in order to improve the performance of LRD when the data are not ideal.
This paper proposes to explicitly model the information gain through dialogue reasoning in order to allow the model to focus on more informative cues.
We propose a general and effective improvement to the BiLSTM model which encodes each suffix and prefix of a sequence of tokens in both forward and reverse directions. This introduces an alternate bias that favors long range dependencies.
We address the problem of unsupervised disentanglement of latent representations learnt via deep generative models. We augment the standard VAE with an inverse-Wishart prior on the covariance matrix of the latent code.
We propose a new structure-expanding regularization method called Adjective Noise Injection (ANI), which considers the output of an extra RNN branch as a kind of adaptive noises and injects it into the main-branch RNN output to improve its training performance in the early stage.
We propose a novel framework for semantic face editing by interpreting the latent semantics learned by GANs. We explore the disentanglement between various semantics.
We propose a divide-and-conquer hole-filling method which refines the background depth pixels around the sharp depth discontinuities to address the disocclusion problem to improve the quality of the synthesized view.
We propose methods to study these interactions, and apply them on a platform called Nico Nico Douga (NND), with the aim of understanding cooperative behaviors, taking the form of collective creation of music videos in NND.
In this paper, we propose a novel binary-based cost computation and aggregation approach for stereo matching problem.
Inference of genome-wide regulatory networks using probabilistic graphical models for expression perturbation .
We propose a simple and effective method to bridge the disparate annotation spaces between databases for improved cross-dataset and unseen data alignment.
We present the Sketchy database, the first large-scale collection of sketch-photo pairs, and use this to train cross-domain convolutional networks which embed sketches and photographs in a common feature space.
We propose an ensemble technique for converting any classifier into a computationally secure classifier that leverages hidden randomness in the multiclass-to-binary reduction.
In this paper, we introduce the Butterfly Transform (BFT), a light weight channel fusion method that reduces the computational complexity of point-wise convolutions from O(n^2) of conventional solutions to O( n log n) with respect to the number of channels while improving the accuracy of the networks under the same range of FLOPs.
This work aims at defining an extension of a competitive method for matching correspondences in stereoscopic image analysis by adding some details that lead to better results.
We conduct the first study of exploring security issues of the operational Wi-Fi calling services in three major U.S. operators' networks and uncover four vulnerabilities which stem from improper standard designs, device implementation issues and network operation slips.
In this paper, we propose the Splenomegaly Segmentation Network (SSNet) to address spatial variations when segmenting extraordinarily large spleens.
We propose an expandable multi-modality system for saliency detection and propose a combined saliency loss based on modified Pearson correlation and normalized scanpath saliency.
We propose a novel framework for fusing multiple clues for person re-identification that improves the results over the original backbones.
Self-supervised learning from multimodal image and text data allows deep neural networks to learn powerful features with no need of human-annotations.
Drug-induced prolongation of the QT interval on the electrocardiogram (long QT syndrome, LQTS) can lead to a potentially fatal ventricular arrhythmia called torsades de pointes (TdP), but drug-drug interactions contributing to LQts (QT-DDIs) remain poorly characterized. In this study we present an integrative data science pipeline that combines mining for latent QT
This paper proposes a novel Non-Local Attention optmization and Improved Context modeling-based image compression algorithm, which is built on top of the deep nerual network (DNN)-based variational auto-encoder (VAE) structure.
The paper gives futuristic challenges disscussed in the cvpaper.challenge.
We propose Fastfood, an approximation that accelerates the computation of kernel functions in d dimensions without sacrificing accuracy.
This paper addresses the challenge of 3D object detection from a single panoramic image under severe deformation. We propose a multi-scale convolutional neural network (MSCNN) to estimate the 3D pose of an object.
Multi-Subregion based Correlation Filter Bank for Robust Face Recognition .
We propose a modified gradient descent search based on resilient propagation, a method commonly used in the machine learning community.
We aim at making the best of both worlds by developing an approach that leverages both context-aware and action-aware features.
In this paper, we propose a method for jointly estimating optical flow and temporally consistent semantic segmentation, which closely connects these two problem domains and leverages each other.
This paper presents a new approach, RLvLR, to learning rules from large knowledge graphs by using the technique of embedding in representation learning together with a new sampling method.
In this paper, we propose a dimensionality reduction method applied to tensor-structured data as a hidden layer (we call it TensorProjection Layer) in a convolutional neural network.
We exploit spatiotemporal relations in training videos for self-supervised learning of pose embeddings in a Siamese convolutional network.
We have developed both an intuitive semantic graph notation or interface allowing one to pose a query by annotating a graph with natural language terms denoting entities and relations and a system that automatically translates the query into SPARQL to produce an answer.
The reliability of a machine learning model's confidence in its predictions is critical for highrisk applications. Calibration-the idea that a model's predicted probabilities of outcomes reflect true probabilities of those outcomes-formalizes this notion. There are many cases where what a practitioner cares about is the calibration of a specific prediction, and so we introduce a dynamic programming based Prediction Specific Calibrration Error (PSCE) that smoothly considers the calibration thereof.
This paper proposes a bidirectional tracking scheme to alleviate the model drift problem during online tracking.
Stratified Dense Matching is able to increase matching density 3×, matching accuracy 1.8×, and occlusion boundary detection 2× as compared to fixed-size rectangular windows algorithm.
AttentionGAN is an attention-guided generative adversarial network for the unpaired image-to-image translation task.
Prototype selection is one of the most popular approaches for addressing the low efficiency issue typically found in the well-known k-Nearest Neighbour classification rule. Most recently, rank methods have been proposed as an alternative to develop new selection strategies.
An e-Research approach has been adopted in order to create a web-accessible corpus of musical analyses in a common framework for use by music scholars, students and beyond, and to establish a methodology and tooling that will enable others to add to the resource in the future.
We use reinforcement learning to efficiently optimize the mapping from states to generalized forces over a discounted infinite horizon, improving the sim-to-real control policy transfer.
We introduce Robust Pixel-level Matching Net-works (RPM-Net), a novel deep architecture that matches pixels between adjacent frames, using only color information for training.
We propose rectified factor networks (RFNs) to efficiently construct very sparse, non-linear, high-dimensional representations of the input. RFN models identify rare and small events in the input, have a small reconstruction error, and explain the data covariance structure.
This paper presents a new method by improving transfer learning and squeeze-and-excitation networks for fine-grained fish image classification on low-quality and small-scale datasets.
We propose an effective defense framework to characterize and defend adversarial videos against adversarial attacks.
This paper proposes a hybrid neural network (HNN) model for commonsense reasoning, which combines the strengths of both language models and semantic similarity models.
In this work, we propose Dilated Point Convolutions (DPC) which drastically increase the receptive field of convolutions on 3D point clouds on S3DIS and ScanNet.
A multi-stage, multimodal summarization process for stereoscopic 3D movies that captures informative image statistics from luminance, color, optical flow, and stereoscopic disparity video data.
We present a novel method for recovering the 3D structure and scene flow from calibrated multi-view sequences using an advanced variational framework and a unified global energy functional.
We propose and evaluate several triplet CNN architectures for measuring the similarity between sketches and photographs, within the context of the sketch based image retrieval (SBIR) task.
We use continuous word space representations to explicitly compute query and detector concept similarity, which leads to fast query-video similarity computation with implicit query expansion.
A dual-purpose method that achieves satisfactory performance in enhancing the visibility of both underwater and low-light images is proposed.
We present a novel joint head and human detection network, namely JointDet, which effectively detectsHead and human body simultaneously.
The tranfer of a neural network (CNN) trained to recognize objects to the task of scene classification is considered. The analysis of these FVs shows that significant benefits can ensue by designing FVs in the natural parameter space of the multinomial distribution, and adopting sophisticated probabilistic models of semantic feature covariance.
In this paper we propose a robust algorithm that generates an efficient and accurate dense 3D reconstruction with associated semantic labellings.
In this paper, we introduce hybrid facial representations for facial expression recognition, which have more powerful description capability with lower dimensionality.
Stereo depth estimation is error-prone; hence, effective error detection methods are desirable. As a remedy, we propose a novel error detection approach based solely on the input image and its depth map.
We exploit this rich structure for performing graph-based inference in label space for a number of tasks, achieving significant improvements against baselines.
We propose a novel visual relationship detection framework by deeply mining and utilizing relative location of object-pair in every stage of the procedure, which significantly improves state-of-the-art.
In this paper we tackle the problem of unsupervised domain adaptation for the task of semantic segmentation, where we attempt to transfer the knowledge learned upon synthetic datasets with ground-truth labels to real-world images without any annotation.
This paper presents an advanced signal processing method using the deep neural network (DNN) for emotion recognition based on EEG signals.
We propose StyleBank, which is composed of multiple convolution filter banks and each filter bank explicitly represents one style, for neural image style transfer.
We introduce a novel model for spatially varying variational data fusion, driven by point-wise confidence values, based on spatial coherence of the data.
In this paper, we propose the Concurrent Reflection Removal Network (CRRN) to tackle this problem in a unified framework that integrates image appearance information and multi-scale gradient information.
We present novel methods for analyzing the activation patterns of recurrent neural networks from a linguistic point of view and explore the types of linguistic structure they learn.
This paper introduces an Attention Conditional GANs approach for face aging, which utilizes attention mechanism to only alert the regions relevant to face aging.
We introduce 10 probing tasks designed to capture simple linguistic features of sentences, and we use them to study embeddings generated by three different encoders trained in eight distinct ways, uncovering intriguing properties of both encoder and training methods.
We study the problem of interpreting trained classification models in the setting of linguistic data sets by exploiting syntactic constituency structure. Leveraging a parse tree, we propose a principled method for detecting and quantifying interactions between words in a sentence.
This paper presents a method to estimate the 3D object position and occupancy given a set of object detections in multiple images and calibrated cameras using linear constraints.
This paper proposes a simple neural model for RTE problem. It first matches each word in hypothesis with its most-similar word in the premise, producing an augmented representation of the hypothesis conditioned on the premise as a sequence of word pairs.
We propose a novel unsupervised image categorisation method which uses the Bag-of-Features approach to find initial matches for each image (pre-filter) and then refines and ranks them using spatial matching of local features.
We propose an effective Relation-Aware Global Attention (RGA) module which captures the global structural information for better attention learning for person re-identification.
We combine pixel-wise image classification with cross entropy loss and pretraining of the CNN as an autoencoder on singing voice spectrograms to solve singing voice separation.
We find that agents that were initially pretrained to produce natural language can also experience detrimental language drift.
We propose a novel framework IterE iteratively learning embeddings and rules, in which rules are learned from existing triples and new triples inferred by rules.
Policy gradient based reinforcement learning algorithms coupled with neural networks have shown success in learning complex policies in the model free continuous action space control setting. We show that alternatively to the likelihood based policy gradient, a related objective can be optimized through advantage weighted quantile regression.
We propose a light-weight variational framework for online tracking of object segmentations in videos based on optical flow and image boundaries.
In this paper, we implement a natural language state representation to learn and complete tasks, showing the benefit of using natural language representations for Reinforcement Learning.
We propose Neural Logic Inductive Learning (NLIL), an efficient differentiable ILP framework that learns first-order logic rules that can explain the data.
Adversarial training causes loss gradients from adversarially trained DNNs to be quantitatively meaningful.
We present a data association method for vision-based multiple pedestrian tracking, using deep convolutional features to distinguish between different people based on their appearances.
We consider the problem of learning multi-stage vision-based tasks on a real robot from a single video of a human performing the task, while leveraging demonstration data of subtasks with other objects.
This paper proposes Document Graph Network (DGN), a message passing architecture for the identification of supporting facts over a graph-structured representation of text.
We propose a near-miss data synthesizing framework based on Variational Bayesian methods and term it as Conditional Multiple Trajectory Synthesizer (CMTS)
We study how to enforce the consistency between surface normal and depth at training time to improve the performance. We propose a novel consistency loss to train an independent consistency module that refines the depths from depth/normal pairs.
We propose Adaptable Cosine Classifier (ACC) and Amphibian to achieve fast and generalized adaptation for few-shot learning.
We propose a novel method for 3D object pose estimation in RGB images, which does not require pose annotations of objects in images in the training stage.
A new approach was proposed to improve traditional background subtraction techniques by integrating a gradient-based edge detector called a second derivative in gradient direction (SDGD) filter with the BGS output.
A biologically-inspired model that combines sequential visual attention using fixations with sparse coding achieves 78.5% accuracy on Caltech-101 and 75.7% on AR Face.
We propose a semi-global stereo matching system which achieves accurate disparity raw matching cost with low computational cost.
This paper presents a near-real-time stereo matching method using both cross-based support regions in stereo views using the logical AND operator.
We propose the Constrained Latent Space Model (CLSM), a generalized framework that combines Mixed Membership Stochastic Blockmodels (MMSB) and Latent Dirichlet Allocation (LDA) incorporating a constraint that forces the latent space to concurrently describe the multiple data modalities.
We propose a new activation function, Multiple Parametric Exponential Linear Units (MPELU), enabling training of very deep networks using exponential linear units.
A comprehensive study on local methods for human action recognition based on spatio-temporal local features.
We propose an end-to-end feature learning strategy integrating discriminative information with various granularities for person re-identification.
We study this optimisation problem and train Classifiers, which take features of a question as input and have the goal of optimising the selection of QA components based on those features. We then devise a greedy algorithm to identify the suitable components and compose QA pipelines.
A brief overview of the recent development in object detection using convolutional neural networks (CNN)
We propose the Deep Minimax Probability Machine (DeepMPM), which applies MPM to deep neural networks in an end-to-end fashion, allowing them to be more robust on adversarial attacks.
In this paper, we combine the principles of temporal slowness and nonnegative parts-based learning into a single framework that aims to learn slow varying parts- based representations of time varying sequences. We demonstrate that the proposed algorithm arises naturally.
In this paper, we make the student network produce more confident predictions with the help of the teacher network, and analyze the lower bound of the perturbation that will destroy the confidence of student network.
The need for synthetic route design arises frequently in discovery-oriented chemistry organizations. Herein we present our own implementation of a retrosynthetic analysis method and demonstrate its capabilities in an attempt to identify synthetic routes for a collection of approved drugs.
We introduce a 3D pose generative model to predict affordances of 3D indoor scenes and learn possible 3D human poses in indoor scenes.
An Egocentric Arm Segmentation Dataset for Augmented Virtuality and the Use of Deep Learning .
We present a novel procedural framework to generate an arbitrary number of labeled crowd videos (LCrowdV). The resulting crowd video datasets are used to design accurate algorithms or training models for crowded scene understanding.
This paper presents our work on "SNaCK," a low-dimensional concept embedding algorithm that combines human expertise with automatic machine similarity kernels.
We propose the Multi-view Aware Attention Networks (MAANet) for image super-resolution task.
We propose a framework for multi-task learning that enables one to selectively share the information across the tasks. We assume that each task parameter vector is a linear combination of a finite number of underlying basis tasks.
How do humans recognize the action"opening a book"? We propose to represent videos as space-time region graphs which capture these two important cues.
We model data association ambiguity, which is typically non-Gaussian, in a way that is amenable to solution within the common nonlinear Gaussian formulation of simultaneous localization and mapping (SLAM), while preserving standard Gaussian posterior assumptions.
This paper reports a study on video anomaly detection, focusing on the analysis of feature embeddings of pre-trained CNNs with novel cross-domain generalization measures that allow to study how source features generalize for different target video domains.
We develop ADADP, an adaptive and fast convergent learning algorithm with a provable privacy guarantee.
We propose a contextual attention framework for human-object interaction detection, which leverages contextually-aware appearance features for human and object instances.
CamStyle can serve as a data augmentation approach that smooths the camera style disparities.
We propose a novel Knowledge Aided Consistency Network (KAC Net) which is optimized by reconstructing input query and proposal's information.
We introduce a language generative model framework for generating a styled paragraph based on a context sentence and a style reference example.
We present an autoregressive pedestrian detection framework with cascaded phases designed to progressively improve precision.
We propose summarization filter mechanism in order to consider more about the whole query in MC. Our mechanism makes the model to better understand the query.
This paper presents a novel algorithm for the efficient detection and measurement of retinal vessels, which can be applied to both low and high resolution fundus photographs and fluorescein angiograms upon the adjustment of only a few intuitive parameters.
We propose the cross-domain few-shot learning benchmark, consist-ing of images from diverse domains with varying similarity to ImageNet, ranging from crop disease images, satellite images, and medical images. The benchmark serves as a challenging platform to guide future research on cross- domain few- shot learning due to its spectrum of diversity and coverage.
We present a method that leverages a fully convolutional network (FCN) to predict semantic labels, depth and an instance-based encoding using each pixel's direction towards its corresponding instance center.
This paper presents a novel dictionary learning approach that incorporates three attributes, namely, reconstruction and discriminative fidelities, block-wise incoherence, and $\ell _{2,1}$ -norm regularization.
We propose SeqFace, a framework for learning discriminative face features by using sequence data.
Generative adversarial network-based GAN-IMC framework for image super-resolution .
Face recognition underpins numerous applications; however, the task is still challenging mainly due to the variability of facial pose appearance.
The way people look in terms of facial attributes (ethnicity, hair color, facial hair, etc) and the clothes or accessories they wear (sunglasses, hat, hoodies, etc.) is highly dependent on geo-location and weather condition, respectively. This work explores, for the first time, the use of this contextual information, as people with wearable cameras walk across different neighborhoods of a city, in order to learn a rich feature representation
We propose a bidirectional proposal method that effectively exploits both past and future contexts for accurate event proposal predictions, and propose a novel context gating mechanism to balance the contributions from the current event and its surrounding contexts dynamically.
Image restoration problems are typically ill-posed requiring the design of suitable priors. In this paper, we introduce a novel framework for handling inverse problems related to image restoration based on elements from the half quadratic splitting method and proximal operators.
In this paper, we propose eager-SGD, which relaxes the global synchronization for decentralized accumulation of Stochastic Gradient Descent.
We propose new unsupervised baselines that leverage distributed word and sentence representations and compare their ability to learn from few annotated examples in weakly supervised schemes.
A lightweight network architecture framework to learn spatiotemporal feature from video. Keeping the model as small and as fast as possible.
We introduce a novel architecture for this task to encode the conversation history and slot semantics more robustly by using attention mechanisms at multiple granularities and resolve cross-domain coreferences.
We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs.
We extend the text-to-image task of face generation to the less addressed domain of conditional multi-modal face generation.
This work explores bidirectional architectures that also reason with top-down feedback: neural units are influenced by both lower and higher-level units.
This paper proposes traditional multilayer perceptrons (MLP) with deep layers and small input size to tackle that computation requirement limitation.
We present a new model for multivariate time-series classification, called the hidden-unit logistic model, that uses binary stochastic hidden units to model latent structure in the data.
We propose an end-to-end deep learning architecture that produces a 3D shape in triangular mesh from a single color image by progressively deforming an ellipsoid, leveraging perceptual features extracted from the input image.
In this study, we developed a method to extract the core structure of weighted heterogeneous networks by transforming the heterogeneity networks into homogeneous networks.
We propose Correlated Variational Auto-Encoders that can take the correlation structure into consideration when learning latent representations for high dimensional data.
We propose a novel combination of deep-learning-based object features and state-of-the-art SIFT point-features that yields improved robustness to scale change.
A universal framework to model contextualized sentence representations with visual awareness that is motivated to overcome the shortcomings of the multimodal parallel data with manual annotations.
The 01 loss is robust to outliers and tolerant to noisy data compared to convex loss functions. We conjecture that the 01 loss may also be more robust to adversarial attacks.
We introduce a structured regularization for convolutional layers, which we call DropCluster, which finds clusters of correlated features and drops the clusters randomly at each iteration.
Iterative Error Feedback expands the expressive power of hierarchical feature extractors to encompass both input and output spaces, by introducing top-down feedback.
We investigate the effect and usefulness of spontaneity in speech (i.e. whether a given speech data is spontaneous or not) in the context of emotion recognition.
We propose an alternative design for pointwise convolution, which uses spatial information from the input efficiently. Our design significantly improves the performance of the networks.
We propose to use synthetic face images to reduce the negative effects of dataset biases on face recognition and facial landmark detection tasks.
We propose a method that directly uses point clouds as input and exploits the implicit space partition of k-d tree structure to learn the local contextual information and aggregate features at different scales hierarchically.
In this paper, we propose a semi-supervised framework that performs Sparse Label Smoothing Regularization by considering similarities between unlabeled sample and training sample in the same feature space.
We propose MuRel, a multimodal relational network which is learned end-to-end to reason over real images, competitive to state-of-the-art results in this challenging context.
The perception system of an autonomous vehicle is responsible for mapping sensor observations into a semantic description of the vehicle's environment. 3D object detection is a common function within this system and outputs a list of 3D bounding boxes around objects of interest. However, occlusion, limited field-of-view and low-point density of the sensor data cannot be reliably and cost-effectively addressed by multi-modal sensing from a single point
This paper proposes an end-to-end approach tailored for image translation that efficiently approximates this transformation with our novel regularization methods.
Part-based Hierarchical Graph Convolutional Network (PH-GCN) for person Re-ID problem.
We address the problem of learning a pose-aware, compact embedding that captures differences in human poses by effectively factoring out variations in clothing, background, and imaging conditions in the wild.
We propose a new model based on Gaussian Conditional Random Field for facial expression and Action Units detection.
We revisit the initialization of deep residual networks (ResNets) by introducing a novel analytical tool in free probability to the community of deep learning, for both linear and nonlinear cases.
This paper describes an efficient single-stage deep convolutional neural network to detect objects in urban environments, using nothing more than point cloud data.
This paper proposes a method for automatic retinal vessel segmentation using Morlet wavelet and Bayesian classifier.
The increasing use of social media networks on handheld devices, especially smartphones with powerful built-in cameras, and the widespread availability of fast and high bandwidth broadband connections, added to the popularity of cloud storage, is enabling the generation and distribution of massive volumes of digital media, including images and videos.
We propose Adaptive Margin Loss (AML) for training translation-based embedding models.
We present Temporal Aggregation Network (TAN) which decomposes 3D convolutions into spatial and temporal aggregation blocks for multi-scale spatio-temporal information.
We develop the first approximate inference algorithm for 1-Best (and M-Best) decoding in bidirectional neural sequence models by extending Beam Search to reason about both forward and backward time dependencies.
We propose a new gated self-attention memory network for answer selection, achieving state-of-the-art results on two standard answer selection datasets.
We introduce the scaling-binning calibrator, which first fits a parametric function to reduce variance and then bins the function values to actually ensure calibration. This requires only $O(B/B)$ samples.
We propose a statistical adaptive stochastic approximation method that automates the most common hand-tuning heuristic: use a constant learning rate until "progress stops," then drop.
In this paper, a feature boosting network is proposed for estimating 3D hand pose and 3D body pose from a single RGB image using Graphical ConvLSTM.
A new machine learning methodology, called successive subspace learning (SSL), is introduced in this work.
We propose structured prediction models for image labeling that explicitly take into account dependencies among image labels, and leverage user input for more accurate predictions.
Max-pooled word vectors are only a special case of fuzzy BoW and should be compared via fuzzy Jaccard index rather than cosine similarity. We propose DynaMax, a completely unsupervised and non-parametric similarity measure.
This paper proposes a new hybrid architecture that consists of a deep Convolu-tional Network and a Markov Random Field. We show how this architecture is successfully applied to the challenging problem of articulated human pose estimation in monocular images.
We propose a novel attention-based saliency map prediction model for making braking decisions.
We extend the analysis of the trade-off by Xie et. al., and propose a novel method adversarial feature learning with accuracy constraint, which explicitly leads to that invariance on adversarial training.
A new variational autoencoder model that learns a succinct common representation of two correlated data variables for conditional and joint generation tasks.
We present a general "compare-aggregate" framework that performs word-level matching followed by aggregation using Convolutional Neural Networks.
The low displacement rank (LDR) framework for structured matrices represents a matrix through two displacement operators and a low-rank residual. We introduce a rich class of LDR matrices with more general displacement operators.
We explore variants of target-propagation (TP) and feedback alignment (FA) algorithms, and explore performance in both fully- and locally-connected architectures.
We present a novel strategy to learn a local feature pipeline from collections of images with deep networks, without the need for human supervision.
We propose a new iterative inference mechanism for Collective Classification, called the Higher Order Propagation Framework (HOPF), which learns end-to-end differentiable variations of Weisfeiler-Lehman kernels to aggregate multi-hop neighborhood information. The iterative formulation of NIP models further helps in incorporating distant hop information concisely and robustly.
We propose a novel normalization method, named Moving Average Batch Normalization (MABN), which restores the performance of vanilla BN in small batch cases, without introducing any additional nonlinear operations in inference procedure.
SiamMask improves the offline training procedure of popular fully-convolutional Siamese approaches for object tracking by augmenting their loss with a binary segmentation task.
We propose a long-term feature bank to augment state-of-the-art video models that otherwise would only view short clips of 2-5 seconds.
Hyperbolic spaces have recently gained momentum in the context of machine learning due to their high capacity and tree-likeliness properties. As a result, we derive hyperbolic versions of important deep learning tools: multinomial logistic regression, feed-forward and recurrent neural networks.
In this paper, we propose a generative model, Temporal Generative Adversarial Nets (TGAN), which can learn a semantic representation of unlabeled videos, and is capable of generating videos.
We propose to use independent subspace analysis to learn descriptors for state-of-the-art handcrafted features for action recognition system.
We use the Fisher Vector as a sentence representation by pooling the word2vec embedding of each word in the sentence.
This work proposes a novel temporal stream for two-stream convolutional networks based on images computed from the optical flow magnitude and orientation, named Magnitude-Orientation Stream (MOS), to learn the motion in a better and richer manner.
We propose the Selective Tuning of Convolutional Networks (STNet) for the weakly-supervised localization task on ImageNet benchmark dataset.
We learn the filters for motion magnification using deep convolutional neural networks, achieving high quality results on real videos.
We propose a novel depth refinement framework that recovers the underlying piece-wise planarity of the inverse depth map, without any need for a priori estimation of the scene planes.
We propose a distributed approach to train deep neural networks (DNNs), which has guaranteed convergence theoretically and great scalability empirically.
We propose a new 3D Scene Point Cloud Sequence Forecasting (SPCSF) pipeline based on SPCSFNet, which eliminates the need of object trajectory labels and enables large-scale training with unlabeled sensor data.
We propose a novel supervised hashing method based on optimizing an information-theoretic quantity, mutual information, which maximally and efficiently utilizes available supervision.
A novel approach to occlusion handling problem in depth estimation using three views. A solution based on modification of similarity cost function.
The success of monocular depth estimation relies on large and diverse training sets. We develop tools that enable mixing multiple datasets during training, even if their annotations are incompatible.
Actor-critic methods, a type of model-free Reinforcement Learning, have been successfully applied to challenging tasks in continuous control, often achieving state-of-the- art performance. However, wide-scale adoption of these methods is made difficult by their poor sample efficiency. We address this problem both theoretically and empirically.
In this paper, we propose a generic tree filtering module that leverages the structural property of minimal spanning tree to model long-range dependencies while preserving the details.
A network analysis of HepG2 cells, a hepatoblastoma cell line that lacks the viral infection, identified HUB genes that are associated with the metabolic processes that control human circadian rhythms, which supports the hypothesis that a number of cancer types are dependent from circadian cycles.
We propose a novel LiDAR simulator that augments real point cloud with synthetic obstacles (e.g., vehicles, pedestrians, and other movable objects) for performance enhancement.
Planning is an essential topic in the realm of automated driving. Besides planning algorithms that are widely covered in the literature, planning requires different software tools for its development, validation, and execution. This paper presents a survey of such tools.
We propose a new LUPI algorithm specifically designed for Convolutional Neural Networks (CNNs) and Recurrent Neural networks (RNNs) that use a heteroscedastic dropout (i.e. dropout with varying variance) and make the variance of the dropout a function of privileged information.
PrivaTube aggregates video content from multiple servers and edge peers to offer a high Quality of Experience (QoE) while providing strong privacy guarantees.
We propose a novel approach for scene labeling by exploring multi-level contextual recurrent neural networks.
We use foreground masks as weak supervision through a raytrace pooling layer that enables perspective projection and backpropagation of 3D reconstruction.
We developed a novel method, referred to as Gemini Network, for effective modeling of temporal structures and achieving state-of-the-art temporal action localization.
We study the internal representations of a deep network using vehicle images from the PASCAL3D+ dataset and use them as building blocks for a simple pattern theoretical model, which we call compositional voting.
In this work we present a new efficient approach to Human Action Recognition called Video Transformer Network (VTN). It leverages the latest advances in Computer Vision and Natural Language Processing and applies them to video understanding.
This study addresses the needs for automatic generation of mesh-based geometries, and propose a novel framework that generates detail preserving three-dimensional surface mesh by a deep learning based approach.
We introduce a Bidirectional Encoder Representations from Transformers for sequential Recommendation (BERT4Rec) for dynamic and evolving preferences from their historical behaviors.
We present U2GAN, a novel unsupervised model leveraging on the strength of the recently introduced universal self-attention network (Dehghani et al, 2019), to learn low-dimensional embeddings of graphs which can be used for graph classification.
A novel motion-control strategy for vision-based autonomous following of a noncooperative multirotor using synthetic data.
We introduce a spectral Multi-Laplacian Graph Convolutional Network that learns convex combinations of other elementary laplacians each one dedicated to a particular topology of the input graphs.
We propose a two-stage 3D object detection framework, named sparse-to-dense 3D Object Detector (STD), which achieves a higher recall with less computation compared with prior works.
Unifying instance segmentation and semantic segmentation using a shared Feature Pyramid Network backbone .
We propose a framework for evaluating algorithms' ability to detect overlapping nodes, which helps to assess overdetection and underdetection.
We propose stochastic, non-parametric activation functions that are fully learnable and individual to each neuron. Complexity and the risk of overfitting are controlled by placing a Gaussian process prior over these functions.
This paper presents an overview of our recent work on shape-based object discovery in images.
A region-wise colour correction method can effectively and robustly alleviate the colour discrepancies, and improve the accuracy of stereo matching.
We automate the task of tissue classification within colorectal cancer histology samples using deep transfer learning and apply structure-preserving colour normalization to boost our results.
This paper describes Pinview, a content-based image retrieval system that exploits implicit relevance feedback during a search session that exploits the current interests of the user.
Landmarking can be formalised as calculating the Maximum A-posteriori Probability (MAP) of a set of land-marks given an image (texture) containing a face.
We introduce a new temporal layer that models variable temporal convolution kernel depths and propose a 3D convolutional network that outperforms state-of-the-art methods on HMDB51, UCF101 and Kinetics.
This paper argues that several labels provided by different individuals convey more information than the consensus labels. We demonstrate that leveraging the information provided by separate evaluations collected by multiple raters can help in building more robust classifiers which maximize the utilization of labeled data.
We focus on the problem of black-box adversarial attacks, where the aim is to generate adversarial examples using information limited to loss function evaluations of input-output pairs using Bayesian optimization.
We propose a novel discrete supervised hash learning framework which can be scalable to large-scale datasets.
We propose a dual pattern learning network architecture that learns patterns from two given images at one time. We show that this can improve the performance for single image classification.
Comparison of energy minimization algorithms for vision tasks such as stereo, image stitching, interactive segmentation, and denoising.
We introduce a novel approach to semantic flow, dubbed proposal flow, that establishes reliable correspondences using object proposals, that exhibit high repeatability at multiple scales, and can take advantage of both local and geometric consistency constraints.
We propose a method of learning confidence estimates for neural networks that is simple to implement and produces intuitively interpretable outputs.
This work adopts the very successful distributional perspective on reinforcement learning and adapts it to the continuous control setting.
We propose to leverage a generic object tracker in order to perform object mining in large-scale unlabeled videos and propose a method for automated novel category discovery and detector learning.
In this paper, we propose a new convolutional module, local binary orientation module (LBoM), which takes advantages of both local binary convolutionAL and active rotating filters to effectively deal with the rotation variations.
We propose a novel framework to exploit the semantic similarity among all predicted targets in each image to boost current face detectors.
We propose to jointly optimize a part-based, trained in-the-wild, flexible appearance model along with a global shape model which results in a joint translational motion model via Gauss-Newton (GN) optimization.
We introduce a novel region proposal network that uses subcategory information to guide the proposal generating process, and a new detection network for joint detection and subcategory classification.
In this paper, we introduce a new ID-adaptation network (ID-AdaptNet), which aims to improve the discriminative power of the IDE features of the testing identities for better person re-ID.
A prototype-based approach is introduced for action recognition. The approach represents an action as a sequence of prototypes for efficient and flexible action matching.
We develop a solution combining state-of-the-art object detection and reasoning modules for VQA.
We present the first CNN -based approach to understand and filter out such adverse weather effects in point cloud data.
The goal of the Semantic Scene Completion (SSC) task is to simultaneously predict a completed 3D voxel representation of volumetric occupancy and semantic labels of objects in the scene from a single-view observation. Since the computational cost generally increases explosively along with the growth of voxal resolution, most current state-of-the-arts have to tailor their framework into a low-resolution representation with the sacrifice of detail
This paper combines the unsupervised representation learning strategy -- Future Observation Prediction (FOP), with transfer learning approaches (such as Fine-tuning and Hypercolumns) for speech emotion recognition.
We use a hierarchy of VQ-VAEs to improve likelihood-based image compression and generate realistic samples.
We propose PointIT, a fast, simple tracking method based on 3D on-road instance segmentation for LiDAR point clouds.
We tackle the problem of automatically reconstructing a complete 3D model of a scene from a single RGB image. Our approach utilizes viewer-centered multi-layer representation of scene geometry adapted from recent methods for single object shape completion.
In order to improve the noise reduction performance and the clarity of denoising images, a composite convolutional neural network composed of the convolutionsal autoencoder network and the feature reconstruction network is proposed. The cross-connected structure is used to fuse feature information in the convolutionalist autoencoders into the feature Reconstruction network.
We introduce stable bipartite subgraphs for generating meaningful BPMs which naturally discard extra genes included by local greedy methods. We show by GO enrichment measures that our BPM set outperforms previous work.
In this work, we study 3D object detection from RGB-D data in both indoor and outdoor scenes. While previous methods focus on images or 3D voxels, often obscuring natural 3D patterns and invariances of 3D data, our method leverages both mature 2D object detectors and advanced 3D deep learning for object localization.
We propose a multi-passage BERT model to globally normalize answer scores across all passages of the same question, and this change enables our QA model find better answers by utilizing more passages.
We propose a simple, intuitive and much more elegant one-stage detection based method that joints the region proposal and matching stage as a single detection network for Visual Grounding.
We investigate challenges posed by reproducibility, proper experimental techniques, and reporting procedures, and propose guidelines to make future results in deep RL more reproducible and easily misinterpreted.
We propose a simple yet effective method to reduce the redundancy of DenseNet by substantially decreasing the number of stacked modules by replacing the original bottleneck by our SMG module, which is augmented by local residual.
We introduce a new test collection named FoxFaces, dedicated to researchers in face recognition and analysis. It contains 3 face datasets obtained with several devices.
We identify the state of the art in compression for each part of BERT, clarify current best practices for compressing large-scale Transformer models, and provide insights into the inner workings of various methods.
We propose to jointly adapt visual representation and policy behavior to leverage the mutual impacts of environment and policy to accelerate 3D indoor navigation training.
We propose a novel probabilistic generative model for action sequences. The model is termed the Action Point Process VAE (APP-VAE), a variational auto-encoder that can capture the distribution over the times and categories ofaction sequences.
We design a new learning-from-motion paradigm to bridge these gaps. Given an input image and several sparse flow guidance vectors, our framework seeks to recover the full-image motion.
In this paper we introduce a new neural network architecture designed to use in embedded vision applications.
In this paper, we propose a novel model named Oriented Objects Detection Network O^2-DNet to detect oriented objects by predicting a pair of middle lines inside each target.
We introduce a method for selecting task-specific and interpretable neurons for unsupervised transfer learning, which can lead to better performance.
Inverse problems in image and audio, and super-resolution in particular, can be seen as high-dimensional structured prediction problems, where the goal is to characterize the conditional distribution of a high-resolution output given its low-resolution corrupted observation.
We introduce a perception module as a set of mid-level visual representations and demonstrate that learning active tasks with mid- level features is significantly more sample-efficient than scratch.
We propose weakly supervised language localization networks (WSLLN) to detect events in long, untrimmed videos given language queries.
In this paper, we propose nearest prime simplicial complex approaches (NSC) by utilizing persistent homology to capture such structures without losing the structure representation.
We propose Deformable Kernels, a family of generic convolutional operators for handling object deformations by directly adapting the ERF while leaving the receptive field untouched.
This paper presents VERAM, a view-enhanced recurrent attention model capable of actively selecting a sequence of views for highly accurate 3D shape classification.
We propose a new hypothesis test that uses only the original test data to detect overfitting, and apply it to ImageNet benchmark.
Online learning to rank (OLTR) with list-level feedback, where the feedback is provided only at the level of an entire ranked list.
We introduce a Target Driven Instance Detector(TDID), which modifies existing general object detectors for the instance recognition setting, improving performance on instances seen during training.
We introduce an adversarial sample detection algorithm based on image residuals, specifically designed to guard against patch-based attacks, including in settings where the adversary has complete knowledge about the detection scheme.
We propose a new dimensionality-driven learning strategy, which monitors the dimensionality of subspaces during training and adapts the loss function accordingly.
We present an approach based on a deep neural network, leveraging shape datasets to learn a shape-aware prior for source-to-target alignment that is robust to shape incompleteness.
We introduce Lifting Autoencoders, a generative 3D surface-based model of object categories that learns a controllable, geometric model of 3D categories in an entirely unsupervised manner.
We propose a novel Siamese network architecture with layers specially designed to address the problem of re-identification, which speeds up pedestrian retrieval.
We propose the EmpGAN, a multi-resolution adversarial empathetic dialogue generation model to capture the nuances of user feelings sufficiently, which improves the state-of-the-art baseline baseline.
We introduce a new block that models correlations between channels of a 3D CNN with respect to temporal and spatial features. This new block can be added as a residual unit to different parts of3D CNNs.
We aim to super-resolve digital paintings, synthesizing realistic details from high-resolution reference painting materials for very large scaling factors with an efficient network structure and feature transferring.
This paper introduces a new model, the Forest Convolutional Network, that avoids all of these challenges, by taking a parse forest as input, rather than a single tree, and by allowing arbitrary branching factors.
The quantitative evaluation of optical flow algorithms by Barron et al. (1994) led to significant advances in performance. We propose a new set of benchmarks and evaluation methods for the next generation of Optical flow algorithms.
Crowd management is of paramount importance when it comes to preventing stampedes and saving lives, especially in a countries like China and India where the combined population is a third of the global population. We present a network for crowd counting which reports state of the art results.
We describe a representation of a scene that captures geometric and semantic attributes of objects within, along with their uncertainty.
We present the first comprehensive and most recent review of the methods on object pose recovery, from 3D bounding box detectors to full 6D pose estimators, for both 2D and 3D.
We describe the DeepMind Kinetics human action video dataset. The dataset contains 400 human action classes, with at least 400 video clips for each action.
WTC and PTC formulate the network inference task as non-smooth convex optimization problems and adopt coordinate proximal gradient descent to solve them.
We present a novel fully probabilistic method to interpret a single face image with the 3D Morphable Model. The new method is based on Bayesian inference and makes use of unreliable information.
Feature representation and metric learning are two critical components in person re-identification models. We propose a novel feature extraction model called Feature Fusion Net (FFN) for pedestrian image representation.
We propose a family of loss functions, fSimilarity Preservation Loss (f-SPL), based on the dual form of f-divergence for DML with soft labels.
Network clustering is a valuable approach for summarizing the structure in large networks, for predicting unobserved interactions, and for predicting functional annotations.
Pedestrian detection is one of the important computer vision problems in automotive safety and driver assistance domain. It is a major component of the advanced driver assistance system (ADAS) which help the driver to drive safely.
An Image-Enhanced Skip-Gram Model to learn grounded word embeddings by representing the word vectors in the same hyper-plane with image vectors.
We propose a simple and reliable method to estimate the size of an interactome, combining literature-curated data involving well-studied proteins with high-throughput data.ResultsWe examined the yeast interactome from a new perspective, by taking into account how thoroughly proteins have been studied.
Kernelized Multiview Projection can better fuse and embed different feature representations for action recognition using a novel spectral coding algorithm.
We first analyze five dialogue attributes to measure the dialogue complexity in multiple perspectives on three publicly available corpora. Then, we propose an adaptive multi-curricula learning framework, which automatically chooses different curricula at the evolving learning process according to the learning status of neural dialogue generation model.
This paper proposes a group recommendation model based on financial social networks and collaborative filtering algorithms. It not only considers the asset status and risk level of individual investors but also considers social relationships and risk levels among groups.
In this paper, we present PAStime, a novel approach to monitor and adapt the runtime progress of highly time-critical applications, to allow for improved service to lower criticality tasks.
In this paper, we propose a new metric for Machine Translation (MT) evaluation, based on bi-directional entailment, which uses deep learning to determine the semantic similarity between candidate and reference translation for generating scores.
We propose a novel cross modal retrieval system using a single stream network for bidirectional retrieval using extended center loss, minimizing distance of image and text descriptions in the latent space from the class centers.
We have extended an LSTM-based neural network designed for sequence tagging to additionally generate character-level sequences.
In this paper, we study tracking by language that localizes the target box sequence in a video based on a language query. We propose a framework called GTI that decomposes the problem into three sub-task: Grounding, Tracking and Integration.
In this work recent advances in conditional adversarial networks are investigated to develop an end-to-end architecture based on Convolutional Neural Networks (CNNs) to directly map realistic colours to an input greyscale image.
A Deep Belief Network (DBN) requires large, multiple hidden layers with high number of hidden units to learn good features from the raw pixels of large images. This implies more training time as well as computational complexity.
A meta- and network analysis on freely available transcriptome data in MSS and MSI-H colorectal cancer ::: from gene expression omnibus (GEO) database to detect common differentially expressed genes (DEGs) and critical ::: biological processes and predict their most significant regulators.
We propose end-to-end trainable composite Convolutional Long Short-Term Memory (Conv-LSTM) networks that are able to predict the evolution of a video sequence from a small number of input frames.
Improving information flow in deep networks helps to ease the training difficulties and utilize parameters more efficiently. Here we propose a new convolutional neural network architecture with alternately updated clique (CliqueNet)
We present a multimodal~(using audio and image features) architecture based on Convolutional Neural Networks for detecting inappropriate scenes in video files.
We combine the two-stage pipeline used in prior work (generic dependency parsing followed by simple post-processing) into one, enabling end-to-end training.
We break two prevailing Byzantine-tolerant techniques for synchronous SGD using new attack strategies based on inner product manipulation.
This paper describes our submitted solution, Hierarchical Context Enhanced Dialogue System (HCEDS), for the DSTC8-track1 challenge.
We present a data-free method for crafting adversarial perturbations that can fool a target model without any knowledge about the training data distribution.
Auto-ReID enables the automated approach to find an efficient and effective CNN architecture that is specifically suitable for the person re-IDentification task.
We propose a dual-exposure fusion framework for low-light image enhancement and introduce a new camera response model to synthesize multi-exposed images.
We propose a method for human pose estimation based on Deep Neural Networks (DNNs) which results in high precision pose estimates.
We propose a novel memory-based attention model for video description, which uses memories of past attention when reasoning about where to attend to in the current time step.
A novel template feature, named gait salient image (GSI) is introduced in this paper. The main contribution of GSI is encoding the motion energy of gait into a single template.
In this paper, we propose the F3Net to solve above problem, which mainly consists of cross feature module (CFM) and cascaded feedback decoder (CFD) trained by minimizing a new pixel position aware loss (PPA), which aims to selectively aggregate multi-level features.
Coupling the high-fidelity generation capabilities of label-conditional image synthesis methods with the flexibility of unconditional generative models, we propose a semantic bottleneck GAN model for unconditional synthesis of complex scenes.
In this paper, we study the problem of author identification in big scholarly data, which is to effectively rank potential authors for each anonymous paper by using historical data.
We propose a new FoveaNet model to fully exploit the perspective geometry of scene images and address the common failures of generic parsing models, which improves state-of-the-art performance.
The best summary of a long video differs among different people due to its highly subjective nature. In this paper, we introduce the task of generating customized video summaries through simple text.
We combine a deep network architecture with a 3D online reconstruction algorithm and propose a complete pipeline to simultaneously analyse the indoor scene from the geometric level and the semantic level.
We use an adversarial learning paradigm to unlearn the private information present in a representation and investigate the effect of varying the strength of the adversarial component on the primary task and on the privacy metric.
We propose an unsupervised learning approach to learn features from an unlabeled point cloud dataset by using part contrasting and object clustering with deep graph convolutional neural networks.
We propose a novel asymmetric supervised deep hashing method to preserve the semantic structure among different categories and generate the binary codes simultaneously.
A visually-grounded navigation instruction can be interpreted as a sequence of expected observations and actions an agent following the correct trajectory would encounter and perform. Based on this intuition, we formulate a new approach to instruction following that explicitly models a probability distribution over states, encoding strong geometric and algorithmic priors while enabling greater explainability.
Three experiments tested the hypothesis of implicit associative links of happiness with ease and sadness with difficulty, as posited by the implicit-affect-primes-effort model.
This paper introduces the space-time extended descriptor, a simple but efficient alternative way to include the spatio-temporal location into the video features.
We present a new generative model, Visual Object Networks (VON), synthesizing natural images of objects with a disentangled 3D representation.
Sketches and real-world user interface examples are frequently used in multiple stages of the user interface design process. This paper introduces Swire, a sketch-based neural-network-driven technique for retrieving user interfaces.
We propose to use the combination of a coarse salient object activation map from the classification network and saliency maps generated from unsupervised methods as pixel-level annotation, and develop a simple yet very effective algorithm to train fully convolutional networks for salient object detection supervised by these noisy annotations.
We propose an Attribute-Specific Embedding Network to jointly learn multiple attribute-specific embeddings in an end-to-end manner.
We propose CR-GAN, a two-pathway generative adversarial network that learns "incomplete" representations.
Cascade is a classic yet powerful architecture that has boosted performance on various tasks. In exploring a more effective approach, we find that the key to a successful instance segmentation cascade is to fully leverage the reciprocal relationship between detection and segmentation. In this work, we propose a new framework, Hybrid Task Cascade (HTC), which differs in two important aspects.
ScaleNet uses stacked convolution-deconvolution blocks and a multipath residual structure for multiscale feature extraction for image classification.
We extend adversarial patch attacks to optical flow networks and show that such attacks can compromise their performance.
We propose a dual reference face retrieval framework in this paper, where the identity and the age are reflected by two reference images respectively.
We investigate tracking-by-detection approaches based on a deep learning detector, joint integrated probabilistic data association (JIPDA), and appearance-based tracking of deep correspondence embeddings.
This paper makes two complementary contributions to event retrieval in large collections of videos. First, we propose hyper-pooling strategies that encode the frame descriptors into a stable representation of the video sequence in a stable manner, without sacrificing efficiency. Second, we introduce a technique to improve the ranking.
We propose a compact image captioning model that achieves comparable performance with state-of-the-art approaches on both MS-COCO and InstaPIC-1.1M datasets despite having an embedded vocabulary size that is 39×−99× smaller.
We present a novel evolutionary algorithm that automatically explores models with different types and combinations of layers to jointly learn interactions between spatial and temporal aspects of video representations.
In this paper we propose a technique to adapt a convolutional neural network (CNN) based object counter to additional visual domains and object types while still preserving the original counting function.
We propose the distributed fast supervised discrete hashing (DFSDH), which both inherits the excellent retrieval performance of SupDisH and gets significant enhancement in efficiency.
We propose a novel bidirectional learning framework for domain adaptation of segmentation of image segmentation.
This paper addresses the problem of generating meaningful summaries from unedited user videos. A framework based on spatiotemporal and high-level features is proposed in this paper to detect the key-shots.
This paper proposes a novel approach for computing the minimum distance for each test patch via the distance comparison within the test patch and cluster centers via the K-means algorithm.
A Kernel-Induced Label Propagation (Kernel-LP) framework for high-dimensional data classification using the most informative patterns of data in kernel space.
We propose an Inverse Reinforcement Learning system for human intent recognition along with the capability to handle high dimensional demonstrations exploiting object affordances.
We propose a novel method that makes the artery/vein (A/V) distinction in retinal color fundus images based on vascular network topological properties.
We propose to learn audio-visual object models from unlabeled video, then exploit the visual context to perform audio source separation in novel videos.
A computational model for retinal hemodynamics accounting for ocular curvature is presented. The model predictions show that changes in ocular shape induce non-uniform alterations of blood pressure and velocity in the retina.
We introduce Interactive Inference Network (IIN), a novel class of neural network architectures that is able to achieve high-level understanding of the sentence pair by hierarchically extracting semantic features from interaction space.
We propose a task-focused network model selection methodology which addresses several key challenges and uses minimum description length (MDL) criteria for selection.
This report investigates the ability of E2E ASR from standard close-talk to far-field applications by encompassing entire multichannel speech enhancement and ASR components within the S2S model.
We propose to use deep neural networks for image compression in the wavelet transform domain.
We propose a novel Recurrent Fusion Network for tackling image captioning. The fusion process in our model can exploit the interactions among the outputs of the image encoders and then generate new compact yet informative representations for the decoder.
In this paper, we propose an analysis mechanism-based structured analysis discriminative dictionary learning framework that seamlessly integrates ADDL, analysis representation, and analysis classifier training.
We study the robustness of a CNN+RNN based image captioning system being subjected to adversarial noises, even the targeted captions are totally irrelevant.
We present an efficient filter pruning framework that accelerates the network in one-step pruning-recovery manner with a novel optimization objective function, which achieves higher accuracy with much less cost compared with existing pruning methods.
Driving Scene Perception Network uses multi-level feature maps and multi-task learning to improve the accuracy and efficiency of object detection, depth estimation and image segmentation tasks from a single input image.
MNGS integrates multiview constrained nonnegative matrix factorization (NMF) and Gaussian mixture model-based spectral clustering for image retrieval.
We present an approach -- supplemental to fine tuning on the real robot -- to further benefit from parallel access to a simulator during training and reduce sample requirements on theReal robot.
This paper proposes a novel method that addresses the selection of the dominant patterns of the histograms of oriented gradients (DPHOGs) in vehicle detection.
This paper presents a new deep-learning based method to simultaneously calibrate the intrinsic parameters of fisheye lens and rectify the distorted images.
We describe a neural network-based system for text-to-speech (TTS) synthesis that is able to generate speech audio in the voice of many different speakers, including those unseen during training.
We propose a novel GAN architecture that can be applied to existing latent vector based GAN structures that allows them to generate on-the-fly images of any size without any resizing.
A modular lightweight network model for road objects detection, such as car, pedestrian and cyclist, especially when they are far away from camera and their sizes are small.
We present an interpretable, controller-based Self-Assembling Neural Modular Network for multi-hop reasoning, where we design novel modules (Find, Relocate, Compare, NoOp) to perform unique types of language reasoning.
In this paper, we propose two orthogonal approaches to reduce the memory cost from the system perspective. Our approaches are transparent to the models, and thus do not affect the model accuracy.
In this paper, Descriptive Visual Words (DVWs and DVPs) are proposed as the visual correspondences to text words and phrases, where visual phrases refer to the frequently co-occurring visual word pairs.
We revisit the problem of purely unsupervised image segmentation and propose a novel deep architecture for this problem. We borrow recent ideas from supervised semantic segmentation methods.
We show that adversarial vulnerability increases with the gradients of the training objective when seen as a function of the inputs. Over the course of our analysis we rediscover and generalize double-backpropagation.
We review the topic of automatic detection of human behaviors from video, covering a selection of 193 papers that were searched from six major scientific publishers from 2000 to 2014.
We propose a deep learning approach aimed at joint semantic segmentation and depth estimation. At training time, our network learns a common feature representation for both tasks and a novel cross-task loss function.
We propose to use a weaker supervision signal provided by the ordinal depths of human joints for 3D human pose estimation from single images, achieving state-of-the-art performance.
We propose a privacy-adversarial framework to eliminate such leakage of private information, and study the trade-off between recommender performance and leakage.
This paper proposes a query expansion technique for image search that is faster and more precise than the existing ones.
We propose a positiveness-focused object detector (PFOD) to progressively propagate the incomplete labels before applying the general object detection algorithm.
This paper introduces a new architecture for human pose estimation using a multi- layer convolutional network architecture and a modified learning technique that learns low-level features and higher-level weak spatial models.
In this paper, we develop a novel 3D CNN model for action recognition in surveillance videos.
We propose a novel idea on video architecture learning - Tiny Video Networks - which automatically designs highly efficient models for video understanding.
This paper describes TasselNetv2 for counting wheat spikes, which simultaneously addresses two important use cases in plant counting: improving the counting accuracy without increasing model capacity, and improving efficiency without sacrificing accuracy.
We propose an accurate and real-time anomaly detection and localization in crowded scenes, and two descriptors for representing anomalous behavior in video.
This paper presents a Deep convolutional network model for Identity-Aware Transfer (DIAT) of facial attributes.
A 3D structure-based pharmacophore model of the enzyme glyoxalase-1 (Glo-1) has been revealed that has a selective feature for a “zinc binding group”.
We present an autoencoder that leverages learned representations to better measure similarities in data space. We apply our method to images of faces.
This paper presents a novel framework for learning a generative image representation-the hybrid image template (HIT) from a small number of image examples.
This paper introduces a novel deep learning-based approach to provide a plausible ordering to images that have been generated from a single image through transformations, which addresses Image Provenance Analysis.
We present a conceptually simple, computationally efficient, and more precise action tubelet detection framework, termed as MovingCenter Detector (MOC-detector), by treating an action instance as a trajectory of moving points.
In this paper, we make the first attempt to build a framework to simultaneously estimate semantic parts, shape, translation, and orientation of cars from single street view. Our framework contains three major contributions.
This paper proposes a novel unsupervised generative adversarial network system for visual depth and ego-motion estimation.
In this paper, we propose a novel Orthogonal Center Learning method with Subspace Masking for person re-identification.
We propose Reweighted Proximal Pruning (RPP), a new pruning method specifically designed for a large-scale language representation model. RPP provides a new perspective to help us analyze what large-Scale language representation might learn.
Meta-Learning Algorithms for Few-Shot Computer Vision .
In this paper, we introduce RARD, the Related-Article Recommendation Dataset, from the digital library Sowiport and the recommendation-as-a-service provider Mr. DLib.
Multilingual neural translation models learn stronger semantic abstractions of sentences than bilingual ones. We test this hypotheses by measuring the perplexity of such models when applied to paraphrases of the source language.
We describe Biperpedia, an ontology with 1.6M (class, attribute) pairs and 67K distinct attribute names, which can increase the number of Web tables whose semantics we can recover by 4 compared with Freebase.
We formulate a real-world human action recognition task as a multi-label zero-shot learning problem and propose a framework to tackle this problem in a holistic way.
The paper focuses on utilizing the FCNN-based dense semantic predictions in the bottom-up image segmentation, arguing to take semantic cues from the very beginning.
Unsupervised monocular depth estimation based on residual neural network of coarse–refined feature extractions for drone using a deep residual convolution neural network.
Reprojection R-CNN is a novel two-stage object detector for omnidirectional 360° images.
We propose a novel self-supervised learning assisted pulmonary nodule detection framework based on a 3D Feature Pyramid Network (3DFPN) which achieves 90.6% sensitivity with 1/8 false positive per scan which outperforms state-of-the-art results 15.8% on LUNA16 dataset.
We propose a structured deep model for automatic activity recognition from RGB-D videos. We represent each human activity as an ensemble of cubic-like video segments, and learn to discover the temporal structures for a category of activities.
We present a new low-drift SLAM algorithm based only on 3D LiDAR data. Our method relies on a scan-to-model matching framework.
This paper makes an early attempt in studying the influence of pedestrian rotation angle on person re-identification (re-ID) accuracy.
In musicology and music research generally, the increasing availability of digital music, storage capacities, and computing power enable and require new and intelligent systems. In the Digital Music Lab (DML) project, a collaboration among music librarians, musicologists, computer scientists, and human-computer interface specialists, a software system has been developed that fills this gap by providing intelligent large-scale music analysis with a user-friendly interactive interface.
We construct the first fine-grained video attractiveness dataset from one of the most popular video websites in the world.
Neural attention mechanism has achieved many successes in various tasks in natural language processing. Motivated by the finding in neuroscience that human possesses the template-searching attention mechanism, we propose to use convolution operation to simulate attentions and give a mathematical explanation of our neural attention model.
We propose an accurate and real-time video system for future Internet of Things (IoT) and smart cities applications.
This paper evaluates three Transformer-based models (RoBERTa, XLNet, and BERT) in Natural Language Inference and Question Answering tasks to know if they are more robust or if they have the same flaws as their predecessors.
We propose a novel method that separately leverages synthetic RGB and synthetic depth for unseen object instance segmentation, outperforming state-of-the-art methods on the task.
This paper proposes a two-branch convolution residual network for image compressive sensing.
We leverage this visual-textual connection to learn effective spatiotemporal features in an efficient weakly-supervised manner, yielding state-of-the-art results for zero-shot action recognition.
In this paper, we study the problem of multi-view sketch correspondence, where we take as input multiple freehand sketches with different views of the same object and predict semantic correspondence among the sketches.
This paper proposes MLModelScope, an open-source, framework/hardware agnostic, extensible and customizable design that enables repeatable, fair, and scalable model evaluation and benchmarking.
We propose a semi-supervised generative latent variable model that addresses both of these levels by modeling continuous observations as well as semantic labels.
Audio tagging aims to infer descriptive labels from audio clips and it is challenging due to the limited size of data and noisy labels. The solution to the tagging task is described in this paper.
We propose a graph kernel for complex and continuous node attributes, whose features are tree structures extracted from specific graph visits. We further present an approximated variant of the kernel, which reduces its complexity significantly.
We propose and discuss two different approaches for evaluating the goodness of scale-selection with spatial regularization.
We present an automated evaluation method to measure fluidity in conversational dialogue systems.
We introduce HUBERT which combines the structured-representational power of Tensor-Product Representations (TPRs) and BERT, a pre-trained bidirectional Transformer language model for better transfer among NLP tasks.
This paper focuses on the construction of stronger local features and the effective fusion of image and LiDAR data. We present an adaptive and azimuth-aware network to aggregate local features from image, bird's eye view maps and point cloud.
Using BERT language model for answer-selection of questions and answers .
This paper extends the popular task of multi-Object tracking to multi-object tracking and segmentation (MOTS) using a semi-automatic annotation procedure and a new baseline method.
In this paper we propose new machine learning techniques to annotate table cells with entities that they likely mention, table columns with types from which entities are drawn for cells in the column, and relations that pairs of table columns seek to express.
We propose a novel dynamic translation principle which supports flexible translation between the embeddings of entities and relations in knowledge graphs.
We explore the effect of JPEG compression under novel Q-tables, which can improve the compression rate by 10% to 200% when the accuracy is fixed, or improve accuracy up to $2%$ at the same compression rate.
In recent years, deep neural networks demonstrated state-of-the-art performance in a large variety of tasks and therefore have been adopted in many applications. On the other hand, the latest studies revealed that neural networks are vulnerable to adversarial examples obtained by carefully adding small perturbation to legitimate samples. In this work, we propose to leverage the information of gradients as a guidance during the search of adversaries.
We propose a robust object tracking framework based on Unified Graph Fusion (UGF) of multi-cue to adapt to the target's appearance variations.
We propose a convolutional neural network that jointly computes the viewpoint and keypoints for different object categories, improving the accuracy of both tasks.
We develop a mathematical model of sparse signal recovery that is consistent with CNNs with random weights. We show empirically that several learned networks are consistent.
This paper proposes a Universal Variational Aging (UVA) framework to formulate facial age priors in a disentangling manner in a universal framework.
We propose a novel graph node embedding method (namely GESF) via the set function technique, which can learn an arbitrary form of representation function from neighborhood and automatically decide the significance of neighbors at different distances.
We build a cross-lingual state tracking framework that uses a state tracker for the source language as a teacher and exploit easy-to-access parallel data to transfer its knowledge to the target language.
We propose two anatomically inspired loss functions and use them with a weakly-supervised learning framework to jointly learn from large-scale in-the-wild 2D and indoor/synthetic 3D data.
We propose a new point-based framework, namely PointINS, to segment instances from single points.
We propose a novel method to segment blood vessels and optic disk in fundus retinal images in a nonintrusive manner.
We propose Force Regularization, which uses attractive forces to enforce filters so as to coordinate more weight information into lower-rank space for faster DNNs.
This paper proposes Self-Imitation Learning (SIL), a simple off-policy actor-critic algorithm that learns to reproduce the agent's past good decisions.
We propose a new, subjective task of quantifying perceived face similarity between a pair of faces, given that they are not of the same person, and introduce the Lookalike network, directed towards similar face classification.
We propose Flexible Iterative Modularization Algorithm (FIMA), a generic and provable paradigm for nonconvex inverse problems.
We propose an end-to-end semi-supervised unconstrained AU detection framework by exploiting accurate labels of AU-related facial landmarks, which soundly outperforms the state-of-the-art approaches on the challenging BP4D, GFT and EmotioNet benchmarks.
We propose to automatically design SFs for distinct KGs by the AutoML techniques, which are KG dependent and perform better than state-of-the-art SFs designed by humans.
We propose a novel text-alignment layer that allows it to precisely compute convolutional features of a text instance in ar- bitrary orientation, which is the key to boost the per- formance.
This paper presents a new adaptive graph-cut based move-making algorithm for energy minimization using the primal-dual interpretation of the Expansion-move algorithm.
This paper introduces a new deep learning architecture, called BottleNet, for reducing the feature size needed to be sent to the cloud with negligible accuracy loss.
We utilize Similarity Ratio as an indicator for the generalization performance of a few-shot model. We then formulate the base class selection problem as a submodular optimization problem over Similarity ratio.
We propose an audio-visual fusion strategy that learns to automatically align the two modalities, leading to enhanced representations which increase the recognition accuracy in both clean and noisy conditions.
We present a deep mutual learning (DML) strategy to transfer knowledge from a teacher to a student network.
This study investigates the use of non-linear unsupervised dimensionality reduction techniques to compress a music dataset into a low-dimensional representation, and its use for the synthesis of new sounds.
Feature extraction is a very crucial task in image and pixel (voxel) classification and regression in biomedical image modelling. In this work we present a multi-scale and multi-layer feature extraction scheme based on inception models for pixel classification tasks.
We demonstrate that state of the art neural networks for CIFAR-10 trained models make confident predictions even when 95% of an input image has been masked and humans are unable to discern salient features in the remaining pixel subset.
This paper presents a novel method for extracting the vocal track from a musical mixture using a convolutional network with skip and residual connections as well as dilated convolutions.
In this paper, we propose a novel dense descriptor, called dense adaptive self-correlation (DASC), to estimate dense multi-modal and multi-spectral correspondences.
We address the problem of indoor scene understanding from RGB-D images using a deep, wide, multi-output convolutional neural network that predicts class, pose, and location of possible objects simultaneously.
In this paper, based on the powerful spatial feature extraction capability of the convolutional neural network, a novel two-channel deep hiding network is designed by introducing advanced ideas such as skip connection, feature fusion, etc., and the two channels are respectively used to input the cover image and the secret image simultaneously.
An intuitive way for a human to write paraphrase sentences is to replace words or phrases in the original sentence with their corresponding synonyms and make necessary changes to ensure the new sentences are fluent and grammatically correct. We propose a novel approach to modeling the process with dictionary-guided editing networks which effectively conduct rewriting on the source sentence to generate paraphrase sentence.
This work describes a fast method for computing dense stereo correspondences that is capable of generating results close to the state-of-the-art.
We investigate the effects of some training techniques, mini-batching and learning rate decay, on the generalization performance of SVRG, and verify the generalized performance of Batch-SVRG.
We show that incorporating dense correspondence into in-the-wild 3D human recovery from single images is promising and competitive due to its high efficiency and relatively low annotating cost.
We address zero-shot recognition in contemporary video action recognition tasks, using semantic word vector space as the common space to embed videos and category labels.
Deep learning for diagnosis of diabetic retinopathy (DR) from retinal images .
In this paper, we introduce Deep Probabilistic Ensembles (DPEs), a scalable technique that uses a regularized ensemble to approximate a deep Bayesian Neural Network (BNN)
The task of facial landmark extraction is fundamental in several applications, such as facial expression analysis, identity and face recognition, facial animation, and 3D face reconstruction.
We show that relation extraction can be reduced to answering simple reading comprehension questions, by associating one or more natural-language questions with each relation slot.
We propose a semantic-aware task-specific label placement method for AR used in street view scenarios.
This paper presents a retinal vessel segmentation algorithm which uses a texton dictionary to classify vessel/non-vessel pixels using a Gabor filter bank.
We focus on improving the last layers of the network, where changes have low impact in terms of computational cost, and achieve state-of-the-art performance.
We propose a novel Structured Pose Representation (SPR) that can directly predict structured poses for multiple persons in a single stage, and thus offer a more compact pipeline and attractive efficiency advantage over two-stage methods.
We present a joint multi-task framework, termed IvaNet, for object detection and semantic segmentation using local top-down modules.
The IEEE Low-Power Image Recognition Challenge (LPIRC) is an annual competition started in 2015 that encourages joint hardware and software solutions for computer vision systems with low latency and power.
In this paper, we perform the first, to the best of our knowledge, thorough evaluation of state-of-the-art deformable face tracking pipelines using the recently introduced 300 VW benchmark.
This paper presents a novel method for structural data recognition using a large number of graph models as well as their ability to capture structural variation.
In this paper, we design a Collaborative-Hierarchical Sparse and Low-Rank (C-HiSLR) model that is natural for recognizing human emotion in visual data.
We augment language model pre-training with a latent knowledge retriever, which allows the model to retrieve and attend over documents from a large corpus such as Wikipedia, used during pre- training, fine-tuning and inference.
We propose a novel learning method for deep sound recognition by learning a discriminative feature space by recognizing the between-class sounds as between- class sounds.
We present an automatic annotation pipeline to recover 9D cuboids and 3D shapes from pre-trained off-the-shelf 2D detectors and sparse LIDAR data.
We propose an attention-based context aggregation network (ACAN) for monocular depth estimation.
We propose a new layer in CNNs to increase their robustness to several types of noise perturbations of the input images, while maintaining state-of-the-art performance.
In this paper, we propose a novel annotation enrichment strategy, which expands existing coarse annotations of training data to a finer scale for semantic segmentation learning.
We propose a novel Incremental Residual Learning (IRL) framework to address these mentioned issues and set a new state of the art for SR.
We propose a detection method that utilizes depth information to estimate the size of anchors for detecting multiple sizes of objects.
We propose a new type of GNN called Graph Sequential Network (GSN), which features a new message passing algorithm based on co-attention between a node and each of its neighbors.
A recommendation system provides personalized recommendations on products and services to users. However, it is a challenge to find an accurate and effective method that can predict the user interest drift in the class and more accurately predict an item’s rating.
We propose two frameworks(i.e.,pipeline framework,an end-to-end framework)to focus answering single-relation factoid question.
We adapt a contemporary automotive dataset, via style and projection transformations, to facilitate the cross-domain retraining of contemporary algorithms for panoramic imagery. Following this approach we retrain and adapt existing architectures to recover scene depth and 3D pose of vehicles from monocular panorama imagery without any panorama training labels or calibration parameters.
We embed this principle in a novel image descriptor, dubbed Heterogeneous Auto-Similarities of Characteristics (HASC), encoding linear relations by co variances and nonlinear associations through information-theoretic measures such as mutual information and entropy.
This paper proposes an image segmentation general framework using complex networks based community detection algorithms, which increases the segmentation performances compared to some existing methods.
Time-aware Large Kernel Convolutions, a novel adaptive convolution operation that learns to predict the size of a summation kernel instead of using the fixed-sized kernel matrix.
In this paper, we innovatively propose a general dynamic inference idea to improve inference efficiency by leveraging the variation in the distinguishability of different videos.
We propose a new method that firstly generates generic action region proposals with good potential to locate one human action in unconstrained videos regardless of camera motion and then uses action proposals to extract and classify effective shape and motion features by a ConvNet framework.
We propose a method where we discover these features required for the separation of the images using deep autoencoder and use them for clustering.
We propose a novel deep generative model, named Wasserstein-Wasserstein auto-encoders, that learns better latent structures than VAEs and generates samples of better visual quality and higher FID scores.
We introduce a novel class of CNNs that exploit second-order statistics, which outperform the first-order CNNs, while relying on up to 90% fewer parameters.
We propose an active learning-based strategy, called CEREALS, in which a human only has to hand-label a few regions within an unlabeled image corpus. This minimizes human annotation effort while maximizing the performance of a semantic image segmentation method.
We propose a variation of cross-entropy loss which depends not only on the sample class but also on a data-driven prior "class-similarity distribution" across the classes encoded in a matrix form.
We propose a pipeline to perform sign language recognition which models hand movements in the context of other parts of the body captured in the 3D space using the MS Kinect sensor.
Sparse Spectral Clustering with Sparse Regularization on Low-dimensional Embeddings .
In this paper we use weak estimates of local similarities and propose a single optimization problem to extract batches of samples with mutually consistent relations.
We address this challenge by combining Convolutional Neural Networks (CNNs) and a state of the art dense Simultaneous Localisation and Mapping (SLAM) system, ElasticFusion, which provides long-term dense correspondence between frames of indoor RGB-D video even during loopy scanning trajectories.
Stereo matching is a difficult and challenging task due to many uncontrollable factors that affect the results. A stereo matching algorithm including cost computation, cost aggregation, disparity computation, and disparity refinement is proposed to overcome these limitations.
This paper presents a method of estimating the geometry of a room and the 3D pose of objects from a single 360-degree panorama image.
We train scene graph embeddings in a layout generation task with different forms of supervision, specifically introducing triplet super-vision and data augmentation, which significantly improves the embedding separability.
We propose a new class-level segmentation network which extracts the global context from a categorical perspective and use it for state-of-the-art performance.
In this paper, we propose an algorithm for estimating the absolute pose of a vehicle using visual data, then localizing the vehicle using this map.
We propose to explicitly address the view-specific bias problem by learning an unsupervised asymmetric distance metric based on cross-view clustering. We then design a novel loss function to embed the asymmetric metric into a deep neural network, and therefore develop a novel un Supervised deep framework named the DEep Clustering-based Asymmetric MEtric Learning (DECAMEL)
In this paper, we propose FedGP, a framework for privacy-preserving data release in the federated learning setting.
SemFlow is a semantic-guided interpolation scheme to handle motion boundaries and occlusions in large displacement optical flow.
We present efficient differentiable implementations of second-order multi-hop reasoning using a large symbolic knowledge base (KB) and evaluate a number of alternative implementations with different time and memory trade offs.
We propose a new L1 norm plane clustering method, termed as $\text{L}1k$ PC, which is more robust to outliers.
We introduce an approach to performing depth super-resolution in more challenging conditions, such as in outdoor scenes, using semantic information to better constrain the super- resolution process.
We propose a two-stage detector based on Faster R-CNN for high occluded vehicle detection, in which we integrate a part-aware region proposal network to sense global and local visual knowledge among different vehicle attributes.
In this paper we introduce Curriculum GANs, a curriculum learning strategy for training Generative Adversarial Networks that increases the strength of the discriminator over the course of training, thereby making the learning task progressively more difficult for the generator.
Constructing interspecies interaction networks for iron and glucose competition in C. albicans and zebrafish during infection and quantifying robustness of these networks.
We propose a novel robust stereo algorithm for weakly-textured scenes. The algorithm is applied to several real stereo images and its performance is evaluated quantitatively.
We extend a re-parameterization technique that learns hyperbolic embeddings of arbitrary parameterized objects from text corpora, and we apply this framework to unsupervised learning of hierarchical data.
In generative modeling, the Wasserstein distance (WD) has emerged as a useful metric to measure the discrepancy between generated and real data distributions. In this paper, we introduce novel approximations of the primal and dual SWD.
A hybrid approach to generate recommendations focusing on long tail items, and then to conduct the user to less popular items in a hybrid way.
We aimed to assess the ability of deep learning (DL) and support vector machine (SVM) to detect a nonperfusion area (NPA) caused by retinal vein occlusion (RVO) with OCTA images.
We develop heuristic rules for annotating a subset of questions, so that the annotation cost is reduced while maintaining both in- and out-of-domain performance.
Wavelet CNNs allow us to utilize spectral information which is lost in conventional CNNs but useful in texture classification.
CoCoPIE is a real-time AI optimization framework that supports all main kinds of DNNs, up to 180X faster compared with current DNN pruning and acceleration frameworks such as TensorFlow-Lite.
We address the problem of person re-identification (reID), that is, retrieving person images from a large dataset, given a query image of the person of interest. A key challenge is to learn person representations robust to intra-class variations, as different persons can have the same attribute and the same person's appearance looks different.
We propose a probabilistic model for semi-automated segmentation of stacks of histological sections, in which the user manually labels a sparse set of sections (e.g., one every n), and the algorithm complete the segmentation for other sections automatically.
We created a probabilistic metric that takes advantage of the high density of these data, including both the presence and absence of individual associations, to provide a measure of the relative confidence of each potential protein-protein interaction.
We consider the problem of approximate $K$-means clustering with outliers and side information provided by same-cluster queries and possibly noisy answers. We extend this settings to the case where some queries to the oracle produce erroneous information, and where certain points do not belong to any clusters.
This paper focuses on the unsupervised domain adaptation of transferring the knowledge from the source domain to the target domain in the context of semantic segmentation.
We propose a new framework for precise segmenting retinal vasculatures, which addresses challenges presented by intensity inhomogeneities, and the relatively low contrast of thin vessels compared to the background.
This paper proposes a novel method for stereo matching which is based on image features to produce a dense disparity map through two different expansion phases.
We propose a novel tracking architecture which can utilize scene information for tracking, achieving state-of-the-art performance.
In this paper, a novel multi-category rotation detector is proposed, which can efficiently detect small objects, arbitrary direction objects, and dense objects in complex remote sensing images.
The recent development of data-driven AI promises to automate medical diagnosis; however, most AI functions as 'black boxes' to physicians with limited computational knowledge. Using medical imaging as a point of departure, we conducted three iterations of design activities to formulate CheXplain---a system that enables physicians to explore and understand AI-enabled chest X-ray analysis.
A popular recent approach to answering open-domain questions is to first search for question-related passages and then apply reading comprehension models to extract answers. We propose two models which make use of multiple passages to generate their answers.
Learning from triplet comparison data has been extensively studied in the context of metric learning, where we want to learn a distance metric between two instances, and ordinal embedding.
The goal of multi-modal learning is to use complimentary information on the relevant task provided by the multiple modalities to achieve reliable and robust performance in the presence of imperfect modalities.
We propose a simple and effective framework to learn and prune deep models in an end-to-end manner. We evaluate our method, Sparse Structure Selection.
We propose a video-based person re-identification system for wide area tracking based on a recurrent neural network architecture.
We derive the form of transformation matrix theoretically and present an arbitrary style transfer approach that learns the transformation matrix with a feed-forward network. Our algorithm is highly efficient while preserving content affinity during style transfer process.
Our QA system KBQA effectively supports binary factoid questions, as well as complex questions which are composed of a series of binary factoids questions.
We propose a novel Co-Attentive Sharing (CAS) module which extracts discriminative channels and spatial regions for more effective feature sharing in multi-task learning.
We investigate the behavior of deep neural networks on training sets with massively noisy labels, and show that successful learning is possible even with an essentially arbitrary amount of noise.
A novel method for the automatic construction of person-specific Facial Deformable Models (PSMs), which can be used for behavioural analysis and motion capture.
We propose a novel fluency boost learning and inference mechanism for grammatical error correction, achieving state-of-the-art performance on CoNLL-2014 10 and JFLEG.
We use Variational Autoencoders (VAEs) for speech emotion recognition tasks.
We introduce associative embedding, a novel method for supervising convolutional neural networks for the task of detection and grouping.
In this paper, we develop a principle upon which auto-encoders can be combined with generative adversarial networks by exploiting the hierarchical structure of the generative model.
In this paper, we propose a sensor fusion framework to fuse local states with global sensors, which achieves locally accurate and globally drift-free pose estimation.
We introduce a semantics-aware distance map for amodal segmentation instead of masks and heatmaps, and introduce a novel convolutional neural network architecture to estimate sem-dist maps layer by layer.
In this paper, we outline an interleaved acting and planning technique to rapidly reduce the uncertainty of the estimated robot's pose by perceiving relevant information from the environment, as recognizing an object or asking someone for a direction.
We propose an alternative to clipping weights: penalize the norm of gradient of the critic with respect to its input, enabling stable training of GANs.
We propose an Attention based Back Projection Network for image super-resolution.
We develop an interactive object segmentation system which uses user input in the form of clicks as the input to a convolutional network. During training, we iteratively add clicks based the errors of the currently predicted segmentation.
We introduce a method to provide vectorial representations of visual classification tasks which can be used to reason about the nature of those tasks and their relations.
Data augmentation methods are often applied to prevent overfitting and improve generalization of deep neural network models. We propose a novel data augmentation method called conditional BERT contextual augmentation.
In this paper, we propose a face recognition algorithm based on a combination of vector quantization (VQ) and Markov stationary features (MSF) to extend the VQ histogram-based features so as to add spatial structural information.
We undertook a global and systematic approach to build and integrate available data in gene networks associated with ASDs, XLID, ADHD and SZ to help understand the unique and common genetic drivers of these conditions.
We present a self-supervised deep pose correction network that applies pose corrections to a visual odometry estimator to improve its accuracy.
We propose a joint label prediction based Robust Semi-Supervised Adaptive Concept Factorization (RS2ACF) framework.
Sketch-based image retrieval (SBIR) using semantic-Aware Knowledge prEservation (SAKE), which fine-tunes the pre-trained model in an economical way and leverages semantic information, e.g., rich discriminative features learned from ImageNet, to improve the model's transfer ability.
Material information can be utilized to boost object tracking from three aspects: dataset, material feature representation and material based tracking.
We propose a novel Cascade Feature Aggregation (CFA) method, which cascades several hourglass networks for robust human pose estimation.
This paper describes AutoFocus, an efficient multi-scale inference algorithm for deep-learning based object detectors which only processes regions which are likely to contain small objects at finer scales.
In this paper we present a deep learning architecture for extracting word embeddings for visual speech recognition.
We present in this paper a novel learning-based approach for video sequence classiﬁcation that automatically learns a sparse shift-invariant representation of the local 2D+t salient information, without any use of prior knowledge.
An effective approach to transcribe old text documents is to follow an interactive-predictive paradigm in which both, the system is guided by the human supervisor in locating possible system errors and deciding how to proceed.
We use convolutional neural networks to predict aesthetic, sentiment, and memorability scores of artworks based on subjective evaluation of the image and explore their distribution in the context of art history.
We develop a theoretical framework for task-specific privacy under the attack of attribute inference, and propose a practical algorithm to protect a given attribute and preserve utility.
Do GANS (Generative Adversarial Nets) actually learn the target distribution? The foundational paper of (Goodfellow 2014) suggested they do, if they were given sufficiently large deep nets, sample size, and computation time.
We propose a method to learn goal-oriented tasks without requiring any prior knowledge other than obtaining a single state in which the task is achieved.
We advance to keep the content information of the input image during the process of style transfer by the power of steganography, with two approaches proposed: a two-stage model and an end-to-end model.
We propose REMIND, a tensor quantization approach that enables efficient replay with tensors for incrementally updated robotic agents.
We propose a Person Transfer Generative Adversarial Network (PTGAN) to bridge the domain gap for person Re-Identification.
We propose a novel fusion-aware 3D point convolution which operates directly on the geometric surface being reconstructed and exploits effectively the inter-frame correlation for high quality 3D feature learning.
A fundamental question in learning to classify 3D shapes is how to treat the data in a way that would allow us to construct efficient and accurate geometric processing and analysis procedures. Here, we restrict ourselves to networks that operate on point clouds.
A neural network deployed in the wild may be asked to make predictions for inputs that were drawn from a different distribution than that of the training data. Generative models are robust to such mistaken confidence as modeling the density of the input features can be used to detect novel, out-of-distribution inputs.
We propose a new two-stage framework to effectively select the appropriate proposal candidate for each object. The first stage suppresses most of easy negative object proposals, while the second stage selects true positives.
We present a novel neural-based architecture that is capable of extracting relevant regions based on a given question-document pair and generating a well-formed answer.
Coherence constraints can improve the quality of the expression recognizer, thus offering a suitable basis to profitably exploit unsupervised video data, where only a few frames are supervised.
This paper presents a generic classification framework for large-scale face recognition systems. The framework can effectively manage large amounts of training data, without regard to feature types, to efficiently train classifiers with high recognition accuracy compared to alternative techniques.
We propose an optimal bit allocation method for extracting binary strings from real-valued templates with maximized overall detection rate.
We introduce ReConvNet, a recurrent convolutional architecture for semi-supervised video object segmentation that is able to fast adapt its features to focus on any specific object of interest at inference time.
We propose a new approach that, given a large number of images of an object and no other supervision, can extract a dense object-centric coordinate frame. This coordinate frame is invariant to deformations of the images and comes with a dense equivariant labelling neural network.
In this paper, we develop a new model for high rank matrix completion, together with batch and online methods to fit the model and out-of-sample extension to complete new data.
We present an output-guided attention module built with multi-scale outputs to overcome the problem of `blind overconfidence' in salient object detection.
Multi-Scale Context-Aware Network to learn powerful features over full body and body parts for person ReID.
We propose a novel multi-stream architecture and training methodology that exploits semantic labels for facial image deblurring.
In this paper, a computation-efficient convolutional module, named SdcBlock, is proposed and based on it, the convolution network SdcNet is introduced for object recognition tasks.
We propose Spatio-TEmporal Progressive (STEP) action detector, a progressive learning framework for spatio-temporal action detection in videos.
This research proposes a novel Dynamic Convolutional Neural Network (DCNN) to improve meaning accuracy of product review on a collaborative filtering recommender system.
We present a method to generate universal 3D adversarial objects to fool LiDAR detectors.
We explore methods for representing the semantic information embedded in the state, and propose to represent the state using natural language.
We propose a novel controllable text-to-image generative adversarial network (ControlGAN), which can effectively synthesise high-quality images and also control parts of the image generation according to natural language descriptions.
We integrate the above two strategies in a unified framework, which consists of Visual Representation Enhancement (VRE) module and Motion Representation Augmentation (MRA) module.
We use the Correlation Filter learner as a differentiable layer in a deep neural network, enabling lightweight architectures to achieve state-of-the-art performance at high framerates.
We propose a new weighting mechanism-based first-order gradient-based optimization algorithm, namely NWM-Adam, to resolve the undesirable convergence behavior of some optimization algorithms which employ fixed sized window of past gradients to scale the gradient updates and improve the performance of Adam and AMSGrad.
The Shape Interaction Matrix (SIM) is one of the earliest approaches to performing subspace clustering (i.e., separating points drawn from a union of subspaces). In this paper, we revisit the SIM and reveal its connections to several recent sub space clustering methods. Our analysis lets us derive a simple, yet effective algorithm to robustify the SIM.
In recent years, the widespread use of deep neural networks (DNNs) has facilitated great improvements in performance for computer vision tasks like image classification and object recognition. In most realistic computer vision applications, an input image undergoes some form of image distortion such as blur and additive noise during image acquisition or transmission. Deep networks trained on pristine images perform poorly when tested on such distortions.
This work proposes an integral regression approach that unifies the heat map representation and joint regression, thus possessing the merits of both paradigms.
In this article, we propose a distributed and collaborative monocular simultaneous localization and mapping system for the multi-robot system in large-scale environments.
We propose KGE bi-vector models, which represent the symmetric relations as vector pair, significantly increasing the processing capability of the symmetry relations.
We propose a method to predict an entire `action tube' (a set of temporally linked bounding boxes) in a trimmed video just by observing a smaller subset of it.
We proposed GPVAD, a weakly supervised voice activity detection framework that can be easily trained from noisy data in aWeakly supervised fashion, requiring only clip-level labels.
We develop a general theoretical calibration evaluation framework grounded in probability theory, and point out subtleties present in model calibration evaluation that lead to refined interpretations of existing evaluation techniques.
Fine-tuning BERT language models on WSC273 and WNLI improves state-of-the-art results on both datasets.
We show that the standard memory-based collaborative filtering rating prediction algorithm using the Pearson correlation can be improved by adapting user ratings using linear regression.
We propose a general applicable transformation unit for visual recognition with deep convolutional neural networks. This transformation explicitly models channel relationships with explainable control variables.
We propose an auto-encoder architecture that can both encode and decode clouds of arbitrary size and demonstrate its effectiveness at upsampling sparse point clouds.
We propose a general and novel framework RIS-GAN which explores residual and illumination with Generative Adversarial Networks for shadow removal.
Our goal is to deploy a high-accuracy system starting with zero training examples, where as inputs arrive, we use real-time crowd-sourcing to resolve uncertainty where needed and output our prediction when confident.
A recently introduced latent feature learning technique for time varying dynamic phenomena analysis is the so called Slow Feature Analysis (SFA).
We propose a novel deep learning architecture, a Cross-Form Pyramid stereo matching network for regressing disparity from a rectified pair of stereo images.
We present a new neural architecture for multi-view sequential learning called the Memory Fusion Network that explicitly accounts for both interactions in a neural architecture and continuously models them through time.
This paper proposes an intuitive approach to facial age classification on child faces - a recursive multi- class binary classification tree using the texture information obtained from facial images.
Generative Autodidactic Models for 3D Medical Image Analysis .
We look at the SAN, RelNet, FiLM and MC models and evaluate their learning behavior on diagnostic data which is solely focused on spatial relations.
We propose a strategy for semi-supervised image classification that leverages unsupervised representation learning and co-training.
We propose a two-stream network that learns a part-aligned representation for person re-identification, which significantly reduces the part misalignment problem.
We present a system for the semi-automatic removal of objects from videos with complex backgrounds.
We propose to learn a Domain-Aware Siamese tracker, that is fully utilizing semantic and objectness information while producing a class-agnostic using a ridge regression network.
In this paper, we introduce the query-agnostic indexable representation of document phrases that can drastically speed up open-domain QA and also allows us to reach long-tail targets.
In this paper, we propose a subspectrogram segmentation based ESC classification framework that can achieve 81.9% classification accuracy.
A general visual SLAM system for dynamic scenes with multiple sensors called DMS-SLAM is proposed.
We explore the impact of global contextual information in semantic segmentation by introducing Context Encoding Module, which captures the semantic context of scenes and selectively highlights class-dependent featuremaps.
We show that by carefully presenting a mixture of labeled source domain and proxy-labeled target domain data to a network, we can achieve state-of-the-art unsupervised domain adaptation results.
Attention-based Pyramid Aggregation Network (APANet) for place recognition in urban environments.
This paper proposes a novel feature affinity-based pseudo labeling method with two possible label encodings for person re-identification using the intermediate feature representations from deep networks.
We establish mathematical correspondence between PR and reinforcement learning (RL), and, based on the connection, expand PR to learn constraints as the extrinsic reward in RL.
We propose a method that explains the outcome of a classification black-box by gradually exaggerating the semantic effect of a given class.
The functional classification of genes plays a vital role in molecular biology. Detecting previously unknown role of genes and their products in physiological and pathological processes is an important and challenging problem.
Our proposed SPReID integrates human semantic parsing in person re-identification and not only considerably outperforms its counter baseline, but achieves state-of-the-art performance.
In this paper, we propose I-GOS, which optimizes for a heatmap so that the classification scores on the masked image would maximally decrease.
In this paper, we propose to automatically generate synthetic clinical notes that are more amenable to sharing using generative models trained on real de-identified records.
We propose a novel discriminative semi-supervised dictionary learning method using label propagation (SSD-LP)
We present new methods to segment thin tree structures, which are, for example, present in microglia extensions and cardiac or neuronal blood vessels.
This paper examines event enrichment in terms of information completeness and presents a unified model for event enrichment that takes place natively within the event processing engine.
We propose a full system stack solution, composed of a reconfigurable architecture design, Field Programmable Synapse Array (FPSA) and its software system including neural synthesizer, temporal-to-spatial mapper, and placement & routing.
This work presents a Residual Attentional Siamese Network (RASNet) for high performance object tracking.
We present a new approach for learning compact and intuitive distributed representations with binary encoding with expert supports.
We propose Feature Quantization (FQ) for the discriminator, to embed both true and fake data samples into a shared discrete space for robust GAN training.
This paper proposes a novel learning framework for n-bit QNNs, whose weights are constrained to the power of two. We also propose a novel QNN structure named n-BQ-NN, which uses shift operation to replace the multiply operation and is suitable for the inference on FPGAs.
We reformulate the facial pose estimation as a label distribution learning problem, considering each face image as an example associated with a Gaussian label distribution, and construct a convolutional neural network which is trained with a multi-loss function on AFLW dataset and 300WLP dataset to predict the facial poses directly from color image.
We propose a new method for solving bilevel optimization, using the penalty function, which avoids computing the inverse of the hessian.
In this paper, we propose a new data set of garden images for testing algorithms for visual place recognition. It contains images with ground truth camera pose recorded in real gardens at different times, with varying light conditions.
We develop a method for learning powerful deep object models automatically from Web data, based on a concept expansion strategy.
We propose a novel method for maximizing a monotone submodular function subject to the combination of a $k$-matchoid and $\ell$-knapsack constraint, inspired by barrier functions in continuous optimization, with state of the art guarantees.
We propose a model, inspired by language modeling from natural language processing, with the ability to learn from a collection of undirected molecular graphs, enabling fitting of any underlying structure rule present in the collection.
Multi-Task Sparse Learning(MTSL) framework for action recognition.
We propose a multi-layer approach to analyze saliency cues in complex images and improve detection quality on complex images.
We extend Binet-Cauchy kernels to take into account the mean of the dynamical process and show similar or better human activity recognition results.
In this paper, we propose a new compact and portable deep learning network named Modulated Binary Cliquenet (MBCliqueNet) aiming to improve the portability of CNNs based on binarized filters while achieving comparable performance with the full-precision CNNs.
We propose to use a generic bi-directional recurrent neural network to predict the semantic connection between the participating objects in the relationship from the aspect of natural language.
This paper aims to integrate fast discriminative denoiser prior into model-based optimization method to solve other inverse problems.
We model the local face blocks with Gabor features and project them into a discriminant identity space for multi-resolution face verification.
We explore an alternative approach to learning vision models from movies that can reduce the training time while obtaining highly effective features and coherent temporal structures.
In this paper, we propose a new target criterion for model confidence, corresponding to the True Class Probability (TCP), a theoretical guarantees for TCP in the context of failure prediction, and introduce a specific learning scheme adapted to this context.
In recent years, deep neural networks have yielded immense success on speech recognition, computer vision and natural language processing. In this work, we strive to develop techniques based on neural networks to tackle the key problem in recommendation --- collaborative filtering.
We propose a multiple convolutional neural network framework trained based on different textural clusters of image local patches for image super-resolution.
The idea of most trackers based on Siamese network is off-line training and online tracking. However, these features are the general representation for similar objects, and therefore, their discrimination ability is not enough to identify the current tracking target, particularly distractors, from the background and distractors. To tackle this problem, we propose to update the features extracted by a Siamesean network online.
We propose a deep neural network fusion architecture for fast and robust pedestrian detection. Our method performs better than existing state-of-the-arts, especially when detecting small-size and occluded pedestrians.
Combinatorial Thompson Sampling achieves regret under the semi-bandit feedback model for combinatorial multi-armed bandit.
We propose a novel effective light-weight framework, called LightTrack, for online human pose tracking. The proposed framework is designed to be generic for top-down pose tracking and is faster than existing online and offline methods.
We propose a simple but effective feature aggregation framework which operates on the object proposal-level. It learns to enhance each proposal's feature.
We propose a lightweight two-stream fully Convolutional Neural Network for face detection, capable of detecting faces in various settings in real-time using the limited processing power Unmanned Aerial Vehicles possess.
We present a probabilistic model that exploits semantic cues in the form of sun direction, presence of an intersection, road type, speed limit as well as the ego-car trajectory in order to produce very reliable localization results.
We propose a spherical convolutional neural network for 3D point cloud processing that exploits `spherical' convolution kernels and octree partitioning of space.
We propose to jointly train a quantized, bit-operation-compatible DNN and its associated quantizers, as opposed to using fixed, handcrafted quantization schemes such as uniform or logarithmic quantization.
This paper proposes a comprehensive study on the application of histogram of oriented gradients descriptor in the FER problem, highlighting as this powerful technique could be effectively exploited for this purpose.
We propose a cloze-style QA system where the end user specifies a set of base documents and only a few labelled examples for the task of extractive Question Answering.
In this paper, we study the mutual information of recurrent neural networks (RNNs) including long short-term memories and self-attention networks such as Transformers.
We propose to more tightly integrate object detection and tracking by conditioning the object detection in the current frame on tracklets computed in prior frames, achieving state-of-the-art performance.
We propose a novel framework involving the feature- tree to index large scale motion features using Sphere/Rectangle-tree (SR-tree) for incremental action recognition. The proposed method can provide the localization of the action.
LRN uses input and forget gates to handle long-range dependencies as well as gradient vanishing and explosion, with all parameter related calculations factored outside the recurrence.
We propose to model multi-domain DST as a question answering problem, referred to as Dialogue State Tracking via Question Answering.
We present a method that leverages BERT's fine-tuning phase to its fullest, by applying an extensive number of parallel classifier heads, which are enforced to be orthogonal.
This paper provides a thorough review of advances made so far in egocentric data analysis and, in view of the current state of the art, indicates new lines of research to move us toward storytelling from visual lifelogging.
Multi-fingerprint browser retrieves nearest neighbors of any query molecule in multi-dimensional chemical spaces defined by four different fingerprints, each of which represents relevant structural and pharmacophoric features in a different way: sFP (substructure fingerprint), ECFP4 (extended connectivity fingerprint), MQNs (molecular quantum numbers) and SMILES fingerprint.
We propose stochastic depth, a training procedure that enables the seemingly contradictory setup to train short networks and use deep networks at test time.
We present a method to incrementally generate complete 2D or 3D scenes with the following properties: (a) it is globally consistent at each step according to a learned scene prior, (b) real observations of a scene can be incorporated while observing global consistency, (c) unobserved regions can be hallucinated locally in consistence with previous observations, hallucinations and global priors, and (d) hallucinations are statistical in nature.
This paper introduces a novel kernel, which serves such issues well. The kernel is learned by exploiting a large amount of low-complex, randomized binary mappings of the input feature, while alleviating the task of kernel selection.
This paper proposes a simplified algorithm framework using fusion features extracted from the salient areas of faces for pattern recognition.
We introduce an exact Lipschitz continuous non-convex penalty so that it can be incorporated in the stochastic gradient descent to approximate permutation at high precision.
Meta3D is a memory-based meta-learning framework for shape reconstruction from a single-view RGB image.
We find that changing clothes makes Reid a much harder problem in the sense of bringing difficulties to learning effective representations and also challenges generalization ability of previous Reid models to identify persons with unseen (new) clothes.
We present a self-supervised learning framework to estimate the individual object motion and monocular depth from video.
We propose a semi-supervised training method for single-image depth prediction that outperforms the state-of-the-art using stereo and LiDAR.
In adversarial training, a set of models learn together by pursuing competing goals, usually defined on single data instances. We use function-free Horn clauses to regularise any neural link predictor, with complexity independent of the domain size.
We present two parameter-reduction techniques to lower memory consumption and increase the training speed of BERT, leading to new state-of-the-art results on the GLUE, RACE, and SQuAD benchmarks.
This paper presents a new approach for fitting a 3D morphable model to images of faces using self-adapting feature layers (SAFL), combining the robustness of feature search with the flexibility of model fitting.
In this paper, we present a new method for computing both trust and distrust (i.e., positive and negative trust).
We present an efficient sparse stereo analysis algorithm that applies a dense consistency check, leading to accurate matching results. We further improve matching accuracy by introducing a new feature detector based on FAST.
We propose intensity guided depth upsampling using edge sparsity and super-weighted $L_{0}$ gradient minimization.
We propose a Sufficient Factor Broadcasting (SFB) computation model for efficient distributed learning of a large family of matrix-parameterized models, which share the following property: the parameter update computed on each data sample is a rank-1 matrix, i.e., the outer product of two sufficient factors.
Transfer learning allows practitioners to recognize and apply knowledge learned in previous tasks (source task) to new tasks or new domains, which share some commonality. The two important factors impacting the performance of transfer learning models are: (a) the size of the target dataset, and (b) the similarity in distribution between source and target domains.
We propose a novel beamformer that combines both approaches into a single framework that exploits the best features of both. Results on data that include a wide variety of room and noise conditions.
We investigate how motion can aid object recognition in short videos. Our approach is based on Long Short-Term Memory (LSTM) deep networks.
We propose Self-Attention - Temporal Convolutional Network (SA-TCN), which is able to capture both complex activity patterns and their dependencies within long-term untrimmed videos.
We formulate the bit allocation problem as a Markovian Decision Process (MDP) and train RL agents to automatically decide the quantization parameter (QP) of each coding tree unit (CTU) for HEVC intra coding, according to the task-driven semantic distortion metrics.
 ASSD learns to highlight useful regions on the feature maps while suppressing the irrelevant information, thereby providing reliable guidance for object detection.
In this paper, we present a canonical structure for controlling information flow in neural networks with an efficient feedback routing mechanism based on a strategy of Distributed Iterative Gating (DIGNet)
We present a generative model to map natural language questions into SQL queries.
We propose an online content popularity prediction algorithm by leveraging the content features and user preferences, and an offline user preference learning algorithm by using the online gradient descent (OGD) method and the (proximally) regularized leader (FTRL-Proximal) method.
We propose a novel WSOD framework with Objectness Distillation (i.e., WSOD^2) by designing a tailored training mechanism for weakly-supervised object detection.
We propose a robust, efficient, and automatic reconnection algorithm for bridging interrupted curvilinear skeletons in ophthalmologic images.
We give a comprehensive overview of the current state of the art of machine learning techniques facilitating these real-world requirements, including DNNs.
In this paper, we propose a novel system named Disp R-CNN for 3D object detection from stereo images that uses a statistical shape model to generate dense disparity pseudo-ground-truth without the need of LiDAR point clouds.
In this paper, we tackle a challenging domain conversion task between photo and icon images. GAN learns sufficient abstraction and simplification ability to generate icon-like images.
We learn a semantic knowledge ranking model to re-rank knowledge retrieved through Lucene based information retrieval systems and propose a knowledge fusion model which leverages BERT-based language models with externally retrieved knowledge.
This letter derives a novel motion prior that assumes white-noise-on-jerk, where the prior mean encourages constant body-centric acceleration.
This paper presents the task on the evaluation of Compositional Distributional Semantics Models on full sentences for the first time within SemEval2014.
Joint modeling of actor and action improves performance over modeling each of them independently, and further improvement can be obtained by considering the multi-scale natural.
We present a new concept - Wikiometrics - the derivation of metrics and indicators from Wikipedia. We demonstrate an innovative mining methodology, where different elements of Wikipedia - content, structure, editorial actions and reader reviews - are used to rank items in a manner which is by no means inferior to experts or other methods.
We review the task of Sentence Pair Scoring, popular in the literature in various forms - viewed as Answer Sentence Selection, Semantic Text Selection, Next Utterance Ranking, Recognizing Textual Entailment, Paraphrasing or e.g. a component of Memory Networks.
We investigate and challenge several aspects of BERT's commonsense representation abilities, and develop a method of fine-tuning knowledge graphs embeddings alongside BERT.
In this paper, we propose a novel deep learning framework, called spatial–temporal recurrent neural network (STRNN), to integrate the feature learning from both spatial and temporal information of signal sources into a unified spatial-temporal dependency model.
The Practical Deep Stereo (PDS) network uses novel bottleneck modules that drastically reduce the memory footprint in inference and additional design choices allow to handle greater image size during training.
In this paper, we propose a neural network-based point cloud registration method that iteratively matches features of points from two point clouds and solve the rigid body motion by minimizing the distance between the matching points.
We utilize conditional computation to make neural sequence models (Transformer) more efficient and computation-aware during inference.
In the presence of noisy or incorrect labels, neural networks have the undesirable tendency to memorize information about the noise. We propose training algorithms that employ an auxiliary network that predicts gradients in the final layers of a classifier without accessing labels.
Unsupervised node embedding methods (e.g., DeepWalk, LINE, and node2vec) have attracted growing interests given their simplicity and effectiveness. This could be very risky if they are attacked by an adversarial party.
We treat the face completion and corruption as disentangling and fusing Generative Adversarial Network (DF-GAN) and propose a dual learning framework along with an adversarial strategy for face completion under structured occlusions.
We propose an effective and efficient two step LDA, called LSR-LDA, to alleviate the affection of irregular distribution to improve the result of LDA.
This paper studies this problem from a perspective of controlling the strictness in training the teacher network. The flowchart is that, in order to optimize the target network (student), another network (teacher) with the same architecture is first trained, and used to provide part of supervision signals.
We propose a data-driven sparse-to-dense interpolation algorithm based on a fully convolutional network for optical flow.
We propose an incremental training method that partitions the original network into sub-networks, which are then gradually incorporated in the running network during the training process. This allows for a smooth dynamic growth of the network.
We introduce a family of $(q,p)$-Wasserstein GANs, which allow the use of more general $p$- Wasserstein metrics for $p\geq 1$ in the GAN learning procedure.
We study the problem of representation learning in goal-conditioned hierarchical reinforcement learning. We develop a notion of sub-optimality of a representation, defined in terms of expected reward of the optimal hierarchical policy using this representation.
We propose a novel adversarial detection method which identifies adversaries by adaptively learning reasonable metrics to characterize adversarial subspaces.
Subspace clustering aims to group a set of data from a union of subspaces into the subspace from which it was drawn.
We propose a deep ALPR system designed to be applicable to multinational LPs.
We introduce inoculation by fine-tuning, a new analysis method for studying challenge datasets by exposing models (the metaphorical patient) to a small amount of data from the challenge dataset (a metaphorical pathogen) and assessing how well they can adapt.
We introduce a general framework for several information extraction tasks that share span representations using dynamically constructed span graphs. The dynamic span graph allows coreference and relation type confidences to propagate through the graph to iteratively refine the span representations.
We present a learning-based scheme for robustly and accurately estimating clothing fitness as well as the human shape on clothed 3D human scans.
In this paper, we propose a customized image narrative generation task, in which the users are interactively engaged in the generation process by providing answers to the questions.
We propose a monocular semi-direct visual odometry framework capable of exploiting the best attributes of edge features and local photometric information for illumination-robust camera motion estimation and scene reconstruction.
In this paper, we present Skeleton Transformer Networks (SkeletonNet), an end-to-end framework that can predict not only 3D joint positions but also 3D angular pose (bone rotations) of a human skeleton from a single color image.
We present a novel method for neural network quantization that emulates a non-uniform $k$-quantile quantizer, which adapts to the distribution of the quantized parameters.
We propose a generic and effective Temporal Shift Module that achieves both high efficiency and high performance. It can be inserted into 2D CNNs to achieve temporal modeling at zero computation and zero parameters.
We analyze the frequency properties of filters in the first layer as it is the entrance of information and relatively more convenient for analysis.
Inferring the latent variable generating a given test sample is a challenging problem in Generative Adversarial Networks (GANs). In this paper, we propose a novel framework for solving the inference problem in GANs, which involves training an encoder network capable of inverting a pre-trained generator network.
A Two-Dimensional Discrete Wavelet Transform, based on the Local Binary Pattern, which is a new approach for face recognition using symmetry.
This paper proposes a novel approach for global localisation of mobile robots in large-scale environments through seeding Monte Carlo Localisation with a deep-learned distribution.
We explore whether different normalization layers in a ConvNet require different normalizers, and whether different tasks and datasets prefer them.
The role of “Jun-Chen-Zuo-Shi” component herbs of QSYQ in treating acute myocardial ischemia by a network pharmacology approach.
We identify one of the causes for the under-performance of AE-based generative models and propose a remedial measure.
The attention mechanism is an important part of the neural machine translation (NMT) where it produces richer source representation compared to fixed-length encoding sequence-to-sequence models.
We propose an ensemble of deep convolutional neural networks to improve further their individual accuracies in the task of classifying dermoscopy images into the three classes melanoma, nevus, and seborrheic keratosis when we have no opportunity to train them on adequate number of annotated images.
We systematically study the ability of feedforward neural networks to learn to recognize a variety of visual relations and demonstrate that same-different visual relations pose a particular strain on these networks.
We develop a 16-layer, yet lightweight, neural network which boosts efficiency while maintaining high accuracy.
Lifelong learning with deep neural networks is well-known to suffer from catastrophic forgetting: the performance on previous tasks drastically degrades when learning a new task. To alleviate this effect, we propose to leverage a large stream of unlabeled data easily obtainable in the wild.
This paper generalizes the hyperprior from lossy model to lossless compression, and proposes a L2-norm term into the loss function to speed up training procedure.
This paper establishes a compact representation for minimizers of a $k$-submodular function by a poset with inconsistent pairs (PIP), a generalization of Ando-Fujishige's signed poset representation.
In this letter, a novel multi-spectrogram fusion framework is proposed, making the spectrograms complement each other for acoustic scene classification.
A connect-and-merge convolutional neural network (CMNet) for fast detecting vehicles in complex scenes.
We explore the use of self-supervision provided by a robot traversing an environment to learn representations of encountered objects to enable effective environment specific object discovery and detection.
Using hyperbolic numerics for variational approaches to correspondence problems can lead to a significant quality gain in computational results.
We present a novel siamese Long Short-Term Memory (LSTM) architecture that can process image regions sequentially and enhance the discriminative capability of local feature representation by leveraging contextual information.
We introduce a two-stage localization and instance identification framework for arbitrary robots based on convolutional neural networks.
We marry two powerful ideas: deep representation learning for visual recognition and language understanding, and symbolic program execution for reasoning. Our neural-symbolic visual question answering system first recovers a structural scene representation from the image and a program trace from the question to obtain an answer.
We introduce a novel loss function for training deep learning architectures to perform classification. It consists in minimizing the smoothness of label signals on similarity graphs built at the output.
Using Inception-v3 transfer learning to classify pulmonary images, and finally to get a practical and feasible computer-aided diagnostic model.
With WEADE we present a free web application that offers an integrated workflow for the exploration of genomic data combining enrichment analysis with a versatile set of tools to directly compare and intersect experiments or candidate gene lists of any size or origin including cross-species data.
We perform an extensive quantitative evaluation of rectangular treemapping algorithms for time-dependent data, and propose a novel classification scheme and evaluation method for such data.
This paper proposes a Pseudo Positive Regularization (PPR) method to enrich the diversity of the training data to reduce the risk of over-fitting.
We propose an effective sparse kernel design by eliminating the large design space, which is able to find designs which are more efficient in using parameters and computation with similar accuracy.
We explore the principles in addressing such feature misalignment issues and inventively propose Feature-Aligned Segmentation Networks (AlignSeg)
We propose a novel dual refinement mechanism for static and temporal detection in real-world scenes in real time.
Adaptive inference is a promising technique to improve the computational efficiency of deep models at test time. This paper investigates how to train such networks more effectively.
We propose a Variational Autoencoder based network model for cross-domain linking with added contextualization to handle sparse data and for better transfer of cross- domain knowledge.
Autonomous vehicles (AVs) must share space with human pedestrians, both in on-road cases such as cars at pedestrian crossings and off-roadcases such as delivery vehicles navigating through crowds on high-streets. Planning AV actions in the presence of pedestrians thus requires modelling of their probable future behaviour as well as detection and tracking which enable such modelling.
A DL model for Disease-NER using dictionary information is proposed and evaluated on National Center for Biotechnology Information (NCBI) disease corpus and BC5CDR dataset.
We develop a novel data-efficient semi-supervised framework for training an image captioning model by learning to associate them.
We propose a novel reinforcement- and ranking-based training framework, which uses a full relative pose estimation pipeline during training, which improves interest point detectors in terms of succinctness.
We introduce a context-based vocabulary remapping model to reprogram neural networks trained on a specific sequence classification task, for a new sequence classificationtask desired by the adversary.
Improving GANs to avoid errors by manipulating the input space .
We propose a discriminative probabilistic model for the instance annotation problem and introduce an expectation maximization framework for inference, based on the maximum likelihood approach.
Neural GEC models outperform state-of-the-art neural GEC systems on CoNLL-2014 benchmark and JFLEG test set.
We propose a new action anticipation method that achieves high prediction accuracy even in the presence of a very small percentage of a video sequence.
We propose a novel deep learning based approach to breast mass segmentation in ultrasound (US) imaging, based on quantitative entropy parametric maps.
In image classification, visual separability between different object categories is highly uneven, and few efforts have been made to leverage the hierarchical structure of categories. In this paper, we introduce hierarchical deep CNNs (HD-CNNs) by embeddingDeep CNNs into a category hierarchy.
We introduce a biologically motivated learning structure called Associated Learning, which modularizes the network into smaller components, each of which has a local objective.
We investigate stable patterns of electroencephalogram (EEG) over time for emotion recognition using a machine learning approach.
A structured training objective based on identifying whether images and sentences co-occur in documents can suffice to predict links between specific sentences and specific images within the same document at test time.
We propose HI2Rec, which integrates multiple information to learn the user and item’s vector representations for top-N recommendation to address the above-mentioned issues.
In this paper, we address the problem of searching action proposals in unconstrained video clips. Our approach starts from actionness estimation on frame-level bounding boxes, and then aggregates the bounding box belonging to the same actor across frames via linking, associating, tracking to generate spatial-temporal continuous action paths.
This paper demonstrates a novel scheme to incorporate a structured Gaussian likelihood prediction network within the VAE that allows the residual correlations to be modeled. We also propose a new mechanism for effectively training this model, and include some suggestions for improving performance.
We address the task of simultaneous feature fusion and modeling of discrete ordinal outputs. We propose a novel Gaussian process(GP) auto-encoder modeling approach.
We present a probabilistic forecasting model of future interactions between a variable number of agents, which reasons about how all agents will likely respond to the goal of a controlled agent.
We propose an image super-resolution method using a deeply-recursive convolutional network (DRCN) using a very deep recursive layer.
We propose a novel cross-modal learning architecture that can leverage all available image and normal data, whether paired or not, thanks to a novel module that we call deactivable skip connections, which allows integrating both the auto-encoded and image-to-normal branches within the same architecture.
We propose two Event-Based control loops to adjust the learning rate of a classical algorithm E (Exponential)/PD (Proportional Derivative)-Control for online learning scenario.
Drug-drug interaction (DDI) is a major cause of morbidity and mortality and a subject of intense scientific interest. Biomedical literature mining can aid DDI research by extracting evidence for large numbers of potential interactions from published literature and clinical databases.
We study network pruning which aims to remove redundant channels/kernels and hence speed up the inference of deep networks by removing redundant kernels.
This paper presents a continuous learning paradigm for open-domain question answering over knowledge bases that learns new templates that capture previously-unseen syntactic structures.
We propose Deep Regression Forests, an end-to-end model for age estimation from facial images that deal with heterogeneous data.
Lifelogging cameras capture everyday life from a first-person perspective, but generate so much data that it is hard for users to browse and organize their image collections effectively. In this paper, we propose to use automatic image captioning algorithms to generate textual representations of these collections.
We address the task of natural image generation guided by a conditioning input. We introduce a new architecture called conditional invertible neural network (cINN)
We propose a probabilistic approach to efficiently estimate GED, which is further leveraged for the graph similarity search, and introduce a novel graph similarity measure by comparing branches between graphs.
This paper pushes forward high-resolution saliency detection, and contributes a new dataset, named High-Resolution Salient Object Detection (HRSOD), to address this challenge.
Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks. While their expressiveness is the reason they succeed, it also causes them to learn uninterpretable solutions.
A method for aggregating multiple decision trees into a strong predictor by interpreting a path taken by a sample down each tree as a binary vector.
We quest into the essence of translation models, and present a generic model, namely, GTrans , to entail all the existing translation models.
We present a new neural text to speech method that is able to transform text tospeech in voices that are sampled in the wild.
We propose a multiple instance learning (MIL) framework for multi-class AED using weakly annotated labels.
We propose attention neural networks for weakly labelled audio tagging, achieving state-of-the-art performance on AudioSet.
We propose Information Fused Temporal Transformation Network (IF-TTN) for action recognition on top of popular Temporal Segment Network framework.
We propose a novel cascade CNN architecture composing of two stages. The first stage advances the recently proposed DispNet by equipping it with extra up-convolution modules, leading to disparity images with more details.
Cross-depiction is the problem of identifying the same object even when it is depicted in a variety of manners. In this paper we address this problem using state-of-the-art deep learning techniques on a dataset of historical watermarks containing images created with different methods of reproduction.
We propose a purely deep transfer Re-ID model consisting of a deep convolutional neural network and an autoencoder for practical Re-identification.
Vehicle detection and pose estimation of vehicles using 3D stereo images .
In this paper, we establish a baseline for object reflection symmetry detection in complex backgrounds by presenting a new benchmark and an end-to-end deep learning approach.
We propose three variants of adding recurrent connections into the student network, and show experimentally on CIFAR-10, Scenes and MiniPlaces, that we can reduce the number of parameters at little loss in accuracy.
We propose a data fusion pipeline based on computer vision techniques, including novel inpainting algorithm with soft masking, for precipitation nowcasting.
The object tracking methods based on multi-domain convolutional neural network (MDNet) commonly fail to track in the case of background clutter. A novel double-channel object tracking (DCOT) is proposed to solve this problem.
In this work we present Google's submission to the BioASQ 7 biomedical question answering (QA) task (specifically Task 7b, Phase B) based on BERT QA models.
We propose a simple yet effective method to teach pretrained language models with commonsense reasoning by leveraging the structured knowledge in ConceptNet, the largest commonsense knowledge base.
In this paper, we propose a novel method called AlignedReID that extracts a global feature which is jointly learned with local features. After the joint learning, we only keep the global feature to compute the similarities between images.
The standard pipeline in pedestrian detection is sliding a pedestrian model on an image feature pyramid to detect pedestrians of different scales. In this pipeline, feature pyramid construction is time consuming and becomes the bottleneck for fast detection.
In this paper, we explore neural network models that learn to associate segments of spoken audio captions with semantically relevant portions of natural images that they refer to.
We explore a transfer learning scheme, whereby we train character-level recurrent neural taggers to predict morphological taggings for high-resource and low-resource languages together.
We introduce a Bayesian approach for uncertainty estimation in super-resolution network and introduce a faster approach for estimating the uncertainty, and it can be useful for real-time applications.
We introduce Patch Refinement a two-stage model for accurate 3D object detection and localization from point cloud data.
We introduce a new system for automatic image content removal and inpainting, which automatically detects the area to be removed and infilled.
We seek to detect visual relations in images of the form of triplets t = (subject, predicate, object), such as"person riding dog", where training examples of the individual entities are available but their combinations are rare or unseen at training.
This paper presents a novel face data generation method for real-time detailed 3D face reconstruction from monocular video as well as from a single image.
In single image deblurring, the"coarse-to-fine"scheme, i.e. gradually restoring the sharp image on different resolutions in a pyramid, is very successful in both traditional optimization-based methods and recent neural-network-based approaches. In this paper, we investigate this strategy and propose a Scale-recurrent Network (SRN-DeblurNet) for the task.
We propose a spatiotemporal architecture for anomaly detection in videos including crowded scenes.
In this paper, we introduce a novel neural network architecture called Multi-layer Embedding with Memory Network for machine reading task.
Multimodal machine translation involves drawing information from more than one modality, based on the assumption that the additional modalities will contain useful alternative views of the input data. The state of the art in end-to-end and pipeline approaches, and also the challenges in performance evaluation.
The design of complexity-aware cascaded detectors, combining features of very different complexities, at state of the art performance.
We propose a graph-based, language-guided attention mechanism for referring expression comprehension that captures inter-object relationships, and properties with a flexibility and power impossible with competing approaches.
We develop a fast deep neural network for real-time video object detection by exploring the ideas of knowledge-guided training and predicted regions of interest.
We introduce a novel single-shot object detector to ease the imbalance of foreground-background class by suppressing the easy negatives while increasing the positives.
We present a generalized, distribution-aware approach to binarizing deep networks that allows us to retain the advantages of a binarized network, while reducing accuracy drops.
In this paper, we prove that layer-wise compression is, in theory, better, because the convergence rate is upper bounded by that of entire-model compression for a wide range of biased and unbiased compression methods.
We point out this attack can be protected by denoise autoencoder, which is used for denoising the perturbation and restoring the original images.
This paper presents a scalable method for learning typed entailment graphs from text, based on new soft constraints that consider both the structures and inside each graph.
We investigate existing metrics for evaluating the fidelity of saliency methods (i.e. saliency metrics). We find that there is little consistency in the literature in how such metrics are calculated, and show that such inconsistencies can have significant effect on the measured fidelity.
We propose a set of practical guidelines of target state estimation for high-performance generic object tracker design, which achieves state-of-the-art performance.
Convolutional neural network driven by image recognition can predict and decode fMRI data from humans watching natural movies, despite its lack of any mechanism to account for temporal dynamics or feedback processing.
We propose a method that reduces the text analysis dependency on this kind of classification giving more importance to the image content giving more accurate classification.
This paper proposes a novel approach to image captioning based on iterative adaptive refinement of an existing caption.
We analyse the remarkable progress of the last decade by dis- cussing the main ideas explored in the 40+ detectors currently present in the Caltech pedestrian detection benchmark, all currently reaching similar detec- tion quality.
In this paper, we show how 1) neural attention and 2) meta learning techniques can be used in combination with autoregressive models to enable effective few-shot density estimation.
A novel framework that integrates incremental structure from motion (SfM) and a scale drift correction method utilizing geo-tagged images, such as those provided by Google Street View.
We present an empirical analysis of the state-of-the-art systems for referring expression recognition -- the task of identifying the object in an image referred to by a natural language expression -- with the goal of gaining insight into how these systems reason about language and vision.
We propose a novel framework of Dynamic Dual Attention Networks or DDAN which models content production strategies of users through a generative process, under the influence of social interactions.
This paper addresses this issue of the KCF based trackers by the introduction of two novel modules, namely online assessment of response map, and a strategy of combining cyclically shifted sampling with random sampling in deep feature space to improve the tracking performance.
This paper introduced a computer simulation model that generates benchmark datasets for evaluating multi-target tracking algorithms with the complexity of multitarget tracking scenarios directly controlled by simulation inputs such as target birth and death rates, target movement, target merges and splits, target appearances, and image noise types and levels.
The ability to estimate rich geometry and camera motion from monocular imagery is fundamental to future interactive robotics and augmented reality applications. We present a SLAM system that unifies these methods in a probabilistic framework while still maintaining real-time performance.
Spatial information describes the relative spatial position of an object in a video. This paper studies the effect of spatial information on video activity recognition.
Automated fact-checking based on machine learning is a promising approach to identify false information distributed on the web. In order to achieve satisfactory performance, machine learning methods require a large corpus with reliable annotations for the different tasks in the fact checking process. Having analyzed existing corpora, we found that none of them meets these criteria in full.
In this paper, we propose a novel medical image segmentation using iterative deep learning framework. We have combined an iterative learning approach and an encoder-decoder network to improve segmentation results.
We propose a novel approach for predicting on-going action with the assistance of a low-cost depth camera. Our approach introduces a soft regression-based early prediction framework.
We propose a novel end-to-end multi-view fusion (MVF) algorithm for point cloud voxelization, which can effectively learn to utilize the complementary information from both.
Online Submodular Bipartite Matching (OSBM) problem, where the goal is to maximize a submodular function f over the set of matched edges.
We address video title generation for the first time by proposing two methods that extend state-of-the-art video captioners to this new task.
We present a scalable framework for accurately inferring six Degree-of-Freedom (6-DoF) pose for a large number of object classes from single or multiple views.
We propose an automatic system to annotate and retrieve images using graph based vocabulary of blobs.
Tensor decomposition is used for many web and user data analysis operations from clustering, trend detection, anomaly detection, to correlation analysis. However, many tensor decomposition schemes are sensitive to noisy data, an inevitable problem in the real world that can lead to false conclusions.
We equip CNNs with a more principled pooling strategy, called SPP-net, to eliminate the above requirement for fixed-size input image.
We propose a new Implicit Dynamic Social Recommendation model, which infers latent social network from cascade data and identify the dynamic changes in the users in time by using the latest updated social network to make recommendations.
We build an anchor-based deep face detector, which only output a single feature map with small anchors, to specifically learn small faces and train it by a novel hard image mining strategy.
We propose using progressive networks to bridge the reality gap and transfer learned policies from simulation to the real world, enabling a compositional, yet simple approach to building complex skills.
We propose an extension called hierarchical information-preserving GSFA (HiGSFA), where information preservation complements the slowness-maximization goal, giving rise to a promising hierarchical supervised-learning approach.
In this paper, we develop an RGC method that is able to reduce the end-to-end training time on real-world multi-GPU systems.
We propose a weakly supervised photo enhancer that converts photos taken by cameras with limited capabilities into DSLR-quality photos automatically.
We proposed a novel self-perception method based on GANs for automatical face attribute inverse that employs only one single generator without being conditioned on other inputs.
In this paper, we propose a method that exploits both local and global contextual cues imposed by the k-d tree to capture the local structures of point clouds.
We propose a methodology of reconstructing a neural network itself optimized to resistive memory crossbar arrays when the synapse devices have nonlinear I-V characteristics.
We propose an unsupervised optical flow estimation framework using pyramid Convolution LSTM with the constraint of adjacent frame reconstruction, which allows flexibly estimating multi-frame optical flows from any video clip.
We propose a novel action reasoning framework that uses prior knowledge to explain semantic-level observations of video state changes.
In this paper, we propose new ensemble methods specialized for deep neural networks, called confident multiple choice learning (CMCL) via addressing its overconfidence this improves the performance.
We propose Star-Transformer, a lightweight alternative by careful sparsification, in which every non-adjacent node is connected through a shared relay node.
We present the first work to systematically explore how the fusion of face recognition features (FRF and facial attribute features (FAF) can enhance face recognition performance in various challenging scenarios.
We address this issue via a model adaptation scheme that uses the result of a local regression forest (RF) voting method for face alignment.
This paper describes the details of Sighthound's fully automated age, gender and emotion recognition system. We tested our system on several public benchmarks and report outstanding results.
We propose two strategies for freeing neural networks from the needs of tuning with OoD data, while improving its OoD detection performance.
Semantic annotation techniques provide the basis for linking textual content with concepts in well grounded knowledge bases. One of the prominent limitations of such systems is that none of the existing semantic annotator systems are able to identify and disambiguate quantitative (numerical) content.
We propose several ways of reusing subword embeddings and other weights in subword-aware neural language models that improve the performance of syllable- and morpheme-aware models while reducing model sizes.
We propose Multi-Cell Multi-Task Convolutional Neural Networks (M$^2$CNN) solution for the diabetic retinal image analysis which improves the classification accuracy.
The cold-start is the situation in which the recommender system has no or not enough information about the (new) users/items, i.e. their ratings/feedback; hence, the recommendations are not accurate. Active learning techniques propose to interact with new users by asking them to rate sequentially a few items while the system tries to detect her preferences.
Feedback based learning based on a feedback received from previous iterations output improves upon feedforward neural networks.
In this paper, we replicate the work of Niklaus et al on Adaptive Separable Convolution, which claims high quality results on the video frame interpolation task.
The locations of the fiducial facial landmark points around facial components and facial contour capture the rigid and non-rigid facial deformations due to head movements and facial expressions. Many facial landmark detection algorithms have been developed to automatically detect those key points over the years.
We propose a novel algorithm, namely Resembled Generative Adversarial Networks (GAN), that generates two different domain data simultaneously where they resemble each other.
We propose a novel multi-task learning architecture, which allows learning of task-specific feature-level attention, whilst simultaneously allowing for features to be shared across different tasks.
This paper focuses on improving face recognition performance with a new signature combining implicit facial features with explicit soft facial attributes.
A weakly supervised learning approach is used to reduce the shift between training on real and synthetic data, allowing us to use only a fraction of the training samples and significantly improving the performances.
We analyze the entries from DAWNBENCH, a benchmark competition focused on end-to-end training time to achieve near-state-of-the-art accuracy on an unseen dataset-a combined metric called TTA.
A novel approach to population-based RL in continuous control that leverages properties of normalizing flows to perform attractive and repulsive operations between current members of the population and previously observed policies.
This paper introduces a novel Action Unit (AU) level facial expression synthesis method called Local Attentive Conditional Generative Adversarial Network.
We empirically investigate weight decay for three optimization algorithms (SGD, Adam, and K-FAC) and a variety of network architectures.
Our proposed competing ratio loss (CRL) calculates the posterior probability ratio between the correct class and the competing incorrect classes to further enlarge the probability differencebetween the correct and incorrect classes.
We find that a simple fusion of low-level and high-level features could be less effective because of the gap in semantic levels and spatial resolution. We propose a new framework, named ExFuse, to bridge the gap.
We propose GhostLink, an unsupervised probabilistic graphical model, to automatically learn the latent influence network underlying a review community - given only the temporal traces (timestamps) of users' posts and their content.
We propose to incorporate an auxiliary task of language modeling to help question generation in a hierarchical multi-task learning structure, achieving state-of-the-art results.
We revisit the core DCF formulation and introduce: a factorized convolution operator, which drastically reduces the number of parameters in the model, a compact generative model of the training sample distribution, and a conservative model update strategy.
We propose to focus on the problem of discovering neural network architectures efficient in terms of both prediction quality and cost, while making no assumption on the nature of this cost.
We re-evaluate the state of the art for object recognition from small images with convolutional networks, questioning the necessity of different components in the pipeline. We find that max-pooling can simply be replaced by a Convolutional layer with increased stride without loss in accuracy.
We present a mapping system capable of constructing detailed instance-level semantic models of room-sized indoor environments by means of an RGB-D camera, and propose modifications of the registration cost function to make full use of the instance class labels.
We propose Flow-GANs, a generative adversarial network with the generator specified as a normalizing flow model which can perform exact likelihood evaluation for unsupervised learning.
We propose a temporally robust global motion compensation (TRGMC) algorithm which performs accurate and stable GMC, despite complicated and long-term camera motion.
We propose a two-stage efficient algorithm for multi-class crowd labeling problems that achieves the optimal convergence rate up to a logarithmic factor.
We propose a tempered learning process for generative adversarial networks which improves quality, stability and/or convergence speed across a range of different GAN architectures.
We perform extensive studies on benchmark datasets to propose a metric that quantifies the "hardness" of a few-shot episode.
We propose a new IQA dataset and a weakly supervised feature learning approach to train features more suitable for IQA of artificially distorted images.
We use a continuous temporal embedding of framewise features to benefit from the sequential nature of activities to identify clusters of temporal segments that correspond to semantic meaningful action classes.
We present FaceFeat-GAN, a novel generative model that improves both image quality and diversity by using two stages.
We propose a novel age progression method for robust and automatic face progression in totally unconstrained conditions in bidirectional fashion.
We address several key open-ended problems such as conversational speech recognition, open domain natural language understanding, commonsense reasoning, statistical dialog management, and dialog evaluation.
In this paper, we address the challenging distance estimation problem by developing an end-to-end learning-based model to directly predict distances for given objects in the images.
We propose CIGAR, a candidate generation and re-ranking based framework that significantly boosts the Top-N accuracy against state-of-the-art recommendation models while reducing query time by orders of magnitude.
We propose and release a large-scale dataset of outdoor scenes, along with manually annotated maps for candidate spaces for augmented video content.
We introduce an unsupervised framework for network construction based on pairwise visual similarities and experimentally demonstrate that the constructed network can be used to automatically discover multiple discrete latent attributes between images.
This paper classifies human action sequences from videos using a machine translation model. Furthermore, we use our model to solve downstream tasks such as video captioning and action localization.
A comprehensive semantic understanding of a scene is important for many applications - but in what space should diverse semantic information (e.g., objects, scene categories, material types, texture, etc.) be grounded and what should be its structure?
A novel, pyrazolopyrimidine-based allosteric KRAS inhibitor that selectively binds to active KRAS with sub-micromolar affinity, slightly modulates exchange factor activity, disrupts effector binding, significantly reduces signal transduction through mutant KRAS and inhibits cancer cell growth.
In presence of occlusions, per expression, we compute the importance of each unoccluded facial region and we construct adapted facial frameworks that boost the performance of per expression binary classifier.
We propose a new corpus for online abuse detection, based on the Wikipedia Comment corpus, with comment-level abuse annotations of different types, which can be used for context-based approaches.
We propose a simple way to resolve this issue by decoupling weight decay and the optimization steps taken w.r.t. the loss function, allowing Adam to compete with SGD with momentum.
We introduce MMM, a Multi-stage Multi-task learning framework for Multi-choice reading comprehension and propose a novel multi-step attention network for this task.
We adaptively fuse the predictions from different scales (using adaptively changing per-pixel weights), which makes our method adapt to scale changes within an image.
We propose an endto-end affect-rich open-domain neural conversational model that produces responses not only appropriate in syntax and semantics, but also with rich affect.
A novel deep convolutional neural network architecture for the environmental sound classification task using multi-temporal resolution and multi-level features.
We present a new video representation, called temporal linear encoding (TLE) and embedded inside of CNNs as a new layer, which captures the appearance and motion throughout entire videos, via end-to-end learning.
The computer vision research aims at a better understanding of the human visual system and building artificial visual systems.
The beneficial, complementary nature of visual and textual information to convey information is widely known, for example, in entertainment, news, advertisements, science, or education. In this paper, we motivate the necessity of an additional metric called Status in order to cover complex image-text relations more completely.
We introduce a suite of tools that exploit sparsity in both the feature maps and the filter weights of a CNN, and thereby allow for significantly lower memory footprints and computation times than the conventional dense framework, when processing data with a high degree of sparsity.
We overcome the artificial separation of optical flow and confidence estimation by introducing a variational inference scheme based on mean field, which incorporates best practices from energy minimization, and introduce a probabilistic approach based on the posterior distribution of the flow given the images.
We consider the task of learning the parameters of a {\em single} component of a mixture model, for the case when we are given side information about that component, we call this the "search problem" in mixture models. We would like to solve this with computational and sample complexity lower than solving the overall original problem.
In this paper, we present a conceptually simple and general yet novel framework for few-shot temporal activity detection based on proposal regression which detects the start and end time of the activities in untrimmed videos.
We present Column Network, a novel deep learning model for collective classification in multi-relational domains.
We aim to learn a domain generalizable person re-identification (ReID) model that is domain-invariant.
We study sequence-to-sequence (seq2seq) pre-training with data augmentation for sentence rewriting. We also introduce multiple data augmented methods to help model pre- training.
In this paper, we introduce an analysis and algorithms for averaging bifocal tensors (essential or fundamental matrices) in collinear settings.
In this paper, we introduce the Reinforced Mnemonic Reader for machine comprehension task, which aims to answer a query about a given context document.
We propose a novel neural network based approach to address the graph similarity search problem, aiming to alleviate the computational burden while preserving a good performance.
We investigate the problem of tag importance prediction, where the goal is to automatically predict the tag importance and use it in image retrieval.
We study a class of orderless aggregation functions designed to minimize interference or equalize contributions in the context of second-order features and we show that they can be computed just as efficiently as their first-order counterparts and they have favorable properties over aggregation by summation.
This paper addresses the problem of mapping natural language text to knowledge base entities. The mapping process is approached as a composition of a phrase or a sentence into a multi-dimensional entity space obtained from a knowledge graph.
3D human pose estimation is frequently seen as the task of estimating 3D poses relative to the root body joint. To that end, we cast the problem into a different perspective, where3D poses are predicted in the image plane, in pixels, and the absolute depth is estimated in millimeters.
We propose a method to efficiently learn diverse strategies in reinforcement learning for query reformulation in the tasks of document retrieval and question answering.
We introduce Sketched SGD, an algorithm for carrying out distributed SGD by communicating sketches instead of full gradients, which reduces the amount of communication required compared to other gradient compression methods.
This paper presents a new weakly supervised architecture, called UntrimmedNet, which is able to directly learn action recognition models from untrimmed videos without the requirement of temporal annotations of action instances.
We propose an end-to-end neural architecture for the Stanford Question Answering Dataset and propose two ways of using Pointer Net for the task.
In existing CNN based detectors, the backbone network is a very important component for basic feature extraction, and the performance of the detectors highly depends on it. In this paper, we aim to achieve better detection performance by building a more powerful backbone from existing backbones like ResNet and ResNeXt.
Neural plasticity is an important functionality of human brain, in which number of neurons and synapses can shrink or expand in response to stimuli throughout the span of life. We unify network sparsification and network expansion in an end-to-end training pipeline.
We propose a convex sparse principal component analysis (CSPCA) algorithm and apply it to feature selection.
This paper optimized the DCT algorithm and the data precision, and successfully deployed the designed accelerator kernel on the FPGA cloud platform to speed up the processing of watermarking.
An unsupervised GAN based sequence inpainting framework based on a recurrent net based grouped noise prior learning.
We propose a new approach based on using inverse generator (IG) model as encoder and pre-trained generator (G) as decoder of an AutoEncoder network to train the IG model. The optimizing method can overcome the difficulty in training and inverse model of an non one-to-one function.
SBSGAN allows the generator to decide whether pixels should be preserved or suppressed to reduce segmentation errors caused by noisy foreground masks.
We study the classical problem of maximizing a monotone submodular function subject to a cardinality constraint k, with two additional twists: (i) elements arrive in a streaming fashion, and (ii) m items from the stream are removed after the stream is finished.
 360{\deg} Stance Detection, a tool that aggregates news with multiple perspectives on a topic, enabling the user to base their opinion on multiple pieces of diverse evidence.
The adoption of human-in-the-loop paradigms in computer vision and machine learning is leading to various applications where the actual data acquisition (e.g., human supervision) and the underlying inference algorithms are closely interwined. We study the completion problem defined on graphs, where requests for additional measurements must be made sequentially.
We propose an architectural block that introduces much lower complexity than the existing methods of CNN performance boosting while performing significantly better than them.
We propose several variations of the attentive NMT architecture bringing this meeting point back.
This paper proposes a visual odometry algorithm, where an ultrarobust and fast feature-matching scheme is combined with an effective antiblurring frame selection strategy.
In this paper, we propose a novel top-down instance segmentation framework based on explicit shape encoding, named \textbf{ESE-Seg}.
We build on top of one such model, namely BiLSTM with max pooling, and show state of the art results for the SNLI sentence encoding-based models and the SciTail dataset.
We develop a mobile application that allows for the recognition of notable sites featured on Wikipedia in an urban environment.
We introduce the Alignment-Free Facial Attribute Classification Technique (AFFACT), a data augmentation technique that allows a network to classify facial attributes without requiring alignment.
We propose a best next viewpoint recommendation method by minimizing the pose ambiguity of an estimated object pose by making use of the current pose estimation result as a latent variable.
Watson, the winner of the Jeopardy! challenge, is a state-of-the-art open-domain Question Answering system that tackles the fundamental issue of answer typing by using a novel type coercion framework, where candidate answers are initially produced without considering type information, and subsequent stages check whether the candidate can be coerced into the expected answer type.
We propose a probabilistic time-frequency model capable of generating high-fidelity audio samples which capture structure at timescales that time-domain models have yet to achieve.
We propose a novel concept of asymmetric feature maps (AFM), which allows to evaluate multiple kernels between a query and database entries without increasing the memory requirements.
This paper proposes a multi-branch model, namely part-based attribute-aware network (PAAN), to leverage both person reID and attribute performance, which not only utilizes ID label visible to the whole image but also utilizes attribute information.
The goal of this work is to learn implicit 3D shape representation with 2D supervision, improve upon the baselines in the accuracy of the reconstructed 3D geometry and rendering.
This paper describes our submission to the 1st 3D Face Alignment in the Wild (3DFAW) Challenge.
Inferring potential adverse drug reactions is an important and challenging task for the drug discovery and healthcare industry. Many previous studies in computational pharmacology have proposed utilizing multi-source drug information to predict drug side effects. However, most of the prediction methods mainly rely on direct similarities inferred from drug information and cannot fully utilize the drug information about the impact of protein–protein interactions.
This paper addresses the task of articulated multi-person pose estimation and tracking towards real-time speed. To alleviate the performance bottleneck caused by scale variation problem, a paradigm which exploits scale-normalized image and feature pyramids (SIFP) is proposed.
We develop a Poisson regressor based on a Gaussian process for the content request distribution and propose a fast block-coordinate descent algorithm to solve it.
We propose an adversarial evaluation scheme for the Stanford Question Answering Dataset (SQuAD) that tests whether systems can answer questions about paragraphs that contain adversarially inserted sentences without changing the correct answer or misleading humans.
This paper presents an infinite variational autoencoder whose capacity adapts to suit the input data.
In this paper, we introduce the multiple-layer auto-encoder into image representation and propose a novel method, called Graph regularized Auto-Encoder (GAE), which can capture the latent structure of the original data and represent the data explicitly for further learning tasks such as clustering.
We propose a distributed caching system called Hoard that efficiently feeds the data across fast local disks of multiple GPU nodes using a distributed file system and achieves a 2.1x speed-up over a 10Gb/s NFS central storage system on a 16 GPU cluster.
The Attention-Dense-UNet algorithm based on the improved U-Net network for retinal vessel image segmentation .
We propose to enhance low-rank structure of the learned filters, which can be realized by constraining the successive filters within a $\ell_2$-norm ball, improving the stability and robustness to the DCF framework.
In this paper, we propose a coarse-to-fine multi-stage prediction framework for image captioning, composed of multiple decoders each of which operates on the output of the previous stage.
The small receptive field and capacity of minimal neural networks limit their performance when using them to be the backbone of detectors. In this work, we find that the appearance feature of a generic face is discriminative enough for a tiny and shallow neural network to verify from the background.
We propose a dual-branch convolutional neural network to extract base features and recovered features separately for single frame super resolution with the presence of image degradation.
We propose Bidding Machine , a comprehensive learning to bid framework, which consists of three optimizers dealing with each challenge above, and as a whole, jointly optimizes these three parts.
In this article, we evaluate computational models of natural language with respect to the universal statistical behaviors of natural Language.
We propose an efficient method which combines skeleton information and appearance features for daily-living action recognition, achieving state-of-the art results.
CutESC: Cutting edge spatial clustering technique based on proximity graphs with parametric version.
We review the progress in research that has contributed to automated pain detection, with focus on 1) the framework-level similarity between spontaneous AFER and APD problems; 2) the evolution of system design including the recent development of deep learning methods.
A promising way to deploy Artificial Intelligence (AI)-based services on mobile devices is to run a part of the AI model on the mobile itself, and the rest in the cloud.
We investigate the effectiveness of conditioning GANs when very few pixel values are provided. We propose a modelling framework to enforce pixel-wise conditioning.
We present a theoretical analysis and empirical evaluations of a novel set of techniques for computational cost reduction of classifiers that are based on learned transform and soft-threshold.
VSGNet extracts visual features from the human-object pairs, refines the features with spatial configurations of the pair, and utilizes the structural connections between the pair via graph convolutions.
In this work we propose R-GPM, a parallel computing framework for graph pattern mining through a user-defined subgraph relation, generalizing traditional GPM methods.
We propose a novel variational Gaussian process model that decouples the representation of mean and covariance functions in reproducing kernel Hilbert space in a stochastic gradient ascent.
We propose another type of adversarial attack that can cheat classifiers by significant changes.
We introduce "DenseReg", a fully-convolutional neural network (F-CNN) that densely regresses at every foreground pixel a pair of U-V template coordinates in a single feedforward pass in order to establish dense correspondences.
In this paper, we formalize continuous hierarchical reasoning and propose an optimized algorithm, namely C-Sprite, that operates in constant time and scales linearly in the number of continuous queries.
We develop a novel approach that explicitly identifies the knowledge gap between a key span in the provided knowledge and an answer choice. We propose jointly training a model to simultaneously fill this knowledge gap and compose it with the provided partial knowledge.
A robust human pose estimation method for rotational changes through large angles.
We propose a novel framework called AnonymousNet, with an effort to address these issues systematically, balance usability, and enhance privacy in a natural and measurable manner.
We propose gradient rescaling for training robust DNNs under label noise, which improves the state-of-the-art noise-tolerant algorithms by a large margin.
We propose an end-to-end region-based actor-action segmentation approach which relies on region masks from an instance segmentation algorithm for consistent labeling of both actor and action categories.
16th IEEE International Workshop on Multimedia Signal Processing, MMSP 2014; Jakarta; Indonesia; 22 September 2014 through 24 September 2014
We introduce a new graph convolution method that combines the strengths of both spatial (message passing) and spectral methods and achieves state-of-the-art performance.
A capsule is a group of neurons whose activity vector models different properties of the same entity. This paper extends the capsule to a generative version, named variational capsules, making it possible to integrate image analysis and image synthesis into a unified framework.
We propose an affine-invariant facial shape representation based on barycentric coordinates for dynamic facial expression recognition.
Learning to control an environment without hand-crafted rewards or expert data using only a stream of observations and actions.
We describe a closed-loop brain–computer interface that re-ranks an image database by iterating between user generated 'interest' scores and computer vision generated visual similarity measures.
We describe a learning-based approach to blind image deconvolution, enabling competitive performance in blind reconstruction.
This paper presents a new approach to the problem of cross-lingual dependency parsing, aiming at leveraging training data from different source languages to learn a parser in a target language.
We propose a discriminative bimodal neural network for natural-language-based visual entity localization, which can be trained with extensive use of negative samples.
We propose a deep multitask architecture for fully automatic 2d and 3d human sensing (DMHS), including recognition and reconstruction, in monocular images. The model supports the joint training of all components by means of multi-task losses.
We propose a mechanism to reconstruct part annotated 3D point clouds of objects given just a single input image. Towards this end, we introduce a location-aware segmentation loss in the training regime in order to aid the other during the training procedure.
Comparison of supervised and unsupervised retinal blood vessel segmentation methods using five publicly available databases with ground truth.
In this paper, we propose a k -reciprocal harmonious attention network (KHAN) to jointly learn discriminative spatiotemporal features and the similarity metrics for person re-identification.
We investigate the performance of features that can capture nonlinear recurrence dynamics embedded in the speech signal for the task of Speech Emotion Recognition (SER)
Neural networks for semantic segmentation can be seen as statistical models that provide for each pixel of one image a probability distribution on predefined classes. The predicted class is then usually obtained by the maximum a-posteriori probability (MAP) which is known as Bayes rule in decision theory.
We propose a method that only requires point-level annotations for instance segmentation with weakly-supervised methods.
We present the Koko system that takes declarative information extraction to a new level by incorporating advances in natural language processing techniques in its extraction language, thereby allowing for more refined extractions.
We explore an ensemble-based framework to enhance the capability of a recommender in handling diverse data, especially those where the items or users are highly diverse.
Generative Adversarial Networks for face aging partially share their parameters with GANs trained for heterogeneous applications and the aging transformation can be learned using general purpose image databases.
We propose \emph{MaxUp}, an embarrassingly simple, highly effective technique for improving the generalization performance of machine learning models, especially deep neural networks.
We propose a general framework of adversarial certification with non-Gaussian smoothing noise and for more general types of attacks, from a unified functional optimization perspective.
We propose the first multi-level face model that generalizes to multiple detail levels and can be trained end-to-end on in-the-wild images.
In local community detection by seed expansion a single cluster concentrated around few given query nodes in a graph is discovered in a localized way. A natural way to avoid the problem of choosing a specific neighborhood structure is to use a continuous relaxation of conductance, which leads to hard clusters.
The robustness of the visual system lies in its ability to perceive degraded images. This is achieved through interacting bottom-up, recurrent, and top-down pathways that process the visual input in concordance with stored prior information.
This paper introduces a method to compress RNNs for resource constrained environments using Kronecker products, achieving state-of-the-art performance.
We propose a robust VIO method based on the analysis of feature confidence in forward motion estimation using an IMU and incorporate the confidence into the Bayesian estimation framework.
We present a novel non-temporal alternative for gesture recognition using the Microsoft Kinect device which identifies distinctive portions of individual gestures which have low overlapping information with other gestures.
We propose an effective interaction-aware self-attention model inspired by PCA to learn attention maps in feature maps.
We introduce a novel knowledge distillation technique for training a student model with a significantly smaller vocabulary and lower embedding and hidden state dimensions, resulting in a language model with under 7MB.
We present the first deep learning based edge-aware technique to facilitate the consolidation of point clouds from 3D scans.
This work presents some preliminary results about exploring and proposing new extensions of common vector based subspace meth- ods that have been recently proposed to deal with very high dimensional classification problems.
We propose a Convex Sparse Principal Component Analysis (CSPCA) algorithm and apply it to feature learning.
We present O-CNN, an Octree-based Convolutional Neural Network (CNN) for 3D shape analysis.
We propose a novel stacked semantic-guided network to address the unique characteristics of sketches in zero-shot sketch-based image retrieval and improve retrieval performance.
We learn a spatial prior for the object dependent on the action (e.g. "ball" is closer to "leg of the person" in "kicking ball"), and incorporate this prior to simultaneously train a joint object detection and action classification model.
We introduce Representative Substitution (RS), a new perspective to understand the interpretation of DNNs, which provides new insights into the internal representations of deep neural networks (DNNs)
We provide an extensive evaluation with different classifiers and evaluation setups, and suggest a suitable evaluation setup for the task, eliminating biases existing in previous ones.
 ES-RNN is a hybrid between classical state space forecasting models and modern RNNs that achieves up to 322x training speedup depending on batch size with similar results as those reported in the original submission.
We formalize the concept of dataset bias under the framework of distribution shift and present a simple debiasing algorithm based on residual fitting, which we call DRiFt, which improves on baseline models on two benchmark datasets.
We propose a differentiable mask-matching network for solving the video object segmentation problem where the initial object masks are provided.
This paper proposes a pipeline using a large-scale training source to achieve a Universal Representation that can generalise to a more realistic Cross-Dataset UAR scenario.
We present a low-shot learning benchmark on complex images that mimics challenges faced by recognition systems in the wild. We then propose a) representation regularization techniques, and b) techniques to hallucinate additional training examples for data-starved classes.
This work describes experiments which probe the hidden representations and attention distributions of several BERT-style models for morphological content.
In this work we propose a method for discovering neural wirings of predefined architectures in a single training run.
In this paper, we introduce a novel multitask encoder-decoder framework for automatic semantic description and captioning of video sequences.
We extend an image-to-image translation method to generate a diverse multitude of realistically looking synthetic images based on images from a simple laparoscopy simulation, which can be used to train models for the task of liver segmentation in laparoscopic images.
Variational inference transforms posterior inference into parametric optimization thereby enabling the use of latent variable models where otherwise impractical. Traditional natural gradients based on the variational approximation fail to correct for correlations when the approximation is not the true posterior.
We introduce the “Optimal LRP” (oLRP), the minimum achievable LRP error representing the best achievable configuration of the detector in terms of recall-precision.
In this paper, a novel monocular pedestrian orientation estimation model, called FFNet, is proposed.
We propose an Information Retention Network (IR-Net) to retain the information that consists in the forward activations and backward gradients, which is the bottleneck of training highly accurate binary neural networks.
We introduce a new sub-problem of open-domain multi-hop QA, which aims to recognize the bridge (\emph{i.e.}, the anchor that links to the answer passage) from the context of a set of start passages with a reading comprehension model.
Explaining decisions of deep neural networks is a hot research topic with applications in medical imaging, video surveillance, and self driving cars. In this paper, we propose a method that can generate contrastive explanations for such data where we not only highlight aspects that are in themselves sufficient to justify the classification by the deep model, but also new aspects which if added will change the classification.
Vehicle Re-Identification in Context (VRIC) is a more realistic and challenging vehicle re-identification benchmark for testing the true performance of a re-id method.
We propose a novel parallel-objective formulation for the objective function of the neural network and introduce a novel features replay algorithm that converges to critical points under certain conditions.
We propose a novel essential tensor learning method to explore the high-order correlations for multi-view representation and improve the performance of clustering.
We present an Information-theoretic Multi-view Adaptation Model (IMAM) using a multi-way clustering scheme, where word and link clusters can draw together seemingly unrelated features across domains.
A progression of a network-only Bayes-classifier-based second-order Markov assumption for heterophilous networks.
We investigate the reported failure of state of the art (SOTA) SLAM techniques on egocentric videos where other SOTA techniques have been reported to fail.
We propose a neural transition-based parser for dependency grammar induction, whose inference procedure utilizes rich neural features with O(n) time complexity.
This paper presents a new efficient algorithm for computing temporally consistent disparity maps from video footage, achieving real-time results.
We propose a method to quantify the sensitivity of black-box vision models to visual context by editing images to remove selected objects and measuring the response of the target models.
In this work, we propose a method that combines unsupervised deep learning predictions for optical flow and monocular disparity with a model based optimization procedure for instantaneous camera pose.
We propose a method of automatically classifying these test patterns in a series of phantom images using deep learning techniques.
An overview of state-of-the-art activity recognition methods, especially for the activity representation and classification methods, as well as the datasets they used.
We introduce a cross-domain embedding from 2D images into a spherical CNN latent space. The trained model learns to encode images with 3D shape properties and is equivariant to the observed object.
We present an approach for identifying the most walkable direction for navigation using a hand-held camera in an unconstrained outdoor environment using a custom encoder-decoder architecture for semantic segmentation.
We propose a novel crowd counting approach that leverages abundantly available unlabeled crowd imagery in a learning-to-rank framework which simultaneously ranks images and estimates crowd density maps.
We propose a graph-based reasoning framework for fact-checking, which leverages the information of graphs.
We improve upon multilingual BERT's zero-resource cross-lingual performance via adversarial learning, where only labeled English data is used.
We propose an adversarial network embedding framework that leverages the strengths of generative adversarial networks in capturing latent features, and investigate its contribution in learning stable and robust graph representations.
We propose style-generators as general purpose image priors for image enhancement.
In this paper, we propose a novel end-to-end model, namely Single-Stage Grounding network (SSG), to localize the referent given a referring expression within an image.
We propose a novel embedding method called Binary Projection Bank, which can effectively reduce the very high-dimensional representations to medium-dimensional binary codes without sacrificing accuracies.
A novel approach to perform online video object detection using two consecutive frames of video sequences involving road users, based on the concatenation of a target frame with a preceding frame.
The Frank-Wolfe algorithm has become a popular first-order optimization algorithm for it is simple and projection-free, and it has been successfully applied to a variety of real-world problems. Its main drawback however lies in its convergence rate, which can be excessively slow due to naive descent directions.
In this paper, based on low-rank representation and eigenface extraction, we present an improvement to the well known Sparse Representation based Classification (SRC)
This paper focuses on better superpixels for graph-based video segmentation.
We develop a synthetic image generation tool enabling to control hazardous factors, such as making objects more specular or transparent, to produce hazardous regions at different degrees.
We present the Self-Normalization Side-Chain (SCNC), a novel approach to blind universal restoration in which no prior knowledge of the degradation is needed.
Synthesizing SQL queries from natural language is a long-standing open problem and has been attracting considerable interest recently. Toward solving the problem, the de facto approach is to employ a sequence-to-sequence-style model. Such an approach will necessarily require the SQL queries to be serialized.
We propose a deep architecture, trained solely on image level annotations, that can be used for both tool presence detection and localization in surgical videos without explicit spatial annotations.
We propose an information theoretic approach for domain adaptation in the novel context of multiple target domains with unlabeled instances and one source domain with labeled instances, which allows simultaneous adaptation from a single source to multiple targets.
This paper aims to utilize the deep learning architecture to break through the limitations of camera perspective, image background, uneven crowd density distribution and pedestrian occlusion to estimate crowd density accurately.
We propose Temporal Attentive Adversarial Adaptation Network (TA3N), which explicitly attends to the temporal dynamics using domain discrepancy, achieving state-of-the-art performance on four video DA datasets.
Automatic analysis of human facial expression is a challenging problem with many applications. In this paper, we present a system for automatic recognition of facial action units (AUs) and their temporal models from long, profile-view face image sequences.
Joint attribute learning for zero-shot learning and person re-identification using dictionary learning .
We propose a modular approach to simplify the training of a semantic segmentation CNN independently of the used dataset and the intended task.
The recent (2019-02) demonstration of the power of huge language models such as GPT-2 to memorise the answers to factoid questions raises questions about the extent to which knowledge is being embedded directly within these large models. This paper describes an architecture through which much smaller models can also answer such questions - by making use of 'raw' external knowledge.
We present a novel approach that converts partial and noisy RGB-D scans into high-quality 3D scene reconstructions by inferring unobserved scene geometry. Our approach is fully self-supervised and can hence be trained solely on real-world, incomplete scans.
A unified invariance framework for supervised neural networks that can induce independence to nuisance factors of data without using any nuisance annotations, but can additionally use labeled information about biasing factors to force their removal from the latent embedding for making fair predictions.
In this paper, we propose a deep multi-task learning framework, named as IrisParseNet, to exploit the inherent correlations between pupil, iris and sclera to boost up the performance of iris segmentation and localization in a unified model.
A novel eye-gaze contingent attention training (ECAT) based on active training in allocating attention toward positive words, in turn predicting greater reappraisal success to down-regulate negative emotions, and larger reductions in state rumination.
We formulate the 6D object pose tracking problem in the Rao-Blackwellized particle filtering framework, where the 3D rotation and 3D translation of an object are decoupled.
In this work we propose the method for a rather unexplored problem of computer vision - discriminatively trained dense surface normal estimation from a single image.
In recent years, we have experienced a flurry of contributions in the multi-label classification literature. Despite great progress, it is still unclear which modeling choices are best suited to address this task, partially due to the lack of well defined benchmarks.
This paper presents a top-down approach to 3D data analysis by fitting a morphable model to scans of faces that optimizes shape, texture, pose and illumination simultaneously.
This paper attacks the challenging problem of zero-example video retrieval. In such a retrieval paradigm, an end user searches for unlabeled videos by ad-hoc queries described in natural language text with no visual example provided.
We propose an active convolution unit, a generalization of convolution, that can define any form of CNN. Its shape can be learned through backpropagation during training.
The paper presents a novel approach to case-based classification. The algorithm is based on a notion of similarity assessment and was developed for supporting flexible retrieval of relevant information.
We present a transductive deep learning-based formulation for the sparse representation-based classification (SRC) method.
In this paper we combine a few techniques to label blood vessels in the ::: matched filter (MF) response image by using a finite element based ::: binary level set method.
In this paper, we have introduced a Transfer learning based method with multistage training for bird species classification.
The Arabic language is a morphologically rich language with relatively few resources and a less explored syntax compared to English. Given these limitations, Arabic Natural Language Processing (NLP) tasks like Sentiment Analysis (SA), Named Entity Recognition (NER), and Question Answering (QA), have proven to be very challenging to tackle.
In this paper, a method to edit face attributes by editing the latent variable with the help of a pre-trained unconditional GAN and a linear classification model is proposed.
We introduce a multimodal approach for the semantic segmentation of historical newspapers that combines visual and textual features.
Spectral Regression Kernel Discriminant Analysis (SRKDA) casts discriminant analysis into a regression framework for efficient computation.
Improving CNN-GP and CNTK with data augmentation and local average pooling .
Convolutional neural networks generate checkerboard artifacts in both of two processes. A condition for avoiding the artifacts is proposed in this paper.
We propose a novel attention mechanism to directly model long-range relationships via second-order feature statistics for person re-identification tasks.
In this paper, we propose a vanishing-point constrained Dijkstra road model for road detection in a stereo-vision paradigm.
In this paper, we build a real-time advanced driver assistance system based on a low-power mobile platform for intelligent vehicles.
Anopheles gambiae OARs and the discovery of new OAR agonists and antagonists based on virtual screening and molecular dynamics simulations.
Concept induction requires the extraction and naming of concepts from noisy perceptual experience. In a series of computational experiments, we highlight how information in the environment can be used to build and align conceptual systems in an unsupervised fashion.
We introduce a key-based classification model and a principled training scheme that protects class scores by using class-specific private keys.
We propose a new training strategy which achieves state-of-the-art results across three evaluation datasets while using 20x~100x less annotated data than competing methods.
We propose an effective approach for spatio-temporal action localization in realistic videos, where our approach outperforms the state of the art with a margin of 15%, 7% and 12% respectively.
We propose another form of weakly supervised image segmentation using image captions as they can be found on the Internet.
We introduce Polysemous Instance Embedding Networks (PIE-Nets) that compute multiple and diverse representations of an instance and optimize them jointly in the multiple instance learning framework.
This paper proposes methods based on approximate computing to reduce energy consumption in state-of-the-art ConvNet accelerators.
This paper presents a new deep neural network design for salient object detection by maximizing the integration of local and global image context within, around, and beyond the salient objects.
We propose a novel adaptive approximation approach for test-time resource-constrained prediction motivated by Mobile, IoT, health, security and other applications, where constraints in the form of computation, communication, latency and feature acquisition costs arise.
This paper extends the classic regime by reframing classification instead with the assumption that concepts present in the training set are only a sample of the hypothetical final set of concepts and introduces a novel elaboration of standard architectures called the competitive overcomplete output layer (COOL) neural network.
Generative adversarial networks (GANs) for image enhancement suffer from two drawbacks that cause a quality degradation due to a loss of detailed information. To overcome these two drawbacks, this paper presents a new resolution-preserving discriminator network architecture which removes the strided convolution layers, and a new content loss generated from the VGG network.
We introduced MARVEL, a large-scale image dataset for maritime vessels, consisting of 2 million user-uploaded images and their various attributes, including vessel identity, type, category, year built, length, and tonnage, collected from a community website.
We formalize the orientation problem in weighted protein interaction graphs as an optimization problem and present three approximation algorithms based on either weighted Boolean satisfiability solvers or probabilistic assignments. We use these algorithms to identify pathways in yeast.
We propose an end-to-end transformer model for dense video captioning, which enables the use of efficient non-recurrent structure during encoding and leads to performance improvements.
We propose a generative adversarial network-based method for unsupervised domain adaptation.
The advent of generative adversarial networks (GAN) has enabled new capabilities in synthesis, interpolation, and data augmentation heretofore considered very challenging. However, one of the common assumptions in most GAN architectures is the assumption of simple parametric latent-space distributions.
We present a method for accelerating and structuring self-attentions: Sparse Adaptive Connection (SAC), which reduces the quadratic complexity regardless of sequence length.
We demonstrate that selecting an optimal diversity subset is an NP-complete problem via reduction to set cover. We propose a slightly modified subset selection problem in which an initial greedy diversity solution is used to effectively prune an exhaustive search for all diversity subsets bounded from below.
We integrate recurrent connections across channels to both inference and generation steps, allowing the high-level features to be captured in global-to-local, coarse- to-fine manners, while maintaining the same level of computational efficacy.
We propose a simple yet robust stochastic answer network (SAN) that simulates multi-step reasoning in machine reading comprehension.
We propose a hierarchical model that encodes the data-structure at the element-level and the structure level.
Initial Contour (IC) is the essential step in level set image segmentation methods due to start the efficient process.
This paper presents a novel text-independent speaker identification method using deep convolutional neural networks and structured self-attention mechanism.
We present a novel approach for the task of human pose retrieval, and make the following contributions: first, we introduce ‘deep poselets’ for pose-sensitive detection of various body parts, that are built on convolutional neural network (CNN) features.
We introduce a new convolutional neural network architecture with the ability to adapt dynamically to computational resource limits at test time.
This paper describes scispaCy, a new tool for practical biomedical/scientific text processing, which heavily leverages the spaCy library.
We evaluated influence of skew on both threshold metrics (Accuracy, F-score, Cohen's kappa, and Krippendorf's alpha) and rank metrics (area under the receiver operating characteristic (ROC) curve and precision-recall curve) and found that skew-biased estimates of performance metrics can mask poor performance.
We show that the basic classification framework alone can be used to tackle some of the most challenging computer vision tasks.
A Generative Adversarial Network with generator $G$ trained to model the prior of images has been shown to perform better than sparsity-based regularizers in ill-posed inverse problems.
We propose a method to quantify the importance of different components in the pipeline, by computing an error contribution relative to an agnostic choice of computational steps, algorithms and hyperparameters. We also propose a methodology to quantify the propagation of error from individual components of the pipeline with the help of a naive set of benchmark algorithms.
This paper proposes a fast, novel method for semantic A/V segmentation combining deep learning and graph propagation.
This paper presents a subject-independent facial action unit (AU) detection method by introducing the concept of relative AU detection, for scenarios where the neutral face is not provided.
In this paper, training a competitive agent for playing Doom’s (FPS Game) basic scenario(s) in a semi-realistic 3D world ‘VizDoom’ using the combination of convolutional Deep learning and Q-learning by considering only the screen raw pixels in order to exhibit agent's usefulness in Doom is proposed.
We propose an attribute-aware face aging model with wavelet based Generative Adversarial Networks (GANs) to address the above issues.
Answer selection aims at identifying the correct answer for a given question from a set of potentially correct answers. Using analogical inference as our use case, we propose a neural network architecture for learning dedicated sentence embeddings that preserve analogical properties in the semantic space.
In this paper, we propose augmented hard example mining, which can be easily integrated to a common Re-ID training process and can utilize sophisticated models without any network modification.
In terrain recognition, the terrain image not only has texture features but also contains spatial features. So how to extract these two features at the same time is a challenging problem. In this paper, we introduce a deep residual texture network (DrtNet) that builds a texture detail layer in the residual convolution network and becomes an end-to-end learning network.
Unstructured point clouds are a representative shape representation of real-world scenes in 3D vision and graphics. Incompletion inevitably arises, due to the way the set of unorganized points is captured, e.g., as fusion of depth images, merged laser scans, or structure-from-x. In this paper, an end-to-end sparse- to-dense multi-encoder neural network is proposed for uniformly completing
We aim to detect all instances of a category in an image and, for each instance, mark the pixels that belong to it.
We present a novel facial expression-aware face frontalization method which directly learns the pair-wise relations between non-frontal face-shape and its frontal counterpart.
We present a novel compact scene representation based on Stixels that infers geometric and semantic information in a sound global energy minimization formulation.
This paper proposes an ordinal distribution regression with a global and local convolutional neural network for gait-based age estimation.
In many personalized recommendation problems available data consists only of positive interactions (implicit feedback) between users and items. This problem is also known as One-Class Collaborative Filtering (OC-CF). Linear models usually achieve state-of-the-art performances on OC-CF problems and many efforts have been devoted to build more expressive and complex representations able to improve the recommendations.
This paper presents an end-to-end trainable scene text recognition system (ESIR) that iteratively removes perspective distortion and text line curvature, achieving superior recognition performance for both normal and abnormal texts.
We propose SIGN, a new regularization method, which modifies the input variables using a linear transformation by estimating each variable's contribution to the final prediction.
In this paper, we address the problem of scientific-social network integration to find a matching relationship between members of these networks (i.e. The DBLP publication network and the Twitter social network).
We propose a new and, arguably, a very simple reduction of instance segmentation to semantic segmentation. This reduction allows to train feed-forward non-recurrent deep instance Segmentation systems in an end-to-end fashion using architectures that have been proposed for semantic segmentations.
We perform a comprehensive evaluation of recent sentence embedding methods using a wide variety of downstream and linguistic feature probing tasks. We show that a simple approach using bag-of-words with a recently introduced language model for deep context-dependent word embeddings proved to yield better results.
In this paper, we investigate the tendency of end-to-end neural Machine Reading Comprehension models to match shallow patterns rather than perform inference-oriented reasoning on RC benchmarks.
We propose an incremental and (near) real-time semantic mapping system that is memory and computationally efficient and bounded for large scale environments.
An efficient non-consecutive feature tracking framework to match interrupted tracks distributed in different subsequences or even in different videos.
In this paper, we investigate the efficacy of the ISP in CNN classification tasks, and outline the system-level trade-offs between prediction accuracy and computational cost.
We propose a novel mixture-of-generators network (MoGNet) for dialogue response generation, where each token of a response is drawn from a mixture of distributions.
We demonstrate first that quantization-aware training of CNNs leads to better accuracy in SNNs and propose an efficient optimization strategy to train spiking networks at lower energy consumption.
We explore the construction of meta-learning techniques for dense image prediction and identify architectures that outperform human-invented architectures and achieve state-of-the-art performance on three dense prediction tasks.
We propose a new approach to train large and diverse ensembles of deep neural networks with diverse architectures in a fraction of their training time.
We introduce a new algorithm, called stream clipper, that uses two thresholds to select elements either into a solution set $S$ or an extra buffer $B$ and then, if needed, greedily adds elements from $B$.
We propose a novel prediction criterion for latent structured prediction that maximizes the Aczel and Daroczy entropy of the latent space. We develop a single optimization algorithm and empirically show that it is as effective as the more complex approaches.
This paper addresses the real-time encoding-decoding problem for high-frame-rate video compressive sensing (CS) using a non-iterative model, named "CSVideoNet".
HyperVec represents an unsupervised measure where embeddings are learned in a specific order and capture the hypernym$-$hyponym distributional hierarchy.
We propose an efficient method for large scale hyperparameter tuning by interpreting these models in a probabilistic framework, which results in a new state of the art in link prediction on standard benchmark data.
Protein complexes do not have to be a dense subgraph of protein interactions to be predicted.
Foveation, the ability to sequentially acquire high-acuity regions of a scene viewed initially at low-ACuity, is a key property of biological vision systems. In a computer vision system, foveation is also desired to increase data efficiency and derive task-relevant features. Yet, most existing deep learning models lack the able to foveate.
We introduce a simple framework for identifying biases of a smiling attribute classifier. We leverage recent advances in generative adversarial networks to build a realistic generative model of face images that affords controlled manipulation.
In this paper, we propose a novel implicit semantic data augmentation (ISDA) approach to complement traditional augmentation techniques like flipping, translation or rotation.
This paper describes the two procedures for determining the semantic similarities between sentences submitted for SemEval 2014 Task 1. MeanMaxSim, an unsupervised procedure, is proposed as a new baseline to assess the efficiency gain provided by compositional models.
This paper proposes a deep salient feature based anti-noise transfer network (DSFATN) method that effectively enhances and explores the high-level features for RS scene classification in different scales and noise conditions.
We present a novel Motion-Attentive Transition Network (MATNet) for zero-shot video object segmentation, which provides a new way of leveraging motion information to reinforce spatio-temporal object representation.
We propose an end-to-end trainable framework, called Self-Supervised Convolutional Subspace Clustering Network (S$^2$ConvSCN), that combines a ConvNet module (for feature learning), a self-expression module ( for subspace clustering) and a spectral clustering module (For self-supervision) into a joint optimization framework.
We present a method for 3D person detection from camera images and lidar point clouds in automotive scenes in an end-to-end manner.
Temporal grounding entails establishing a correspondence between natural language event descriptions and their visual depictions. Compositional modeling becomes central: we first ground atomic descriptions "girl eating an apple," "batter hitting the ball" to short video segments, and then establish temporal relationships between the segments.
In this paper, we propose a novel convolutional encoder-decoder network with skip connections, named CEDNS, to improve the performance of saliency prediction.
In this paper we present an efficient method for visual descriptors retrieval based on compact hash codes computed using a multiple k-means assignment.
This paper tries to understand transferability from the perspectives of improved generalization, optimization and the feasibility of transferability.
We present a deep convolutional decoder architecture that can generate volumetric 3D outputs in a compute- and memory-efficient manner by using an octree representation.
This paper proposes a new scheduling method, named hyperbolic-tangent decay (HTD), for learning rate training.
We propose Sparse Weight Activation Training (SWAT), an algorithm that embodies these observations. SWAT reduces computations by 50% to 80% with better accuracy.
We propose quadric loss, a point-surface loss function, which minimizes the quadric error between the reconstructed points and the input surface and achieves better reconstruction results.
We propose a method that utilizes both the manifold structure of data and local discriminative information for semi-supervised feature learning.
We present an intriguing behavior: pre-trained CNNs can be made to improve their predictions by structurally perturbing the input.
A robust FER system which can work across several datasets using maximum entropy Markov model.
We propose a delineation algorithm that deals with bar-like structures of different thickness. The proposed method is suited for any delineation problem and employs a set of B-COSFIRE filters selective for lines and line-endings ofdifferent thickness.
Learning embedding functions, which map semantically related inputs to nearby locations in a feature space, improves state of the art performance on CUB-200-2011, Cars-196, In-Shop Clothes Retrieval and VehicleID.
A novel What-Where-When (W3) video attention module models all three facets of video attention jointly.
In this paper we propose a sequential learning framework for Domain Generalization (DG), the problem of training a model that is robust to domain shift by design.
This paper proposes a novel point-cloud-based place recognition system that adopts a deep learning approach for feature extraction without fine-tuning.
An in-depth review of recent research advances in sensor-based hand pose estimation, including wearable and vision-based solutions.
We present a semi-parametric approach to photographic image synthesis from semantic layouts that combines the complementary strengths of parametric and nonparametric techniques.
The Stixel World is a medium-level model of the environment that provides compressed and structured access to all relevant visual content of the scene. We generalize it to take into account multiple dense input streams.
We propose Hierarchical Planning and Reinforcement Learning (HIP-RL), a method for merging the benefits and capabilities of Symbolic Planning with the learning abilities of Deep Reinforcement learning.
We fuse stereo matching and the depth sensor using their complementary characteristics to improve the depth estimation.
We propose a novel approach for learning robot manipulation policies through reinforcement learning with self-learned demonstrations.
Feature-to-feature forecasting of future frames in driving scenarios using deformable convolutions .
A comprehensive analysis of the impact of each component in training VQA models so as to maximize their predictive performance.
We present DeepCache, a principled cache design for deep learning inference in continuous mobile vision that exploits temporal locality in input video streams.
In this paper, we present an efficient pedestrian detection system, designed by fusion of multiple deep neural network (DNN) systems, which achieves state-of-the-art results.
We exploit the observation from previous work that in a denoising autoencoder, training with lower levels of noise results in more specific, fine-grained features. We introduce a novel cascaded training procedure to address this.
We develop a contextualized multitask learning framework for single-image super-resolution.
Unsupervised methods for learning distributed representations of words are ubiquitous in today's NLP research, but far less is known about the best ways to learn such representations from unlabelled data.
We present LCAV-31, a multi-view object recognition dataset designed specifically for benchmarking light field image analysis tasks.
We proposed a novel single stage end-to-end trainable object detection network with Recurrent Rolling Convolution architecture over multi-scale feature maps to achieve state of the art results.
We propose a method for unsupervised video object segmentation by transferring the knowledge encapsulated in image-based instance embedding networks.
We propose an automatic biography generation framework that generates a short collection of biographical sentences clustered into multiple events of life.
We present BOLD5000, a human functional MRI (fMRI) study that includes almost 5,000 distinct images depicting real-world scenes.
In this paper, we propose a novel face alignment method that trains deep convolutional network from coarse to fine.
A robust estimator, namely M-smoother, for piecewise-constant smoothing is revisited in a numerical scheme/framework for solving it via a series of weighted-average filtering (e.g., box filtering, Gaussian filtering, bilateral filtering, and guided filtering).
We propose an innovative lightweight particle filter tracking (LPFT) approach that retains the robust tracking ability of the particle filter while alleviating the time-consuming sampling burden by the correlation filter method with response maps.
We propose a relationship-aware adversarial domain adaptation (RADA) algorithm, which first utilizes a single multi-class domain discriminator to enforce the learning of inter-class dependency structure during domain-adversarial training and then aligns this structure with the label predictor that are characterized from training source domain.
We study the nature of diffusion and damping effect of nonlocal networks by doing the spectrum analysis on the weight matrices of the well-trained networks, and propose a new formulation of the nonlocal block, which learns stable dynamics and thus allows deeper nonlocal structures.
We tested the performance of faster region-based convolutional neural network with residual neural network for detecting maize tassels from UAV images.
We formulate the problem as one of inference in a hybrid MRF composed of both continuous (i.e., slanted 3D planes) and discrete random variables.
We propose an extensible and modular lan- guage that allows the human expert to compactly represent complex search spaces over architectures and their hyperparameters, and introduce different model search algorithms, such as random search, Monte Carlo tree search, and sequen- tial model-based optimization.
This paper proposes a novel facial expression restoration method based on generative adversarial network by integrating an improved graph convolutional network (IGCN) and region relation modeling block (RRMB), which aims to restore facial expression as the ground truth.
We propose a novel Saliency Dual Attention Residual Network (SDAResNet) to extract both cross-channel and spatial saliency information for scene classification of RSI.
We propose a novel Supervised COSMOS Autoencoder which utilizes a multi-objective loss function to learn representations that simultaneously encode the (i) "similarity" between input and reconstructed vectors in terms of their direction, (ii) "distribution" of pixel values of the reconstruction with respect to the input sample, and (iii) "discriminability" in the feature learning pipeline.
We propose a novel lip-reading model which captures not only the nuance between words but also styles of different speakers, by a multi-grained spatio-temporal modeling of the speaking process, and which is robust to various conditions in speaker identity, lighting conditions, and so on.
An improved Reinforcement Learning based Action-Decision Network for object tracking.
We present a novel approach to Facial Action Unit detection using a combination of Convolutional and Bi-directional Long Short-Term Memory Neural Networks (CNN-BLSTM), which jointly learns shape, appearance and dynamics in a deep learning manner.
We introduce Guided Stereo Matching, a novel paradigm leveraging a small amount of sparse, yet reliable depth measurements retrieved from an external source enabling to ameliorate this weakness.
We propose a unified framework to train saliency detection models with diverse weak supervision sources, using category labels, captions, and unlabelled data for training.
We propose a new learning strategy to produce generalizable features by way of deep negative correlation learning (NCL), independent of the backbone fully-convolutional networks.
We revisit a pioneer unsupervised learning technique called archetypal analysis, which is related to successful data analysis methods such as sparse coding and non-negative matrix factorization.
We propose a new regularization method based on virtual adversarial loss: a new measure of local smoothness of the conditional label distribution given input.
Quantization reduces computation costs of neural networks but suffers from performance degeneration. We propose a simple yet effective technique, named scale-adjusted training (SAT), to comply with the discovered rules and facilitates efficient training.
In natural language processing, it has been observed recently that generalization could be greatly improved by finetuning a large-scale language model pretrained on a large unlabeled corpus. In this paper, we introduce a new regularization technique, to which we refer as “mixout”, motivated by dropout. Mixout stochastically mixes the parameters of two models.
We propose a new Guided Attention Network (GANet) to deal with both object detection and counting tasks based on the feature pyramid.
We propose RefineLoc, a new method for weakly-supervised temporal action localization where videos are untrimmed and only a video-level label is available.
We develop a tool, named Local Protein Community Finder, which quickly finds a community close to a queried protein in any network available from BioGRID or specified by the user. We show that the communities found by our tool form good clusters and are functionally coherent.
In this paper, we address cross-domain ReID and make contributions for both model generalization and adaptation.
We propose a metamorphic testing approach that assesses if a given inference is made based on irrelevant features and propose a new image generation strategy that can effectively attack existing models.
We propose SACANet, a novel scale-adaptive long-range context-aware network for crowd counting, effective for a wide range of crowd images.
We propose a new class of physically-realizable attacks that fool deep classifiers in a targeted fashion 49.6% of the time.
We propose negative sampling as an approach to improve the notoriously bad out-of-distribution likelihood estimates of Variational Autoencoder models. Our model pushes latent images of negative samples away from the prior.
We introduce Sparse Graphical Memory (SGM), a new data structure that stores observations and feasible transitions in a sparse memory and use it to solve long-horizon tasks.
This work introduces a new scheme for action unit detection in 3D facial videos. Sets of features that define action unit activation in a robust manner are proposed.
We propose a method based on self-training to perform unsupervised domain adaptation in the task of food classification.
We introduce RF-ReID, a novel approach that harnesses radio frequency (RF) signals for longterm person ReID, where the person wears different clothes across days.
Our paper provides information on the risk of myopathy associated with adding new drugs on the already prescribed medication, and visualizes the identified directional DDI patterns as user-friendly graphical representation.
Learning in the frequency domain with static channel selection can achieve higher accuracy than the conventional spatial downsampling approach and meanwhile further reduce the input data size.
We propose a simple yet powerful method for compressing the size of deep CNNs based on parameter binarization, based on which we design a small network with $\sim 1$ million parameters.
We propose a unified style transfer framework that combines style encoder, content encoder and mixer for unsupervised style transfer and generalizes to new styles and contents.
In this paper, we establish sensible baselines for the bAbI, SQuAD, CBT, CNN, and Who-did-What datasets, finding that question- and passage-only models often perform surprisingly well.
We develop a powerful untargeted adversarial attack for action recognition systems in both white-box and black-box settings which achieve state-of-the-art success rates on a two-stream classifier trained on the UCF-101 dataset.
We propose a data-driven non-rigid reconstruction approach that operates on RGB-D frames, while maintaining robustness under large non-Rigid deformations and producing accurate predictions.
From a simplified analysis of adaptive methods, we derive AvaGrad, an optimizer which outperforms SGD on vision tasks when its adaptability is properly tuned.
We present the first practical and competitive solution to the challenge of tracking with NL specification and propose a novel formulation to represent the history of past visual exemplars and use those exemplars to automatically reset the tracker together with our NL-RPN.
We present a human-centric method to sample and synthesize 3D room layouts and 2D images thereof, to obtain large-scale 2D/3D image data with perfect per-pixel ground truth.
We propose an in-domain GAN inversion approach, which not only faithfully reconstructs the input image but also ensures the inverted code to be semantically meaningful for editing.
We present a uniform benchmark with novel evaluation metrics and a large-scale dataset for evaluating the overall performance of image matching methods and conduct in-depth analyses regarding various aspects such as application requirements, matching types, and data diversity.
We propose a class-incremental learning paradigm called Deep Model Consolidation (DMC), which works well even when the original training data is not available.
The ability to generate novel, diverse, and realistic 3D shapes along with associated part semantics and structure is central to many applications requiring high-quality 3D assets or large volumes of realistic training data. A key challenge towards this goal is how to accommodate diverse shape variations, including both continuous deformations of parts and discrete alterations which add to, remove from, or modify the shape constituents and compositional structure.
We propose a new framework that uses a pair of multi-layer perceptron (MLP and look-up table (LUT) to transform point-coordinate inputs into high-dimensional features.
We present a method to train neural networks in a way that is almost invulnerable to severe label noise by utilizing a tiny trusted set.
We propose a novel architecture that leverages recurrent neural networks (RNN) and Kalman filtering to anticipate motions and interac- tions between objects and improve the robustness of IoT communication.
We propose three different and complementary feature learning strategies: a multi-scale architecture, an adversarial training method, and an image gradient difference loss function for pixel-space video prediction.
In this paper, we propose a deep convolution network for learning a robust face representation.
We propose SmoothOut framework to smooth out sharp minima in Stochastic Gradient Descent and thereby improve generalization.
We study the video super-resolution (SR) problem not for visual quality, but for facilitating video analytics tasks, e.g. action recognition.
We propose an imitation learning method based on video prediction with context translation and deep reinforcement learning that can learn robotic skills from videos of human demonstrations.
Annotating human poses in realistic scenes is very time consuming, yet necessary for training human pose estimators. We propose to address this problem in an active learning framework, which alternates between requesting the most useful annotations among a large set of unlabelled images, and re-training the pose estimator.
We describe an end-to-end generative approach for the segmentation and recognition of human activities using Fisher Vectors and structured temporal models.
We directly compared the MPRAGE and vNav sequences to determine if the morphometric measurements obtained from both protocols are equivalent. Reliability and reproducibility were assessed.
In this paper, we extend the intrinsic metric learning problem to semi-definite case, by which the data distribution is better described for various classification tasks.
We use gaze information as implicit information on users' mental picture and present a novel gaze pooling layer to seamlessly integrate semantic and localized fixation information into a deep image representation.
We present a method for creating video summaries in real-time on commodity hardware. Our method on average is able to generate a video summary in time that is shorter than the duration of the input video.
We present FLow Adaptive Video Object Segmentation, an efficient pipeline based on a novel online adaptation algorithm that utilizes optical flow, capable of tracking objects effectively throughout videos.
We propose a multi-scale body-part mask guided attention network (MMGA), which learns whole-body and part body attention to help extract global and local features simultaneously.
We introduce a new adversarial attack under which an adversary can choose an arbitrary image to start with and is allowed to add perceptible perturbations on it. Following this approach, we propose two techniques to significantly reduce the query complexity.
We analysed multiple instances of an identical architecture trained to classify objects in static images (CIFAR and ImageNet data sets) and compared their performance under various distortions and compared it to the intrinsic similarity between their constituent kernels.
We propose the visualization regularizer for image tasks. The proposed regularization technique enforces smoothness of the features learned by hidden nodes and turns out to be a special case of Tikhonov regularization.
In this survey, we provide a comprehensive review of PTMs for NLP.
We propose a framework to jointly prune and quantize the DNNs automatically according to a target model size without using any hyper-parameters to manually set the compression ratio.
We study the problem of restoring severely degraded face images such as images scanned from passport photos or images subjected to fax compression, downscaling, and printing.
We present recurrent geometry-aware neural networks that integrate visual information across multiple views of a scene into 3D latent feature tensors, while maintaining an one-to-one mapping between 3D physical locations in the world scene and latent feature locations.
We examine the effect of decoupling box proposal and featurization for down-stream tasks on effective transfer learning and improved image captioning and visual question answering.
We analyze the eigenspectrum dynamics of the covariance matrix of each feature map in object detectors and show that object detectors trained from ImageNet pre-trained models behave differently from those trained from scratch.
We study the phenomenon of adversarial perturbations under the assumption that the data is generated with a smooth generative model, and derive fundamental upper bounds on the robustness to perturbation of any classification function.
A new local feature based image representation method based on Gabor phase difference pattern.
This paper leverages excellent characteristics of convolution neural network in the field of image application, by using deep learning method to extract face features, and adopts factor analysis model to extract robust features.
We propose a data augmentation algorithm based on the imaging principle of the retina and convex lens, to acquire the different sizes of spectrogram and increase the amount of training data by changing the distance between the Spectrogram and the convex Lens.
We present a multimodal Recurrent Neural Network (m-RNN) model for generating novel image captions.
We utilize the most fundamental property of instance labeling- the pairwise relationship between pixels-as the learning objective, then apply it to train a fully convolutional network (FCN) for learning to perform pixel-wise clustering.
We construct a bypass enhanced RGB flow model, which combines the previous two-branch algorithm to extract RGB feature information and optical flow feature information respectively. The real-time behavior of the behavior recognition algorithm is significantly improved.
We propose a saliency guided self-attention network (SGAN) to address the WSSS problem and improve the weakly supervised semantic segmentation performance.
We propose a convolutional neural network based encoder-decoder architecture for embedding of images as payload for image steganography.
We present a character-based model for joint segmentation and POS tagging for Chinese.
We introduce a bottom-up and top-down approach for reorganization of the ImageNet hierarchy based on all its 21,814 classes and more than 14 million images.
We address the problem of Visual Question Answering (VQA), which requires joint image and language understanding to answer a question about a given photograph. We propose a model we call the Spatial Memory Network and apply it to the VQA task.
In this paper, we propose a novel dense surfel mapping system that scales well in different environments with only CPU computation.
We tackle the problem of Human Locomotion Forecasting, a task for jointly predicting the spatial positions of several keypoints on the human body in the near future under an egocentric setting. We use state-of-the-art models to generate (noisy) annotations and propose robust forecasting models.
Detecting manipulated images has become a significant emerging challenge. We address this problem in this paper, for which we introduce a manipulated image generation process that creates true positives using currently available datasets.
We propose an interpretable reinforcement learning based approach to the multi-shot pedestrian re-identification problem.
We present a fast and flexible denoising convolutional neural network, namely FFDNet, with a tunable noise level map as input.
We propose a method of incorporating high-level semantic concepts into the CNN-RNN approach, and show that it achieves a significant improvement on the state-of-the-art performance in both image captioning and visual question answering.
We propose a new, simple, and computationally inexpensive termination test for constant step-size stochastic gradient descent applied to binary classification on the logistic and hinge loss.
The combination of neural network and fuzzy systems into neuro-fuzzy systems integrates fuzzy reasoning rules into the connectionist networks.
We present a novel feature learning framework for salient object detection, in which we cast the SOD as a pixel-wise classification problem.
The paper introduces a novel deep learning architecture aiming to mitigate the gradient-vanishing problem, in which the earlier hidden layer neurons could be directly connected with the last hidden layer and feed into the last layer for classification.
We present a novel identity-enhanced network (IDEnNet) for facial expression recognition.
Symmetric Two Dimensional Clustering based Discriminant Analysis for two dimensional subspace learning .
This paper introduces a video representation based on dense trajectories and motion boundary descriptors and introduces a descriptor based on differential optical flow.
We show that for PGD-attacks, there is a training stage where neural networks start heavily relying on non-robust features to boost natural accuracy, while natural accuracy is not hurt.
We design a novel framework for video-based person re-id, which consists of two main modules: Synchronized Transformation (ST and Intra-clip Aggregation (ICA)
In this paper, we ask the fundamental question of whether Chinese word segmentation (CWS) is necessary for deep learning-based Chinese Natural Language Processing. We benchmark neural word-based models which rely on word Segmentation against neural char- based models which do.
In this paper, a new lightweight Siamese network is proposed for feature extraction. Inspired by the face verification algorithm DeepID2, the Bayesian verification model is applied for candidate selection.
We present GLNet, a self-supervised framework for learning depth, optical flow, camera pose and intrinsic parameters from monocular video -- addressing the difficulty of acquiring realistic ground-truth for such tasks.
We propose an adaptive logarithmic loss function to mitigate two prominent problems in medical image segmentation namely: i) class imbalance and poor loss function convergence.
Fusing instance and semantic segmentation can automatically identify reflection false positives, without explicitly needing to have the reflective regions labelled.
The purpose of this study is to determine whether current video datasets have sufficient data for training very deep convolutional neural networks (CNNs) with spatio-temporal threeD kernels.
We propose Convolution 3D feature, a generic spatio-temporal feature obtained by training a deep 3D convolutional network on a large annotated video dataset comprising objects, scenes, actions, and other frequently occurring concepts.
We propose a novel model named Interaction-Aware Factorization Machine, which learns feature interaction importance in a stratified manner, which allows for more leverage in tweaking the interactions on both feature-wise and field-wise levels.
We construct a new visual encoding framework to predict cortical responses in a fMRI dataset and train a nonlinear mapping from visual features to brain activity.
This paper presents StereoNet, an end-to-end deep architecture for real-time stereo matching that runs at 60fps on an NVidia Titan X, producing high-quality, edge-preserved, quantization-free disparity maps.
We propose a novel double-batch-split co-training approach for person re-identification using a multi-branch network architecture that achieves diversity between global and feature-dropping branches.
An ability to generalize unconstrained conditions such as severe occlusions and large pose variations in face alignment using spatial transformer networks, hourglass networks and exemplar-based shape constraints.
This paper describes a substantial effort to build a real-time interactive multimodal dialogue system with a focus on emotional and nonverbal interaction capabilities.
We propose a framework based on multi-stream convolutional neural networks for group activity recognition.
This paper describes the ON-TRAC Consortium translation systems developed for the end-to-end model task of IWSLT Evaluation 2019 for the English- to-Portuguese language pair.
We present a deep learning model to efficiently detect a disease from an image and annotate its contexts (e.g., location, severity and the affected organs).
We unite these discrepant findings by reporting that object recognition involves enhanced feedback activity (recurrent processing within early visual cortex) when target objects are embedded in natural scenes that are characterized by high complexity.
We propose a task-guided and path-augmented heterogeneous network embedding model for author identification under double-blind review setting.
To address the uncertain motion tracking problem, a tracking method based on the Markov Chain Monte Carlo and correlation filters is proposed that performs favorably against state-of-the-art methods.
We propose a novel face recognition method that uses texture features obtained by calculating mean and standard deviation of Gabor and curvelet transformed face images.
We propose a novel database generation method that requires only (i) arbitrary natural images, i.e., templates synthetically created to illustrate the appearance of the category of a traffic sign, and (ii) templates of the traffic signs, and it is effective for the training of a deep detector.
We formulate a "universal model learning" approach enabling domain-generic person re-identification using only limited training data of a "{\em single}" seed domain.
This paper presents resource-aware algorithms for distributed inter-robot loop closure detection for applications such as collaborative simultaneous localization and mapping.
We propose a novel two-branch stripe-based and attribute-aware deep convolutional neural network to learn the efficient feature embedding for vehicle Re-ID task.
We propose to balance the popular VQA dataset by collecting complementary images such that every question in our balanced dataset is associated with not just a single image, but rather a pair of similar images that result in two different answers to the question.
We propose SkyNet, a bottom-up DNN design approach with comprehensive understanding of the hardware constraints at the very beginning to deliver hardware-efficient DNNs.
In this work, we propose a light-weighted saliency detection approach with distinctively lower runtime memory cost and model size.
We propose a new Q\&A model that does not require recurrent networks, yet achieves equivalent or better performance than existing models.
This thesis explore different approaches using Convolutional and Recurrent Neural Networks to classify and temporally localize activities on videos, furthermore an implementation to achieve it has been proposed.
Singing voice detection is the task to identify the frames which contain singer vocal or not. Although there are several methods which have been proposed, a more robust and more complete system is desired to improve the detection performance.
We proposed a method for blood-vessel segmentation that could deal with the problem of detecting vessels of varying diameters in high- and low-resolution fundus images and improve the multiscale line detection method.
We propose a scalable, efficient and accurate approach to retrieve 3D models for objects in the wild using a CNN-based multi-view metric learning approach.
We perform a series of refinements with the MSPN and PoseFix Networks, and empirically evaluate their impact on the final model performance through ablation studies.
In this paper, we propose a hybrid network architecture, grounded on self-attention and relational reasoning for abstract visual reasoning.
We introduce a new pretext task, Region Reconstruction, motivated by deformations encountered in sim-to-real transformation.
We introduce a novel distributed derivative-free optimization framework that is resilient to stragglers.
We proposed a cross-subject decoding approach using deep transfer learning (DTL) to decipher the behavior tasks from functional magnetic resonance imaging (fMRI) recording during subjects performing different tasks.
We use generative adversarial networks to generate privacy-preserving artificial data that retain statistical properties of real data while limiting potential privacy loss.
One-Shot Fine-Grained Instance Retrieval (OSFGIR) for large-scale fine-grained object identification.
We propose in this paper a new approach for fast disparity map estimation from pair of stereo images using neuronal DSI.
We propose a Transformer-based neural network for answer selection, where we deploy a bidirectional long short-term memory behind the Transformer to acquire both global information and sequential features in the question or answer sentence.
We propose a novel salient object detection algorithm for RGB-D images using center-dark channel priors.
In this paper, we introduce a new metric named Mean Local Group Average Precision (mLGAP), a retrieval performance measure that also reconciles the utilization of hash codes, leading to a more practically meaningful performance metric than conventional ones like mAP.
We propose exploiting the multi-shots of the same identity to guide the feature learning of each individual image for boosting the single image based re-id.
We propose a novel Pyramid Density-Aware Attention-based network, abbreviated as PDANet, for density-aware crowd counting.
In this paper, we introduce a drastically different way to handle synthetic images that does not require seeing any real images at training time.
We propose an end-to-end trainable and single-column crowd counting model called the SMCA-CNN which achieves state-of-the-art performance on five challenging datasets.
RGB-D data has turned out to be a very useful representation of an indoor scene for solving fundamental computer vision problems. In this paper, we systematically survey popular RGB-D datasets for different applications including object recognition, scene classification, 3D-simultaneous localization and mapping, and pose estimation.
Robotic challenges like the Amazon Picking Challenge (APC) or the DARPA Challenges are an established and important way to drive scientific progress. However, such challenge events occur only occasionally, are limited to a small number of contestants, and the test conditions are very difficult to replicate after the main event.
Automatically describing an image with a sentence is a long-standing challenge in computer vision and natural language processing. We propose a novel paradigm for evaluating image descriptions that uses human consensus.
Visual question answering is the task of returning the answer to a question about an image. A challenge is that different people often provide different answers to the same visual question. To our knowledge, this is the first work that aims to understand why.
An explicit embedding reducing manifold search to Euclidean search followed by dot product similarity search.
We present a reformulation of Deformable Convolutional Networks that improves its ability to focus on pertinent image regions, through increased modeling power and stronger training.
This paper investigates the use of conic section geometry to improve the shape cue of the traffic lights detection and pose estimation.
We propose an end-to-end method to learn discriminative binary representation for cross-view retrieval, image to image retrieval, and image annotation/tagging.
We propose the head-body alignment net (HBAN) in this work, which aims to enhance pedestrian detection by fully utilizing the human head prior by using weak annotations inferred directly from body boxes.
We present an approach that combines automatic features learned by convolutional neural networks (CNN) and handcrafted features computed by the bag- of-visual-words (BOVW) model in order to achieve state-of-the-art results in facial expression recognition.
We identify two pathological cases of temporal inconsistencies in video generation: video freezing and video looping. To address this, we reformulate the problem of video generation as a Markov Decision Process (MDP) with an infinite forecast horizon to mitigate the presence of temporal artifacts.
We propose a novel two-step method for rewriting Wikipedia articles for new claims, achieving SARI score.
We show that shape correspondences can be obtained by performing many shape recognition tasks where the core evaluation mechanism only recognizes shapes globally. This is made possible by casting the part correspondence problem in a deformation-driven framework.
We address the task of 3D semantic scene completion, i.e. predicting the semantic labels and occupancy of voxels in a 3D grid representing the scene.
We audit ArcFace, a state-of-the-art, open-source facerecognition system, in a large-scale face identification experiment and find Rank-1 identification accuracy of 79.71% for individualspresent in training data and 75.73% for those not present.
In this work we propose a novel method for supervised, keyshots based video summarization by applying a conceptually simple and computationally efficient soft, self-attention mechanism.
We propose a novel Fashion Editing Generative Adversarial Network (FE-GAN), which is capable of manipulating fashion images by free-form sketches and sparse color strokes.
We apply Generative Adversarial Networks (GANs) to the domain of digital pathology to capture key tissue features, and present a vision of how these could link cancer tissue and DNA in the future.
This paper aims to raise people's awareness about the security of the quantized models, and we designed a novel Defensive Quantization (DQ) method to jointly optimize the efficiency and robustness of deep learning models.
We study the case of additive `at most one' (AMO) preferences where individuals want at most 1 of each item and lotteries are allowed. We show that in this case the MNW solution is still a convex program and importantly is a CEEI solution.
We extend powerful recent unsupervised loss functions for learning deep nonlinear embeddings to multi-stream temporal processing architectures on large-scale video datasets, improving state of the art learning from video data.
We propose a deep continuous conditional random field (DCCRF) for solving the online MOT problem in a track-by-detection framework.
This paper proposes an end-to-end deep learning framework for facial AU detection with graph convolutional network (GCN)
We define graphon signals and introduce the Graphon Fourier Transform (WFT), to which the GFT converges, hinting to the possibility of centralizing analysis and design on graphons to leverage transferability.
We propose a novel technique to make neural network robust to adversarial examples using a generative adversarial network.
We present a numerical methodology for construction of reduced order models, ROMs, of fluid flows through the combination of flow modal decomposition and regression analysis.
We develop a system to disambiguate between novel objects, observed via depth images, based on natural language descriptions, and generalize to viewpoints not represented in the language-annotated depth image training set.
We present a method for discovering and exploiting object specific convolutional channels of a CNN in which neurons are activated by the presence of specific objects in the input image.
In this paper, we design a simple convolutional neural network architecture that is able to learn to compute dense disparity maps directly from the stereo inputs.
In this paper, we propose to unify all the input information by natural language so as to convert VQA into a machine reading comprehension problem.
We propose to solve the 3D pose estimation problem in a CNN regression framework with a suitable representation, data augmentation and loss function that captures the geometry of the pose space.
We present a novel 3D object detection framework, named IPOD, based on raw point cloud. It seeds object proposal for each point, which is the basic element.
GLAMOR performs global and local feature extraction simultaneously in a unified model to achieve state-of-the-art performance in vehicle re-id.
We build a simple person recognition framework that leverages convnet features from multiple image regions (head, body, etc.). We propose new recognition scenarios that focus on the time and appearance gap between training and testing samples.
The authors propose a new metric learning method for person re-identification, which formulates the metric learning problem as a constrained optimisation problem by imposing a constraint on the linear transformation matrix.
We propose a new neural network topology for similarity learning that significantly improves the performance on the author verification task with such challenging data sets.
We consider the problem of aligning continuous word representations, learned in multiple languages, to a common space, leading to better alignments.
In this paper, we introduce a novel style-attentional network (SANet) that efficiently and flexibly integrates the local style patterns according to the semantic spatial distribution of the content image.
We introduce a human-mask loss to automatically guide the activations of the feature maps to the target human who is performing the action, and hence suppress the activATIONS of misleading contexts.
We empirically demonstrate that mutual information-based representation learning approaches do fail to learn complete representations on a number of designed and real-world tasks. To mitigate these problems we introduce the Wasserstein dependency measure, which learns more complete representations.
We study the role of cortical noise in generalization during learning, and propose a hypothesis that the noise in the cortex can be used to move the representation of the stimulus in-class.
We provide design principles for optimizing the crypto-oriented neural network architectures to reduce the runtime of secure inference, which significantly improves the efficiency ofsecure inference.
We investigate the question of where to binarize inputs at layer-level granularity and show that selectively binarizing the inputs to specific layers in the network could lead to significant improvements in accuracy while preserving most of the advantages of binarization.
We propose a salient object segmentation method which integrates saliency, superpixel, and background connectivity prior to achieve state-of-the-art performance and computational efficiency.
We propose an efficient likelihood Bayesian constrained local model, which employs random-forest regressors to estimate the location of each landmark, as a likelihood term, efficiently.
We propose a meta-learning framework for video frame interpolation that generalizes across different videos by making use of test time information.
We present a novel algorithm for the semantic labeling of photographs shared via social media that maximizes classifier performance.
In this paper, we propose a novel method based on deep learning for complex HAR in the real-scene in the off-line training stage.
We propose and evaluate several deep neural network architectures to combine image information across a video over longer time periods than previously attempted.
We address the problem of high-dimensionality of feature vectors extracted from neural networks by taking care of the global statistics of feature space. We utilize the equivalence between LDA and Canonical Correlation Analysis.
We introduce a neural network layer based on canonical correlation analysis (CCA) that learns better embedding spaces by analytically computing projections that maximize correlation.
Adversarial examples are an academic curiosity, not a security threat, when one considers the normal image acquisition process. Normal preprocessing, such as text binarization, almost completely neutralizes adversarial examples.
We propose to solve cluster selection problem monotonically in the dual LP, iteratively selecting clusters with guaranteed improvement, and quickly re-solving with the added clusters by reusing the existing solution.
We propose a deep neural architecture that combines learned local and global features in its initial stages and replicates a message passing algorithm between classes similar to a graphical model inference approach in later stages.
We investigate how to help AI systems to better recognize rare relationships like, where the subject S, predicate P, and/or the object O come from the tail of the corresponding distributions.
We propose to replace the handcrafted update function for Siamese trackers with a convolutional neural network which learns to update.
A comparison of state-of-the-art aggregation methods applied to binary features and the combination of the aggregated binary features with the emerging Convolutional Neural Network features.
We present a semantic grasping framework that learns object detection, classification, and grasp planning in an end-to-end fashion in a self-supervised fashion.
In this paper, a deep convolutional neural network is proposed to extract high-level semantic features and a binary hash function is then integrated into this framework to achieve an end-to-end optimization.
Unsupervised Bag-of-Words for person re-identification as an image search problem.
We propose a probabilistic regression formulation for visual tracking and apply it to the task.
In this paper, we address the problem of learning discriminative part detectors from image sets with category labels. We propose a novel latent SVM model regularized by group sparsity.
In this paper, we propose a feature describing expression intensity over time, while being invariant to person and the type of performed expression.
Training robust deep video representations has proven to be much more challenging than learning deep image representations and consequently hampered tasks like video action recognition.
We revive the use of old-fashioned handcrafted video representations and put new life into these techniques via a CNN-based hallucination step.
RepPoints are a finer representation of objects as a set of sample points useful for both localization and recognition. They furthermore do not require the use of anchors.
We propose a novel deep 2D convolutional neural network (CNN) architecture for DBT classification that simultaneously overcomes both challenges.
Multi-channel auto-encoder for emotion recognition from acoustic information .
In many learning tasks, including semantic image segmentation, performance can be effectively improved through the fine-tuning of a pre-trained convolutional network, instead of training from scratch.
We propose D3VO as a novel framework for monocular visual odometry that exploits deep networks on three levels -- deep depth, pose and uncertainty estimation. We first propose a novel self-supervised monocular depth estimation network trained on stereo videos without any external supervision.
We provide a novel deep image saliency computing (DISC) framework for fine-grained image Saliency computing, capable of uniformly highlighting the objects of interest from complex background while preserving well object details.
We introduce a new convolutional neural network module that combines residual structure and multiple convolution, achieving state-of-the-art results on CIFAR-10, MNIST and CIFar-100 with 26 layers and only 19k parameters.
We propose a video loss module for one-shot video object segmentation, which can improve the segmentation performance significantly, compared to that of OSVOS.
We describe a policy learning approach to map visual inputs to driving controls that leverages side information on semantics and affordances of objects in the scene from a secondary teacher model.
We use thousands of 3D scans to train a new, unified, 3D model of human body, SMPL-X, that extends SMPL with fully articulated hands and an expressive face.
We propose an end-to-end and efficient HPO algorithm named as Transfer Neural Processes, which achieves transfer learning by incorporating trials on other datasets, initializing the model with well-generalized parameters, and learning an initial set of hyperparameters to evaluate.
We study a theoretical model that connects deep learning to finding the ground state of the Hamiltonian of a spherical spin glass. We leverage a technique known as topology trivialization where, upon perturbation by an external magnetic field, the energy landscape of the spin glass Hamiltonian changes dramatically from exponentially many local minima to total trivialization.
We provide a comprehensive survey of the recent developments on deep FR, covering the broad topics on algorithms, data, and scenes.
This paper introduces a novel methodology that combines the multiresolution feature of the discrete wavelet transform (DWT) with the local interactions of the facial structures expressed through the structural hidden Markov model (SHMM) for face identification.
In this paper, we introduce an unsupervised framework for training image estimation networks, from a training set that contains only measurements---with two varied measurements per image---but no ground-truth for the full images desired as output.
The method based on the two-stream networks has achieved great success in video action recognition. In this paper, we propose a spatiotemporal heterogeneous two- stream network, which employs two different network structures for spatial and temporal information.
We introduce an adversarial framework to enforce fairness constraints on graph embeddings, which can flexibly accommodate different combinations of fairness constraints.
In this paper, we explore meta-learning for few-shot text classification.
We propose a simple model that is able to generate descriptive sentences given a sample image using the phrases inferred.
In this paper, we address the single image haze removal problem in a nighttime scene using a deep learning based DeGlow-DeHaze iterative architecture.
This paper explicitly focuses on a content-and style-aware stylization of a content image. We introduce a content transformation module between the encoder and decoder and introduce a novel normalization layer critical for high resolution image synthesis.
We present Hierarchical Graph Network (HGN) for multi-hop question answering.
In this paper, we propose a novel multi-scale residual convolutional neural network structure based on a \emph{scale-space approximation (SSA)} block of layers, comprising subsampling and subsequent upsampling.
Instrument recognition is a fundamental task in music information retrieval, yet little has been done to predict the presence of instruments in multi-instrument music for each time frame. In this paper, we use the newly released MusicNet dataset to study this front, by building and evaluating a convolutional neural network for making frame-level instrument prediction.
This paper proposes the novel task of video generation conditioned on a SINGLE semantic label map, which provides a good balance between flexibility and quality in the generation process.
We present a deep reinforcement learning method of progressive view inpainting for 3D point scene completion under volume guidance, achieving high-quality scene reconstruction from only a single depth image with severe occlusion.
This paper proposes a Low-rank and Sparse DCF that improves the relevance of features used by discriminative filters, delivering outstanding performance compared to state-of-the-art trackers.
We provide a block-wise network generation pipeline which automatically builds high-performance networks using the Q-Learning paradigm with epsilon-greedy exploration strategy.
We dramatically improve the qualitative state of the art of activation maximization by harnessing a powerful, learned prior: a deep generator network (DGN)
In this paper, we introduce weighted mean curvature as a novel image prior and present an efficient computation scheme for its discretization in practical image processing applications.
We adapt a neural QA system trained on a large open-domain dataset (SQuAD, source) to a biomedical dataset (BioASQ, target) and achieve state-of-the-art results on factoid questions and competitive results on list questions.
This paper proposes a novel coarse-to-fine feature adaptation approach to cross-domain object detection.
Dense disparity map estimation from a high-resolution stereo image is a very difficult problem in terms of both matching accuracy and computation efficiency. To solve these problems, we introduce an efficient hierarchical stereo matching method in two-scale space.
We propose a new KB relation detection model via multi-view matching which utilizes more useful information extracted from question and KB.
In this paper, we propose a simple feed-forward deep network for motion prediction, which takes into account both temporal smoothness and spatial dependencies among human body joints for state of the art performance.
In this paper we show how the design of an optimization algorithm can be cast as a learning problem, allowing the algorithm to learn to exploit structure in the problems of interest in an automatic way.
We demonstrate that the Bayesian uncertainty estimates directly correlate with the rarity of classes and the difficulty level of individual samples and propose a novel framework for uncertainty based class imbalance learning that efficiently utilizes sample and class uncertainty information.
In this paper, we propose a novel generalized deep neural network architecture where temporal streams from multiple modalities are combined.
We propose an expertdriven probabilistic approach for joint modeling and estimation of AU intensities, allowing human coders to faster make decisions about target AU intensity.
We study the problem of learning to learn at both training and test time in the context of visual navigation and propose a self-adaptive visual navigation method which learns to adapt to new environments without any explicit supervision.
We propose a generative adversarial network for tracking-by-detection based on adversarial learning to address the problem of class imbalance.
We propose a method to incrementally learn an embedding space over the domain of network architectures, to enable the careful selection of architectures for evaluation during compressed architecture search.
We investigate deep generative models that can exchange multiple modalities bi-directionally, e.g., generating images from corresponding texts and vice versa.
We study to what extend Chinese, Japanese and Korean faces can be classified and which facial attributes offer the most important cues.
This paper presents a novel model-free reinforcement learning (RL) framework to design feedback control policies for 3D bipedal walking.
We propose a novel asymmetric deep supervised hashing method for large-scale nearest neighbor search.
In this paper we address the detection of micro and full-expression with a common facial model characterizing facial movements by means of consistent Optical Flow estimation.
We explore the bounds on improvement by using contextual relations between objects and provide a tool for identifying the most helpful ones. We show that simple co-occurrence relations can often provide large gains.
We introduce a general-purpose conditioning method for neural networks called FiLM: Feature-wise Linear Modulation. FiLM layers influence neural network computation via a simple, feature-wise affine transformation based on conditioning information.
This is the final peer-reviewed manuscript that was accepted for publication in Natural Language Engineering. Changes resulting from the publishing process, such as editing, corrections, structural formatting, and other quality control mechanisms may not be reflected in this document.
Accurate depth maps are a pre-requisite in three-dimensional television, e.g. for high quality view synthesis, but this information is not always easily obtained.
We discuss and predict the evolution of Simultaneous Localisation and Mapping (SLAM) into a general geometric and semantic `Spatial AI' perception capability for intelligent embodied devices.
We propose a progressive generative model of three stages, i.e., generating a coarse bounding-boxes layout, refining it to a finer segmentation layout, and mapping the layout to a realistic output.
We propose a novel temporal pooling approach to aggregate the frame-level features for video-based action recognition.
We investigate whether generative conversational models can be leveraged to transfer affective knowledge for the target task of detecting emotions in context.
A comparative study of classifiers used for facial emotion recognition along with intensity estimation of those emotions for databases.
We introduce Appearance-MAT (AMAT), a generalization of the medial axis transform for natural images, that is framed as a weighted geometric set cover problem, and introduce a clustering scheme that takes advantage of the additional scale and appearance information to group individual points into medial branches.
We investigated the functional brain networks under different attributes of vocal emotion by graph-theoretical network analysis.
We propose the Siamese network of fused response map that use the Alexnet network with fine tuning to extract target features, and weight fusion of score maps to estimate the final position of object.
This paper presents a novel way to transfer model weights from one domain to another using residual learning framework instead of direct fine-tuning for multi-shot person re-identification.
A simple and efficient network for small target detection in deep learning.
This paper proposes the method of learning a mixture of SR inference modules in a unified framework to tackle this problem, achieving state-of-the-arts restoration results.
We introduce Scheduled Differentiable Architecture Search (SDAS) for both image and video recognition that nicely integrates the selection of operations during training with a schedule.
We present a gesture recognition deep neural network which recognises ego hand gestures from videos (videos containing a single gesture) by generating and recognising embeddings of ego hands from image sequences of varying length.
We study and formulate statistical arbitrage in display advertising and propose a meta-bidder that captures and exploits the transient arbitrage opportunities in Real-Time Bidding.
We propose a self-similarity-based approach that is able to use large groups of similar patches extracted from the input image to solve the SISR problem. We introduce a novel prior leading to the collaborative filtering of patch groups in a 1D similarity domain.
We propose an end-to-end graph-based feature learning framework for neuromorphic vision sensing, which generalizes to both object classification and action recognition.
In the paper, a method for the estimation of the contact force and contact location is proposed. The method is based on nonlinear constrained optimization.
We provide a rigorous non-asymptotic analysis for the convergence of LPs and GPRs to their mean-field values on edge-independent random graphs, and propose a new GPR, termed Inverse PR, with LP weights that increase for initial few steps of the walks.
Action prediction on a partially observed action sequence is a very challenging task. To address this challenge, we first design a global-local distance model, where a local-temporal distance compares subsequences as a whole and local-Temporal distance focuses on individual segment to adapt its contribution.
We use a Siamese embedding function to improve three aspects of tracking by detection.
We propose a fully-attentive VLN architecture incorporating three different modalities - natural language, images, and discrete actions for the agent control.
Residual networks, which use a residual unit to supplement the identity mappings, enable very deep convolutional architecture to operate well, however, the residual architecture has been proved to be diverse and redundant, which may leads to low-efficient modeling. In this work, we propose a competitive squeeze-excitation mechanism for the residual network, which can challenge state-of-the-art results.
We present Action Bank, a new high-level representation of video that is semantically rich and capable of highly discriminative performance.
We propose a deep neural network-based framework which utilizes the view information in the feature extraction stage for person re-identification.
We propose to quantize all parts of standard classification networks and replace the activation-weight--multiply step with a simple table-based lookup, which results in networks that are free of floating-point operations and free of multiplications.
We introduce a real-world seismogram quality classification dataset based on 6,613 examples, manually labeled by human experts as good, bad or ugly, according to their noise intensity, for seismic shot-gathers quality prediction.
We propose Bayesian Conditional Generative Adversarial Networks (BC-GANs) that extend traditional GANs to a Bayesian framework, and naturally handle unsupervised learning, supervised learning, and semi-supervisedLearning problems.
We propose semantic PBA which incorporates a 3D object prior, obtained through deep learning, within the photometric bundle adjustment problem, and achieve state of the art performance across natural sequences.
This paper addresses the problem of recovering 3D human pose from a single monocular image, using a discriminative bag-of-words approach.
We present EmotiCon, a learning-based algorithm for context-aware perceived human emotion recognition from videos and images.
In order to learn semantically discriminative features, we propose to map images onto class embeddings whose pair-wise dot products correspond to a measure of semantic similarity between classes.
We proposed a new and simple structure based on the original residual block and named as feature reuse residual block which combines feature from the input signal of a residual block with the residual signal.
We propose a new machine learning approach (VAMBN) to learn a generative model of longitudinal clinical study data that simulates virtual patients in a sufficiently realistic manner.
We introduce a new minima path-based model for minimally interactive tubular structure centerline extraction in conjunction with a perceptual grouping scheme.
We present M-PACT to overcome existing issues by removing the need to develop boilerplate code which allows users to quickly prototype action classification models while leveraging existing state-of-the-art (SOTA) models.
In this paper, a feature selection visual tracking algorithm combining CNN based MDNet(Multi-Domain Network) and RoIAlign was developed and it can run at around 10 fps(while the speed of MDNet is about 1 fps).
We study the problem of learning representations with controllable connectivity properties. In particular, we control the connectivity of an autoencoder's latent space via a novel type of loss, operating on persistent homology.
We present a novel view synthesis approach based on stereo-vision and CNNs that decomposes the problem into two sub-tasks: view dependent geometry estimation and texture inpainting.
This paper presents an approach to whole cervical cell segmentation using a mask regional convolutional neural network and classifies this using a smaller Visual Geometry Group-like Network (VGG-like Net)
We propose a general adversarial training framework for neural network-based recommendation models, which improves both the model robustness and the overall performance.
A cell’s epigenome arises from interactions among regulatory factors—transcription factors and histone modifications—co-localized at particular genomic regions. We developed a statistical method, ChromNet, to infer a network of these interactions, the chromatin network, by inferring conditional-dependence relationships among a large number of ChIP-seq data sets.
A vehicle Re-ID framework with a background interference removal mechanism to improve the vehicle re-identification performance as well as robustness against complex background in large-scale spatio-temporal scenes.
We propose an interpretable parametric generative model of human action videos that relies on procedural generation, physics models and other components of modern game engines. We introduce a deep multi-task learning architecture that is able to simultaneously learn from synthetic and real video datasets, even when their action categories differ.
Feature Interaction-Aware Graph Neural Networks for Graph Learning .
We propose a new method that optimizes the generation of 3D training data based on what we call "hybrid gradient". We parametrize the design decisions as a real vector, and combine the approximate gradient and the analytical gradient to obtain the hybrid gradient.
Estimation of facial expressions, as spatio-temporal processes, can take advantage of kernel methods if one considers facial landmark positions and their motion in 3D space.
In this paper, we introduce Random Erasing, a new data augmentation method for training the convolutional neural network (CNN)
We learn a patch-based graph representation for visual tracking and apply it in object tracking and model updating.
Improving Spatial Tensor Aggregation using co-occurrences of local patterns in a tensor framework.
We investigate whether providing the full reasoning chain of multiple passages, instead of just one final passage where the answer appears, could improve the performance of existing QA models.
We propose a novel domain adaptation technique that takes advantage of our synthetic data and performs fine-tuning in a completely unsupervised way to achieve better accuracy in unseen illumination conditions.
In this paper we tackle the problem of vehicle re-identification in a camera network utilizing triplet embeddings.
In this paper, we propose our Correlation For Completion Network (CFCNet), an end-to-end deep learning model that uses the correlation between two data sources to perform sparse depth completion.
In this paper, we present a generalized Fisher score to jointly select features.
We propose a deep covariance estimation hashing method with robust covariance form to improve hash code quality.
We show that there is a strong norm bias in the MIPS problem, which means that the large norm items are very likely to become the result of MIPS. We propose the ip-NSW+ algorithm, which improves ip- NSW by introducing an additional angular proximity graph.
We define rational recurrences to be recurrent hidden state update functions that can be written as the Forward calculation of a finite set of WFSAs. We show that recurrent neural networks also share this connection to WFSA.
Evolution-based evolutionary algorithms can work at DNN scales, including Atari, humanoid locomotion, and novelty search.
We capitalize on large amounts of unlabeled video in order to learn a model of scene dynamics for both video recognition tasks (e.g. action classification) and video generation tasks.
We present a deep convolutional neural network (CNN) architecture to localize semantic parts in 2D image and 3D space while inferring their visibility states, given a single RGB image.
In this paper we introduce an ensemble method for convolutional neural network (CNN), called"virtual branching,"which can be implemented with nearly no additional parameters and computation on top of standard CNNs.
A Siamese network to generate representative 3D descriptors for point matching in point cloud registration.
Deep CNNs for semantic segmentation have high memory and run time requirements. Various approaches have been proposed to make CNNs efficient like grouped, shuffled, depth-wise separable convolutions.
We introduce a data-efficient, model-based reinforcement learning algorithm that learns a closed-loop control policy directly from pixel information.
In this paper, we proposed a pose estimation system based on rendered image training set, which predicts the pose of objects in real image, with knowledge of object category and tight bounding box.
In this paper, we propose a decision controller (DC) which is generally applicable to both SOT and multiple object tracking tasks.
We introduce XLDA, cross-lingual data augmentation, a method that replaces a segment of the input text with its translation in another language.
We study the influence of factors intrinsic to the models or found in the dataset used on their ability to generalise to new in-domain instances under a variety of conditions.
We develop a novel pipeline Meta Neural Trojaned model Detection system to predict if a given NN is Trojaned via meta neural analysis on a set of trained shallow models.
In this paper, we use a promising deep learning model called BERT to solve the fine-grained sentiment classification task without sophisticated architecture.
We propose a novel 3D face recognition algorithm using a deep convolutional neural network (DCNN) and a 3D augmentation technique.
Human activity recognition is a key task in ambient intelligence applications to achieve proper ambient assisted living. Our goal in this work is to provide a system that allows the modeling and recognition of complex activities in real life scenarios involving interaction with the environment with semantics.
In this paper, we propose a novel method for a sentence-level answer-selection task that is a fundamental problem in natural language processing that achieves state-of-the-art performance.
We propose a general framework to learn deep generative models via Variational Fl\textbf{ow} on probability spaces, achieving competitive performance with state-of-the-art GANs.
We propose and train a mixed convolutional and residual network (MiCoRe-Net) for eye recognition task, which improves the data collection procedure, improves the anti-fake quality, and promotes the performance of biometric identification.
We propose a novel quantization algorithm for energy-efficient deployment of the hardware accelerators in which network parameters and feature-map data are represented with limited precision.
We propose a novel method to measure data from an aerial perspective for scenario-based validation fulfilling the mentioned requirements. We evaluate the data in terms of quantity, variety and contained scenarios.
We incorporate the intent-aware framework into the item-based recommendation algorithm, which improves both accuracy and diversity of recommendations, offering better accuracy/diversity tradeoff than existing solutions.
This paper addresses the problem of saliency prediction by training a convolutional network which is fast and accurate.
We show the existence of a universal and very small adversarial perturbation vector (in the embedding space) that causes natural text to be misclassified with high probability.
We introduce a new task (named Kleister) with two new datasets. We propose Pipeline method as a text-only baseline with different Named Entity Recognition architectures (Flair, BERT, RoBERTa)
A pool-based semi-supervised active learning algorithm that implicitly learns an effective low dimensional latent space in an adversarial manner.
In this paper, we study two state-of-the-art attention mechanisms called Bi-Directional Attention Flow (BiDAF) and Dynamic Co-Attention Network (DCN) and propose a hybrid scheme combining these two architectures that gives better overall performance.
We propose a framework for embedding watermarks into deep neural networks without impairing the network's performance.
We address the issue of sample drop detection in the context of a conversational speech scenario, recorded by a set of microphones distributed in space, using a neural network.
We propose a manifold-based affinity learning algorithm for person re-identification, which can scale up to large repositories with low on-line time complexity and outperforms state-of-the-art algorithms.
3LC is a lossy compression scheme for state change traffic that strikes balance between multiple goals: traffic reduction, accuracy, computation overhead, and generality.
We find resource-constrained neural network architectures with better performance than state-of-the-art models designed for mobile devices.
We introduce DeCaFA, an end-to-end deep convolutional cascade architecture for face alignment.
We provide in-depth assessment of this pipeline using two popular benchmark datasets. Surprisingly, we observe that randomly generated summaries achieve comparable or better performance to the state-of-the-art.
We present a novel dimension-decomposition region proposal network that can perfectly displace the traditional Region Proposal Network (RPN) that can significantly outperform RPN.
In this work, we propose a goal-driven collaborative task that contains vision, language, and action in a virtual environment as its core components.
We explore the connections between iterative algorithms that are used widely in signal processing and deep neural networks.
We use homomorphic encryption to construct a secure matrix multiplication protocol with a small communication overhead and computation overhead on the client's side, which works particularly well when a large number of clients access to the server simultaneously.
Automatic detection and classification of Alzheimer’s through brain Magnetic Resonance Imaging (MRI) using transfer learning.
We propose a graph encoder built upon Graph Neural Networks (GNN) and provide a new variational-sequential graph autoencoder (VS-GAE) based on the proposed encoder.
We tackle the domain shift on two levels: 1) the image-level shift, such as image style, illumination, etc, and 2) the instance- level shift, Such as object appearance, size, etc. We build our approach based on the recent state-of-the-art Faster R-CNN model, and design two domain adaptation components, on image level and instance level.
Generating text from graph-based data, such as Abstract Meaning Representation (AMR), is a challenging task due to the inherent difficulty in how to properly encode the structure of a graph with labeled edges.
We propose an adversarial training framework that can prevent extracted features from being utilized to reconstruct raw images and infer private attributes, while retaining the useful information for the intended cloud service.
We propose Scene Graph Auto-Encoder (SGAE) that incorporates the language inductive bias into the encoder-decoder image captioning framework for more human-like captions.
We propose a hypernetwork architecture that generates simplified relation-specific convolutional filters that outperforms ConvE and all previous approaches across standard datasets.
A critical issue in pedestrian detection is to detect small-scale objects that will introduce feeble contrast and motion blur in images and videos, which in our opinion should partially resort to deep-rooted annotation bias. We propose a novel method integrated with somatic topological line localization (TLL) and temporal feature aggregation for detecting multi-scale pedestrians.
We present a Siamese neural network based model that is able to recognise unseen raw materials present in objects given a list of candidate material images.
We study how to set channel numbers in a neural network to achieve better accuracy under constrained resources (e.g., FLOPs, latency, memory footprint or model size). A simple and one-shot solution, named AutoSlim, is presented.
We formulate a combinatorial optimization problem that allows evaluating the regions in the image space where a given model is more vulnerable to distributional shifts, in terms of image transformations applied to the input, and face it with standard search algorithms.
We propose and study the problem of distribution-preserving lossy compression under the constraint that reconstructed samples follow the distribution of the training data.
We investigate Binary Patterns encoded CNN models for texture recognition and remote sensing scene classification. We demonstrate that TEX-Nets provide complementary information to standard RGB deep model of the same network architecture.
This paper proposes two types of recommender systems based on sparse dictionary coding. Firstly, a novel predictive recommender system that attempts to predict a user’s future rating of a specific item. Secondly, a top-nRecommender system which finds a list of items predicted to be most relevant for a given user.
We present an end-to-end trainable parametric network to deterministically start from good initial solutions leading to more photo realistic reconstructions with significant optimization speed up.
We propose a spatial region-wise normalization for image inpainting network training and apply it in the early layers.
We propose a semi-supervised approach named Alleviating Semantic-level Shift (ASS), which can successfully promote the distribution consistency from both global and local views.
We present an online visual tracking algorithm by managing multiple target appearance models in a tree structure, where multiple CNNs collaborate to estimate target states and determine the desirable paths for online model updates in the tree.
We propose a gradient-based optimization strategy to generate a symmetric mixture of Gaussian modes (SGM) where each mode belongs to a particular quantization stage and achieve 2-bit state-of-the-art performance.
In this paper, we propose a dual-graph regularized discriminative low-rank learning for a multitask tracker, which exploits the intrinsic relationship among tasks, and preserves the spatial layout structure among the local patches inside each candidate (or samples).
A block-wise network generation pipeline which automatically builds high-performance networks using the Q-Learning paradigm with epsilon-greedy exploration strategy.
We propose a new few-shot action-recognition method which exploits joint spatial and temporal attention mechanisms in conjunction with self-supervised representation learning on videos.
We propose a less-forgetful learning method for domain expansion that works well with both old and new domains.
Sphingosine kinase 1 (SphK1) is a promising therapeutic target against several diseases including mammary cancer.
A survey of recent studies that proposed to improve the person Re-ID systems using deep learning.
We generalize the distant supervision by extending the dictionary with headword based non-exact matching. We apply a function to better weight the matched entity mentions.
We propose a novel approach for generating unrestricted adversarial examples by manipulating fine-grained aspects of image generation, bypassing certified defenses.
In this paper, we investigate the role of Rademacher complexity in improving generalization of DNNs and propose a novel regularizer rooted in LocalRademacher Complexity (LRC).
We propose a data efficient GAN based structured prediction based adversarial framework for medical image segmentation in low annotation regime.
We show that a sparse coding model particularly designed for super-resolution can be incarnated as a neural network, and trained in a cascaded structure from end to end.
We present an attention-based method which reduces the model setup time by updating the newly added data via online adaptation without a gradient update process.
In this paper, we propose a novel semi-supervised visual integration framework for sentence level language representation.
We present a tracker (without bells and whistles) that accomplishes tracking without specifically targeting any of these tasks, in particular, we perform no training or optimization on tracking data.
Multimodal Compact Bilinear Pooling for Visual Question Answering and Grounding .
We develop a new convolutional network module that uses dilated convolutions to systematically aggregate multi-scale contextual information without losing resolution.
We provide theoretical investigation of curriculum learning in the context of stochastic gradient descent when optimizing the convex linear regression loss, and observe empirically similar behavior.
The most common environment in which ranking is used takes a very specific form. Users sequentially generate queries in a digital library. For each query, ranking is applied to order a set of relevant items from which the user selects his favorite. In this work, we present a new online ranking algorithm, called NoRegret KLRank, designed to use "clickthrough" information as it is provided by the users to improve future ranking decisions.
We propose Noise Sensitivity Score, a metric that quantifies the performance of a DNN on a specific input under different forms of fix-directional attacks. An insightful mathematical explanation is provided for deeply understanding the proposed metric.
DCNN with fine-tuning outperformed the other models including handcrafted features for automatically detecting illustrations from photographs.
We present SemAuto , a novel approach based on an Autoencoder Neural Network that makes it possible to semantically label neurons in hidden layers, thus paving the way to the model’s interpretability and consequently to the explanation of a recommendation.
We propose a new unsupervised learning method to train a deep feature extractor from unlabeled images. Combining the learned features with a prediction system, we can detect irregularities in robot surveillance video.
We adapt the ideas underlying the success of Deep Q-Learning to the continuous action domain. We present an actor-critic, model-free algorithm based on the deterministic policy gradient that can operate over continuous action spaces.
We propose an image caption system that exploits the parallel structures between images and sentences and captures higher-level semantic information encoded in an image.
We propose a new set of tools that leverage the PyData stack to enable the kinds of research experiments and educational experiences that we have been able to deliver with LensKit, along with new experimental structures.
Information Extraction (IE) refers to automatically extracting structured relation tuples from unstructured texts. Common IE solutions, including Relation Extraction and open IE systems, can hardly handle cross-sentence tuples.
This paper proposes an improvement to the well-known AlexNet feature extraction technique. The proposed approach applies a recursive neural network structure on features extracted by a deep convolutional neural network pre-trained on a large data set.
The objective of this paper is 'open-set' speaker recognition of unseen speakers, where ideal embeddings should be able to condense information into a compact utterance-level representation that has small intra-class (same speaker) and large inter-class distance.
In this paper, we propose an adaptive learning method of RBM that can discover an optimal number of hidden neurons according to the training situation by applying the neuron generation and annihilation algorithm.
We introduce a system that recognizes concurrent activities from real-world data captured by multiple sensors of different types using a single classifier.
We develop data-independent and data-dependent hashing methods for fast approximate nearest neighbor searching in large data sets.
We develop the relational topic model (RTM), a hierarchical model of both network structure and node attributes that can be used to summarize a network of documents, predict links between them, and predict words within them.
We present a noise resilient probabilistic model for active learning of a Gaussian process classifier from crowds, i.e., a set of noisy labelers with two levels of flip models.
We apply a self-paced constraint and symmetric regularization to help the relative distance metric training the deep neural network, so as to learn the stable and discriminative features for person Re-ID.
We propose S-Net, a scalable CNN that can scale dynamically in a multitask system for real-time operation with little performance loss.
We present a new approach, conceptual expansion, that serves as a general representation for reusing existing trained models to derive new models without backpropagation.
We propose to learn a non-metric visual similarity function directly from image representations to measure how alike two images are in content-based image retrieval datasets.
We propose an interactive multimodal framework for zero-resource neural machine translation using cooperative image description games, which significantly improves over state-of-the-art methods.
The recent years have seen a revival of interest in textual entailment, sparked by i) the emergence of powerful deep neural network learners for natural language processing and ii) the timely development of large-scale evaluation datasets such as SNLI.
This paper extends, for the first time, transductive Zero-Shot Learning to 3D point cloud classification.
We first investigate temporal modulation cues from auditory front-ends and then propose a joint 3D convolutions and attention-based sliding recurrent neural networks for emotion recognition.
We propose a novel generative adversarial network to address cross-resolution person re-ID, allowing query images with varying resolutions.
We propose to regress via an efficient "divide and conquer" manner in a generalization of negative correlation learning that works well for non-deep regression problems.
We propose a Federated Latest Averaging algorithm, which leverages the latest gradients of all clients, even when the clients are not available, to jointly update the global model in each iteration.
We show how the sample complexity can be reduced by providing semantic information about the relevance of features per sample, and develop an online algorithm that minimizes this loss effectively.
In this work, we connect two distinct concepts for unsupervised domain adaptation: feature distribution alignment between domains by utilizing the task-specific decision boundary and the Wasserstein metric.
We introduce a new model for building conditional generative models in semi-supervised setting to conditionally generate data given attributes by adapting the GAN framework.
In this paper, we propose a Cross-Modal Relationship Extractor to adaptively highlight objects and relationships, that have connections with a given expression, with a cross-modal attention mechanism, and represent the extracted information as a language-guided visual relation graph.
We propose a model that embeds multi-relational graph data in the Poincare ball model of hyperbolic space, which captures simultaneous hierarchies.
In this paper, we introduce a new relay-style execution technique called L2L (layer-to-layer) where at any given moment, the device memory is primarily populated only with the executing layer(s)'s footprint.
Pushing popular content to cheap "helper" nodes (e.g., small cells) during off-peak hours has recently been proposed to cope with the increase in mobile data traffic. We propose to depart from the assumption of hard cache hits, common in existing works, and consider "soft" cache hits where if the original content is not available, some related contents that are locally cached can be recommended instead.
We propose a novel variational model that jointly estimates both illumination changes and optical flow and achieve state-of-the-art results for robust optical flow estimation.
Unsupervised network representation learning over graphs using context-based embeddings.
We propose an effective and interpretable Select, Answer and Explain (SAE) system to solve the multi-document RC problem.
This paper addresses the above limitations by semantically refining and expanding the labels suggested by learning-based object detection, improving the quality of the state-of-the-art visual labeling tools like LSDA and YOLO.
We investigate whether Big Two/Big Five personality judgments can be mapped onto the 2D space defined by the dimensions trustworthiness and dominance, and if so, whether these judgments are valid.
We present Harmonic Networks, a CNN exhibiting equivariance to patch-wise translation and 360-rotation. We achieve this by replacing regular CNN filters with circular harmonics.
We combine ideas from weight hashing and dimensionality reductions resulting in a simple and powerful structured multi-hashing method based on matrix products that allows direct control of model size of any deep network and is trained end-to-end.
We focus on precise 3D track state estimation and propose a learning-based approach for object-centric relative motion estimation of partially observed objects.
We present a generic multi-agent conversational architecture that follows the divide and conquer philosophy.
We propose a metric learning based approach to jointly learn a rich embedding and 3D pose regression from the embedding using multi-view synchronised videos of human motions and very limited3D pose annotations.
UnifiGem combines optimal transport, numerical ODE, density-ratio (density-difference) estimation and deep neural networks for generative learning.
This paper presents a fully automated method for OD segmentation algorithm for retinal disease screening.
This paper proposes an improved multi-task cascaded convolutional network-based intelligent fruit detection method that is based on image fusion to improve the detector performance.
We propose a system that utilizes context from the presence of such inter-modal influences to recognize facial expressions.
We find that existing state-of-the-art pedestrian detectors generalize poorly from one dataset to another, using a general principle of direct cross-dataset evaluation.
Artwork is a mode of creative expression and this paper is particularly interested in investigating if machine can learn and synthetically create artwork that are usually non- figurative and structured abstract.
We propose a new evolutionary approach to extracting discriminant features with low space complexity and high search efficiency for face recognition.
In this work we present a self-supervised learning framework to simultaneously train two Convolutional Neural Networks to predict depth and surface normals from a single image.
We propose a simple yet effective method for deep networks compression, named Cluster Regularized Quantization (CRQ), which can reduce the presentation precision of a full-precision model to ternary values without significant accuracy drop.
We study the first-order scattering transform as a candidate for reducing the signal processed by a convolutional neural network (CNN) while preserving most of the signal information needed for classification.
We show that the regularly accepted labeling scheme of crowd density maps for training deep neural networks is less effective than our alternative inverse k-nearest neighbor (i$k$NN) maps, even when used directly in existing state-of-the-art network structures. We also provide a new network architecture MUD-i$K$NN.
We explored the extent of mutational robustness in the budding yeast by genome wide dosage suppressor analysis of 53 conditional lethal mutations, revealing 660 suppressor interactions of which 642 are novel.
Facial attribute analysis has received considerable attention when deep learning techniques made remarkable breakthroughs in this field over the past few years.
The recent phenomenal interest in convolutional neural networks (CNNs) must have made it inevitable for the super-resolution (SR) community to explore its potential.
We present a hierarchical ROI dictionary for spatial pooling, to beyond the widely used spatial pyramid in image classification literature.
We introduce DiscEval, a compilation of $11$ evaluation datasets with a focus on discourse, that can be used for evaluation of English Natural Language Understanding when considering meaning as use.
We develop an algorithm that can detect pneumonia from chest X-rays at a level exceeding practicing radiologists.
A survey on scene text detection and recognition in the era of deep learning.
We propose a novel end-to-end StructureAware Convolutional Network (SACN) that takes the benefit of GCN and ConvE together for knowledge graph embedding.
We describe the Yeast Kinase Interaction Database (KID, http://www.moseslab.csb.utoronto.ca/KID/ ), which contains high- and low-throughput data relevant to phosphorylation events.
We propose an approach to retrofitting contextualized embedding models with paraphrase contexts with an orthogonal transformation on the input space.
In this paper, we incorporate the uncertainty of labels into a max-margin learning algorithm, and the algorithm allows the labels to deviate over iterations in order to find a better solution.
We introduce BERT-gen, an architecture for text generation based on BERT, able to leverage on either mono- or multi- modal representations. The results reported under different configurations indicate a positive answer to our research question.
This paper attempt to exploit the text guided attention and semantic-guided attention to find the more correlated spatial information and reduce the semantic gap between vision and language.
Context-Aware ZSL leverages semantic representations in a new way to model conditional likelihood of an object to appear in a given context.
We extend an existing approach to real-time instance segmentation, called `Straight to Shapes' (STS), which makes use of low-dimensional shape embedding spaces to directly regress to object shape masks, achieving 19.7 point improvement in mAP (at IOU of 0.5) over the original method.
Language grounding is an active field aiming at enriching textual representations with visual information. We propose an intermediate representation space that can be used to learn sentence representations.
We characterize convolutional neural networks with respect to the relative amount of features per layer. We investigate the common assumption of monotonously increasing feature-counts with higher layers of architecture designs.
We explored the idea of using unsupervised clustering to construct a variety of auxiliary tasks from unlabeled data or existing labeled data, and proposed a meta-learning-based multi-task learning approach, which trained the shared hidden layers on auxiliary tasks, while the meta-optimization objective was to minimize the loss on the main task.
A novel, two-stage reconstruction pipeline that learns a disentangled representation of the aforementioned image factors and generates novel person images at the same time.
We present a diversity-driven approach for exploration, which can be easily combined with both off- and on-policy reinforcement learning algorithms, which significantly enhances an agent's exploratory behaviors, and thus preventing the policy from being trapped in local optima.
In this paper, we propose the first, to the best of our knowledge, in-the-wild 3DMM by combining a powerful statistical model of 3D facial shape and texture, which describes both identity and expression, with an in- the-wild texture model.
This paper proposes a computationally efficient approach to detecting objects natively in 3D point clouds using convolutional neural networks (CNNs) which explicitly exploit the sparsity encountered in the input.
We introduce and study Generative Latent Optimization (GLO), a framework to train a generator without the need to learn a discriminator, thus avoiding challenging adversarial optimization problems.
This paper presents a supervised feature learning method to learn discriminative and compact descriptors for drusen segmentation from retinal images.
We propose GradMix, a model-agnostic method applicable to any model trained with gradient-based learning rule, to transfer knowledge via gradient descent by weighting and mixing the gradients from all sources during training.
We propose a novel deep neural network architecture for describing and discriminating vital spatiotemporal information across videos with different points of view.
We propose a novel method that enables DNNs to flexibly change their size after training, enabling to effectively compress the error and complexity of models as little as possible.
We consider the task of visual net surgery, in which a CNN can be reconfigured without extra data to recognize novel concepts that may be omitted from the training set. We demonstrate the robustness of simple PLCs by applying them in a weakly supervised manner.
We consider the reachability indexing problem for private-public directed graphs. We first formulate the problem as asymmetric k-center with outliers, and give an efficient and practical algorithm.
This work presents three frameworks for evaluating Olympic sports which utilize spatiotemporal features learned using 3D convolutional neural networks (C3D) and perform score regression with i) SVR ii) LSTM and iii) L STM.
This work proposes to mitigate the ASR errors by aligning the mismatch between ASR hypotheses and their corresponding reference transcriptions. An adversarial model is applied to this domain adaptation task.
Retraction due to significant oversight <|TLDR|
A simple semisupervised learning procedure (self-training) achieves high robust accuracy using the same number of labels required for achieving high standard accuracy.
This paper proposes a method to gain extra supervision via multi-task learning for multi-modal video question answering.
A proposal generation acceleration framework for real-time face detection with faster inference time.
We propose two Deep Differentiable Random Forests methods, Deep Label Distribution Learning Forest (DLDLF) and Deep Regression Forest (DRF), for age estimation.
We develop the first random features for pdfs whose dot product approximates kernels using these non-Euclidean metrics, allowing estimators using such kernels to scale to large datasets by working in a primal space, without computing large Gram matrices.
A fully automated computer vision application for littering quantification based on images taken from the streets and sidewalks.
In this paper, we introduce a novel visual descriptor named Group Invariant Feature Transform (GIFT), which is both discriminative and robust to geometric transformations.
We synthesize this growing body of literature by formulating a generalization of the evidence lower bound that explicitly represents the trade-offs between sparsity of the latent code, bijectivity of representations, and coverage of the support of the empirical data distribution.
We propose a general variational framework for training deep energy-based models using any desired f-divergence and prove its local convergence property with non-linear systems theory.
We present a fully end-to-end 3D object detection framework that can infer oriented 3D boxes solely from BEV images by using a two-stage object detector and ad-hoc regression branches, eliminating the need for a post-processing stage.
We propose a novel unsupervised online video object segmentation (UOVOS) framework by construing the motion property to mean moving in concurrence with a generic object for online setting.
This paper presents an approach to estimate depths and normals for transparent objects using a single image acquired under a distant but otherwise arbitrary environment map.
The article describes a reconstruction pipeline that generates piecewise-planar models of man-made environments using two calibrated views. The pipeline outputs an accurate semi-dense Piecewise-Planar Reconstruction of the 3D scene.
We propose Collaborative Memory Networks (CMN), a deep architecture to unify the strengths of the global structure of latent factor model and local neighborhood-based structure in a nonlinear fashion for collaborative filtering.
In this paper, we propose to replace the combination of ReLU and Batch Normalization with Exponential Linear Unit (ELU) in Residual Networks, which speeds up the learning behavior, but also improves the classification performance.
We propose mixed dimension embedding layers in which the dimension of a particular embedding vector can depend on the frequency of the item. This approach drastically reduces memory requirement for the embedding, while maintaining and sometimes improving the ML performance.
The cross-entropy is an upper bound on a new pairwise loss, which has a structure similar to various pairwise losses: it minimizes intra- class distances while maximizing inter-class distances.
We propose a semantic guided and response-time-bounded graph query to return top-k answers effectively and efficiently over knowledge graphs.
In this paper, we propose simple models trained with sentence-level annotation, but also attempt to generating linguistically coherent representations by employing regularizers that model the linguistic role of sentiment lexicons, negation words, and intensity words.
This paper makes an empirical exploration of several factors, including variations on Gaussian, exponential and hyperbolic-L1 priors for improved regularization, and several classes of features and Markov order.
We propose a semi-automatic annotation methodology for annotating massive face datasets.
In this paper, we propose a channel pruning algorithm for depth-wise separable convolution units and introduce a new channel selection algorithm based on information gain and a method for quickly recovering network performance after pruning.
We propose a spectral CNN method for semantic annotation on shape graphs.
We train an inverse dynamics model and use it to predict actions for state-only demonstrations for dexterous manipulation.
We propose a novel framework, DeepSEE, for Deep disentangled Semantic Explorative Extreme super-resolution.
We challenge the benchmark algorithm on emotion classification of the Extended Cohn-Kanade (CK$+) database, and we present a facial component-based system for emotion classification, which beats the given benchmark performance.
We introduce a method to infer a variational approximation to the posterior distribution of solutions in computational imaging inverse problems with empirical prior, thereby obtaining a probabilistic description of the solution space.
We investigate the role that geometric, textual and visual features play in the task of predicting a preposition that links two visual entities depicted in an image.
This paper presents a time series forecasting framework which combines standard forecasting methods and a machine learning model and achieves state of the art results.
We introduce novel subspace-based methods for learning from the azimuth angle of surface normals for robust 3D face recognition from facial surfaces.
Ensemble-based Low-Level Sample-Variances Method (ELSM) to encourage each base learner of hidden layers to have a low-level sample-variance.
In this paper we develop an extension of the SPM method, by generalizing vector quantization to sparse coding followed by multi-scale spatial max pooling, and propose a linear SPM kernel based on SIFT sparse codes.
We propose a Multi-Branch Ensemble Learning architecture based on the three-dimensional (3D) convolutional neural networks for accurate detection of lung nodules in CT images for early diagnosis of lung cancer.
Data driven models for supervised visual recognition problems, which can detect novelty in ego-motions of people, and changes in the static environments surrounding them.
This paper explores the potential of utilizing BERT intermediate layers to enhance the performance of fine-tuning of BERT.
We propose a new neural model based on an algebraic method to estimate orientations. This algebraic model need not obey the constraints of Hubel-Wiesel hypothesis and is easily implemented with a neural network.
In this paper, we explore the importance of network input for achieving optimal accuracy-efficiency trade-off.
A feature extraction method using multi-frequency bands for face recognition, named as the Multi-band Gradient Component Pattern (MGCP).
This paper provides a unified derivation of recent approaches, so that similarities and differences are easily observed. We also present a simple meta-algorithm which wraps any existing algorithm, yielding 100% success rate.
We present an intuitive explanation and interpretation of the performance of deep networks in a natural-image space and introduce an additional random-noise category during training.
In this paper, we design a tracking model consisting of response generation and bounding box regression, where the first component produces a heat map to indicate the presence of the object at different positions and the second part regresses the relative boundingbox shifts to anchors mounted on sliding-window locations. To effectively adapt the model to appearance variations, we propose to offline train a recurrent neural optimizer to update tracking model in a meta-learning setting.
Adaptive fractional dilated convolution for image aesthetics assessment in convolutional kernel level.
In this paper we propose corruption-mimicking, a new strategy that utilizes a surrogate network to approximate the unknown corruption directly at test time, without the need for additional supervision or data augmentation.
Transformation invariance is an important property in pattern recognition, where different observations of the same object typically receive the same label. We propose representing a pattern of interest as a linear combination of few geometric functions extracted from a structured and redundant basis.
Unsupervised cross-lingual embeddings mapping has provided a unique tool for completely unsupervised translation.
This paper presents a detailed description of a real-time correlation-based stereo algorithm running completely on the graphics processing unit (GPU).
We propose a local metric learning algorithm, which augments the small amount of labeled data with unlabeled data in order to learn the semantic information in the manifold structure in a local way.
This work systematically explores the robustness of BERT, the state-of-the-art Transformer-style model in NLP, in dealing with noisy data, particularly mistakes in typing the keyboard, that occur inadvertently.
Multimodal language models attempt to incorporate non-linguistic features for the language modeling task. We perform a thorough exploration of model architectures for combining visual and text features.
We propose a novel method which actualizes recurrent knowledge transfer between the two spaces for zero-shot learning.
We revisit the paradigm of pre-training on large supervised datasets and fine-tuning the model on a target task, and propose a simple recipe that we call Big Transfer (BiT), which achieves strong performance on over 20 datasets.
We introduce a novel unsupervised deep learning approach for binocular stereo depth estimation that combines information provided by both stereo views.
We present a prediction scheme called Back-and-Forth (BaF) prediction, developed for deep feature tensors, which allows us to dramatically reduce tensor size and improve its compressibility.
We explore the problem of object detection in the shoe manufacturing application. We propose different methods for the automatic or semi-automatic generation of image datasets.
A model combining convolutional neural network with self-attention mechanism for face image super-resolution reconstruction.
We propose a framework that drives the reID network to learn semantics-aligned feature representation through delicate supervision designs.
We propose inferring directly camera calibration parameters from a single image using a deep convolutional neural network, and demonstrate that our calibration network outperforms other methods on this measure.
We propose a novel image hashing method, termed as asymmetric deep semantic quantization (ADSQ), which leverages the power of three fully-connected layers to capture rich semantic information between image pairs.
This paper proposes a new deep convolutional neural network (DCNN) architecture that learns pixel embeddings, such that pairwise distances between the embedDings ::: can be used to infer whether or not the pixels lie on the same region.
We introduce a path signature feature to encode information from intra-frame and inter-frame contexts and use it for action classification.
We propose a meta-learner to reduce catastrophic forgetting on the representation level, as the output layer can be quickly recovered later with a small number of examples.
This paper proposes to impose the circulant structure to the construction of convolutional layers, and hence leads tocirculant convolutionAL layers (CircConvs) and circulante CNNs.
ImageNet is a large-scale database of object classes with millions of images. Unfortunately only a small fraction of them are annotated with bounding-boxes, which prevents useful developments, such as learning reliable object detectors for thousands of classes. In this paper we propose to automatically populate ImageNet with many more bounding boxes.
In this paper, we propose an accurate and efficient single shot object detector with fea-ture aggregation and enhancement (FAENet)
In vision-based object classification systems, imaging sensors perceive the environment and then objects are detected and classified for decision-making purposes. Vulnerabilities in the perception domain enable an attacker to inject false data into the sensor which could lead to unsafe consequences. We propose GhostImage attacks, with the goal of either creating a fake perceived object or obfuscating the object's image that leads to wrong classification results.
We introduce deformable convolution and deformable RoI pooling to enhance the transformation modeling capability of CNNs, giving rise to deformable networks.
We propose an algorithm for meta-learning that is model-agnostic, compatible with any model trained with gradient descent and applicable to a variety of different learning problems.
Sparse coding has received extensive attention in the literature of image classification. Traditional sparse coding strategies tend to approximate local features in terms of a linear combination of basis vectors, without considering feature neighboring relationships. To address this shortcoming, we develop new sparse representations which preserve feature similarities.
We study the problem of semi-supervised question answering----utilizing unlabeled text to boost the performance of question answering models. We propose a novel training framework, the Generative Domain-Adaptive Nets.
We propose Topology Distance (TD), a distance complementary to existing measures in the field of GANs' learning.
We propose two probabilistic methods to build models that are more robust to hypothesis-only biases and better transfer across datasets.
We propose a novel model for 3D semantic completion from a single depth image, based on a single encoder and three separate generators used to reconstruct different geometric and semantic representations of the original and completed scene, all sharing the same latent space.
We investigate the use of different syntactic dependency representations in a neural relation classification task and compare the CoNLL, Stanford Basic and Universal Dependencies schemes.
In this paper, we propose a deep neural network approach for encoding images individually, by learning a mapping from the 2D pixel coordinate space to the RGB color space.
In this paper, we propose Ghost Networks to improve the transferability of adversarial examples and improve adversarial attacks.
We present a conceptually simple, flexible, and general framework for instance-level recognition, extending Faster R-CNN by adding a branch for predicting an object mask in parallel.
A Sogou Machine Reading Comprehension toolkit that can be used to provide the fast and efficient development of modern machine comprehension models, including both published models and original prototypes.
We propose orthogonal convolutions as regularizations in CNNs and benchmark its effect on various tasks. We observe up to 3% gain for CIFAR100 and up to 1% gain on ImageNet classification.
We propose a domain-independent training technique for bias mitigation that is effective at mitigating real-world gender bias, and validate its effectiveness on attribute classification tasks.
In this paper, we propose a method for jointly localising container-like objects and estimating their dimensions using two wide-baseline, calibrated RGB cameras.
Knowledge graph embedding models perform poorly for knowledge base completion, i.e., the task of inferring new facts from an incomplete knowledge base. We propose an alternative entity ranking protocol that considers all model predictions as a whole.
We develop a deep learning algorithm for contour detection with a fully convolutional encoder-decoder network on PASCAL VOC with refined ground truth.
We present a new loss function for the validation of image landmarks detected via Convolutional Neural Networks (CNN) and formulate a novel batch balancing approach which weights the importance of samples based on their produced loss.
We present Neural Random Forest Imitation - a novel approach for transforming random forests into neural networks.
This paper presents a simple but effective way that improves the performance of generative adversarial networks (GANs) without imposing the training overhead or modifying the network architectures of existing methods.
We propose a novel learning paradigm for the LVIS task: divide the whole data into balanced parts and then apply incremental learning to conquer each one.
A novel end-to-end deep auto-encoder for unsupervised learning on point clouds.
We present a novel generative model for compositional image generation, SEIGAN (Segment-Enhance-Inpaint Generative Adversarial Network), which learns these three operations together in an adversarial architecture with additional cycle consistency losses.
We examine systematically this under-studied FR problem, and introduce a novel Complement Super-Resolution and Identity (CSRI) joint deep learning method with a unified end-to-end network architecture for solving this largely ignored FR scenario.
We propose a recurrent convolutional network that captures temporal context across frames at every level of network depth, while being causal and using fewer parameters.
In this paper we extend UD to Indian languages through conversion of Pānịnian Dependencies to UD for the Hindi Dependency Treebank.
We propose a novel spatio–temporal U-Net for frame prediction using normal events and abnormality detection using prediction error, which achieves 96.5% AUC.
We present the Uppsala submission to the CoNLL 2017 shared task on parsing from raw text to universal dependencies, a simple pipeline consisting of two components.
We propose an efficient lighting estimation pipeline that is suitable to run on modern mobile devices, with comparable resource complexities to state-of-the-art on-device deep learning models.
We exploit the simple observation that actions are accompanied by contextual cues to build a strong action recognition system that achieves 90.2% mean AP on PASAL VOC Action dataset.
In this paper, we propose a novel perspective-guided convolution (PGC) for convolutional neural network (CNN) based crowd counting (i.e. PGCNet), which aims to overcome the dramatic intra-scene scale variations of people due to the perspective effect.
In this paper, we propose a computer vision system based on deep learning for algae monitoring for autonomous algae monitoring.
We propose an efficient framework, called MetaPAD, which discovers high-quality typed textual patterns efficiently from massive corpora and facilitates information extraction.
We propose a multi-granularity reasoning framework for social relation recognition from images.
In this paper, we aim at automatically searching an efficient network architecture for dense image prediction, using gradient descent.
We propose a novel randomized tensor decomposition for tensor regression, which improves both the performance and robustness of neural networks augmented with it, without requiring any adversarial training.
The two predominant families of deformable models for the task of face alignment are: (i) discriminative cascaded regression models, and (ii) generative models optimised with Gauss-Newton. Although these approaches have found to work well in practise, they each suffer from convergence issues.
In this paper, we propose a Deep Recurrent Fusion Network (DRFN), which utilizes transposed convolution instead of bicubic interpolation for upsampling and integrates different-level features extracted from recurrent residual blocks to reconstruct the final HR images.
The so-called fast inertial relaxation engine is a first-order method for unconstrained smooth optimization problems. It updates the search direction by a linear combination of the past search direction, the current gradient and the normalized gradient direction.
This paper proposes the novel Pose Guided Person Generation Network (PG$^2$) that allows to synthesize person images in arbitrary poses, based on an image of that person and a novel pose.
We propose a meta-learning approach that learns to reshape model gradients, such that information across incremental tasks is optimally shared. This ensures a seamless information transfer.
In this paper, we introduce a new vessel enhancement method which combines different structuring elements to detect innate features of vessel-like structures.
We improve lemmatization performance on a set of non-standard historical languages in which the difficulty is increased by an additional aspect (iii) of spelling variation due to lacking orthographic standards.
Spatial data exhibits the property that nearby points are correlated. This holds also for learnt representations across layers, but not for uncorrelated initialization. We propose multiple methods for correlated initialization.
We provided a comprehensive review of computational models for DTI identification, including network-based algorithms and machine learning-based methods.
We propose a new kernel-based method that exploits low-dimensional structures that exploit changes in geometric and statistical properties from the source to the target domain and automatically selects the optimal source domain to adapt and avoid less desirable ones.
We propose random hinge forests, a simple, efficient, and novel variant of decision forests, which can be incorporated as a general component within arbitrary computation graphs.
An ensemble of several CNNs where only the last layer is fine-tuned with the help of a small labeled set of tuning labels made available by the organizers.
We propose a novel HRL architecture, Hierarchical Decompositional Reinforcement Learning (HiDe), which allows decomposition of the hierarchical layers into independent subtasks, yet allows for joint training of all layers in end-to-end manner.
We proposed a deep learning based framework that can lead to an efficient representation of vehicles from its multi-viewpoint images.
We address Unsupervised Video Object Segmentation (UVOS), the task of automatically generating accurate pixel masks for salient objects in a video sequence and of tracking these objects consistently through time, without any input about which objects should be tracked.
We present a modular methodology for evaluating network model selection from data, focusing on fundamental predictive tasks on networks.
We propose a novel Boundary Likelihood Pinpointing (BLP) network to alleviate this deficiency of boundary regression and improve the localization accuracy.
We propose a new perspective for pan-density crowd counting, which aims to count people in varying density crowds, achieving state-of-the-art recognition performance and high robustness.
This paper proposes a Deep Learning based edge detector, which is inspired on both HED (Holistically-Nested Edge Detection) and Xception networks.
We propose an approach that integrates interference-target spatial structure (ITSS) constraints into existing CF model to alleviate similar object interference.
Cross-based framework strategy for cost aggregation for depth map estimation based on video sensor networks.
In this paper, we introduce "Power Linear Unit" (PoLU) which increases the nonlinearity capacity of a neural network and thus helps improving its performance.
We propose a differentiable rendering formulation for implicit shape and texture representations from RGB images, which can be used for multi-view reconstructions.
Data augmentation is an effective technique for improving the accuracy of modern image classifiers. We use a search algorithm to find the best policy such that the neural network yields the highest validation accuracy.
We develop a technique for transfer learning in machine comprehension (MC) using a novel two-stage synthesis network (SynNet)
This paper addresses the problem of inferring unseen cross-domain and cross-modal image-to-image translations between multiple domains and modalities, where only some of the pairwise translations have been seen.
We introduce a novel tracking system based on similarity mapping by Enhanced Siamese Neural Network (ESNN), which accounts for both appearance and geometric information, and is trainable end-to-end.
We quantify the accuracy of various simulators compared to a real world robotic reaching and interaction task, and present quantitative data for various manipulation-oriented robotic tasks.
We analyzed the computation cost of Convolutional Neural Network(CNN) and found that the inefficiency of CNN is mainly caused by its wide structure rather than the deep structure. Thus, we designed a very narrow while deep backbone network to improve the efficiency of semantic segmentation.
Unsupervised learning of accurate camera pose (translation and rotation vector) and high-resolution depth map with the Kalman filter.
This paper addresses spatio-temporal localization of human actions in video. We propose a recurrent localization network (RecLNet) designed to model the temporal structure of actions on the level of person tracks.
We propose a plug-and-play (PnP) module for improving depth prediction with taking arbitrary patterns of sparse depths as input.
We introduce a novel multimodal machine translation model that utilizes parallel visual and textual information for competitive state-of-the-art results on the Multi30K and the Ambiguous COCO datasets.
We exploit the spatio-temporal coherence of vehicle video to generate accurate labels in the field, and generalize these labels to a larger scene using an object detection system.
We present SIVO, a novel information-theoretic feature selection method for visual simultaneous localization and mapping which incorporates semantic segmentation and neural network uncertainty into the feature selection pipeline.
We apply a tensor decomposition method named Tensor-Train (TT) on the neural network, by which the number of parameters is reduced by a tremendous factor and the computational complexity is further decreased so that the large signals can be recovered as a whole.
We propose Aggregated Momentum (AggMo), a variant of momentum which combines multiple velocity vectors with different $\beta$ parameters. AggMo is trivial to implement, but significantly dampens oscillations.
This paper focuses on selecting and combining multiple Gabor classifiers that are trained on, for example, different scales and local regions.
We have fine-tuned the existing convolutional neural network model trained on the visual recognition dataset used in the ILSVRC2012 to two widely used facial expression datasets, which yielded test accuracies of 74.79% and 95.71%, respectively.
We compare the performance of three state-of-the-art matrix completion algorithms (OptSpace, ADMiRA and FPCA) on a single simulation platform and present numerical results.
The thresholded feature has recently emerged as an extremely efficient, yet rough empirical approximation, of the time-consuming sparse coding inference process. In this paper, we first present theoretical recovery guarantees for thresholded features to exactly recover the nonzero support of the sparse code. Motivated by them, we then formulate the <italic>Dictionary Learning for Thresholded Features</italic>(DLTF) model, which learns an optimized dictionary.
We propose an end-to-end multitask objective that leverages the commonalities of an action performed by different objects, enabling to detect actions of an object without training.
We propose multi-stage adaptive latent action learning (MALA) that learns semantic latent actions by distinguishing the effects of utterances on dialogue progress, achieving consistent improvements over the baselines models.
We use synthetic images to probe DCNN invariance to object-class variations caused by 3D shape, pose, and photorealism, with surprising findings.
This paper proposes a unified deep architecture (DANA) to obtain a domain-invariant representation for network alignment via an adversarial domain classifier.
We propose the new problem of learning to recover reasoning chains from weakly supervised signals.
Convolutional Neural Network (CNN) is one of the most significant networks in the deep learning field. The existing reviews mainly focus on the applications of CNN in different scenarios without considering CNN from a general perspective.
This paper introduces the several techniques we develop for the Content Based Video Relevance Prediction (CBVRP) dataset to make use of the provided frame and video level features and generate predictions of videos that are similar to other videos.
Inter-Annotator Agreement (IAA) is used as a means of assessing the quality of NLG evaluation data, in particular, its reliability. Given human language variability, we propose that correlation coefficients and agreement coefficients should be used together to obtain a better assessment of the evaluation data reliability.
We propose a novel keypoint-based approach for monocular 3D object detection and localization from a single RGB image, performing in an end-to-end manner.
We propose a novel method, coined MetaStyle, which formulates the neural style transfer as a bilevel optimization problem and combines learning with only a few post-processing update steps to adapt to a fast approximation model with satisfying artistic effects, comparable to optimization-based methods for an arbitrary style.
In this paper we develop a pipeline to rapidly generate high quality RGBD data with pixelwise labels and object poses and use this data for robotic manipulation tasks.
We extend a deep Adversarial Autoencoder model to obtain meaningful representations of 3D shapes that can be used for challenging tasks like 3D points generation, reconstruction, compression, and clustering.
Multi-feature max-margin Hierarchical Bayesian model for action recognition .
This paper presents a deep learning based approach to the problem of human pose estimation.
We propose QuickMatch, a clustering-based algorithm that identifies multi-image matches from a density function in feature space, and then extracts the matches by breaking this tree using measure of distinctiveness.
We propose a subgraph-based connection graph to concisely represent the scene graph during the inference, improving the efficiency of scene graph generation.
Fine-grain labeling can improve CNN accuracy on classifying coarse-grain classes, in this case "cat."
We propose a novel approach that learns spatio-temporal embeddings for instance segmentation in videos in a single stage and achieves state-of-the-art results.
In this paper, we introduce a simple but quite effective recognition framework dubbed D-PCN, aiming at enhancing feature extracting ability of CNN.
We introduce a scalable approach for object pose estimation trained on simulated RGB views of multiple 3D models together, achieving state-of-the-art results on T-LESS.
In this paper, we propose Multi-Matching Network (MMN) which models the semantic relationship among passage, question and candidate answers from multiple different paradigms of matching.
We propose a new training procedure and a thresholding test strategy based on a new metric to improve the robustness in the adversarial setting.
In this paper, a recognition framework named D-PCN using a discriminator is proposed, which can intensify the feature extracting ability of convolutional neural networks.
In this technical report we investigate speed estimation of the ego-vehicle on the KITTI benchmark using state-of-the-art deep neural network based optical flow and single-view depth prediction methods.
We compare five state-of-the-art VQA algorithms across eight V QA datasets covering both domains. We find that methods do not generalize across the two domains.
We consider an important task of effective and efficient semantic image segmentation, and propose two modifications aimed to decrease the number of parameters and floating point operations, while keeping the performance levels almost intact.
We investigate if it is possible to create a copycat CNN by simply querying a target network as black-box with random non-labeled data.
In this paper we present Saliency Moments, a holistic descriptor for image recognition inspired by two biological vision principles: the gist perception and the selective visual attention.
We study the performance of a computer-aided detection (CAD) system for lung nodules in computed tomography (CT) as a function of slice thickness.
We propose a new method for modeling the indoor scene from a single image, based on the observation that good segmentation of the objects of interest can significantly improve the accuracy of model retrieval and make it robust to cluttered background and occlusion.
We analysed adversarial robustness of SNNs and stochastic ANNs against standard attack methods and proposed a modified version of the CWL2 attack.
We leverage metadata through a filtering mechanism, which increases the precision of document retrieval, and develop a novel fuse-and-oversample approach for transfer learning to improve the performance of answer extraction.
We propose a convolutional neural network architecture for unobtrusive students' engagement analysis using non-verbal cues.
We study the effect of curriculum learning on Long Short-Term Memory (LSTM) networks, which have shown strong competency in NLP problems.
A novel decoding framework based on deep neural networks, named spike-image decoder (SID), for reconstructing natural visual scenes, including static images and dynamic videos, from experimentally recorded spikes of retinal ganglion cells.
We propose to learn sentiment-specific word embeddings from Arabic tweets and use them for Sentiment Analysis.
We introduce an energy layer to discard the overall shape information and focus on texture features. We combine our texture CNN to a classic CNN to improve the results.
Generating hypotheses from premises in a multimodal setting, to generate a sentence (hypothesis) given an image and/or its description (premise) as input.
We attack the anomaly detection problem by directly modeling the data distribution with deep architectures. We develop novel model architectures to integrate EBMs with different types of data.
We propose Ripples, a high-performance heterogeneity-aware asynchronous decentralized training approach that has both high performance as All-Reduce in homogeneous environment and good heterogeneity tolerance.
This study addresses the problem of traffic flow estimation based on the data from a video surveillance camera using Faster R-CNN two-stage detector together with SORT tracker.
JPML leverages group sparsity by selecting a sparse subset of facial patches while learning a multi-label classifier to exploit dependencies among AU and facial features.
A novel copy-pasting GAN framework where the generator learns to discover an object in one image by compositing it into another image such that the discriminator cannot tell that the resulting image is fake.
We design, implement, and evaluate Chiron, a system for privacy-preserving machine learning as a service, enabling customers who have the data but not ML expertise to train predictive models on this data.
In this paper, we introduce SimpleBooks, a small dataset with the average word frequency as high as that of much larger ones. SimpleBooks can be downloaded from this https URL.
We present a new method of cross fusing feature, named multi-semantic pyramids (MSP), for detecting different-scale objects.
We propose feature map and kernel level pruning for reducing the computational complexity of a deep convolutional neural network.
We propose a framework to address both issues by combining render-based image synthesis and CNN, together with a novel CNN specifically tailored for the viewpoint estimation task.
We introduce the Intermediate Level Attack (ILA), which attempts to fine-tune an existing adversarial example for greater black-box transferability by increasing its perturbation on a pre-specified layer of the source model without any knowledge of the target models.
We developed EEM parameters enabling the fast calculation of high-quality partial atomic charges for almost all drug-like molecules for chemoinformatics.
We study high-order statistics of the interaction among regions of interest in actions and propose a mid-level representation for action recognition, inspired by the Julesz school of n-gon statistics.
This paper aims to create neutral reference models from synthetic speech to contrast the emotional content of a speech signal to compare a target sentence in a fictitious scenario.
We present a novel layerwise optimization algorithm for the learning objective of Piecewise-Linear Convolutional Neural Networks (PL-CNNs), a large class of convolutional neural networks.
A new training scenario for convolutional neural network based image upscaling method for noisy medical images.
A novel method on the basis of conditional Wasserstein generative adversarial network (cWGAN) for road crack detection.
We study the factors affecting training time in multi-device deep learning systems. We identify the degree of asynchronous parallelization as a key factor affecting both hardware and statistical efficiency.
We build a self-balancing federated learning framework call Astraea, which alleviates the imbalances by 1) Global data distribution based data augmentation, and 2) Mediator based multi-client rescheduling.
We present a random field based model for stereo vision with explicit occlusion labeling in a probabilistic framework using structured support vector machine.
We propose Stochastic Activation Pruning (SAP), a mixed strategy for adversarial defense, increasing accuracy and preserving calibration.
We propose LeafGAN, a novel image-to-image translation system with own attention mechanism, as a data augmentation tool for improving the performance of plant disease diagnosis.
We propose a hybrid incremental learning method based on Support Vector Machine, which can incrementally improve its recognition ability by learning new object samples and new object concepts during the interaction.
A new knowledge distillation method based on transferring feature statistics, specifically the channel-wise mean and variance, from the teacher to the student.
Image captioning is an interdisciplinary research problem that stands between computer vision and natural language processing. The task is to generate a textual description of the content of an image.
We propose a framework for multimodal sentiment analysis and emotion recognition using convolutional neural network-based feature extraction from text and visual modalities.
We propose a new area-based stereo matching method by improving the classical Census transform by using Maximum intensity differences of the pixel placed in the center of a defined window and the pixel in the neighborhood.
We present Felix --- a flexible text-editing approach for generation, designed to derive the maximum benefit from the ideas of decoding with bi-directional contexts and self-supervised pre-training.
We propose an efficient real-time 3D object detection method consisting of 3D proposal generation and classification using lightweight convolution neural network.
We advance the concept of end-to-end learning of optical flow and make it work really well, while running at interactive frame rates.
We explore cross-range adaptation for 3D object detection using LiDAR, i.e., far-range observations are adapted to near-range, without adding any auxiliary parameters to the model.
We present Discriminative Region Proposal Adversarial Networks (DRPAN) for image-to-image translation.
We explore the descriptive power of hashtags, and especially those provided by the photo owner/creator, for developing Automatic Image Annotation (AIA) methods.
We propose an algorithm that enables a network to learn continually and efficiently by partitioning the representational space into a Core space, that contains condensed information from previously learned tasks, and a Residual space, which is akin to a scratch space for learning the current task.
In many classification problems a classifier should be robust to small variations in the input vector. We propose two extensions of the backpropagation algorithm that train a neural network to be robust.
We use large-scale commonsense knowledge bases, e.g. ConceptNet, to establish semantic relationships among entities directly hypothesized from video signal, such as putative object and actions labels, and infer a deeper interpretation of events than what is directly sensed.
Visual Question Answering (VQA) is a recent problem in computer vision and natural language processing that has garnered a large amount of interest from the deep learning, computer vision, andnatural language processing communities.
We propose a novel framework which endows the model capabilities in answering more complex questions by leveraging massive external knowledge with dynamic memory networks.
We address the size and imbalance of training data by exploiting the stochastic subsampling intrinsic into the method and a novel, fast, bootstrapping approach.
We propose a robust variant of Canonical Correlation Analysis (RCCA) for performing audio-visual fusion, which we apply to the prediction of interest.
We develop an instance-aware and context-focused unified framework for weakly supervised video object detection.
In this paper we propose an efficient method for the recognition of long and complex action streams, whilst preserving useful motion information for recognition.
In this paper, we propose a novel scheme to learn target-aware features, which can better recognize the targets undergoing significant appearance variations than pre-trained deep features.
We present a generic and flexible module that encodes region proposals by both their intrinsic features and the extrinsic correlations to the others. The proposed non-local region of interest (NL-RoI) can be seamlessly adapted into different generalized R-CNN architectures to better address various perception tasks.
We compare features extracted by four state-of-the-art image classification networks as a way of describing patches from security video frames and analyze the usage of different feature normalization techniques.
Network Dissection quantifies the interpretability of CNN representations by evaluating the alignment between individual hidden units and a set of visual semantic concepts.
In this paper, we attempt to explore the robustness of current person re-ID models against adversarial samples using universal adversarial perturbations.
Neural networks trained with backpropagation often struggle to identify classes that have been observed a small number of times. One potential remedy is to augment the network with a fast-learning non-parametric model which stores recent activations and class labels into an external memory.
We present a method that exploits ensemble decisions based on multiple stochastically sampled network models to increase performance figures of bitwise neural networks in terms of classification accuracy at inference.
We propose a novel 3D Spatial Transformer Network to combine the 3D shape of the face and the semantically consistent 2D alignment points for faster and consistent 3D alignment.
This survey paper provides an essential reference for those interested in further research on human action recognition.
We propose a weakly-supervised method which can effectively predict 3d human pose from 2d pose using a deep neural network trained on a combination of ground-truth 3d pose and ground- truth 2D pose.
In this paper, we introduce diffusion component analysis (DCA), a framework that plugs in a diffusion model and learns a low-dimensional vector representation of each node in a network to encode the topological properties of a network.
We propose two transform units to learn pixel-level consensus features for scene parsing and propose a Consensus Feature Network based on the units.
We extend the unsupervised rank pooling temporal encoding method for action and activity classification by extending it to a high capacity video representation that can be used as input to standard machine learning classifiers.
This paper introduces geometry and object shape and pose costs for multi-object tracking in urban driving scenarios. The proposed costs are agnostic to the data association method and can be incorporated into any optimization framework.
This paper aims at mitigating these drawbacks by: (1) modeling a complex, high DOF system with a representative simple one, (2) making explicit use of forward and inverse kinematics without forcing the RL algorithm to "learn" them on its own, and (3) learning locomotion policies in Cartesian space instead of joint space.
We focus on the occasions when large-scale web search engines find it difficult to cope with specific information-seeking behaviors and we accordingly introduce a query construction service that is targeted towards the solution of this problem.
Fast and accurate Optic Disk Segmentation from Retinal Images for Early Glaucoma Detection .
Combining architectural, regularization and rehearsal strategies for multi-task and single-incremental learning .
In this paper, we present a deep regression approach for face alignment.
We present a novel deep convolutional neural network system for fine-grained image classification, called a mixture of DCNNs (MixDCNN)
We study the most practical problem setup for evaluating adversarial robustness of a machine learning system with limited access: the hard-label black-box attack setting where limited model queries are allowed and only the decision is provided to a queried data input.
We propose a new method for evaluating the calibration of uncertainty prediction for regression tasks which often arise in real-world systems.
Iteratively attending to image patches in a recurrent fashion and subsequently enhancing the predicted segmentation mask in an end-to-end manner.
We propose a novel approach to combining multiple functional association networks for predicting gene function that is faster, simpler and faster.
The recent advance of monocular depth estimation is largely based on deeply nested convolutional networks, combined with supervised training. Inspired by the human visual system, we propose a student-teacher strategy in which a shallow student network is trained with the auxiliary information obtained from a deeper and accurate teacher network.
We propose a linked dynamic graph CNN (LDGCNN) to classify and segment point cloud directly.
Zero-shot methods in language, vision and other domains rely on a cross-space mapping function that projects vectors from the relevant feature space (e.g., visualfeature-based image representations) to a large semantic word space (induced in an unsupervised way from corpus data), where the entities of interest are labeled with the nearest neighbours of the mapped vectors.
In this study, we investigated the capability of state-of-the-art deep learning models in classifying mosquito species having high inter-species similarity and intra-species variations.
We present a simple and intuitive method for multi-oriented text detection where each location of feature maps only associates with one reference box.
We propose a covariate and label distribution CO-ALignment (COAL) model to tackle the task of Generalized Domain Adaptation (GDA) in the presence of both covariATE and label shift.
We present a novel approach that learns disentangled representations of these characteristics and explains them individually. Training requires only pairs of images depicting the same object appearance, but no pose annotations.
We propose a framework that learns event cues from off-policy data, and can flexibly combine these event cues at test time to accomplish a variety of different tasks.
A computational systems approach to predicting human synthetic lethal interactions that works by exploiting conserved patterns in protein interaction network topology both within and across species.
We aim at providing a two-stage face alignment network for mobile platform for real-time processing.
We provide an online convex optimization algorithm with regret that interpolates between the regret of an algorithm using an optimal preconditioning matrix and one using a diagonal preconditionsing matrix. We incorporate new techniques that streamline and improve logarithmic factors in prior regret analyses.
A Unified Tensor-based Active Appearance Model (UT-AAM) for jointly modelling the geometry and texture information of 2D faces.
In this paper, we analyze the significance of the affect-related component of brain signals within the subject identification context, suggesting that the dominant component of the signal is subject-related, but the affective state also has a contribution that affects identification accuracy.
In this paper we propose new methods based on the NMF of the rating matrix and we compare them with classical algorithms such as the SVD and the regularized and unregularized non-negative matrix factorization approach.
We consider the statistical problem of learning common source of variability in data which are synchronously captured by multiple sensors, and demonstrate that Siamese neural networks can be naturally applied to this problem.
We present a novel method to extract features from visual and textual modalities using deep convolutional neural networks, which significantly outperform the state of the art of multimodal emotion recognition and sentiment analysis.
We introduce RC-QED, a new reading comprehension task that requires giving not only the correct answer to a question, but also the reasoning employed for arriving at this answer.
This paper introduces the Eighth Dialog System Technology Challenge. In line with recent challenges, the eighth edition focuses on applying end-to-end dialog technologies in a pragmatic way for multi-domain task-completion.
We study the layer-wise transferability of representations in deep networks across a few datasets and tasks and note some interesting empirical observations.
Two methods are presented to improve word confidence scores for Line-Level Query-by-String Lexicon-Free Keyword Spotting (KWS) in handwritten text images.
The objective of this paper is to design an embedding method that maps local features describing an image (e.g. SIFT) to a higher dimensional representation useful for image retrieval problem.
This paper presents a meta normalization mechanism called Instance-Level Meta Normalization (ILM~Norm) to address a learning-to-normalize problem.
We extend the stochastic gradient descent for support vector machines (SVM-SGD) in several ways to develop the new multiclass SVM- SGD for efficiently classifying large image datasets into many classes.
Combining Gabor wavelets and Local Binary Patterns for robust face recognition with PCA.
The attention layer in a neural network model provides insights into the model's reasoning behind its prediction, which are usually criticized for being opaque. We propose a comprehensive explanation which justifies both kinds of observations (i.e., when is attention interpretable and when it is not).
This paper presents a robust algorithm to identify the letter boundaries in images of unconstrained handwritten word using vertical contour analysis.
We propose a robust security based on face recognition system for giving access into a home for authenticated users.
We propose a novel method to recover the vehicle trajectory using stereo vision technology based on geometrical constraints and improved random sample consensus.
A generalized statement over convolutional layers from input till fully connected layer is introduced that helps further in understanding and designing a successful deep network.
This paper presents a review of the state of the art of egocentric vision systems for the recognition of ADLs following a hierarchical structure, where each level provides higher semantic information and involves a longer time frame.
In this paper, we propose a Hierarchical Transferability Calibration Network (HTCN) that calibrates the transferability of feature representations for harmonizing transferability and discriminability.
We propose a condition to avoid checkerboard artifacts using convolutional neural networks.
Our goal is to shift the focus from individual domain-specific datasets to all the datasets available for entity typing, improving the performance of a model on an individual dataset.
This work proposes an end-to-end learning framework called DARI, i.e. Distance metric And Representation Integration, and validates the effectiveness of DARI in the challenging task of person verification.
We introduce a new convolutional neural network architecture, what/where CNN (2W-CNN), built on a linear-chain feedforward CNN, augmented by hierarchical layers regularized by object pose information to improve deep network learning.
We present a multilingual dependency parser with a bidirectional LSTM (BiLSTM) feature extractor and a multi-layer perceptron (MLP) classifier.
In this paper, we study the value of using synthetically produced videos as training data for neural networks used for action categorization.
This paper addresses a new problem of joint object boundary detection and boundary motion estimation in videos, which we named boundary flow estimation.
We consider the compression artifacts reduction problem, where a compressed image is transformed into an artifact-free image. We propose a one-to-many network, which measures output quality using a perceptual loss, a naturalness loss, and a JPEG loss.
We improve the fundamental 2D fully convolutions by proposing a new local convolutional network (LCN), where the filters and their receptive fields can be automatically learned from image-based depth maps, making different pixels of different images have different filters.
Recommender systems rarely go beyond trivial "best seller" lists or very basic personalized recommendation algorithms which nevertheless exhibit superior performance to more elaborate techniques both in our experiments and other related studies.
We propose evaluation of stereo algorithms based on receiver operating characteristics (ROC) which captures both errors and sparsity, so that reporting results does not take up much space.
We propose a joint source and channel coding (JSCC) technique for wireless image transmission that does not rely on explicit codes for either compression or error correction.
We propose a brain image synthesis procedure intended to generate a new image set that share characteristics with an original one. The synthetic images maintain the differences between groups found at the original dataset.
We propose a Recurrent Highway Network with Language CNN for image caption generation.
We propose a Multi-Scale Transformer which uses multi-scale multi-head self-attention to capture features from different scales.
We present a novel object tracking scheme that can track rigid objects in real time. The approach uses subpixel-precise edges to track objects with high accuracy.
In this paper, a joint feature and similarity deep learning method for vehicle re-identification is proposed.
This paper presents a gait recognition method which combines spatio-temporal motion characteristics, statistical and physical parameters (referred to as STM-SPP) for its classification by analysing shape of a human subject's silhouette contours using Procrustes shape analysis (PSA) and elliptic Fourier descriptors (EFDs).
We investigate how the final parameters found by stochastic gradient descent are influenced by over-parameterization. We find that the optimal SGD hyper-parameters are determined by a "normalized noise scale," which is a function of the batch size, learning rate, and network width.
In this paper, we propose two novel modules to perform the enhancement of the information for the multi-person pose estimation.
We revisit regulariza- tion for Canonical Correlation Analysis (CCA) within the framework of spectral filtering and the Bjork Golub algorithm.
An improved dense scene flow method based on red-green-blue-depth (RGB-D) data for large displacement motion.
We introduce a fast and efficient convolutional neural network for semantic segmentation of high resolution images under resource constraints.
A novel face recognition algorithm based on large-scale supervised hierarchical feature learning.
We propose an efficient and effective method to learn convolutions for non-uniformly sampled point clouds, as they are obtained with modern acquisition techniques.
Our team participated in the CAAD 2018 competition, and won 1st place in both attack subtracks, non-targeted and targeted adversarial attacks, and 3rd place in defense.
In this paper, we propose Continuous Graph Flow, a generative continuous flow based method that aims to model distributions of graph-structured complex data that performs continuous message passing over time.
We hypothesize that the use of background commonsense knowledge on query terms can significantly aid in retrieval of documents with associated images.
We propose a novel approach for 3D classification that takes sparse point clouds as input and learns a model that is robust to rotational and positional variance as well as point sparsity.
We present a novel learning-based method for eye region landmark localization that enables conventional methods to be competitive to latest appearance-based methods in unconstrained settings.
We study image inverse problems with invertible generative priors and establish theoretical recovery guarantees for denoising and compressed sensing under our framework.
We propose to integrate dynamic parameter allocation into parameter servers, describe an efficient implementation of such a parameter server called Lapse, and explore whether such support is beneficial.
We proposed a novel representation model that projects dense word vectors into a higher dimensional space and favors a highly sparse and binary representation of word vectors with potentially interpretable components, while trying to maintain pairwise inner products.
We synthesize person-specific eye images that satisfy a given semantic segmentation mask (content), while following the style of a specified person from only a few reference images.
In this work, we introduce a novel interpretation of residual networks showing they are exponential ensembles. Subsequently, we perform an analysis showing these ensembling mostly consist of networks that are each relatively shallow.
We consider the problem of unsupervised camera pose estimation. We propose an alternative approach that utilizes a compositional re-estimation process.
This paper presents a weakly-supervised approach to object instance segmentation, without requiring hand-tuned segment proposals.
We propose a novel deep representation calibrated Bayesian neural network for semantically explainable face inpainting and editing.
We revisit the relaxed seeded isoperimetric graph partitioning problem and rectify a few discrepancies in the simplifications of the heuristic continuous relaxation, leading to a better interpretation of what is really done by this algorithm.
We propose a novel framework for training efficient deep neural networks by exploiting generative adversarial networks (GANs) without any training data.
A ResNet-based multi-path refinement CNN is used for object contour detection. For this task, we prioritise the effective utilization of the high-level abstraction capability of a ResNet.
We present the first solution for reasoning over large streams of RDF data using big data platforms, where new instance and schema triples can arrive at any time, and where saturation operations can be performed in incremental manner.
The structure of real-world networks is usually difficult to characterize owing to the variation of topological scales, the nondyadic complex interactions, and the fluctuations in the network. We aim to address these problems by introducing a general framework using a method based on topological data analysis.
We investigate ways to expand a given labeled corpus of remote sensed imagery into a larger corpus using Generative Adversarial Networks (GANs). We then measure how these additional synthetic data affect supervised machine learning performance on an object detection task.
We evaluated Bayesian DNNs trained with Bernoulli or Gaussian multiplicative masking of either the units (dropout) or the weights (dropconnect) trained with sampling at prediction time. We found that spike-and-slab sampling had higher test set performance than Gaussian dropconnect and more robustly represented its uncertainty compared to sampling of units.
We introduce both data-independent and data-dependent heuristics to prune convolutional edges, and introduce an end-to-end framework to fine-tune the pruned network while maintaining retrieval performance.
We propose a novel accumulative motion context (AMOC) network for video-based person re-identification.
Large margin learning approaches, such as support vector machines (SVM), have been successfully applied to numerous classification tasks, especially for automatic facial expression recognition.
In this paper, we propose a hierarchical structure that mimics the information flow and transformations that take place in the human brain. The system finds good solutions during the initial stage of genetic and evolutionary search.
This work focuses on mitigating two limitations in the joint learning of local feature detectors and descriptors. First, the ability to estimate the local shape (scale, orientation, etc.) of feature points is often neglected during dense feature extraction, while the shape-awareness is crucial to acquire stronger geometric invariance. Second, the localization accuracy of detected keypoints is not sufficient to reliably recover camera geometry.
We introduce CleanNet, a joint neural embedding network, which only requires a fraction of the classes being manually verified to provide the knowledge of label noise that can be transferred to other classes.
We present a generative model based on a deep recurrent architecture that combines recent advances in computer vision and machine translation and that can be used to generate natural sentences describing an image.
We propose a new form of quantization loss measured in triplets, which can be used to learn discriminative real-valued descriptors for image retrieval.
We introduce a new method of obtaining saliency maps for latent representations of known or novel high-level concepts, often called concept vectors in generative models, and apply them to the CelebA dataset.
We develop a rotation invariant point-cloud segmentation and classification scheme based on the omni-directional camera model (dubbed as {\bf POIRot$1$}).
We introduce a novel principle for self-supervised feature learning based on the discrimination of specific transformations of an image. We propose a criterion to choose and design image transformations.
In this paper, we propose a novel representation approach by constructing mid-level words in videos and encoding them on Riemannian manifold, achieving competitive performance on four popular realistic datasets.
We study the effect of noise within the context of Boolean networks trained to learn complex tasks under supervision. quasi-critical networks are the ones learning in the fastest possible way –even for asynchronous updating rules.
We propose a knowledge transfer method to aid the training of binary weight neural networks using a full-precision teacher network. The proposed method maintains high detection accuracy while reducing the model size.
We address the multi-view subspace clustering problem using tensor-Singular Value Decomposition and a new type of low-rank tensor constraint to ensure consensus among multiple views.
We present a method called dynamic importance sampling, where ranked classes are sampled from a dynamic distribution derived from the interaction between the teacher and student in full distillation.
An automatic modeling of SIFT descriptors, regardless of the number of detected keypoints and using a GMM-based Universal Background Model method, is proposed.
A phrase grounding system localizes a particular object in an image referred to by a natural language query. We propose a new single-stage model called ZSGNet which combines the detector network and the grounding system and predicts classification scores and regression parameters.
In this paper we predict a full 3D avatar of a person from a single image using an image-to-image translation method. We further use our model to digitally change pose, shape, swap garments between people and edit clothing.
In recent years, supervised approaches using deep neural networks (DNNs) have become the mainstream for speech enhancement. However, we find that DNNs fail to generalize to new speech corpora in low signal-to-noise ratio (SNR) conditions.
We introduce an unsupervised method to identify interpretable directions in the latent space of a pretrained GAN model without any form of self-supervision.
In this paper, we propose a new procedure for fast approximation of the metric while preserving its invariance properties.
Digital Health and Deep Learning from the Institute for Infocomm Research (I2R) and the Science and Engineering Research Council (Project Nos. A1718g0045 and A1818g 0044)
This paper describes an integrated robot system, known as Curious George, that has demonstrated state-of-the-art capabilities to recognize objects in the real world, and provides several avenues for potential improvement.
Evenly Cascaded Convolutional Network (ECN), a neural network taking inspiration from the cascade algorithm of wavelet analysis, achieves state-of-the-art results for small networks.
We present DenseRaC, a novel end-to-end framework for jointly estimating 3D human pose and body shape from a monocular RGB image. The generated data covers diversified camera views, human actions and body shapes, and is paired with full ground truth.
Identification of potential drug targets as well as development of novel antimalarial chemotherapies with unique mode of actions due to drug resistance by Plasmodium parasites are inevitable.
We present a fast and accurate algorithmic approach, Node Handprinting (NH), based on our previous work with Node Fingerprinting, which enables quick and accurate alignment of multiple networks.
We measure race and gender inclusion in the context of smiling detection, and introduce a method for improving smiling detection across demographic groups using a twofold transfer learning framework.
We provide a framework for corner case detection in video and propose a system framework that can handle video signals from front cameras of a naturally moving vehicle and can output a corner case score.
We propose our Clue Guided Copy Network for Question Generation (CGC-QG), which is a sequence-to-sequence generative model with copying mechanism, yet employing a variety of novel components and techniques to boost the performance of question generation.
In this paper, we propose a new algorithm that computes the radius and the diameter of a weakly connected digraph G = ( V , E ) , by finding bounds through heuristics and improving them until they are validated.
We propose a modified matched filter for retinal vessel extraction that applies a local vessel cross-section analysis using double-sided thresholding to reduce false responses to nonline edges.
We develop an encoder–decoder convolutional neural network that uses a joint embedding of the face and audio to generate synthesised talking face video frames.
We introduce a weighted residual network to address the incompatibility between \texttt{ReLU} and element-wise addition and the deep network initialization problem.
We present LS-CRF, a new method for very efficient large-scale training of Conditional Random Fields (CRFs) and apply it to image segmentation.
A novel automatic neuron discovery approach based on learned polyharmonic spline activations.
We present Inconsistent Stochastic Gradient Descent (ISGD) to dynamically vary training effort according to learning statuses on batches.
In this paper we propose an approach for articulated tracking of multiple people in unconstrained videos that achieves state-of-the-art results while using only a fraction of time.
In this paper, a simple but effective CNN model was developed based on our image dataset, which can be used in mobile devices.
We propose a recourse algorithm that provides an actionable set of changes a person can undertake in order to improve their outcome under differentiable machine learning based decision making systems.
We propose bilinear models, a recognition architecture that consists of two feature extractors whose outputs are multiplied using outer product at each location of the image and pooled to obtain an image descriptor.
We construct an efficient boosted exemplar-based face detector which overcomes the defect of the previous work by being faster, more memory efficient, and more accurate.
This paper focuses on analyzing existing detection approaches for their generalization ability. Inspired by recent literature regarding person detection in the VIS spectrum, we perform a cross-validation study to empirically determine the most promising dataset to train a well-generalizing detector.
This work explores the transferability of features learned by an object detection CNN (Faster R-CNN) to nucleus classification in histopathology images using class-agnostic models.
Autoregressive models are among the best performing neural density estimators. We describe an approach for increasing the flexibility of an autoregressive model, based on modelling the random numbers that the model uses internally when generating data.
Feature selection can facilitate the learning of mixtures of discrete random variables as they arise, e.g. in crowdsourcing tasks.
We propose a multiple receptive field and small-object-focusing weakly-supervised segmentation network (MRFSWSnet) for fast object detection.
We present the instance segmentation and the object detection method used by team PFDet for Open Images Challenge 2019.
This paper introduces a first effort to apply a deep learning method for direct estimation of scene flow in RGB-D videos using an encoder-decoder (ED) architecture.
This paper presents an innovative Spatial Fusion GAN that combines a geometry synthesizer and an appearance synthesizer to achieve synthesis realism in both geometry and appearance spaces.
We propose a multi-discriminator discriminator which encourages better multi-sentence video description, as shown by automatic as well as human evaluation.
We propose a novel adaptive attention model with a visual sentinel for image captioning. The model decides whether to attend to the image and where, in order to extract meaningful information.
A generative adversarial network with discrete structure autoencoder with a code space regularized by Generative Adversarial Training.
Content based image retrieval (CBIR), the problem of searching digital images in large databases according to their visual content, is a well established research area in computer vision.
We examine the stability of the FD measurement with respect to (1) different vessel annotations obtained from human observers, (2) automatic segmentation methods, (3) various regions of interest, (4) accuracy of vessel segmentation method, and (5) different imaging modalities.
In this paper, we describes a correspondence identification method between two-views of regular RGB camera that can be run in real-time.
This paper extends the task of probing sentence representations for linguistic insight in a multilingual domain to evaluate six sentence encoders for each language.
We consider the problem of minimizing a high-dimensional objective function, which may include a regularization term, using (possibly noisy) evaluations of the function, using an adaptive, randomized gradient estimator, followed by an inexact proximal-gradient scheme. We propose a new $\textbf{Z}$eroth-order, zeroth-$\textbf_{O}$rder $R}$ptimization method.
Unsupervised learning of optical flow, which leverages the supervision from view synthesis, has emerged as a promising alternative to supervised methods.
We propose a privacy-preserving framework for learning visual classifiers by leveraging distributed private image data. We utilize a homomorphic cryptosystem that can aggregate multiple classifiers updated locally using private data.
MS-MIL extends the idea of detecting facial expressions through ‘concept frames’ to “concept segments” and argues through extensive experiments that algorithms such as MIL are needed to reap the benefits of such representation.
We propose a selective multimodal Long Short-Term Memory network (sm-LSTM) for instance-aware image and sentence matching.
We propose spontaneous motion estimation module, along with a refinement module, to learn attribute-driven deformation between source and target domains.
This paper presents an approach for learning from synthesized data effectively.
We explore an asymmetric encoder-decoder structure for unsupervised context-based sentence representation learning.
We propose convolutional fusion networks (CFN) to integrate multi-level deep features and fuse a richer visual representation for pixel-level classification.
3D human articulated pose recovery from monocular image sequences using a recurrent 3D Pose Sequence Machine .
We propose VoxelNet, a generic 3D detection network that unifies feature extraction and bounding box prediction into a single stage, end-to-end trainable deep network for LiDAR point clouds.
This paper presents a single-crop visual object tracking algorithm based on a fully convolutional Siamese network that significantly reduces the computation burden by extracting multiple scale feature maps from a single image crop.
In this paper, we propose a novel method named low-rank representation based action recognition to recognize human actions.
We learn robust bipedal locomotion controllers that imitate a reference motion with DRL.
This paper proposes an approach that uses direction and magnitude models to perform human action recognition from videos captured using monocular cameras.
We propose Dynamic Hierarchical Mimicking, a generic feature learning mechanism, to advance CNN training with enhanced generalization ability.
This paper proposes a new dataset, named VASUN, that records the free-viewing human attention on solar images, and uses it to revisit the problem of visual attention prediction from a novel perspective.
We present a recurrent model for semantic instance segmentation that sequentially generates pairs of masks and their associated class probabilities for every object in an image.
We present a modular reconstruction framework for photoacoustic tomography that enables easy comparisons between regularisers with different properties, e.g. nonlinear, higher-order or directional.
In this paper, inspired by spatial neural-attention for image captioning, we propose a decoupled spatial neural attention network for weakly supervised semantic segmentation with image label annotations.
In this paper, we propose an optimization scheme aiming at optimal nonlinear data projection, in terms of Fisher ratio maximization, which increases class discrimination in the reduced-dimensionality feature space.
We propose an effective approach to localize frame-level action regions through integrating static and kinematic information by the early- and late-fusion detection scheme.
We propose a transfer learning methodology where we adapt HWR models trained on a source language to a target language that uses the same writing script in a bootstrapping fashion.
In this paper, we attempt to maintain the information propagated in the forward process and propose a Balanced Binary Neural Networks with Gated Residual (BBG for short) for image classification and detection.
We introduce a new way of learning to encode position information for non-recurrent models, such as Transformer models, which is capable of modeling many kinds of dynamical systems.
In this paper, we propose a novel $e$-exponentiated transformation, $0.5< e<1$, for loss functions. The transformed loss function enjoys the following desirable property: all the stationary points of the empirical risk are global minima.
Adaptive neural trees combine representation learning and data-driven architectures to achieve competitive performance on classification and regression datasets.
We propose a simple yet effective Semantics Induced Learner (SIL) model for solving this challenging task.
We propose a multimodal learning framework using relation and dependencies among the utterances for conversational emotion analysis.
We explore a very simple alternative to the dropout mask by performing batchwise dropout, so that one pattern of dropout is used for each sample in a minibatch.
We compute deep convolutional network generators by inverting a fixed embedding operator. The embedding is Lipschitz continuous to deformations so that generators transform linear interpolations between input white noise vectors into deformations between output images.
We present methods addressing the problem of automatic video highlight prediction based on joint visual features and textual analysis of the real-world audience discourse, in both English and traditional Chinese.
Regularization is crucial to the success of many practical deep learning models, in particular in a more often than not scenario where there are only a few to a moderate number of accessible training samples, let alone the baffling interaction between Shake-Shake regularization and shaking.
We propose a GAN-based video compression framework using conditional Generative Adversarial Networks (GANs), which achieves much higher quality reconstructions at very low bitrates.
Contour detection is an important and fundamental problem in computer vision which finds numerous applications. To address this problem, we first capture multi-scale features from pixel-level to segmentlevel using Gaussian mixture models and then train a random forest classifier for contour detection.
A video dataset that is designed to study fine-grained categorisation of pedestrians is introduced.
Reading comprehension (RC) is a challenging task that requires synthesis of information across sentences and multiple turns of reasoning. Using a state-of-the-art RC model, we empirically investigate the performance of single-turn and multiple-turn reasoning on the SQuAD and MARCO datasets.
We propose a novel cross-modal self-attention (CMSA) network to aggregate the diverse features from video frames and subtitles from a clip of video to reduce the huge annotation cost.
We focus on explicitly learning disentangled representation for natural image generation, where the underlying spatial structure and the rendering on the structure can be independently controlled, yet using no tuple supervision.
We have developed the prototype semantic video search engine 'yovisto' that demonstrates the advantages of semantically enhanced exploratory video search and enables investigative navigation and browsing in large video repositories.
This paper presents a low-overhead real-time ego-motion estimation (visual odometry) system based on either a stereo or RGB-D sensor.
We propose an algorithm for transforming probabilistic programs to coarse-to-fine programs which have the same marginal distribution as the original programs, but generate the data at increasing levels of detail.
We introduce a fast image processing system that allows to analyse digital data-bases of retinal images in a short time, and to process the image in situ while the patient is examined.
Batch Normalization (BN) techniques have been proposed to reduce the Internal Covariate Shift (ICS) by attempting to keep the distributions of layer outputs unchanged. However, since only two moments are controlled in these BN techniques, it seems that a weak constraint is imposed on layer distributions and furthermore whether such constraint can reduce ICS is unknown.
We propose PQ-AQ, a simple yet effective method to generate adversarial examples for product quantization based retrieval systems.
We propose a generative segmentation model based on a combination of a U-Net with a conditional variational autoencoder that is capable of efficiently producing an unlimited number of plausible hypotheses.
We propose a search framework for finding effective architectural building blocks for convolutional neural networks (CNN) and apply it to generate state-of-the-art models.
In this paper, we propose a trainable end-to-end system called DehazeNet, for medium transmission estimation, which achieves superior performance over existing methods.
A novel ResNet-TP based representation based on a convolutional neural network with context aggregation for scene classification.
We propose Defense-GAN, a new framework leveraging the expressive capability of generative models to defend deep neural networks against adversarial perturbations.
The Semantic Web contains an enormous amount of information in the form of knowledge bases (KB). To make this information available, many question answering (QA) systems over KBs were created in the last years. The aim of this survey is to give an overview of the techniques used in current QA systems overKBs.
We propose to combine positive evidence of attribute synonymity from query click logs, with negative evidence from web table attribute name co-occurrences in a linear programming based algorithm that has bi-criteria approximation guarantees.
We present a new generative adversarial network based on conditional GANs for image inpanting and introduce a new strategy called adversarial loss annealing to reduce the artifacts.
This study proposes a semantic search framework to support efficient keyword-based semantic search on RDF data utilizing near neighbor explorations.
We propose an approach that can be trained end-to-end on videos that are only weakly labeled and achieves state-of-the-art results.
We begin by investigating the numerical reasoning capabilities of a state-of-the-art question answering model on the DROP dataset. We find this model excels on questions that require numerical reasoning, i.e., it already captures numeracy.
In many real-world applications of Machine Learning it is of paramount importance not only to provide accurate predictions, but also to ensure certain levels of robustness. In this paper, a new algorithm, called Wasserstein Projected Gradient Descent, for adversarial training is proposed.
Zero-shot recognition aims to accurately recognize objects of unseen classes by using a shared visual-semantic mapping between the image feature space and the semantic embedding space.
We propose an alternative approach to model high-order interaction signals in the embedding level, namely Generalized Embedding Machine (GEM).
The choice of activation functions in deep networks has a significant effect on the training dynamics and task performance. In this work, we propose a new activation function, named Swish, which is simply $f(x) = x \cdot \text{sigmoid}(x), which works better than ReLUs on deeper models.
Neural networks utilize the softmax as a building block in classification tasks, which contains an overconfidence problem and lacks an uncertainty representation ability. As a Bayesian alternative to softmax, we consider a random variable of a categorical probability over class labels.
Multi-head Asymmetric Hashing for low-bit hash codes, achieving state-of-the-art performance.
In this paper, we explore a natural setup for learning cross-lingual sentence representations: the dual-encoder.
We propose a simple, lightweight approach for better context exploitation in CNNs by introducing a pair of operators: gather, which efficiently aggregates feature responses from a large spatial extent, and excite, which redistributes the pooled information to local features.
We propose an end-to-end supervised model for OD abnormality detection. The most informative features of the OD are learned directly from retinal images.
We present a new min-max framework for filter-level pruning of CNNs. Our framework, called Play and Prune (PP), jointly prunes and fine-tunes CNN model parameters, with an adaptive pruning rate, while maintaining the model's predictive performance.
We introduce Pixel-aligned Implicit Function (PIFu), a highly effective implicit representation that locally aligns pixels of 2D images with the global context of their corresponding 3D object. Using PIFu, we propose an end-to-end deep learning method for digitizing highly detailed clothed humans that can infer both 3D surface and texture from a single image.
We investigate video classification via a two-stream convolutional neural network (CNN) design that directly ingests information extracted from compressed video bitstreams.
In this paper, we propose a zoom-out-and-in network for generating object proposals. Inspired by the conv/deconv structure, we fully leverage the low-level local details and high-level regional semantics from two feature map streams, which are complimentary to each other.
We explore subspaces of adversarial examples in unitary vector domain, and we propose a novel detector for defending our models trained for environmental sound classification.
Learning to construct text representations in end-to-end systems can be difficult, as natural languages are highly compositional and task-specific annotated datasets are often limited in size. Methods for directly supervising language composition can allow us to guide the models based on existing knowledge.
We used structure-based virtual screening to uncover new inhibitor chemotypes of UGM, including a triazolothiadiazine series, which can be used as antimicrobial leads.
We propose a new occupational-aware adversarial face aging network, which learns human aging process under different occupations, for studying the influences of occupations on the appearances.
We increase the feature map dimension at downsampling locations to involve as many locations as possible to increase generalization ability.
This paper proposes CF-NADE, a neural autoregressive architecture for collaborative filtering tasks, which is inspired by the Restricted Boltzmann Machine (RBM) based CF model and the Neural Autoregressive Distribution Estimator (NADE)
In this paper, we propose metrics to evaluate both the quality and diversity simultaneously by approximating the distance of the learned generative model and the real data distribution.
We propose a differentiable search space that allows the annealing of architecture weights, while gradually pruning inferior operations, thus the search converges to a single output network in a continuous manner.
We propose a video prediction-based methodology to scale up training sets by synthesizing new training samples in order to improve the accuracy of semantic segmentation networks.
We address the task of predicting future frame segmentation from a stream of monocular video by leveraging the 3D structure of the scene, achieving state of the art accuracy in future semantic segmentation.
AHINE uses an adaptive deep model to learn network embeddings that maximizes the likelihood of preserving the relationship chains between non-adjacent nodes.
We introduce regularization techniques in deep reinforcement learning for continuous control through the application of sample elimination and early stopping and increase generalization capacity in widely used transfer learning benchmarks by using entropy bonus, different critic methods and curriculum learning in an adversarial setup.
We develop an ACE-net that aims to enhance the feature representation and utilization by augmenting the contracting and expansive paths for biomedical image segmentation applications.
This paper explores a variety of models for frame-based music transcription, with an emphasis on the methods needed to reach state-of-the-art on human recordings.
A dominant paradigm for learning-based approaches in computer vision is training generic models, such as ResNet for image recognition, or I3D for video understanding, on large datasets and allowing them to discover the optimal representation for the problem at hand.
We propose a Bayesian approach to operational calibration that gradually corrects the confidence given by the model under calibration with a small number of labeled operational data deliberately selected from a larger set of unlabeled operational data.
We propose a multimodal convolutional neural network that takes into consideration faithful representations of both color and luminance channels, and performs stylization hierarchically with multiple losses of increasing scales.
We design a new connectivity pattern for the U-Net architecture. The coupling connections could make the information flow more efficiently across U-Nets.
We exploit the kernel canonical correlation analysis (KCCA) to learn a similarity between images and texts. We then propose methods to build improved visual and text kernels.
We investigate the use of depthwise separable convolutions to reduce training time while maintaining data generation performance.
In this paper, we look at Natural Language Inference, arguing that the notion of inference the current NLP systems are learning is much narrower compared to the range of inference patterns found in human reasoning. We then propose ways in which this can be remedied, effectively producing more realistic datasets for NLI.
We describe Human Mesh Recovery (HMR), an end-to-end framework for reconstructing a full 3D mesh of a human body from a single RGB image that is parameterized by shape and 3D joint angles.
We propose an impostor resilient multimodal metric that can effectively restrict large number of impostors from both Probe and Gallery views in person reidentification.
We propose a new interface where classes are annotated via speech, yielding high-quality annotations at 2.9x less annotation time than existing methods.
First-person videos have unique characteristics such as heavy egocentric motion, strong preceding events, salient transitional activities and post-event impacts. We propose a method to represent the high level dynamics of sub-events in first- person videos using a temporal feature pooling function using a pyramidal temporal structure.
We introduce a fast splitting-based method for global EPS that minimizes the objective function of ${l_2} data and prior terms (possibly non-smooth and non-convex) in linear time.
We present an approach to semantic scene analysis using deep convolutional networks. Our approach is based on tangent convolutions.
This paper presents a novel method for deriving a compact and distinctive representation of image content called Robust Visual Descriptor with Whitening (RVD-W).
We propose a novel Graph mask Convolutional Network (GmCN) in which nodes can adaptively select optimal neighbors in their feature aggregation to better serve GCN learning.
Neural-Backed Decision Trees improve state-of-the-art explainable models on ImageNet, improving the baseline by ~14% to 75.30% top-1 accuracy.
This paper presents a novel Deep Appearance Models (DAMs) approach, an efficient replacement for AAMs, to accurately capture both shape and texture of face images under large variations.
This paper presents a method for learning a feature representation that is invariant to pose, without requiring extensive pose coverage in training data.
In Saccharomyces cerevisiae, DNA replication stress activates the replication checkpoint, which slows S-phase progression, stabilizes slowed or stalled replication forks, and relieves inhibition of the ribonucleotide reductase (RNR) complex. We found that Ccr4 cooperated with the Dun1 branch of replication checkpoint to overcome replication stress.
We present an approach that does both tasks within the same trained model, and only uses regular language parallel data, without requiring error-corrected or style-adapted texts.
We propose an alternative to the lexicon driven decoding process based on a lexicon verification process, coupled with an original cascade architecture, which achieves new state-of-the-art word recognition performance on the Rimes and IAM databases.
This paper presents an unsupervised learning approach for simultaneous sample and feature selection based on the CUR matrix decomposition, in the absence of supervision.
VALAN is a lightweight and scalable software framework for deep reinforcement learning based on the SEED RL architecture. The framework facilitates the development and evaluation of embodied agents for solving grounded language understanding tasks.
In this paper, a cross-subject graph that depicts the (dis)similarities between samples across subjects is used as a priori for developing a more flexible framework that suits an assortment of fMRI datasets.
Regularizing the gradient norm of the output of a neural network with respect to its inputs is a powerful technique, first proposed by Drucker & LeCun (1991) who named it Double Backpropagation.
In this paper, we propose to integrate recurrent connections across channels to both inference and generation steps of VAE, improving existing VAE.
Stochastic configuration networks (SCNs) for fast building randomized learners with matrix-inputs.
This work proposes a novel multi-value segmentation algorithm that utilizes CCA to segment color images.
We propose a new learning approach, MIL-NCE, capable of learning strong video representations from scratch, without the need for any manual annotation.
We introduce LiteSeg, a lightweight architecture for semantic image segmentation that achieves 67.81% mean intersection over union at 161 frames per second.
In this paper, we present two methods for parsing to a Universal Dependencies graph representation that explicitly encodes elided material with additional nodes and edges.
We present a recurrent layer which uses coreference annotations extracted from an external system to connect entity mentions belonging to the same cluster.
We propose an end-to-end network model to learn reinforced attentional representation for accurate target object discrimination and localization in a computationally efficient fashion.
We propose an iterative two-step algorithm to effectively prune each layer, by a LASSO regression based channel selection and least square reconstruction, to accelerate very deep CNN models.
The current state-of-the-art for image annotation and image retrieval tasks is obtained through deep neural networks, which combine an image representation and a text representation into a shared embedding space into a competitive multimodal embedding generation scheme.
We examine the possibility that recent promising results in automatic caption generation are due primarily to language models, and find that a state-of-the-art neural captioning algorithm is able to produce quality captions even when provided with surprisingly poor image representations.
We propose a framework for rotation and translation covariant deep learning using SE(2) group convolutions, which allow to generically deal with rotated input samples without the need for data augmentation.
The thud of a bouncing ball, the onset of speech as lips open—when visual and audio events occur together, it suggests that there might be a common, underlying event that produced both signals.
We propose a novel latent CNN framework for image classification, which treats the most discriminate region as a latent variable and achieves state-of-the-art performance.
We present a convolutional neural network based approach for motion prediction based on optical flow.
We propose an actor-critic framework that models the uncertainty of the future and simultaneously learns a policy based on that uncertainty model. The learned policy can map the same state to different actions depending on the propensity for risk.
SimCLR: a simple framework for contrastive learning of visual representations without specialized architectures or memory banks.
We propose a fast and accurate data selection method, referred to as iterative projection and matching (IPM), with linear complexity w.r.t. the number of data.
We propose a novel method that relies on the Wasserstein distance between the node feature vector distributions of two graphs, which allows to find subtler differences in data sets by considering graphs as high-dimensional objects.
Modularity can serve as an intrinsic validation metric for cross-lingual word embeddings, particularly on distant language pairs in low-resource settings.
We present an approach that takes a single child as input and automatically produces a series of age-progressed outputs between 1 and 80 years of age, accounting for pose, expression, and illumination.
We consider the problem of automated recognition of temporal segments (neutral, onset, apex and offset) of Facial Action Units. To this end, we propose the Laplacian-regularized Kernel Conditional Orditional Ordinal Random Field model.
We present a fusion of handcrafted features and deep feature representa- tion learned using multiple body parts to complement the global body features that achieves state-of-the-art performance in image-based per- son re-identification.
We propose the incorporation of exemplar based approaches towards solving semantic tasks such as VQA and VQG, where one aims to answers related to an image.
In this paper, we introduce a new modeling approach of texts for handwriting recognition based on syllables.
We propose the Reinforced Evolutionary Neural Architecture Search (RENAS), which is an evolutionary method with reinforced mutation for neural architecture search.
We introduce a context-based vocabulary remapping model to reprogram neural networks trained on a specific sequence classification task, for a new sequence ::: classification task desired by the adversary.
We present a new algorithm, global positioning graph matching (GPGM), to perform global network alignments between pairs of undirected graphs by minimizing a dissimilarity score over matched vertices.
We seek a few-shot, unsupervised image-to-image translation algorithm that works on previously unseen target classes that are specified, at test time, only by a few example images.
We address the problem of spatio-temporal action detection in videos using deformable tube proposal networks.
In this paper, we propose a gradient-based importance measure that we use to empirically analyze relative importance of training images in four datasets of varying complexity.
Using the theory of positive semidefinite kernels we show in this paper that for a certain class of regularizers on the output kernel, the constraint of being positive semidesfinite can be dropped as it is automatically satisfied for the relaxed problem.
We introduce a multiple input deep regression model to predict the CF latent embedding vectors of items based on their textual description and metadata.
We present a novel and high-performance 3D object detection framework, named PointVoxel-RCNN, for accurate 3Dobject detection from point clouds.
We propose convolutional networks with adaptive inference graphs (ConvNet-AIG) that adaptively define their network topology conditioned on the input image.
In this paper, we propose a novel model compression approach to effectively compress BERT by progressive module replacing.
This paper provides the observation that the spatial misalignment between the two object functions in the sibling head can considerably hurt the training process, but this misal alignment can be resolved by a very simple operator called task-aware spatial disentanglement (TSD). Considering the classification and regression, TSD decouples them from the spatial dimension by generating two disentangled proposals for them, which are estimated by the shared proposal.
This paper presents a segmentation-based stereo matching algorithm using an adaptive multi-cost approach, which is exploited for obtaining accuracy disparity maps.
We propose a multi-task network, generating labels for vessel interior, centerline, edges and junction patterns, to provide additional information to facilitate junction detection.
This paper proposes a holistic multi-task Convolutional Neural Networks (CNN) with the dynamic weights of the tasks,namely FaceLiveNet+, for face authentication.
We present a recursive model inspired by NangiaB18 that learns the correct parsing strategy on mathematical expressions generated from a simple context-free grammar.
We explore the idea of compositional set embeddings that can be used to infer not just a single class per input (e.g., image, video, audio signal), but a collection of classes in the setting of one-shot learning.
We propose a new hypothesis that noise may occur in saliency maps when irrelevant features pass through ReLU activation functions. We propose a method that alleviates this problem through layer-wise thresholding.
We bring together ideas from recent work on feature design for egocentric action recognition under one framework by exploring the use of deep convolutional neural networks (CNN), where one stream analyzes appearance information and the other stream evaluates motion information.
This paper proposes to compensate for this reaction lag by finding the time-shift that maximizes the mutual information between the expressive behaviors and the Time-continuous annotations. The benefits of compensating for the delay is demonstrated with emotion classification experiments.
We reformulate the group feature selection problem as a sparse problem by prescribing the maximum number of active groups and propose a novel method based on the ADMM algorithm.
Learning a visual representation from the raw spatiotemporal signals in videos for use in action recognition.
A ResNet-based model that dynamically selects Computational Units (CU) for each input object from a learned set of transformations.
We propose a novel semi-supervised deep convolutional network that leverages extremely limited AU annotations for intensity estimation, which greatly improves the efficiency during inference.
We propose a fluency-guided learning framework for cross-lingual image captioning from machine-translated sentences.
We propose a state-of-the-art baseline 3D MOT system for KITTI, improving the 3D MOTA from 72.23 prior art to 76.47.
This paper presents a novel framework for learning a hierarchical compositional shape vocabulary for representing multiple object classes.
This paper presents study on the combination of difference image and K-means clustering for the segmentation of retinal vessels. The combination of arc-chord ratio with stationary points is used to compute tortuosity index.
We propose a sign correlation subspace method for domain partition in only one reduced low-dimensional subspace for multi-pose face alignment.
We propose a multi-level feature network with multiple losses for person re-identification.
We propose a principled approach for training binary neural networks which justifies and extends existing approaches which justifies some of the algorithmic choices made by previous approaches.
Using gaze information for integrating automatic detection systems in the clinical practice for detecting lung nodules.
We propose the Max-Mahalanobis center (MMC) loss to explicitly induce dense regions in the feature space in order to benefit robustness.
We propose the Cross-Domain Semi-Supervised Learning (CDSSL) framework for cross-domain object detection. The code will be released.
We propose a biologically-inspired context-aware object recognition model consisting of a two-stream architecture that captures the role of contextual information in visual recognition and captures the dependence of context enhancement on image properties.
Drug-drug interactions (DDIs) are responsible for many serious adverse events; their detection is crucial for the safety of the patient but also it is very challenging. This study describes a model which can be used to predict novel DDIs based on the similarity of drug interaction candidates to drugs involved in established DDIs.
Unsupervised learning permits the development of algorithms that are able to adapt to a variety of different datasets using the same underlying rules thanks to the autonomous discovery of discriminating features during training.
A variety of platforms, such as micro-unmanned vehicles, are limited in the amount of computational hardware they can support due to weight and power constraints. An efficient stereo vision algorithm implemented on an FPGA would be able to minimize payload and power consumption, while providing 3D information and still leaving computational resources available for other processing tasks.
Similarity-Guided Graph Neural Network for person re-identification task.
Generative models produce realistic objects in many domains, including text, image, video, and audio synthesis. Most popular models---Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs) employ a standard Gaussian distribution as a prior. We propose a new family of priors that pack an exponential number of Gaussians into a high-dimensional lattice with a relatively small number of parameters.
We propose the Multimodal Factorization Model (MFM) that factorizes multimodal representations into two sets of independent factors of variation in the data, capture important features for both 2) discriminative and 3) generative tasks, and couple both modality-specific and multimodAL information.
We present a method for data-free knowledge distillation, which is able to compress deep neural networks trained on large-scale datasets to a fraction of their size leveraging only some extra metadata to be provided with a pretrained model release.
Query is GAN based on text-to-image GAN that improves scene retrieval performance by simple procedures.
We propose a novel high-order predictor to accelerate the generation of spatially correlated visual words in natural images and propose two methods of co-occurrence weighting similarity measure for image ranking.
We propose a plug-in module for existing SR networks to perform scale-arbitrary SR while maintaining state-of-the-art performance.
We propose a method for building large collections of human poses with full 3D annotations captured `in the wild', for which specialized capture equipment cannot be used.
Polygonal objects are prevalent in man-made scenes. Early approaches to detecting them relied mainly on geometry while subsequent ones also incorporated appearance-based cues. In this paper, we propose an approach that eliminates this restriction. Given a weighted line-fragment graph, we use its cyclomatic number to partition the graph into managebly-sized sub-graphs that preserve nodes and edges that are most likely to contain object contours.
Facial expressions play a significant role in human communication and behavior. The ability to recognize facial expressions automatically, enables novel applications in fields like human-computer interaction, social gaming, and psychological research. In this paper, we employ CNN understanding methods to study the relation between the features these computational networks are using, the FACS and Action Units (AU), and exploit the nature of the FER based CNN models for the detection of micro-expressions
We propose `EvalNorm' to address the issue by estimating corrected normalization statistics to use for BN during evaluation. EvalNorm yields large gains for models trained with smaller batches.
We propose a manifold-based method for visual object counting (M-VOC), based on the manifold assumption that similar image patches share similar object densities.
In this paper, we introduce an in-depth application of high-resolution disparity map estimation using stereo images from Curiosity rover’s Mastcams, which have two imagers with different resolutions.
We propose a method for object localization that learns incrementally without retraining existing objects, and address four key aspects.
We introduce a new large dataset for fine-grained object pose estimation and introduce a CNN-based pose estimation framework based on Faster/Mask R-CNN for the new dataset.
In this work, we propose a new layer-by-layer channel pruning method called Channel Pruning guided by classification Loss and feature Importance (CPLI)
This paper presents methods for recovering accurate binocular disparity estimates in the vicinity of 3D surface discontinuities. Two advances are put forth.
We present a novel deep learning approach to reconstruct confocal microscopy stacks from single light field images, thus dramatically reducing 720-fold the time for confocal scanning at the same volumetric resolution.
This paper presents a real-time stereovision algorithm implemented on a GPGPU (General-purpose graphics processing unit) using a trinocular stereovISION camera array using a winner-take-all method applied to perform fusion of disparities.
We extend the state of the art for the GAN-based image-to-image translation method by enhancing the perceptual quality of the generated images and preserving the semantics.
We present a novel image stylization method that involves an additional structure representation that effectively reflects the spatial distribution of all the components in an image as well as the structure of dominant objects.
We propose a novel self-supervised learning approach for predicting the omnidirectional depth and camera motion from a 360{\deg} video on PanoSUNCG with faster inference speed comparing to equirectangular.
We propose Generalized Ternary Connect (GTC), which allows an arbitrary number of levels while at the same time eliminating multiplications by restricting the parameters to integer powers of two.
In this paper, we propose a Ubiquitous Reweighting Network (URNet) that can learn an image classification model from noisy web data.
The recognition and classification of the diversity of materials that exist in the environment around us are a key visual competence that computer vision systems focus on in recent years. Building on various widely used material databases collected, a selection of CNN architectures is evaluated to understand which is the best approach to extract features in order to achieve outstanding results for the task.
We present a novel dynamic configuration technique for deep neural networks that permits step-wise energy-accuracy tradeoffs during runtime.
We propose a novel method for temporally pooling frames in a video for the task of human action recognition. Our algorithm does so by continuously predicting the discriminative importance of each video frame and subsequently pooling them in a deep learning framework.
This paper focuses on regularizing the training of the convolutional neural network (CNN). We propose a new regularization approach named ``PatchShuffle`` that can be adopted in any classification-oriented CNN models.
We study the problem of recovering an underlying 3D shape from a set of images. We present a new feed-forward neural module, named AttSets, together with a dedicated training algorithm, named FASet, to attentively aggregate an arbitrarily sized deep feature set for multi-view 3D reconstruction.
We present a corpus of spoken Dutch image descriptions, paired with two sets of eye-tracking data: free viewing, where participants look at images without any particular purpose, and description viewing,where we track eye movements while participants produce spoken descriptions of the images they are viewing.
We propose a self-expressive kernel subspace clustering method that can handle non-linear models.
We present AQQUCN, a QA system that gracefully combines KG and corpus evidence to directly rank KG entities, rather than commit to one semantic interpretation of the query.
We present a simple methods to leverage the table content for the BERT-based model to solve the text-to-SQL problem to state-of-the-art.
In this paper, we propose a multiresolution feature coding (MFC) framework via aggregating feature codings obtained from a set of small visual vocabularies with different sizes, where each vocabulary is obtained by a clustering algorithm, and different clustering algorithms discovers different aspect of image features.
Pose guided synthesis aims to generate a new image in an arbitrary target pose while preserving the appearance details from the source image.
We propose a new facial dataset collected with an innovative RGB–D multi-camera setup whose optimization is presented and validated. 3DWF includes 3D raw and registered data collection for 92 persons.
We exploited the application of different Convolutional Neural Networks (CNN) schemes to show the influence in the performance of relevant factors like the data set size, the architecture and the use of transfer learning.
We propose a simple architecture model with emphasis on relation prediction by using a Multi-Label Deep Neural Network (DNN), and developed KGML.
We propose an extension of a position-based model MV-LSTM with an attention-based weighting process, allowing a parameterizable architecture.
We propose a new adversary resistant technique that obstructs attackers from constructing impactful adversarial samples by randomly nullifying features within data vectors, which significantly boosts DNN robustness to adversarial sampling.
An ideal description for a given video should fix its gaze on salient and representative content, which is capable of distinguishing this video from others. The dataset bias often results in recognition error or detail deficiency of salient but unusual objects.
We propose a novel community-based model for measuring bonding and bridging social capital in a social network that captures both direct and indirect connections.
We address the task of interactive full image annotation, where we propose an interactive, scribble-based annotation framework which operates on the whole image to produce accurate segmentations for all regions.
In this paper, we propose a novel active learning (AL) framework, which is capable of building a competitive classifier with optimal feature representation via a limited amount of labeled training instances in an incremental learning manner.
We propose Dynamics of Attention for Focus Transition (DAFT) as a human prior for machine reasoning that obeys the human prior towards shorter reasoning paths in addition to producing more interpretable attention maps.
In this work, we present a rules-based method for localizing retinal blood vessels in confocal scanning laser ophthalmoscopy (cSLO) images and evaluate its feasibility.
We use Gaussian Mixture model based feature representation for audio event recognition and combine them with linear as well as non-linear kernel Support Vector Machines.
We propose an attentive computation framework with a three-layer architecture, which consists of an unconsciousness flowlayer, a consciousness flow layer, and an attention flow layer.
Decoupled Greedy Learning addresses the update locking problem of back-propagation and can be used for large-scale training.
We propose a general directed acyclic graph (DAG) model to describe the distributed synchronous stochastic gradient descent (S-SGD) algorithm, which has been widely used in distributed deep learning frameworks.
This paper presents a multimodal emotion recognition method that uses a feature-level combination of three-dimensional (3D) geometric features (coordinates, distance and angle of joints), kinematic features such as velocity and displacement of joints, and features extracted from daily behavioral patterns such as frequency of head nod, hand wave, and body gestures.
We proposed a new model which employs convolutional autoencoders as feature extractors for end to end sentence level Lip-reading.
We capitalize on large amounts of readily-available, synchronous data to learn a deep discriminative representations shared across three major natural modalities: vision, sound and language.
We propose a new algorithm MINERVA, which addresses the much more difficult and practical task of answering questions where the relation is known, but only one entity.
We use a neural network to learn the training pattern from MNIST classification and utilize it to accelerate training of novel neural networks.
Mini-YOLOv3 is a lightweight network for multi-scale object detection on embedded devices. It has smaller model size and fewer trainable parameters and floating point operations (FLOPs) in comparison of YOLOV3.
We introduce an efficient combination of established techniques to improve classifier performance, in terms of accuracy and training time, by dynamically tuning the learning rate.
We propose a novel scene graph generation algorithm with external knowledge and image reconstruction loss to overcome these dataset issues.
We present a new, simple model that uses attention to directly pick the answer from the context as opposed to computing the answer using a blended representation of words in the document.
This paper performs the first investigation into depth for large-scale human action recognition in video where the depth cues are estimated from the videos themselves.
We introduce an adaptive CNN architecture that shares most of the structure for multiple tasks including source detection, article illustration and geolocation of articles in which the textual content often expresses connotative and ambiguous relations.
We propose a training method for visual attention networks, Coarse2Fine, which creates a differentiable path from the input space to the attended feature maps to better attend the fine-grained features.
We present a novel Convolutional Neural Network architecture, reinforced with a Self-Attention module that it can be deployed on an embedded system, due to its lightweight nature, with just 1.9 Million parameters.
The need to increase security in open or public spaces has in turn given rise to the requirement to monitor these spaces and analyse those images on-site and on-time. At this point, the use of smart cameras – of which the popularity has been increasing – is one step ahead. With sensors and Digital Signal Processors (DSPs), smart cameras generate ad hoc results for face detection and recognition.
We propose a region-level stacked bi-directional deep learning framework for EEG-based image classification of brain activities evoked by images.
We introduce the Hardware-Aware Automated Quantization (HAQ) framework which leverages the reinforcement learning to automatically determine the quantization policy for different neural network architectures and hardware architectures.
We present a pipeline for multi-view 3D pose estimation of multiple individuals which combines a state-of-art 2D pose detector with a factor graph of 3D limb constraints optimized with belief propagation.
This paper introduces an efficient, non-linear image adaptive filtering as a generalization of the standard spatial convolution of convolutional neural networks (CNNs) and make the filters amendable to learning.
We provide a comprehensive review on the development of multiple object tracking in recent decades. We inspect the recent advances in various aspects and propose some interesting directions for future research.
We propose in this paper an active pedestrian detector that explicitly operates over multiple-layer neuronal representations of the input still image.
We present QuAC, a dataset for Question Answering in Context that contains 14K information-seeking QA dialogs (100K questions in total). The dialogs involve two crowd workers: (1) a student who poses a sequence of freeform questions to learn as much as possible about a hidden Wikipedia text, and (2) a teacher who answers the questions.
We propose a semi-automated method for efficient labelling of image sequences by utilising an estimated road plane in 3D based on where the car has driven and projecting labels from this plane into all images of the sequence.
We propose to distill knowledge from BERT, a state-of-the-art language representation model, into a single-layer BiLSTM, as well as its siamese counterpart for sentence-pair tasks.
In order to accurately count the number of animals grazing on grassland, we present a livestock detection algorithm using modified versions of U-net and Google Inception-v4 net.
In the context of Multi Instance Learning, we analyze the Single Instance learning objective. We show that when the data is unbalanced and the family of classifiers is sufficiently rich, the SI method is a useful learning algorithm.
We propose a novel color clustering and spatio-temporal regularized correlation regressions-based complementary tracker that can adaptively deal with significant color variations and deformations for each sequence.
Comunicacio presentada a la 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP 2018), celebrada del 31 d'octubre al 4 de novembre de 2018 a Brussel·les, Belgica.
We describe a strategy for detection and classification of man-made objects in large high-resolution satellite photos under computational resource constraints, where inferences are restricted to be on 8GB memory limit.
In this paper, we propose a single compact and lightweight architecture for real-time semantic stereo matching.
We propose a novel approach to learn embeddings with triple trustiness on KGs, which takes possible noises into consideration. Through extensive experiments on three datasets, we demonstrate that our proposed model can learn better embeddlings than all baselines.
We present Active Orientation Models (AOMs), generative models of facial shape and appearance, which extend the well-known paradigm of Active Appearance Models for the case of generic face alignment under unconstrained conditions.
We explore an advanced, correlation-based representation learning method on a 4way parallel, multimodal dataset, and assess the quality of the learned representations on retrieval-based tasks.
We propose a new task which aims to generate informative image captions, given images and hashtags as input.
We compare distance metrics (and divergences) to rank features generated from a neural network, for content-based image retrieval.
We introduce a novel, simple convolution neural network (CNN) architecture - multi-group norm constraint CNN (MGNC-CNN) that capitalizes on multiple sets of word embeddings.
Policy search methods can allow robots to learn control policies for a wide range of tasks, but practical applications of policy search often require hand-engineered components for perception, state estimation, and low-level control. In this paper, we aim to answer the following question: does training the perception and control systems jointly end-to-end provide better performance than training each component separately?
Inspired by"predictive coding"- a theory in neuroscience, we develop a bi-directional and dynamic neural network with local recurrent processing for image classification.
We propose a novel CNN plus Graph Convolutional Network (GCN) architecture that integrates both semantic and spatial visual relationships into image encoder.
We propose a fully learnable clustering framework without requiring a large number of overlapped subgraphs. Instead, we transform the clustering problem into two sub-problems.
In the field of machine learning, it is still a critical issue to identify and supervise the learned representation without manually intervention or intuition assistance to extract useful knowledge or serve for the latter tasks.
Positron emission tomography (PET) imaging is an imaging modality for diagnosing neurological diseases. Motivated by developments in modality transfer in vision, we study the generation of certain types of PET images from MRI data.
Hierarchical sentence factorization can be used to improve the performance of existing unsupervised distance-based metrics as well as multiple supervised deep learning models based on the convolutional neural network (CNN) and long short-term memory.
We extend the set of descriptors to include materialmotivated attributes using variances of gradient orientation and magnitude. Large-Margin Nearest Neighbor learning is used for a 30-fold dimension reduction.
We propose a novel and simple pruning method that compresses neural networks by removing entire filters and neurons according to a global threshold across the network without any pre-calculation of layer sensitivity.
We propose a first-of-its-kind approach of learning saliency prediction from sparse fixation pixel map, and a novel loss function for training from such sparse fixation.
We propose neural embedding propagation (NEP), which leverages distributed embeddings to represent heterogeneous networks and dynamically composed modular networks to model their complex interactions.
We present a Dirichlet process mixture model over discrete incomplete rankings and study two Gibbs sampling inference techniques for estimating posterior clusterings and their applicability to exploring large realworld ranking datasets.
We propose a capped l ::: 1 ::: -norm sparse representation method to deal with the outliers in graph clustering.
The ability to decompose and represent challenging 3D scenes into semantically meaningful components, such as objects and background elements, is crucial for general intelligence. To address this problem, we have developed the Multi-Object Network.
We propose a framework called Recurrent Residual Module (RRM) to accelerate the CNN inference for video recognition tasks.
We propose a method to automatically generate furniture layouts for indoor environments. The generated layouts are specified as 3D object models, along with their positions and orientations.
We introduce region-wise classifier networks that use shared, region-independent convolutional features for object detection and demonstrate their effectiveness.
We examine the representational stability of several approaches that recently advanced the state of the art on the CelebA benchmark by generating adversarial examples formed by adding small, non-random perturbations to inputs yielding altered classifications.
We propose a method that replaces the fully-connected layers of convolution neural network models with a tree classifier, and use a multi-kernel SVM plus classifier with hierarchical constraints to train it.
We present a method for visual object classification using only a single feature, transformed color SIFT with a variant of Spatial Pyramid Matching (SPM), trained with an ensemble of linear regression (provided by LINEAR) to obtained state of the art result.
In this paper, we explicitly model the uncertainty of user click-through rate estimation and auction competition to capture the risk. We borrow an idea from finance and derive the value at risk for each ad display opportunity.
In this paper, a weighted sigmoid gate unit (WiG) is proposed as the activation function for a deep neural network.
We propose a novel semantics and temporal information based maven search (STMS) approach to discover latent topics (semantically related soft clusters of words) between the authors, venues (conferences or journals) and time simultaneously.
This paper presents a novel approach for segmenting moving objects in unconstrained environments using guided convolutional neural networks that incorporates the spatial location of foreground and background to compute their separated representations.
This is a pre-copyedited, author-produced PDF of an article accepted for publication in Interacting with computers following peer review. The version of record is available online.
We explicitly cast multi-task learning as multi-objective optimization, with the overall objective of finding a Pareto optimal solution. We therefore propose an upper bound for the multi-Objective loss and show that it can be optimized efficiently.
We propose a new epipolar flow approach with low computational complexity achieving the best error rate on the KITTI optical flow 2012 benchmark and running 1000 faster than the second ranked approach.
A progressive GTL method that gradually finds an intrinsic data representation that more accurately aligns imaging features with the phenotype data.
This paper studies the problem of cross-network node classification to overcome the insufficiency of labeled data in a single network. We propose a novel network transfer learning framework AdaGCN by leveraging the techniques of adversarial domain adaptation and graph convolution.
We present a new approach to modeling sequential data: the deep equilibrium model (DEQ) that directly finds these equilibrium points via root-finding and uses only constant memory.
We propose to integrate deep and unsupervised saliency for salient object detection under a unified framework and achieve state-of-the-art performance on 8 benchmark datasets.
We propose SDFDiff, a novel approach for image-based shape optimization using differentiable rendering of 3D shapes represented by signed distance functions (SDF), where we achieve state-of-the-art results.
We propose a novel method for efficient pixel-level hand detection using structured forests and enforce shape constraints.
We design a Deep InfoMax (DIM) network to maximize the mutual information (MI) between the input image and encoder output, which achieves the state-of-the-art results.
We propose two fast and straightforward approaches for multi-focus image fusion based on deep neural networks.
ResiliNet combines two concepts to provide resiliency: skip connection in residual neural networks, and a novel technique called failout, which is introduced in this paper.
We propose Character-level Intra Attention Network (CIAN) for the NLI task.
In this paper we present a methodology to justify the suggestions generated by a recommendation algorithm through the identification of relevant and distinguishing characteristics of the recommended item, automatically extracted by mining users' reviews.
In order to balance model performance and complexity, we introduce a novel neural network architecture exploiting local features from a subsampled point set.
We explore the idea of using local action attributes to form an action descriptor, where an action is no longer characterized with the motion changes in the temporal domain but the local semantic description.
Neural dependency parsing has proven very effective, achieving state-of-the-art results on numerous domains and languages.
In this work, we build an entity/event-level sentiment analysis system, which is able to recognize and infer both explicit and implicit sentiments toward entities and events in the text.
In this paper, focusing on the illumination change challenge, we propose a deep network model which takes both visible light image and near-infrared image into account to perform face recognition.
Learning to efficiently navigate an environment using only an on-board camera is a difficult task for an agent when the final goal is far from the initial state and extrinsic rewards are sparse. To address this problem, we present a self-supervised prediction network to train the agent with intrinsic rewards that relate to the desired final goal.
This paper is a brief introduction to our submission to the seven basic expression classification track of Affective Behavior Analysis in-the-wild Competition held in conjunction with the IEEE International Conference on Automatic Face and Gesture Recognition (FG) 2020.
We propose a continual object detector that can learn sequentially from different domains and categories without forgetting.
In this paper, we propose a novel framework for abnormal event detection in crowded scenes using bag-of-atomic-ev (BoAE) modeling.
Learning representations with diversified information remains as an open problem. Towards learning diversified representations, a new approach, termed Information Competing Process (ICP), is proposed in this paper. ICP separates a representation into two parts with different mutual information constraints.
We review the current schemes of text-image matching models and propose improvements for both training and inference, enhancing scores of all metrics by a large margin.
Online Hyper-parameter Learning for Auto-Augmentation (OHL-Auto-Aug), an economical solution that learns the augmentation policy distribution along with network training.
We investigate a novel training procedure to learn a generative model as the transition operator of a Markov chain, such that, when applied repeatedly on an unstructured random noise sample, it will denoise it into a sample that matches the target distribution from the training set.
We present a method for estimating articulated human pose from a single static image based on a graphical model with novel pairwise relations that make adaptive use of local image measurements.
We demonstrate, to the best of our knowledge, the first results for monocular object localization and shape estimation on surfaces that do not share the same plane with the moving monocular camera.
We design a Bayesian nonparametric prior for embeddings of discrete objects that encourages sparsity and leverages natural groupings among objects.
We propose a fully-trained Generative Adversarial Network (FTGAN) for text-to-face generation.
We show that standard neural-network approaches, which perform poorly when trained on synthetic RGB images, can perform well when the data is pre-processed to extract cues about the person’s motion, notably as optical flow and the motion of 2D keypoints.
Autonomous vehicles may make wrong decisions due to inaccurate detection and recognition. In this work, relying on LiDAR 3D point clouds, we fuse the sensor data collected from different positions and angles of connected vehicles to enhance perceptive ability.
Automatically creating the description of an image using any natural languages sentence like English is a very challenging task. It requires expertise of both image processing as well as natural language processing.
The primary characteristic of robust speaker representations is that they are invariant to factors of variability not related to speaker identity. Disentanglement reduces the information with respect to nuisance factors from speaker representations while retaining speaker information.
We present a novel framework for finding complex activities matching user-described queries in cluttered surveillance videos and propose a probabilistic activity localization objective.
Deep models have achieved impressive performance for face hallucination tasks. However, we observe that directly feeding the hallucinated facial images into recog- nition models can even degrade the recognition performance.
We propose new conformalized density- and distance-based anomaly detection algorithms for a one-dimensional time-series data.
In this paper we take advantage of the structure present in local image patches to learn both an accurate and computationally efficient edge detector.
We propose a novel method called adaptive Visual- Depth Embedding (aVDE) which learns the compact shared latent space between two representations of labeled RGB and depth modalities in the source domain first.
A systematic review of approaches in building an emotionally-aware chatbot (EAC)
Adversarial Data Programming (ADP), an adversarial methodology to generate data as well as a curated aggregated label, given a set of weak labeling functions.
A fast and effective motion deblurring method has great application values in real life. This work presents an innovative approach in which a self-paced learning is combined with GAN to deblur image.
In this work, we propose the first quantum Ans\"atze for the statistical relational learning using parametric quantum circuits.
We propose an effective data augmentation method based on generative adversarial networks (GANs), called Domain Fusion, which uses a multi-domain learning GAN to generate new samples for the target tasks.
In this paper, we propose to leverage intra-class variance in metric learning of triplet network to improve the performance of fine-grained recognition.
We present MCF3D, a multi-stage complementary fusion three-dimensional (3D) object detection network for autonomous driving, robot navigation, and virtual reality.
A novel method for joint face landmark localization and frontal face reconstruction (pose correction) using a small set of frontal images only.
We propose a novel algorithm designed to optimize the performance of of the specialist-generalist classification system for class assignment.
We develop an algorithm to detect the sentiment of Named Entities based on the majority of attitudes towards them and exploit them for sentiment analysis.
This paper introduces t-SNE-CUDA, a GPU-accelerated implementation of t-distributed Symmetric Neighbor Embedding for visualizing datasets and models.
We propose a novel unsupervised approach that can discover and learn landmarks in object categories, thus characterizing their structure.
We investigate the effect of various dependency-based word embeddings on distinguishing between functional and domain similarity, word similarity rankings, and two downstream tasks in English.
We propose a unified framework, the ParalleL AttentioN (PLAN) network, to discover object in an image that is being referred to in variable length natural expression descriptions, from short phrases query to long multi-round dialogs.
We propose to pretrain a sequence-to-sequence model to represent different languages in the shared space, so that we can conduct zero-shot cross-lingual transfer.
We propose a genetic algorithm for hyperparameter optimization of artificial neural networks which includes chromosomal crossover as well as a decoupling of parameters (i.e., weights and biases) from hyperparameters (e.g., learning rate, weight decay, and dropout) during sexual reproduction.
We introduce a scene graph context network that pools features generated by a graph convolutional neural network that are then provided to both the image generation network and the adversarial loss to improve image generation from scene graphs.
We propose a multi-task network that simultaneously computes the identification loss and verification loss for person re-identification.
A stochastic second-order trust region method is proposed, which is an extension of the trust-region-ish algorithm proposed by Curtis et al.
We investigate in this paper architectures of deep convolutional networks. Building on existing state of the art models, we propose a reconfiguration of the model parameters into several parallel branches at the global network level.
We propose an image annotation model that incorporates contextual cues collected from sources both intrinsic and extrinsic to images, to bridge the semantic gap .
We introduce a probabilistic framework that efficiently learns latent variables to jointly model the multi-step future motions of agents in a scene, without requiring explicit labels.
Background Suppression Network for weakly-supervised temporal action localization using an asymmetrical training strategy.
We propose an efficient algorithm for fast encoding large Semantic Web data using the state-of-art asynchronous partitioned global address space model.
We use class-semantic descriptions (i.e., attributes) which provide additional semantic information about unseen concepts as supervision and propose a novel loss function which encourages the selected features to capture the central characteristics of seen concepts.
UniPCM is a unified PCM framework for partially occluded object detection. It largely reduces the convolution overhead during both training and detection.
We consider the problem of unconstrained minimization of a smooth objective function in $\mathbb{R}^d$ in setting where only function evaluations are possible. We propose and analyze stochastic zeroth-order method with heavy ball momentum.
We present a mechanism for focusing RNN encoders for sequence modelling tasks which allows them to attend to key parts of the input as needed.
We address automatic matching of street images with relevant web resources to enable the identification of store signage in street images.
We introduce the Intermediate Level Attack (ILA), which attempts to fine-tune an existing adversarial example for greater black-box transferability by increasing its perturbation on a pre-specified layer of the source model, improving upon state-of-the-art methods.
We propose a convnet based person recognition system on which we provide an in-depth analysis of informativeness of different body cues, impact of training data, and the common failure modes of the system.
We introduce a new self-supervised pretext task of predicting responses to Gabor filter banks and demonstrate that multi-task learning of compatible pretext tasks improves domain generalization performance.
The machine learning community has been overwhelmed by a plethora of deep learning--based approaches for image segmentation. This article approaches these various deep learning techniques of image segmentations from an analytical perspective. The main goal of this work is to provide an intuitive understanding of the major techniques that have made a significant contribution to the image segmentization domain.
In this paper, we proposed Unsupervised coupled Cycle generative adversarial Hashing networks (UCH), for cross-modal retrieval.
This paper presents a multi-layer dictionary learning method for classification tasks. It relies on a succession of sparse coding and pooling steps in order to find an efficient representation of data for classification.
We propose Triplet Center Loss based Part-aware Model (TCPM) that leverages the discriminative features in part details of vehicles to refine the accuracy of vehicle re-identification.
We introduce a new scalable learning algorithm for large-scale multi-class image classification, based on the multinomial logistic loss and the trace-norm regularization penalty, which performs significantly better than state-of-the-art approaches.
This work presents a novel 3D segmentation framework, RSNet, to efficiently model local structures in point clouds.
This paper proposes a simple yet effective method for human action recognition in video using state-of-the-art three-dimensional convolutional neural networks from sampled snippets of a video.
This paper addresses the problem of learning optimal feedback policy for a nonlinear stochastic dynamical system with continuous state space, continuous action space and unknown dynamics.
This paper develops and compares the performance of different vessel segmentation techniques based on global thresholding using phase congruency and contrast limited adaptive histogram equalization for the preprocessing of retinal fundus images.
We train three commonly used neural vocoders, including WaveNet, WaveRNN, and WaveGlow, alternately on five different datasets. We evaluate the models using acoustic features from seen/unseen speakers, seen/ unseen languages, a text-to-speech model, and a voice conversion model.
Winning ticket initializations generalize across a variety of datasets, optimizers, and training configurations.
We present a large-scale benchmark of existing state-of-the-art methods for quantifying predictive uncertainty under dataset shift and investigate the effect of dataset shift on accuracy and calibration.
We introduce an attentive semantic alignment method that focuses on reliable correlations, filtering out distractors. For effective attention, we also propose an offset-aware correlation kernel that learns to capture translation-invariant local transformations.
A Multimodal Transformer model for image captioning.
Self-taught learning is a transfer learning technique that uses a large number of unlabeled data as source samples to improve the task performance on target samples. However, knowledge transferred from source samples that are not sufficiently related to the target samples may negatively influence the target learner.
Our 3D object class detection method consists of several stages gradually enriching the object detection output with object viewpoint, keypoints and 3D shape estimates.
We compare the performance of state of the art deep learning algorithms with a subjective evaluation obtained via crowdsourcing to understand how privacy protection filters affect both machine and human vision.
In this paper, a novel approach named Pulling Reduction with Local Compensation (PRLC) is proposed.
In this paper, we demonstrate the sensitivity of optimizer comparisons to the hyperparameter tuning protocol, and propose practical tips around tuning often ignored hyperparameters.
We study how maximum entropy policies trained using soft Q-learning can be applied to real-world robotic manipulation, where the optimality of the resulting policy can be bounded.
We perform a systematic comparison of three state-of-the-art strategies for 6-DoF camera pose estimation, i.e. feature-based, photometric-based and mutual-information-based approaches.
In this paper, we propose a novel deep supervised hashing model to learn more compact class-level similarity-preserving binary codes.
We propose Point Completion Network (PCN), a novel learning-based approach for shape completion, which produces dense, complete point clouds with realistic structures in the missing regions.
We explore the idea of hard attention aimed for latency-sensitive applications. We propose a Q-learning-based policy training strategy that enables our approach to intelligently select the sub-windows such that staleness in the memory hurts the performance the least.
We adopt a non-parametric approach for visual recognition by optimizing feature embeddings instead of parametric classifiers, based on the Neighborhood Component Analysis criterion.
We develop a task-agnostic reading module for the dynamic integration of explicit background knowledge in neural natural language understanding models.
We propose to explain the predictions of a deep neural network, by pointing to the set of what we call representer points in the training set, for a given test point prediction, which provides considerably more insight.
We present a novel strategy for unsupervised feature learning in image applications inspired by the Spike-Timing-Dependent-Plasticity biological learning rule.
We propose a new descriptor vector for expressive human motions inspired from the Laban movement analysis method (LMA), a descriptive language with an underlying semantics that allows to qualify human motion in its different aspects.
We speed up SBIR by introducing a novel binary coding method, named Deep Sketch Hashing (DSH), where a semi-heterogeneous deep architecture is proposed and incorporated into an end-to-end binary coding framework.
In this paper, a new similarity-based descriptor, dubbed Structural Similarity Cross-Covariance Tensor is proposed, aimed to encode relations among different regions of an image in terms of cross-covariant matrices.
We propose a joint inference model that leverages knowledge from predictors that optimize subtasks of opinion extraction, and seeks a globally optimal solution.
We present a multi-objective design space exploration method that reduces the number of solution networks trained and evaluated through response surface modelling, while maintaining performance.
This paper analyzes the state of the art of the blood vessel segmentation algorithms for imaging modalities, anatomical region and imaging techniques.
This paper investigates the problem of modeling Internet images and associated text or tags for tasks such as image search, tag-to-image search, and image- to-tag search.
We propose a general framework for manifold-based synthetic oversampling that helps users to select a domain-appropriate manifold learning method, such as PCA or autoencoder, and apply it to model and generate additional training samples.
Legendre duality provides a variational lower-bound for the Kullback-Leibler divergence which can be estimated using samples, without explicit knowledge of the density ratio. We then extend this procedure to adversarial training, where the discriminator represents the energy and the generator is the base measure of the energy-based model.
We show that an attacker can force a pre-trained generator to reproduce an arbitrary out-domain example if fed by a suitable adversarial input.
We propose methodologies to train highly accurate and efficient deep convolutional neural networks for image super resolution (SR) while gradually increasing the number of network layers.
We propose to apply robust optimization from adversarial machine learning to improve the robustness of a CNN-based watermarking framework.
A neural network (NN) is a parameterised function that can be tuned via gradient descent to approximate a labelled collection of data with high precision. A Gaussian process (GP), on the other hand, is a probabilistic model that defines a distribution over possible functions, and is updated in light of data via the rules of Probabilistic inference.
This work was supported by the TIMUL project (TIN2013- 48152-C2-1-R) and the University Institute for Computing Research (IUII) from the University of Alicante
In this paper, we propose a novel robust visual classification framework that uses double quantization (dquant) to defend against adversarial examples in a specific attack scenario called “subsequent adversarial example” where test images are injected with adversarial noise.
We introduce a new architecture of this type, with a visual path that leverages recent spaceaware pooling mechanisms. Once trained, it yields new state-of-the-art performance on cross-modal retrieval.
We define the Gap as a measure of gradient staleness and propose Gap-Aware, a novel asynchronous-distributed method that penalizes stale gradients linearly to the Gap and performs well even when scaling up.
This paper introduces the Seventh Dialog System Technology Challenges (DSTC), which use shared datasets to explore the problem of building dialog systems for sentence selection and sentence generation.
The Online Action Detection (OAD) problem needs to be revisited. In this work we propose to rethink the OAD scenario, clearly defining the problem itself and the main characteristics that the models which are considered online must comply with. We also introduce a novel metric: the Instantaneous Accuracy ($IA$).
We expose a structure in the derivative of the logits with respect to the parameters of the model, which is used to explain the existence of outliers in the spectrum of the Hessian.
We propose to build a 3D backbone network to learn rich 3D feature maps by using sparse 3D CNN operations for 3D object detection in point cloud.
DFST proposes an optimized visual tracking algorithm based on the real-time selection of locally and temporally discriminative features. A feature selection mechanism is embedded in the Adaptive Colour Names (CN) tracking system.
We propose an end-to-end network for image inpainting that uses a different image to guide the synthesis of new content to fill the hole.
We apply shape epitomes to image labeling by using Conditional Random Field (CRF) Models.
We propose a fast landmark manipulation method for generating adversarial faces, which is approximately 200 times faster than the previous geometric attacks and obtains 99.86% success rate on the state-of-the-art face recognition models.
We propose the neural nearest neighbors block, a novel non-local processing layer that leverages the principle of self-similarity and can be used as building block in modern neural network architectures.
Deep neural networks are known to suffer from catastrophic forgetting in class-incremental learning, where the performance on previous tasks drastically degrades when learning a new task. To alleviate this effect, we propose to leverage a continuous and large stream of unlabeled data in the wild.
In this paper, we propose a simple yet effective method for detecting any abnormal samples, which is applicable to any pre-trained softmax neural classifier.
Adaptive Composition GAN incorporates image synthesis in geometry and appearance domains into an end-to-end trainable network and achieves synthesis realism in both domains simultaneously.
This paper introduces the concept of color-dependent adaptive support weights to the definition of local support areas in cooperative stereo methods to improve the accuracy of depth estimation at object borders.
An accurate edge detector using richer convolutional features (RCF) .
We demonstrate that the Bayes posterior induced by Bayesian neural networks yields systematically worse predictions compared to simpler methods including point estimates obtained from SGD. We propose several hypotheses that could explain cold posteriors.
In this paper, we reinvestigate the affinity matrices originally used in image segmentation methods based on spectral clustering. A new affinity matrix, which is robust to color distortions, is formulated for object discovery.
We propose a knowledge-guided pairwise reconstruction network (KPRN), which models the relationship between the target entity (subject) and contextual entity (object) and grounds these two entities.
Generative Adversarial Networks have shown impressive results for the task of object translation, including face-to-face translation. A key component behind the success of recent approaches is the self-consistency loss, which encourages a network to recover the original input image when the output generated for a desired attribute is itself passed through the same network, but with the target attribute inverted.
We propose monoResMatch, a novel deep architecture designed to infer depth from a single input image by synthesizing features from a different point of view, horizontally aligned with the input image, performing stereo matching between the two cues.
We introduce Pix2Vex, a network trained to convert camera-captured images into 3D geometry, without needing any 3D model as ground truth.
We evaluate the robustness of neural networks that implement these proposed modifications using existing attacks, showing an increase in accuracy against untargeted attacks of up to 98.7\% and a decrease of targeted attack success rates ofUp to 99.8\%.
Evidence transfer is a robust solution against external unknown categorical evidence that can introduce noise or uncertainty in the labelset.
Learning Hierarchical AND-OR networks of sparsely connected semantically meaningful nodes for interpretable image synthesis.
We propose a method to quantify the importance of different layers in the pipeline, by computing an error contribution relative to an agnostic choice of algorithms in that layer. We demonstrate our methodology on image classification pipelines.
In this paper, we introduce pairwise polar quantization, aiming to optimize the discrimination between the genuine Hamming distance (GHD) and the imposter Hamming Distance (IHD), we propose two feature pairing strategies: long-short (LS) strategy for phase quantization and long-long strategy for magnitude quantization.
We extend a 2-D convolutional neural network extended to a concatenated 3-D network that learns to extract features from the spatio-temporal domain of raw video data.
We introduce a two-stream network for lip reading that learns from each other in the learning process and achieves state-of-the-art performance on two large-scale lip reading benchmarks.
We propose a novel method to track this change for each user, as well as over the whole population of users, given only the system match scores. We overcome the dilemma between precision in performance and the time resolution, i.e., higher performance precision entails lower time resolution and vice-versa.
This paper explores the connection between view-predictive representation learning and its role in the development of 3D visual recognition. We propose inverse graphics networks, which take as input 2.5D video streams captured by a moving camera, and map to stable 3D feature maps.
We propose a novel approach to create adversarial examples that generalize across multiple networks for classification, object detection and segmentation.
The prevalent scene text detection approach follows four sequential steps comprising character candidate detection, false character candidate removal, text line extraction, and text line verification. To address these issues, we propose a unified scene text Detection system, namely Text Flow, by utilizing the minimum cost (min-cost) flow network model.
This paper tackles the problem of semi-supervised video object segmentation, that is, segmenting an object in a sequence given its mask in the first frame, using a semantic prior that guides the appearance model.
A recurrent neural network language model can be used for caption generation in two ways: directly incorporating it in the RNN or conditioning the language model by merging it.
We analyze the contribution of different face areas to different emotions in real-world conditions through experimental analysis and establish convincing results.
We propose the Novel Object Captioner (NOC), a deep visual semantic captioning model that can describe a large number of object categories not present in existing image-caption datasets.
Generative adversarial networks and their applications in computer vision are systematically reviewed.
The cross-depiction problem refers to the task of recognising visual objects regardless of their depictions; whether photographed, painted, sketched, {\em etc}.
We propose an approach based on adversarial optimization, which allows us to learn more robust models that do not depend on hospital- and patient-level confounders.
Klebsiella pneumoniae metabolism for drug target prediction through the constraint-based analysis of its GMN .
We studied head movements and postures that occurred during the painful and control trials by measuring head orientation from video over time, followed by analyzing posture and movement summary statistics.
We propose a generalized dense correspondence computation algorithm, so that stereo matching and optical flow can be performed robustly and efficiently at the same time.
We formalize the notion of iterative refinement in Resnets by showing that residual connections naturally encourage features of residual blocks to move along the negative gradient of loss.
A GAN-based unsupervised transformation network for image-to-image translation without paired images.
We propose to explicitly measure the border consistency between segmentation and depth and minimize it in a greedy manner by iteratively supervising the network towards a locally optimal solution.
This paper proposes to tackle open- domain question answering using Wikipedia as the unique knowledge source: the answer to any factoid question is a text span in Wikipedia article.
We find that there exists a universal score function for CNNs whose correlation is statistically significant than the widely used model confidence.
We develop an optimization algorithm based on generalized-optimal updates derived from minibatches that lead to faster convergence, and generalization.
We present Deeply Supervised Object Detector (DSOD), a framework that can learn object detectors from scratch.
We address this by introducing a robust system based on the lambda calculus for deriving neo-Davidsonian logical forms from dependency trees.
This paper recasts facial attractiveness computation as a label distribution learning (LDL) problem rather than a traditional single label supervised learning task. A very deep residual network is utilized to enable automatic learning of hierarchical aesthetics representation.
We introduce the dynamic memory network (DMN), a neural network architecture which processes input sequences and questions, forms episodic memories, and generates relevant answers.
We rigorously analyze the VAE objective, differentiating situations where this belief is and is not actually true. We then leverage the corresponding insights to develop a simple VAE enhancement that requires no additional hyperparameters or sensitive tuning.
We propose Batch Nuclear-norm Maximization to improve both discriminability and diversity of batch output matrix.
This paper is on improving the training of binary neural networks in which both activations and weights are binary. While prior methods for neural network binarization binarize each filter independently, we propose to instead parametrize the weight tensor of each layer using matrix or tensor decomposition, which improves the accuracy of the trained models.
In this paper, we propose a novel system that achieves 95.98% driving posture estimation classification accuracy and operate in a realtime environment.
In this paper, we investigate the problem of selection bias on six NLSM datasets and find that four out of them are significantly biased. We propose a training and evaluation framework to alleviate the bias.
In this work, we propose a novel system for smart copy-paste, enabling the synthesis of high-quality results given a masked source image content and a target image context as input.
We provide a hybrid algorithm that retrofits and repurposes a pre-filtering contextual incorporation method and feeds the new dimension to a DL-based neural collaborative filtering method, thus preserving and recovering the benefits of both without their limitations.
We have devised and implemented a novel computational strategy for de novo design of molecules with desired properties termed ReLeaSE (Reinforcement Learning for Structural Evolution).
We propose an extension of Semi-Global Matching that utilizes image warping to reduce the fronto-parallel bias in the data term, based on estimating dominant slanted planes.
We investigate systems that identify opinion expressions and assigns polarities to the extracted expressions using large-margin structured prediction methods.
We propose a novel multi-branch scale-aware attention network that exploits the hierarchical structure of convolutional neural networks and generates, in a single forward pass, multi-scale density predictions from different layers of the architecture.
In this paper, considering the fundamental difference between the two domains as the texture, we propose a method to adapt to the texture of the target domain.
This paper presents sparse relational topic models (SRTM) under a non-probabilistic formulation that can effectively control the sparsity via a sparsity-inducing regularizer.
An event happening in the world is often made of different activities and actions that can unfold simultaneously or sequentially within a few seconds. A new multi-label dataset for multi-action detection introduces novel challenges on how to train and analyze models trained for action detection.
We propose a novel approach for cost-adjustable inference in CNNs - Stochastic Downsampling Point (SDPoint). During training, SDPoint applies feature map downsampling to a random point in the layer hierarchy, with a random Downsampling ratio.
In this paper, we propose a simple and effective discriminative feature extractor via a Single-Stream Deep Similarity learning for online visual Tracking.
We present a novel unsupervised deep learning framework for anomalous event detection in complex video scenes, leveraging the complementary information of both appearance and motion patterns.
In this paper we propose a novel easily reproducible technique to attack the best public Face ID system ArcFace in different shooting conditions.
RNA metabolism is controlled by an expanding, yet incomplete, catalog of RNA-binding proteins (RBPs), many of which lack characterized RNA binding domains. Here, HaloTag fusion pull down of 12 nuclear and cytoplasmic RBPs followed by quantitative mass spectrometry demonstrates that proteins interacting with multiple RBPs in an RNA-dependent manner are enriched for RBPs.
We propose an Additive Angular Margin Loss (ArcFace) to obtain highly discriminative features for large-scale face recognition.
We propose Dynamically Fused Graph Network(DFGN), a novel method to answer those questions requiring multiple scattered evidence and reasoning over them.
We propose a fully trainable solution to visual ego-motion estimation for varied camera optics, in a minimally supervised setting, as they gain experience.
We propose a new end-to-end unsupervised deep learning framework for monocular depth estimation consisting of two Generative Adversarial Networks (GAN), deeply coupled with a structured Conditional Random Field (CRF) model.
This paper proposes that the dominance we are witnessing would not have been possible by the methods of deep learning alone: the tacit change has been the evolution of empirical practice in computer vision and AI over the past decades.
We propose an algorithm for calculating the cardiothoracic ratio (CTR) from chest X-ray films using U-Net with VGG16 encoder.
We compare human-generated and automatically generated questions, characterizing properties of queries necessary for real-world applications, and propose improvements to current evaluations of text-to-SQL systems.
We present a novel and effective approach for salient object detection for video sequences based on 3D convolutional neural networks.
We propose Distance-based Self-Attention Network, which considers the word distance by using a simple distance mask in order to model the local dependency without losing the ability of modeling global dependency.
We propose an ensemble clustering approach based on the technique of matrix completion that can deal with uncertain data pairs.
We propose a novel architecture termed as "temporal channel-aware" (TCA) block, which achieves the capability of exploiting the temporal interdependencies among video sequences.
We propose an explainability constrained MF technique that computes the top-n recommendation list from items that are explainable. Experimental results are effective in generating accurate and explainable recommendations.
We propose a query-based generative model for solving both tasks of question generation (QG) and question an- swering (QA). The model follows the classic encoder- decoder framework.
Generative neural samplers are probabilistic models that implement sampling using feedforward neural networks: they take a random input vector and produce a sample from a probability distribution defined by the network weights.
The paper presents a Traffic Sign Recognition (TSR) system, which can fast and accurately recognize traffic signs of different sizes in images.
We propose a couple-network with gated multi-layer feature extraction sub-network and deformable regional RoI-pooling for pedestrian detection.
We present Convolutional Oriented Boundaries (COB), which produces multiscale oriented contours and region hierarchies starting from generic image classification convolutional Neural Networks (CNNs).
We study the issue of mode collapse of Boundary Equilibrium Generative Adversarial Network (BEGAN), which is one of the state-of-the-art generative models. We propose a new model, called BEGAN-CS, which includes a latent-space constraint in the loss function, which can significantly improve training stability and suppress mode collapse.
A multidimensional representation of motor state is encoded across the forebrain, and is integrated with visual input by neuronal populations in primary visual cortex.
Predictive recurrent neural networks learn to model predictions as a combination of multiple Gaussian distributions, making them particularly interesting for problems where a sequence of inputs may lead to several distinct future possibilities.
This paper presents a novel method for learning a pose lexicon comprising semantic poses defined by textual instructions and their associated visual pose candidates defined by visual features.
A novel SVM formulation that constrains the orientation of the SVM hyperplane to agree with the human visual system.
We propose the LXMERT (Learning Cross-Modality Encoder Representations from Transformers) framework to learn these vision and language connections.
Is recurrent network really necessary for learning a good visual representation for person re-identification (VPRe-id)?
This paper evaluates state-of-the-art weakly-supervised semantic segmentation methods on natural scene, histopathology, and satellite image datasets.
We propose CompGCN, a novel Graph Convolutional framework which jointly embeds both nodes and relations in a relational graph and achieve demonstrably superior results.
We present a new dense video captioning approach that can utilize any number of modalities for event description.
We develop an open-domain QA approach using web tables that works for both factoid and non-factoid queries.
In this paper we introduce Deep Matching Autoencoders (DMAE), which learn a common latent space and pairing from unpaired multi-modal data for cross-view learning.
Ensemble Projection captures not only the characteristics of individual images, but also the relationships among images, leading to diverse classifiers.
Integrative computational biology can help diminish them by creating new software tools, analytical methods, and data standards.
We present a simple, effective technique for accounting for label noise when training deep neural networks.
We explore a novel data generation pipeline for training a deep neural network to perform grasp planning that applies the idea of \emph{domain randomization} to object synthesis.
We explored transfer with and without fine-tuning, sequential transfers and usage of pre-trained models in general and specific datasets in medical imaging context.
We present an unsupervised re-id deep learning approach that maximises the discovery of tracklet identity matching both within and across camera views.
We propose an approach to learn action categories from static images that leverages prior observations of generic human motion to augment its training process.
We propose stacked dense U-Nets for 3D face localisation in images captured in-the-wild.
We present the Escape Room Domain (ERD), a new flexible, scalable, and fully implemented testing domain for Hierarchical Reinforcement Learning that bridges the "moderate complexity" gap left behind by existing alternatives.
In this paper, we propose a new unsupervised feature learning framework that extends sparse coding to a multi-layer architecture for visual object recognition tasks.
In this paper, a novel robust subspace segmentation algorithm has been proposed by integrating lp-norm and Schatten p-norm constraints.
We introduce a novel continual learning protocol based on the CORe50 benchmark and propose two continual learning techniques that can learn effectively even in the challenging case of nearly 400 small non-i.i.d. incremental batches.
We use a recently proposed generative model known as neural rendering model (NRM) for OoD detection, and we show that NRM unifies both approaches.
We study the effect of exposure to media manipulations on over 15,000 individuals' ability to discern machine-manipulated media.
We propose negative bootstrap, a novel method for learning better visual concept classifiers by iteratively finding relevant negatives.
We propose a Multimodal Memory Model (M3) to describe videos, which builds a visual and textual shared memory to model the long-term visual-textual dependency and further guide global visual attention on described targets.
Learning multi-hop reasoning has been a key challenge for reading comprehension models, leading to the design of datasets that explicitly focus on it. In this paper, we investigate two recently proposed datasets, WikiHop and HotpotQA, and explore sentence-factored models for these tasks; by design, these models cannot do multi-Hop reasoning.
Self-supervised goal-conditioned reinforcement learning with raw image observations in the real world, enabling a robot to manipulate a variety of objects and generalize to new objects that were not seen during training.
GANs excel at learning high dimensional distributions, but they can update generator parameters in directions that do not correspond to the steepest descent direction of the objective. We propose a novel divergence which approximates the Wasserstein distance while regularizing the critic's first order information.
We demonstrate that relational features derived from dependency-syntactic and semantic role structures are useful for the task of detecting opinionated expressions in natural language text, significantly improving over conventional models based on sequence labeling with local features.
We propose a novel adaptive empirical Bayesian method for sparse deep learning, where the sparsity is ensured via a class of self-adaptive spike-and-slab priors.
We present Neural-Guided RANSAC (NG-RANSAC), an extension to the classic RansAC algorithm from robust optimization that uses prior information to improve hypothesis search, increasing the chance of finding outlier-free minimal sets.
We developed a tool, named Hedera, that efficiently extracts semantic information from Wikipedia revision history datasets.
We propose a new length-controllable abstractive summarization model that incorporates a word-level extractive module in the encoder-decoder model instead of length embeddings for controlling the summary length.
In this paper, we propose a novel model: Deep Interest Network (DIN) which tackles this challenge by designing a local activation unit to adaptively learn the representation of user interests from historical behaviors with respect to a certain ad.
We propose a novel generalized framework called fusion hashing (FH) to improve the precision of existing hashing methods without adding new constraints or penalty terms.
We develop Faster CryptoNets, a method for efficient encrypted inference using neural networks that achieves competitive accuracy and achieves a significant speedup over previous methods.
We point out that deep learning automatically induces group sparsity of weights, in which all weights connected to an output channel (node) are zero, when training DNNs under the following three conditions: (1) rectified-linear-unit (ReLU) activations, (2) an $L_2$-regularized objective function, and (3) the Adam optimizer.
We propose a novel Auto-Reconstructor Network (ARNet), which, coupling with the conventional encoder-decoder framework, works in an end-to-end fashion to generate captions.
Understanding and defining the meaning of “action” is substantial for robotics research. This becomes utterly evident when aiming at equipping autonomous robots with robust manipulation skills.
Cross-modal data retrieval has been the basis of various creative tasks performed by Artificial Intelligence (AI).
We propose a deep learning-based framework for instance-level object segmentation using ResNet-101 and spatial propagation network.
We propose path-augmented TransR (PTransR) model to improve the accuracy of link prediction.
We propose a method for representing generic objects as quadrics which allows object detections to seamlessly integrated in a SLAM framework.
This paper studies the problem of post-hoc calibration of machine learning classifiers. We introduce the following desiderata for uncertainty calibration: (a) accuracy-preserving, (b) data-efficient, and (c) high expressive power.
This paper presents a novel generative structure with Bijective Generative Adversarial Networks in a Distillation framework (DiBiGAN), for synthesizing faces of an identity given that person's features.
We propose a novel annotation method that employs two layers of sparse coding and performs coarse-to-fine labeling and achieves symmetric response in terms of precision and recall.
We propose a novel method for constraining the output space of unpaired image-to-image translation. We experiment on preserving ground-truth information such as semantic segmentation, disparity, and instance segmentation.
Trust is an important criterion for access control in the field of online social networks privacy preservation. In the present methods, the subjectivity and individualization of the trust is ignore...
We propose the usage of co-occurrences information to characterize human actions. We obtained state-of-the-arts classification performance.
This paper presents a review of the 2018 WIDER Challenge on Face and Pedestrian.
We study KD from a new perspective: rather than compressing models, we train students parameterized identically to their teachers. Surprisingly, these BANs outperform their teachers significantly, both on computer vision and language modeling tasks.
We develop a method for user-controllable semantic image inpainting: Given an arbitrary set of observed pixels, the unobserved pixels can be imputed in an arbitrary range of possibilities, each of which is semantically coherent and locally consistent with the observed pixels.
We introduce a framework for multi-modal data transformations that preserve semantics and induce the learning of high-level representations across modalities.
We revisit the Bellman optimality equation with Nesterov's smoothing technique and provide a unique saddle-point optimization perspective of the policy optimization problem in reinforcement learning based on Fenchel duality.
We propose a unified framework, named deep prior ensemble (DPE), to integrate both knowledge and data-based cues for image enhancement tasks.
OIP5-AS1 overexpression in undifferentiated oral tumors may be suggestive of enhanced cancer stemness, and consequently, poor clinical outcome.
We construct and release a Non-I.I.D. image dataset called NICO, which makes use of contexts to create Non- IIDness consciously. Extended experimental results and anslyses demonstrate that the NICO dataset can well support the training of a ConvNet model from scratch.
We present a method for extracting depth layers in the presence of occlusions for image based rendering, based on spectral analysis of the plenoptic function.
Deep Learning is arguably the most rapidly evolving research area in recent years. As a result it is not surprising that the design of state-of-the-art deep neural net models proceeds without much consideration of the latest hardware targets, and neural net accelerators are co-designed.
We present a non-parametric end-to-end pipeline to find mislabeled instances in numerical, image and natural language datasets.
We introduce discrete wavelet transform (DWT) into the CNN encoder-decoder architecture and propose WCNN, a novel CNN architecture for dense pixelwise prediction.
We propose a novel method for detecting boundaries between semantically meaningful objects in visual scenes using pointwise mutual information and spectral clustering.
A key challenge in designing convolutional network models is sizing them appropriately. Many factors are involved in these decisions, including number of layers, feature maps, kernel sizes, etc. We find that while increasing the numbers of layers and parameters each have clear benefit, the number of feature maps (and hence dimensionality of the representation) appears ancillary.
AVSlowFast extends SlowFast Networks with a Faster Audio pathway that is deeply integrated with its visual counterparts, enabling audio to contribute to the formation of hierarchical audiovisual concepts.
HW2MP-GAN improves state-of-the-art GAN models for handwritten recognition and image-to-image translation.
This paper demonstrates a feasible method for using a deep neural network as a sensor to estimate the attitude of a flying vehicle using only flight video.
We show that numerical reasoning is amenable to automatic data generation, and thus one can inject this skill into pre-trained LMs, by generating large amounts of data, and training in a multi-task setup.
Our goal is to design architectures that retain the groundbreaking performance of Convolutional Neural Networks (CNNs) for landmark localization and at the same time are lightweight, compact and suitable for applications with limited computational resources.
This paper presents a geodesic voting method for tubular tree structure segmentation, using minimal interaction.
We present an overview of the methodology used to build a new stereo vision solution that is suitable for System on Chip.
We study the benefits of utilizing the heterogeneous (CPU and GPU) computing resources available on commodity android devices while running deep learning models.
In this paper, we propose a simple and robust local descriptor, called the robust local binary pattern (RLBP) for texture classification and face recognition.
This paper proposes a Convolutional Neural Network (CNN) inspired by Multitask Learning (MTL) and based on speech features trained under the joint supervision of softmax and center loss, a powerful metric learning strategy, for the recognition of emotion in speech.
We propose a novel end-to-end adaptive reconstruction network (ARN), which builds the correspondence between image region proposal and query in an adaptive manner.
We extend Faster /Mask R-CNN into a meta-learner to achieve low-shot object detection/segmentation.
This paper proposes a new end-to-end architecture called SpatioTemporal Relation Networks (STRN) to extract spatial information and temporal information simultaneously from the video with the only RGB input.
We propose a principled Perceptual Adversarial Networks (PAN) for image-to-image transformation tasks.
We propose a few-shot classification method which adapts to novel domains as well as novel classes, which is believed to more practical in the real world.
This paper exploits pre-trained lightweight CNNs models to propose two efficient scale estimation methods that improve the visual tracking performance but also provide acceptable tracking speeds.
We present SfSNet, an end-to-end learning framework for producing an accurate decomposition of an unconstrained image of a human face into shape, reflectance and illuminance.
We provide deep performance analysis based on different types of images and point out the weaknesses of convolutional neural networks through experiment.
We propose a loss function that allows to simultaneously optimize the unscaled relative pose, as well as the set of feature correspondences directly considering the image intensity values.
We capitalize on the latest advancements of deep learning, combining them with the power of generative hand pose estimation techniques to achieve real-time monocular 3D hand Pose estimation in unrestricted scenarios.
We propose a novel model-based counterfactual advantage learning method for sample-efficient reinforcement learning, which eliminates most of the noises in long term rewards.
We proposed an automatic fuzzy clustering framework for image segmentation.
We propose a novel Domain Balancing mechanism to address the long-tailed domain distribution problem in face recognition task.
We developed an adaptive structure learning method of Restricted Boltzmann Machine (RBM) which can generate/annihilate neurons by self-organizing learning method according to input patterns.
In light of the recent breakthroughs in automatic machine translation systems, we propose a novel approach that we term as "Face-to-Face Translation" by incorporating a novel visual module, LipGAN for generating realistic talking faces from the translated audio.
Deep Affinity Network learns compact, yet comprehensive features of pre-detected objects at several levels of abstraction, and performs exhaustive pairing permutations of those features in any two frames to infer object affinities.
We propose a novel Policy Transfer Framework (PTF) to accelerate Reinforcement Learning (RL) by taking advantage of this idea.
We proposed a novel attention convolutional neural network architecture combined with the novel attention model for pose estimation.
We introduce DropBlock, a form of structured dropout, where units in a contiguous region of a feature map are dropped together, which improves the accuracy of convolutional networks.
Unsupervised word embeddings trained in hyperbolic manifolds are state-of-the-art on similarity, analogy and hypernymy detection.
We propose a novel Attribute Manifold Encoding GAN for fully-featured attribute transfer, which can modify and adjust every detail in the images.
A learning-based cost aggregation method for stereo matching by a novel sub-architecture in the end-to-end trainable pipeline.
We present Snuba, a system to automatically generate heuristics using a small labeled dataset to assign training labels to a large, unlabeled dataset in the weak supervision setting.
We propose a novel pulmonary nodule detection approach based on DCNNs for computed tomography images.
We revisit the Frank-Wolfe optimization under strongly convex constraint sets. With line search, we show that FW can converge to the global optimum, even for smooth functions that are quasi-convex and locally-Lipschitz.
We address the issue of detecting and recognizing a large number of traffic-sign categories suitable for automating traffic- sign inventory management.
Unpaired multimodal image-to-image translation is a task of translating a given image in a source domain into diverse images in the target domain, overcoming the limitation of one- to-one mapping.
We present a new type of convolutional network for semantic segmentation that uses multiple paths for information flow and achieves superior performance.
We propose finding shortest paths in a finite graph of samples from the aggregate approximate posterior, that can be solved exactly, at greatly reduced runtime, and without a notable loss in quality.
We present a general approach to video understanding, inspired by semantic transfer techniques successfully used for 2D image understanding. We use our method for video captioning and summarization.
R-Codean autoencoder for facial attribute prediction using a novel deep learning formulation.
We propose a teaching framework that provides interpretable explanations as feedback and models how the learner incorporates this additional information.
Facial expressions are a valuable source of information that accompanies facial biometrics. In this article, a new method that utilizes both texture and geometric information of facial fiducial points is presented.
This paper proposes a new unsupervised embedding approach, called Super-AND, which extends the current state-of-the-art model and achieves an accuracy of 89.2% on CIFAR-10.
We investigate the use of a neural network model for question answering to address this information extraction task and improve on the results of a passage retrieval based IE system.
We propose an end-to-end method for training both encoder and decoder simultaneously for video captioning, achieving state-of-the-art performance.
We propose a generative adversarial network based on Wasserstein generative models for image inpainting that incorporates semantic information and achieves state-of-the-art results.
This paper proposes a novel and general method to incorporate lexicon information, including sentiment lexicons(+/-), negation words and intensifiers, into neural sequence models.
We extend generalized policy improvement to the max-entropy framework and introduce a method for the practical implementation of successor features in continuous action spaces.
We propose BlackMarks, the first end-to-end multi-bit watermarking framework that is applicable in the black-box scenario that preserves the functionality of the original DNN.
We propose to use the energy distance to evaluate both the inter-cluster and intra-Cluster distance in hierarchical clustering, and use the sum of squares of deviations(SSD) as a regularization term to further balance the diversity and similarity of energy distance evaluation.
A novel unsupervised domain adaptation strategy that exploits both labeled synthetic data and unlabeled real data to improve the performance of deep networks trained on synthetic data.
We present a full evaluation of local spatio-temporal descriptors for action recognition in videos.
Speaker-driven data augmentation, pragmatic reasoning and panoramic action space improve vision-and-language navigation.
We propose a novel deep learning-based framework to tackle the challenge of semantic segmentation of large-scale point clouds of millions of points.
We present results of a visual recognition neuro-imaging fusion experiment, and compare them within and across experimental settings, showing high agreement within participants.
We construct a novel RND-based OOD detector, SVD-RND, that utilizes blurred images during training.
In this paper, we formulate reading comprehension as an extract-then-select two-stage procedure. We first extract answer candidates from passages, then select the final answer by combining information from all the candidates.
In this paper, we introduce the concept of learning latent super-events from activity videos, and present how it benefits activity detection in continuous videos.
In this paper we propose a new representation that leverages the uncertainty in relative temporal alignments between pairs of sequences while not destroying temporal ordering. Our representation, like BOW, is of a fixed dimensionality making it easily integrated with a linear detection function.
We propose a multi-scale GAN model to hallucinate realistic context (forehead, hair, neck, clothes) and background pixels automatically from a single input face mask.
We combine supervised learning via backpropagation with a specialized unsupervised learning rule to learn lateral connections between neurons within a convolutional neural network, improving performance on noisy versions of the MNIST and CIFAR-10 datasets.
We propose a novel coarse-to-fine pyramid model that not only incorporates local and global information, but also integrates the gradual cues between them. We explore a dynamic training scheme to seamlessly unify two losses and extract appropriate shared information between them .
We develop a model that can simultaneously transform multiple facial attributes with lower memory footprint and fewer number of computations, making it easier to be processed on a mobile phone.
We propose a Global Convolutional Network to address both the classification and localization issues for the semantic segmentation.
We present a data-efficient representation learning approach to learn video representation with small amount of labeled data and improve action recognition accuracy.
This paper attempts to address three questions: 1) are simple tree models sufficient? more specifically, how to use tree models effectively in human pose estimation? and 3) how shall we use combined parts together with single parts efficiently?
We propose 2.5D anchors which provide the candidate of distances based on a perspective camera model, which relax the difficulty of the regression model.
Language pivoting can effectively capture the characteristics of an image captioner from the pivot language (Chinese) and align it to the target language (English) using another pivot-target parallel corpus.
We propose using a convolutional neural network approach based on ResNet-50 to predict the foreground of an image: the parts with the head, torso, and limbs of a person and extract features primarily from the foreground areas.
We present a series of three single-stage RCNNs with different sized backbones and a six-layer feature pyramid trained exclusively on the WIDER FACE dataset.
We propose a framework to construct and learn a data-dependent kernel based on random features and implicit spectral distributions (Fourier transform of the kernel) parameterized by deep neural networks.
We make a thorough investigation of the mainstream deep convolutional neural network architectures for multi-label image classification and present a strong baseline.
We introduce a scalable symmetric discrete hashing algorithm that gradually and smoothly updates each batch of binary codes for binary code learning.
In this paper, we propose two novel information flow patterns that enable cross-group information flow for multiple group convolution layers with and without any channel permute/shuffle.
We propose a deep convolutional object detector for automated driving applications that also estimates classification, pose and shape uncertainty of each detected object.
We present a PTAS for computing the maximum a posteriori assignment on Pairwise Markov Random Fields with non-negative weights in planar graphs.
We propose a novel CQA algorithm called parallel recurrent fusion of image and language (PReFIL) that learns bimodal embeddings by fusing question and image features and then intelligently aggregates these learned Embeddings to answer the given question.
We present the first approach for 3D point-cloud to image translation based on conditional Generative Adversarial Networks (cGAN)
Generative Multi-Adversarial Network (GMAN), a framework that extends GANs to multiple discriminators.
Video captioning has attracted an increasing amount of interest, due in part to its potential for improved accessibility and information retrieval.
In this letter, we present a novel multi-talker minimum variance distortionless response (MVDR) beamforming as the front-end of an automatic speech recognition system in a dinner party scenario with severe noise.
We use hyperpixels to represent images by a small number of relevant features selected among early to late layers of a convolutional neural network. We develop an effective real-time matching algorithm based on Hough geometric voting.
We take a time-sensitive view of popularity bias, in which the algorithm assesses its long-tail coverage at regular intervals, and compensate in the present moment for omissions in the past.
We propose an approach to produce photorealistic textures for approximate surfaces, even from misaligned images, by learning an objective function that is robust to these errors.
We provide a comprehensive review on knowledge graph covering overall research topics about 1) knowledge graph representation learning, 2) knowledge acquisition and completion, 3) temporal knowledge graph, and 4) knowledge-aware applications, and summarize recent breakthroughs and perspective directions to facilitate future research.
This paper introduces the 3DCapsule, which is a 3D extension of the recently introduced Capsule concept that makes it applicable to unordered point sets.
We propose a class of the deterministic value gradient algorithm with infinite horizon, and different rollout steps of the analytical gradients by the learned model trade off between the variance of the value gradients and the model bias.
We present an approach that relies on historical rating data to learn user long-tail novelty preferences. We integrate these preferences into a generic re-ranking framework that customizes balance between accuracy and coverage.
We propose a neural network-based approach for nonalcoholic fatty liver disease assessment in ultrasound using deep convolutional neural network.
We exploit the classical network flow formulation of MOT to define a fully differentiable framework based on Message Passing Networks (MPNs) that can reason globally over an entire set of detections and predict final solutions.
Panoptic-level image-to-image translation extends the current image translation task to two separate objectives of semantic style translation and instance transfiguration.
We develop a novel framework to quantify the suitability of yeast as a model organism for studying tissue-specific physiology and pathophysiology in humans, and propose a statistical model to assess the overall similarity of each tissue with yeast.
We incorporate tensor mode-d product with low-rank matrices for self-representation for subspace clustering and obtain a robust affinity matrix for spectral clustering.
We set out to build a system that given 2d joint locations predicts 3d positions with state-of-the-art results.
In this paper, we present the computational tools and a hardware prototype for 3D face recognition. We present our results on the largest known, and now publicly available, face recognition grand challenge 3D facial database.
We propose a novel method which integrates pruning as part of the training procedure by exploring and tracking the relative importance of convolutional channels, thus reducing the memory and computational demands for discovering and training compact neural network models.
We propose adversarial attacks based on solving different optimization problems, like minimizing the perceptibility of our generated adversarial examples, or maintaining a uniform density distribution of points across the adversarial object surfaces.
In this paper, we propose Video-level 4D Convolutional Neural Networks, referred as V4D, to model the evolution of long-range spatio-temporal representation with 4D convolutions, and at the same time, to preserve strong 3D spatial representation.
We introduce an automated approach to extract time series features based on images, from which local features are extracted using computer vision algorithms. The extracted features are used for forecast model selection and model averaging.
We propose a novel self-supervised deep model for estimating monocular depth maps which outperforms state of the art unsupervised methods on KITTI benchmark.
We show that instead of using a semantic parser to produce the logical form, if we apply the generate-validate framework i.e. generate a natural language description of the logicalform, we get a better scope for transfer learning and our method outperforms the state-of-the-art by a large margin of 7.93%.
In this paper, we propose a novel approach, 3D-RecGAN++ , which reconstructs the complete 3D structure of a given object from a single arbitrary depth view using generative adversarial networks, and is able to reconstruct unseen types of objects.
We investigate machine comprehension on the challenging {\it MCTest} benchmark. We tackle the dataset with a neural approach, harnessing simple neural networks arranged in a parallel hierarchy.
We propose a novel framework to identify candidate GANs for a specific use case based on architecture, loss, regularization and divergence, and we demonstrate a significant reduction in search space.
In this paper, we propose a novel regression analysis approach, called maximal correlation regression, by exploiting the ideas from the Hirschfeld-Gebelein-Renyi (HGR) maximal correlation.
We introduce a novel query-guided end-to-end person search network (QEEPS) to address both aspects of person search.
We propose a novel Convolutional Neural Network (CNN) architecture to directly learn features for confidence estimation from volumetric 3D data.
The article describes a system for image recognition using deep convolutional neural networks. Modified network architecture is proposed that focuses on improving convergence and reducing training complexity.
Distributed label embedding based slot filling framework for adaptive NLU .
In this work, we present a simple yet better variant of Self-Critical Sequence Training for REINFORCE.
A survey on different aspects of machine reading comprehension systems, including their approaches, structures, input/output, and research novelties.
This paper presents a discriminative model adaptation algorithm able to proficiently learn a target object with few examples by relying on other previously learned source categories.
We describe the process of constructing subjectivity lexicon(s) for recognizing sentiment polarity in essays written by test-takers, to be used within a commercial essay-scoring system.
We introduce DeepInversion, a new method for synthesizing images from the image distribution used to train a deep neural network, without any additional information about the training dataset.
We propose to label large-loss U data as P, based on the memorization properties of deep networks. We develop a novel learning objective that can handle such biased P data properly.
We propose a part-based, sparse representation for automated measurement of continuous variation in AU intensity. The algorithm achieved state-of-the-art performance.
We propose a novel deep multi-task multi-label CNN, termed DMM-CNN, for effective FAC.
Rule-based mediation, a method of semantic data integration applied to systems biology model annotation, provides richly-modelled biological knowledge suitable for annotation of SBML models.
We propose an LSTM-in-LSTM architecture for generating long rich fine-grained textual descriptions of images.
An amino-oxazole inhibitor that inhibits biotin carboxylase activity and also exhibits antibacterial activity against Gram-negative organisms.
In this work we propose a new method for simultaneous object detection and 6DoF pose estimation that uses full-sized 2D images containing multiclass object masks and dense 2D-3D correspondences.
We propose a novel method that constructs new class weights from few labelled samples in the support set without back-propagation, while updating the previously learned classes.
We propose a novel recurrent architecture, termed Coupled Recurrent Network (CRN), to deal with multiple input sources in a recurrent manner. Experiments show the efficacy of the proposed CRN.
We propose the Variational Shape Learner (VSL), a hierarchical latent-variable model for 3D shape learning, made possible through the use of skip connections.
We propose manifold regularized networks that utilize a novel training objective function that minimizes the difference between multi-layer embedding results of samples and those adversarial.
We propose Path-Restore, a multi-path CNN with a pathfinder that could dynamically select an appropriate route for each image region of a corrupted region.
We propose a novel model to classify five distinct groups of vehicle images from actual life based on AdaBoost algorithm and deep convolutional neural networks (CNNs).
We present a new AI task -- Embodied Question Answering (EmbodiedQA) -- where an agent is spawned at a random location in a 3D environment and asked a natural language question ("What color is the car?"). In order to answer, the agent must first intelligently navigate to explore the environment, gather information through first-person (egocentric) vision, and then answer the question.
We show that current automatic evaluation metrics based on $n$-gram similarity do not always correlate well with human judgments about answerability of a question. To alleviate this problem and as a first step towards better evaluation metrics for AQG, we introduce a scoring function to capture answerability.
In this paper, we present a multi-step coarse to fine question answering (MSCQA) system which can efficiently processes documents with different lengths by choosing appropriate actions.
We present an approach to synthesizing photographic images conditioned on semantic layouts by a single feedforward network with appropriate structure.
In this paper, we extend the standard belief propagation (BP) sequential technique proposed in the tree-reweighted sequential method to the fully connected conditional random field models with geodesic distance affinity.
We propose FishNet, a fish-like network for predicting objects on different levels, which can be used for detection and segmentation.
We introduce 15 word-level probing tasks that can explore word embeddings or black-box neural models for linguistic cues in a multilingual setting.
This paper assesses the performance of three convolutional neural networks for object detection at sea using Long Wavelength Infrared images in the 8- 14µm range.
We propose incremental temporal training with constructed MT level dataset from time-resolved dataset, develop novel MT-RNNs with recurrent feature maps and investigate progressive single image deblurring over iterations.
We describe a deep learning based method for estimating 3D facial expression coefficients. Unlike previous work, our process does not relay on facial landmark detection methods as a proxy step.
In this paper, we propose convolutional neural networks for learning an optimal representation of question and answer sentences. Their main aspect is the use of relational information.
We propose Cross-Modal Deep Clustering (XDC), a novel self-supervised method that leverages unsupervised clustering in one modality as a supervisory signal for the other modality (e.g. video) and achieves state-of-the-art accuracy on several video and audio benchmarks.
We propose an edge-assisted intelligent caching replacement framework based on deep Long Short-Term Memory network, which outperforms state-of-the-art methods in cache hit rate on three real-traces of video requests.
We propose a decimated redundant DWT (DRDWT)-based face recognition method, where the decimation-based DWTs are performed on original signal and its 1-stepshift, respectively.
DeepStreamCE uses streaming approaches for real-time concept evolution detection in deep neural networks in a streaming environment.
In 3D human pose estimation one of the biggest problems is the lack of large, diverse datasets. To mitigate this issue, we introduce a network that can be trained with additional RGB-D images in a weakly supervised fashion and achieve state-of-the-art results.
This work addresses the problem of estimating the full body 3D human pose and shape from a single color image and proposes an efficient and effective direct prediction method based on ConvNets.
The sheer increase in volume of RDF data demands efficient solutions for the triple indexing problem, that is compressed data structure to compactly represent RDF triples by guaranteeing, at the same time, fast pattern matching operations.
We introduce a novel Concept Sharing Network (CSN) for part attribute recognition.
We describe a general mathematical strategy to learn the parameters and, to some extent, the architecture of nested systems, called the method of auxiliary coordinates (MAC).
We propose a novel single shot object detection network named Detection with Enriched Semantics (DES) which learns relationship between channels and object classes in a self-supervised manner.
We propose a dynamic distribution pruning method towards extremely efficient NAS, which samples architectures from a joint categorical distribution, and the optimal structure is obtained when there is only one structure remained.
We introduce targeted dropout, a method for training a neural network so that it is robust to subsequent pruning.
We cast the sketch-based retrieval as edge-map matching. A shared convolutional network is trained to extract descriptors from edge maps and sketches.
This paper introduces a novel age estimation method using a new texture descriptor Weber Local Descriptor (WLD) for age estimation problem.
We present a framework for efficient inference in structured image models that explicitly reason about objects in a probabilistic fashion.
We introduce a mutual suppression network (MSnet) which produces spatial features which are free of motion information, and motion features with no spatial information.
We propose a novel neural network architecture (DynMat) consisting of dual learning systems inspired by the complementary learning system (CLS) theory suggesting that the brain relies on short- and long-term learning systems to learn continuously.
We propose a new family of discrete energy minimization problems, which we call parsimonious labeling, and propose an efficient graph-cuts based algorithm that provides strong theoretical guarantees on the quality of solution.
We propose a generative adversarial network based on an objective function that trades-off mutual information between observed examples and their predicted categorical class distribution, against robustness of classifier to an adversarial generative model.
We introduce Training-with-Confusion, an optimization procedure for fine-grained classification tasks that regularizes training by introducing confusion in activations to prevent overfitting.
We use a linear approximation of the sigmoid function to convert these consistency equations to linear systems, which have a closed-form solution.
We compare the topological consistency of citation networks extracted from six popular bibliographic databases including Web of Science, CiteSeer and arXiv.org.
We present a structured inference approach in deep neural networks for multiple attribute prediction. The structured inference improves attribute prediction performance, and possibly uncovers the hidden relationship between attributes.
We propose $\Pi$-Nets, a new class of DCNNs that can be implemented using special kind of skip connections and their parameters can be represented via high-order tensors.
We propose an end to end solution for image matting i.e high-precision extraction of foreground objects from natural scenes with complex depth backgrounds.
We leverage adversarial perturbations and generative models to execute efficient, yet label-consistent, backdoor attacks.
We introduce Transitive Semantic Relationships (TSR), a new technique for ranking recommendations from cold-starts in datasets with very sparse, partial labelling, by making use of semantic embeddings of auxiliary information, in this case, textual item descriptions.
We build task agnostic relation representations solely from entity-linked text, which significantly outperform previous methods on SemEval 2010 Task 8, KBP37, and TACRED.
We propose a point pair descriptor that is robust to noise and occlusion and achieves high retrieval accuracy and can be used in a 4D convolutional neural network for the task of object classification.
We present the Reversible Residual Network (RevNet), a variant of ResNets where each layer's activations can be reconstructed exactly from the next layer's.
We introduce a co-separation training paradigm that permits learning object-level sounds from unlabeled multi-source videos, while simultaneously reproducing accurate video-level audio tracks for each source training pair.
We propose a novel memory-based tracker via part-level dense memory and voting-based retrieval, called DMV, for Siamese trackers.
We tackle the problem of building explainable recommendation systems that are based on a per-user decision tree, with decision rules that areBased on single attribute values.
This paper presents a new architecture, termed as Appearance-and-Relation Network (ARTNet), to learn video representation in an end-to-end manner.
We introduce an adaptive learned LISTA solver, termed Ada-LISTA, which receives pairs of signals and their corresponding dictionaries as inputs, learns a universal architecture to serve them all.
A robust and real-time CNN architecture for Moving Object Detection under low-light conditions by capturing motion information from both camera and LiDAR sensors.
We introduce three generic point cloud processing blocks that improve both accuracy and memory consumption of state-of-the-art networks thus allowing to design deeper and more accurate networks.
In this paper, we propose Local Context Normalization (LCN), a normalization layer where every feature is normalized based on a window around it and filters in its group.
This paper explores the generalization ability of open source models to differentiate between nine categories of surface ice features from close-range optical imagery.
Following the gaze of people inside videos is an important signal for understanding people and their actions. In this paper, we present an approach for following gaze in video by predicting where a person (in the video) is looking even when the object is in different frame.
In this work, we propose a new type of convolution that can take the camera parameters into account, thus allowing neural networks to learn calibration-aware patterns.
This paper proposes a video anomaly detection method based on wake motion descriptors and a perspective grid for anomaly detection.
We extended a CNN by adding recurrent connections to different layers of the CNN to allow spatial representations to be remembered and accumulated over time, leading to a hierarchical and distributed model of process memory as an integral part of visual processing.
We propose a simple yet effective sampling and learning strategy called PISA that directs the focus of the training process towards prime samples, those that play a key role in driving the detection performance.
A novel approach that improves place recognition in environments populated by dynamic objects by incorporating the very knowledge of these objects to improve the overall quality of the representations of places used for matching.
We introduce a general approach, called test-time training, for improving the performance of predictive models when test and training data come from different distributions.
A comparison of state-of-the-art detection, tracking, and obfuscation methods as they relate to video redaction.
We propose Zeno, a new robust aggregation rule, for distributed synchronous Stochastic Gradient Descent under a general Byzantine failure model, using a ranking-based preference mechanism.
What is the right way to reason about human activities? What directions forward are most promising? In this work, we analyze the current state of human activity understanding in videos, examine datasets, evaluation metrics, algorithms, and potential future directions.
This paper improves the MSA by using a feature pyramid module, which enhances speaker-discriminative information of features at multiple layers via a top-down pathway and lateral connections.
This paper introduces Bounded Residual Gradient Networks (BReG-Net) for Facial Expression Recognition.
In this paper, an interactive perception-based multiple object tracking method is proposed, which combines the visual perception of AV and information interaction of CVIS.
We present PointRend (Point-based Rendering) neural network module for efficient high-quality image segmentation of objects and scenes.
We propose an extension of U-Net, Squeeze and Excitation block, bi-directional ConvLSTM, and dense convolutions for medical image segmentation, achieving state of the art performance.
We propose a semi-supervised learning algorithm specifically designed for training temporal action proposal networks.
We develop an online product quantization (online PQ) model and incrementally updating the quantization codebook that accommodates to the incoming streaming data.
We explore self-supervised models that can be potentially deployed on mobile devices to learn general purpose audio representations, and propose methods that exploit the temporal context in the spectrogram domain.
This paper presents a new model that captures the continuous evolution of user experience, and the resulting language model in reviews and other posts.
We examine the contribution of these architectures by holding them randomly initialised and fixed, effectively treating them as as hand-crafted language priors, and evaluating the resulting sentence encoders on downstream language tasks.
We introduce language-driven image generation, the task of generating an image visualizing the semantic contents of a word embedding, e.g., given the word Embedding of Grasshopper, we generate a natural image of a grasshopper.
This paper presents an extension of the Stochastic Answer Network (SAN), one of the state-of-the-art machine reading comprehension models, to be able to judge whether a question is unanswerable or not.
We investigate the relation of conductance with weighted kernel k-means for a single community, which leads to the introduction of a new objective function, $\sigma$-conductance, for local community detection.
In this paper, we model an API method as a view with binding patterns over a global RDF schema. We present an algorithm that can automatically infer the view definition of a method in the global schema.
We introduce Paragraph Ranker which ranks paragraphs of retrieved documents for a higher answer recall with less noise and improves performance of open-domain QA pipeline on four open- domain QA datasets.
A conference session on medical image data and datasets for machine learning identified multiple issues. There is an urgent need to find better ways to collect, annotate, and reuse medical imaging data.
In this paper, a deep neural architecture is proposed to effectively fuse the two kinds of informations into one representation for structural and textual network embeddings.
In this paper, we propose a knowledge transfer method via distillation of activation boundaries formed by hidden neurons.
In high dimensional settings, density estimation algorithms rely crucially on their inductive bias. In this paper we propose a framework to systematically investigate bias and generalization in deep generative models of images.
We propose Deep Epipolar Flow, an unsupervised optical flow method which incorporates global geometric constraints into network learning and achieves competitive performance compared with supervised methods.
This paper brings together these two techniques and propose to train arbitrarily designed networks, with a focus on relatively small databases, in two stages: patch pre-training and full sized image fine-tuning.
This paper focuses on multi-person action forecasting in videos using Discriminative Relational Recurrent Network.
This paper introduces an approach to produce accurate 3D detection boxes for objects on the ground using single monocular images, without directly predicting the 6DoF pose of the object.
We propose an original method for detecting and localizing anomalous motion patterns in videos from a camera view -based motion representation perspective.
Generative Shape Proposal Network (GSPN) for instance segmentation in point cloud data.
We propose a self-supervised learning framework for 3D volumetric medical data, which can improve the accuracies of 3D neural networks without using extra data.
We establish the performance range of deep learning-based descriptors for unsupervised near-duplicate detection on a range of datasets, encompassing a broad spectrum of near-fluid definitions.
We present a framework for learning disentangled and interpretable jointly continuous and discrete representations in an unsupervised manner.
We propose a multi-scale gated fusion network for image denoising, which learns end-to-end mappings from corrupted images to clean images.
We propose a simple yet effective convolutional spatial propagation network (CSPN) to learn the affinity matrix for various depth estimation tasks, which is effective in stereo matching using 3D cost volume.
We propose a novel meta-learning based training procedure (MLTP) for DNNs and demonstrate that the meta- learning idea can indeed improve the generalization abilities of Dnns.
We present non-local operations as a generic family of building blocks for capturing long-range dependencies in computer vision.
This paper proposes an entropy-difference weighting matrix for covariance-based principal components analysis, which can be used for face recognition with nearest neighbor classifier.
We explore sampling techniques that eliminate stochastic behavior in DOCK3.6, allowing us to optimize the method for regularly variable sampling of orientations, with a threefold increase in the speed of the program.
We propose RNN-Capsule, a capsule model based on Recurrent Neural Network (RNN) for sentiment analysis.
We propose a co-attention enhanced hierarchical architecture to better capture the interactions between the article and question, thus guide the decoder to generate more coherent distractors, achieving state-of-the-art performance.
We present an edge guidance network for salient object detection with three steps to simultaneously model these two kinds of complementary information in a single network.
We analyze and compare the pixel-based 3D-JND models thoroughly using qualitative and quantitative performance evaluation.
This paper presents a conceptually simple yet powerful solution – Spatial Memory Network (SMN), to model the instance-level context efficiently and effectively.
We propose a hybrid regression and isophote curvature method for accurate eye center localization under low resolution.
We explore how to adapt the Layer-wise Relevance Propagation (LRP) technique used for explaining the predictions of feed-forward networks to the LSTM architecture used for sequential data modeling and forecasting.
We present an unsupervised learning framework for simultaneously training single-view depth prediction and optical flow estimation models using unlabeled video sequences.
A hybrid vision-map system is presented to solve the road detection problem in urban scenarios, fusing stereo vision with digital maps.
We show that two stages of feature extraction yield better accuracy than one, provided that the proper non-linearities and pooling layers are used.
We analyze failure cases of state-of-the-art detectors and observe that most hard false positives result from classification instead of localization. We propose a simple, effective, and widely-applicable Decoupled Classification Refinement network.
Memory-based neural networks model temporal data by leveraging an ability to remember information for long periods. It is unclear, however, whether they also have the ability to perform complex relational reasoning with the information they remember.
We propose to use a neural network built from stacked convolutional and recurrent layers in order to estimate the directions of arrival of multiple sources from a first-order Ambisonics recording, using features derived from the acoustic intensity vector.
We propose a novel framework to capture and track the visual aspect of an arbitrary object in a scene, given a first closed outline of this object, using a rich appearance model of the enclosed object.
We propose a method for segmenting an arbitrary number of moving objects using the geometry of 6 points in 2D images to infer motion consistency, competing with state of the art methods.
Question Generation is the task of automatically creating questions from textual input. In this work we present a new Attentional Encoder--Decoder Recurrent Neural Network model for automatic question generation.
Pretraining real-time segmentation architectures with synthetic segmentation data instead of ImageNet improves fine-tuning performance by reducing the bias learned in pretraining and closing the transfer gap.
This paper proposes a method to use deep neural networks as end-to-end open-set classifiers. It is based on intra-class data splitting.
By approximating the tangent subspace, we suggest a sparse representation that enables switching to shallow networks, GradNet after a very early training stage.
We propose to learn a classwise pairwise similarity function that directly compares two input proposals as well for weakly Supervised object localization.
Manifold-Aware Wasserestein GAN can generate high quality manifold-valued images.
We propose a system which aims to allow computers to read articles and answer related questions with commonsense knowledge like a human being for CAT level 2.
We propose an unsupervised domain adaptation technique which does not require groundtruth labels and leverages on classical stereo algorithms to produce disparity measurements alongside with confidence estimators to assess upon their reliability.
In this work we propose a novel method to include a connectivity prior into image segmentation that is based on a binary labeling of a directed graph, in this case a geodesic shortest path tree.
We present a new dataset for DRL based robot visual navigation. It provides high-quality visual inputs with real-world scene complexity to the robot at dense grid locations.
Unsupervised landmark learning is the task of learning semantic keypoint-like representations without the use of expensive input key point-level annotations.
We propose a novel family of "clockwork" convnets driven by fixed or adaptive clock signals that schedule the processing of different layers at different update rates according to their semantic stability.
We propose the onion-peel networks for video completion. Given a set of reference images and a target image with holes, our network fills the hole by referring the contents in the reference images in a non-local manner.
We investigate the effect of attack strategies crafted on a target user in order to push the recommendation of a low-ranking item to a higher position, referred to as user-item attack.
We propose a novel dynamic grouping convolution (DGConv) operation, which learns the number of groups in an end-to-end manner.
We propose a novel captioning method that is able to leverage contextual information provided by the text of news articles associated with an image, by integrating such contextual information into the captioning pipeline.
We introduce a novel architecture FigureNet, that learns to identify various plot elements, quantify the represented values and determine a relative ordering of these statistical values.
This paper proposes an enhanced LSTM architecture, called relation gated LSTMs, which can model the relationship between two inputs of a sequence using a control input. We also introduce a Tree-LSTM model that uses the sentence dependency parse structure as well as the dependency type.
We borrow ideas from engineered circuit design and study Rentian scaling, which states that the number of external connections between nodes in different modules is related to theNumber of nodes inside the modules by a power-law relationship.
We propose a high-resolution 3D object class model for scene understanding, which enables fine-grained modeling at the level of individual vertices and faces, which improves monocular 3D pose estimation.
We propose a new method to detect salient objects by using Conditional Generative Adversarial Network (GAN).
We introduce a method for creating very dense reconstructions of datasets, particularly turn-table varieties, and make them denser by interpolating depth values in two-dimensional image space within a superpixel region.
We propose a novel ensemble learning method which achieves a maximal detection rate at a user-defined range of false positive rates by directly optimizing the partial AUC using structured learning.
Feeding an explicit model of the scale changes to the network considerably increases performance, especially when perspective effects are strong.
The proposed HetConv (Heterogeneous Kernel-Based Convolution) reduces the computation (FLOPs) and the number of parameters as compared to standard convolution operation while still maintaining representational efficiency.
We use deep neural networks for inverting face sketches to synthesize photorealistic face images, achieving state-of-the-art results.
We propose Harmonious Bottleneck on two Orthogonal dimensions (HBO), a novel architecture unit, specially tailored to boost the accuracy of extremely lightweight MobileNets at the level of less than 40 MFLOPs.
We show that the local sensitivity can be efficiently estimated using the leverage scores of a quadratic approximation to F and that the sample size required to approximate $F$ around $x_0$ can be bounded.
We propose a text-based dynamic attention model, which imposes a dynamic attention mechanism on all the generated words with the motivation to improve the context semantic information and enhance the overall control of the whole sentence.
This paper presents a review of various techniques for improving the performance of neural networks on segmentation task using 3D convolutions and voxel grids, including max pooling, weighting, masking out the segmentation results, and oversampling.
We propose a novel framework for visual localization from relative poses. Using a classical feature-based approach within this framework, we show state-of-the-art performance.
In this work, we propose a novel Cycle In Cycle Generative Adversarial Network (C$^2$GAN) for the task of keypoint-guided image generation.
In this paper we incorporate the Lie group structure into a deep network architecture to learn more appropriate Lie group features for 3D action recognition.
We search the space of two-lobed differential operators for those that constitute a good representational code under recognition and discrimination criteria. We find a novel operator, which we call the dissociated dipole, displays useful properties.
We tackle the problem of generating a pun sentence given a pair of homophones (e.g., "died" and "dyed") using a corpus of unhumorous text and what we call the local-global surprisal principle.
We propose a simple yet effective Learning to Scale (L2S) module to cope with significant scale variations in both regression and localization.
In a biometric identification system, the identity corresponding to the input data (probe) is typically determined by comparing it against the templates of all identities in a database (gallery). Exhaustive matching against a large number of identities increases the response time of the system and may also reduce the accuracy of identification.
We propose a novel approach for verifying recurrent neural networks that performs orders-of-magnitude better than the state of the art.
The"cvpaper.challenge" is a group composed of members from AIST, Tokyo Denki Univ. (TDU), and Univ. of Tsukuba that aims to systematically summarize papers on computer vision, pattern recognition, and related fields.
This paper conducts a rigorous evaluation of these new CNN methods, exploring different deep architectures and comparing them on a common ground, identifying and disclosing important implementation details.
A fast feature fusion algorithm to satisfy the requirement of CPS in the area of image classification from a comprehensive perspective.
In this paper, a coherent constraint is constructed to suppress the noise in the initialization step of the PMP algorithm. Moreover, an Accelerated Expectation Maximization (AEM) algorithm is devised to optimize PMP estimation model.
In this paper, we design a new collaborative intelligence friendly architecture by introducing a unit responsible for reducing the size of the feature data needed to be offloaded to the cloud to a greater extent, where this unit is placed after a selected layer of a deep model.
We make progress on this problem by training with full label distributions that reflect human perceptual uncertainty, leading to improved generalization to increasingly out-of-training-distribution test datasets.
In this paper we propose bag-of-vector embeddings of arbitrary linguistic graphs in a nonparametric extension of vector space.
The words-as-classifiers model of grounded lexical semantics learns a semantic fitness score between physical entities and the words that are used to denote those entities and can incrementally perform composition.
We propose an alternative approach to graph classification that is based on feature vectors constructed from different global topological attributes, as well as global label features.
We propose a novel self-supervised method, referred to as Video Cloze Procedure (VCP), to learn rich spatial-temporal representations.
We propose to regress directly to objects shapes in addition to their bounding boxes and categories, yielding the first real-time shape prediction network, running at 35 FPS on a high-end desktop.
We introduce a new generative model where samples are produced via Langevin dynamics using gradients of the data distribution estimated with score matching.
We study whether and where the conditional formulation of group normalization improves generalization compared to conditional batch normalization.
We propose Multi-Scale Link Prediction (MSLP), a framework for large-scale link prediction, which can handle massive networks.
This paper represents a matched filter-based vasculature segmentation method for 2-D retinal images.
We introduce the new task of Acoustic Question Answering (AQA) to promote research in acoustic reasoning. The AQA task consists of analyzing an acoustic scene composed of elementary sounds and answering questions that relate the position and properties of these sounds.
We propose a clearing algorithm for annotations in computed tomography (CT) imaging segmentation where there are several annotators labeling each image.
We examine the role of the image signal processing (ISP) pipeline in computer vision to identify opportunities to reduce computation and save energy. We propose a new imaging system that disables the ISP entirely and configures the sensor to produce subsampled, lower-precision image data.
In this paper, we propose a novel attention-based convolutional neural network (CNN) which regulates multiple object parts among different input images.
This paper proposed a Domain-Adaptive Crowd Counting framework, which consists of Inter-domain Features Segregation (IFS) and Gaussian-prior Reconstruction (GPR)
We proposed a novel Incremental Boosting CNN to integrate boosting into the CNN via an incremental boosting layer that selects discriminative neurons from the lower layer and is incrementally updated on successive mini-batches.
In this paper, we aim to reduce the computational cost of spatio-temporal deep neural networks, making them run as fast as their 2D counterparts while preserving state-of-the-art accuracy on video recognition benchmarks.
Device Lending enables direct low latency access to physical resources while still retaining the flexibility of virtualization.
We propose methods to train binary neural networks with both binarized weights and activations, leading to quantized models that are specifically friendly to mobile devices with limited power capacity and computation resources.
Information Extraction (IE) is the task of distilling structured information from unstructured texts by identifying references to named entities as well as relationships between such entities. Existing IE solutions, including Relation Extraction and Open IE, can hardly take cross-sentence information like coreferences into account.
This paper proposes to learn reliable dense correspondence from videos in a self-supervised manner. We exploit the synergy between both tasks through a shared inter-frame affinity matrix.
We propose Adanets, a family of convolutional networks with adaptive computation graphs that efficiently allocate computational budget among layers and learn distinct layers specializing in similar categories.
We propose an end-to-end architecture for joint 2D and 3D human pose estimation in natural images. Key to our approach is the generation and scoring of a number of pose proposals of multiple people simultaneously.
We propose KerBS, a novel approach for learning better embeddings for text generation that captures the closeness of words (senses) in the embedding space.
We present a sensor fusion approach to time-of-flight super resolution, based on the combination of depth and texture sources, for depth scenery capture.
We propose a novel one-shot face reenactment learning framework that achieves competitive results to those using a set of target images, demonstrating the practical merit of this work.
Convolutional Neural Networks (CNNs) are well established models capable of achieving state-of-the-art classification accuracy for various computer vision tasks. However, they are becoming increasingly larger, using millions of parameters, while they are restricted to handling images of fixed size. In this paper, a quantization-based approach, inspired from the well-known Bag-ofFeatures model, is proposed to overcome these limitations.
In this paper, we present a method to estimate a vehicle's pose and shape from off-board multi-view images, which can be applied to massive surveillance camera networks for intelligent transportation.
We propose a Mixture-of-Embedding-Experts model with ability to handle missing input modalities during training. As a result, our framework can learn improved text-video embeddings simultaneously from image and video datasets.
We propose a principled approach for learning a video anonymizer that performs pixel-level modifications to anonymize each person's face, with minimal effect on action detection performance.
We propose a novel unsupervised learning of Graph Transformation Equivariant Representations (GraphTER), aiming to capture intrinsic patterns of graph structure under both global and local transformations.
We propose a hybrid method for stereo disparity estimation by combining block and region-based stereo matching approaches. It generates dense depth maps from disparity measurements of only 18 % image pixels (left or right).
We propose a novel Disentangled Expression learning-Generative Adversarial Network (DE-GAN) which combines the concept of disentangled representation learning with residue learning to explicitly disentangle facial expression representation from identity information.
Image-to-image (I2I) translation is a pixel-level mapping that requires a large number of paired training data and often suffers from the problems of high diversity and strong category bias in image scenes. In order to tackle these problems, we propose a novel BiLevel learning paradigm that alternates the learning of two models, respectively at an instance-specific (IS) and a general-purpose (GP) level.
We examine two different techniques for parameter averaging in GAN training. Both improve inception and FID scores on different architectures and for different GAN objectives.
We tested the effectiveness of a playback attack using this method by using the speech enhancement generative adversarial network to transform acoustic characteristics of the played-back speech close to that of the genuine speech.
A generic method for self-supervised domain adaptation, using object recognition and semantic segmentation of urban scenes as use cases.
We propose a discriminative framework that exploits the presence of bias during training, and apply the learned weights to a novel dataset.
We provide assessment of existing tools/techniques for CDCR subtasks and highlight big data challenges in each of them to help readers identify important and outstanding issues for further investigation.
We present a method that extracts effective features in videos for human action recognition and achieve state-of-the-art performance.
We show that increasing input image resolution (i.e. upsampling) offers up to 12 percentage-points higher accuracy compared to an off-the-shelf baseline.
Our pose-invariant point-pair descriptors, which encode 3D shape between a pair of 3D points, are able to identify the nose-tip and the eye-corner of a human face simultaneously.
We develop a training strategy that not only leads a more explainable AI system for object classification, but as a consequence, suffers no perceptible accuracy degradation.
A general-purpose, Conditional Batch Normalization approach achieves state-of-the-art results on the CLEVR Visual Reasoning benchmark with a 2.4% error rate.
We introduce an unsupervised multi-task model to jointly learn point and shape features on point clouds.
We introduce a method that maps a CNN to its equivalent FCN (denoted as eFCN) and use this method to test a new training protocol, which consists in training a CNN, embedding it to FCN space at a certain ``relax time'', then resuming the training inFCN space.
We propose the Generative Multisensory Network (GMN) for learning latent representations of 3D scenes which are partially observable through multiple sensory modalities.
This paper addresses the problem of estimating and tracking human body keypoints in complex, multi-person video.
Conditional generators are extended to regression problems wherein the conditional generator is restrained to any continuous aspect of the data.
Trained machine learning models are increasingly used to perform high-impact tasks in areas such as law enforcement, medicine, education, and employment. In order to clarify the intended use cases of machine Learning models and minimize their usage in contexts for which they are not well suited, we recommend that released models be accompanied by documentation detailing their performance characteristics.
In this paper, we propose a generic framework that can accurately detect a wide variety of activities from untrimmed videos, demonstrating superior accuracy and strong adaptivity.
We propose a webly supervised approach for learning a generalizable emotion recognition model by leveraging a large quantity of stock image data.
Person re-identification across different surveillance cameras with disjoint fields of view has become one of the most interesting and challenging subjects in the area of intelligent video surveillance. Although several methods have been developed and proposed, certain limitations and unresolved issues remain.
We study the intrinsic challenge of the instance segmentation problem, the presence of a quotient space (swapping the labels of different instances leads to the same result), and propose new methods that are object proposal- and object detection- free.
We propose the Target-Oriented Deformation Network (TOD-Net), a novel module that continuously transforms the embedding space into a new space under a given condition, thereby adjusting similarities between entities.
We introduce a novel learning framework to automatically discover global planar reflective symmetry of a 3D shape, where input shapes are represented using voxels.
We learn rich natural sound representations by capitalizing on large amounts of unlabeled sound data collected in the wild.
We introduce Item Response Theory (IRT) from psychometrics as an alternative to majority voting to create an IRT gold standard for Recognizing Textual Entailment.
This paper comes up with a simple yet powerful training algorithm named Adversarial Noise Propagation (ANP) that injects diversified noises into the hidden layers in a layer-wise manner.
We present a new local spatiotemporal descriptor for action recognition that encodes both the appearance and motion in a scene with a short binary string.
In this paper we propose a technique to adapt convolutional neural network (CNN) based object detectors trained on RGB images to effectively leverage depth images at test time to boost detection performance.
We propose a novel approach to reduce the computational overhead caused by volumetric representation and 3D convolution: Holistic 2D prediction and Local 3D prediction.
We propose a novel Bilateral Segmentation Network with a fast downsampling strategy and a novel Feature Fusion Module to achieve fast segmentation performance.
Image caption generators with transferred parameters perform better than those trained from scratch, even when pre-training them on the text of the same captions dataset.
Sparse coding facilitates better depth inference with sparse activations than comparable feed-forward networks of the same size.
We revisit the classical triplet network from deep metric learning, and extend it into a deep K-tuplet network for few-shot learning, utilizing the relationship among the input samples to learn a general representation learning via episode-training.
We propose a new end-to-end 3D deep convolutional neural net (DCNN), called NoduleNet, to solve nodule detection, false positive reduction and nodule segmentation jointly in a multi-task fashion.
We address the problem of localisation of weakly supervised objects as bounding boxes in images and videos with weak labels using Bayesian joint topic modelling.
In this paper, an unsupervised domain adaptation framework based on ResNet-18 is presented to transfer the knowledge of an existing annotated land cover dataset to other remote sensing data, decreasing the discrepancy among images across sensors.
We consider the problem of adapting neural paragraph-level question answering models to the case where entire documents are given as input. Our proposed solution trains models to produce well calibrated confidence scores for their results on individual paragraphs.
We present a method that allows end-to-end top grasp planning methods to generate full six-degree-of-freedom grasps using a single RGB-D view as input.
We show that a much simpler model obtained by ablating and pruning the existing intricate baseline can perform better with half the number of trainable parameters.
In recent years, deep-learning-based visual object trackers have been studied thoroughly, but handling occlusions and/or rapid motion of the target remains challenging. We propose a novel deep tracking-by-detection formulation that can take advantage of NL descriptions.
FairTest, a testing toolkit that detects unwarranted associations between an algorithm's outputs and user subpopulations, including protected groups (e.g., defined by race or gender), and ranks them as potential bugs.
A properly designed classifier can improve robustness to adversarial attacks and lead to better prediction results.
The recent research for person re-identification has been focused on two trends. One is learning the part-based local features to form more informative feature descriptors. The other is designing effective metric learning loss functions such as the triplet loss family. We argue that learning global features with classification loss could achieve the same goal.
A hybrid architecture that combines Fisher vectors and deep neural networks to learn non-linear transformations of pedestrian images to a deep space where data can be linearly separable.
The aim of this paper is to benchmark various semantic repositories in order to evaluate their deployment in a commercial image retrieval and browsing application, which provides us with the opportunity of consolidating our findings.
In this paper, we propose a novel signal-level information fusion method to mitigate the influence of noise and degradations in the iris recognition systems.
In this paper, we propose a hybrid learning framework for video classification, which is able to model static spatial information, short-term motion, as well as long-term temporal clues in the videos.
A novel approach that predicts the relationships between various entities in an image in a weakly supervised manner by relying on image captions and object bounding box annotations as the sole source of supervision.
We combine channel saliency metrics with empirical observations of runtime performance to design more accurate networks for a given latency budget.
We improve the performance of DP models by fine-tuning them through active learning on public data in a privacy-aware way.
We propose an incremental strategy for learning hash functions with kernels for large-scale image search, which is based on a two-stage classification framework.
In this paper we show that, under the assumption that the augmentation space is approximately distribution invariant, a uniform sampling over the continuous space of augmentation transformations is sufficient to train highly effective models.
In this paper we introduce a novel approach to scalable semi-supervised learning, called Local Label Propagation (LLP), which first embeds datapoints, labelled and otherwise, in a common latent space using a deep neural network. It then propagates pseudolabels in a manner that depends on the local geometry of the embedding, taking into account both inter-point distance and local data density as a weighting.
We proposed a holistic solution for fast and energy-efficient GAN computation through a memristor-based neuromorphic system that achieves 2.8x speedup and 6.1x energy-saving compared with the traditional GPU accelerator.
We propose a meta-learning method capable of adaptively learning hyperparameter in robust loss functions that can be simultaneously finely learned and coordinated.
In this paper, we train deep neural networks on the foreground (object) and background (context) regions of images respectively. Experiments show that useful visual hints can be explicitly learned separately and then combined to achieve higher performance.
In this paper, we propose a new approach for body gesture recognition. The proposed approach achieves high recognition rates (more than 92% for certain categories of gestures), when tested and evaluated on a corpus including 11 different actions.
We seek the generalization power of disentangled representations, but relax the requirement of explicit latent disentanglement and instead encourage linearity of individual factors of variation.
We propose the Hierarchical Probabilistic U-Net, a segmentation network with a conditional variational auto-encoder (cVAE) that uses a hierarchical latent space decomposition to learn a flexible distribution that can account for multiple scales of variations.
Generative Adversarial Networks are powerful generative models that are able to model the manifold of natural images. We leverage this property to perform manifold regularization by approximating a Monte Carlo approximation that is easily computed with the GAN.
Multistructure elements-based morphology operators are used to detect high-quality image ridges. A fuzzy noise reduction algorithm was employed to enhance illumination and increase the contrast of retinal images captured from state-of-the-art cameras.
An essential task of most Question Answering (QA) systems is to re-rank the set of answer candidates, i.e., Answer Sentence Selection (A2S), while retaining competitive results with respect to the state of the art.
We propose OBJ2TEXT, a sequence-to-sequence model that encodes a set of objects and their locations as an input sequence, and decodes this representation using an LSTM language model, and generate descriptions that are globally coherent and semantically relevant.
We propose a large-scale dataset for modeling affordances and propose a two-step approach to predict affordances in a new scene.
We present a modular deep reinforcement learning approach to predict the steering angle of the car from raw images in a simulator.
We propose a novel collaborative weight-based classification method to fully take advantage of deep features in classic machine learning.
Tensor factorization has become an increasingly popular approach to knowledge graph completion(KGC), which is the task of automatically predicting missing facts in a knowledge graph. However, even with a simple model like CANDECOMP/PARAFAC tensor decomposition, KGC on existing knowledge graphs is impractical in resource-limited environments, as a large amount of memory is required.
This paper addresses the matter by applying a sturdy region tracking method, instead of the conventional space-time interest point feature based techniques, demonstrating that region descriptors can be attained for the action classification task.
We propose a novel Dilated Temporal Relational Generative Adversarial Network (DTR-GAN) to achieve frame-level video summarization.
We propose a novel paradigm called the Chained Context Aggregation Module (CAM), which gains features of various spatial scales through chain-connected ladder-style information flows. We further adopt attention models in CAM to productively recombine and select those fused features to refine performance.
We propose a novel efficient three-stage unsupervised video anomaly detection method that learns anomalies by exploiting videos under the fully Unsupervised setting.
We present Fishyscapes, the first public benchmark for uncertainty estimation in a real-world task of semantic segmentation for urban driving.
We propose Semantic Graph Convolutional Networks (SemGCN), a novel neural network architecture that operates on regression tasks with graph-structured data.
We show that even for easy examples where the answer is clearly embedded in the passage, the neural components designed for paying attention to relevant portions of the passage fail to serve their intended purpose.
This paper proposes an attention boosted natural language inference model named aESIM by adding word attention and adaptive direction-oriented attention mechanisms to the traditional Bi-LSTM layer ofnatural language inference models.
We propose a fully learnable group convolution module (FLGC for short) which can be embedded into any deep neural networks for acceleration.
We introduce a family of multimodal deep generative models derived from variational bounds on the evidence, and investigate the effect of language on learned image representations.
We propose a novel deep hashing model, named deep saliency hashing (DSaH), which automatically mines salient regions and learns semantic-preserving hashing codes simultaneously.
We present an algorithm that synthesizes sound from silent videos of people hitting and scratching objects with a drumstick. The sounds predicted by our model are realistic enough to fool participants in a psychophysical experiment.
A novel, robust, and stand-alone algorithm based on hybrid combination between adaptive fuzzy thresholding and mathematical morphology used to extract multi-anatomical objects with broad features and characteristics in retinal image.
We enable material-aware 3D shape analysis by employing a projective convolutional neural network architecture to learn material- aware descriptors from view-based representations of 3D points for point-wise material classification or material- Aware retrieval.
This paper investigates the feasibility of using the periocular region for expression recognition.
We present a simple, yet effective fusion approach for multi-frame optical flow that benefits from longer-term temporal cues.
We present structured domain randomization (SDR), a variant of Domain Randomization (DR) that takes into account the structure of the scene in order to add context to the generated data.
We propose a plug-and-play (PnP) module for improving depth prediction with taking arbitrary patterns of sparse depths as input.
We study the task of generating from Wikipedia articles question-answer pairs that cover content beyond a single sentence. We propose a neural network approach that incorporates coreference knowledge via a novel gating mechanism and create a large-scale generated corpus from Wikipedia.
In this paper, we proposed an unsupervised learning method for estimating optical flow between video frames, especially to solve the occlusion problem.
We address the challenge of robustness and stability of neural networks and propose a general training method that can be used to make the existing neural network architectures more robust and stable to input visual perturbations.
We propose a novel convolutional fusion network based on a two-stream network, called 3D Multi-Level Dense Fusion (MLDF-3D) for the deep spatiotemporal relation learning.
In this paper, we attempt to automatically construct CNN architectures for an image classification task based on Cartesian genetic programming (CGP).
In this paper we propose a supervised object recognition method using new global features and inspired by the model of the human primary visual cortex V1 as the semidiscrete roto-translation group, which are invariant to natural geometric transformations.
Learning Deep Fully Convolutional Features for Correlation Filter Based Visual Tracking .
In the context of autonomous driving, where humans may need to take over in the event where the computer may issue a takeover request, a key step towards driving safety is to locate the hands to ensure the driver is ready for such a request.
In this paper, we propose a novel Complete Layer-wise Adaptive Rate Scaling (CLARS) algorithm for large-batch training. The proposed algorithm outperforms gradual warmup technique by a large margin.
We propose the first unsupervised method, Multilabel Classification with Pseudo Target (MCPT), for RPM problems.
We show that, for models trained from scratch as well as pretrained ones, using a variant of the triplet loss to perform end-to-end deep metric learning outperforms most other published methods by a large margin.
We propose a novel network called Image Pyramid Guidance Network(IPG-Net) to make sure both the spatial information and semantic information are abundant for each layer.
We present a novel approach leveraging a task-independent intrinsic reward function trained on spontaneous smile behavior that captures positive affect. The policy based on intrinsic affective rewards successfully increases the duration of episodes, area explored and reduces collisions.
We present a novel hierarchical model for human activity recognition that captures a richer class of contextual information in both state-state and observation-state pairs, and their labels are simultaneously predicted.
Inverse-Reinforcement Learning can learn target-specific reward functions and policies for goal-directed attention control in large-scale datasets.
This paper presents an efficient one-stage keypoint-based detector which explores the visual patterns within each cropped region with minimal costs.
We introduce MCScript2.0, a machine comprehension corpus for the end-to-end evaluation of script knowledge. We give a thorough analysis of our corpus and show that existing machine comprehension models fail to perform well on the data.
 MirrorGAN exploits the idea of learning text-to-image generation by redescription and consists of three modules: a semantic text embedding module (STEM), a global-local collaborative attentive module for cascaded image generation (GLAM), and a Semantic text regeneration and alignment module (STREAM)
We formulate a novel Deep Association Learning (DAL) scheme, the first end-to-end deep learning method using none of the identity labels in model initialisation and training, for video-based person re-identification task.
In this paper we present the Multilingual AllWords Sense Disambiguation and Entity Linking task. Our aim with this task is to analyze whether, and if so, using a resource that integrates both kinds of inventories (i.e., BabelNet 2.5.1) might enable WSD and EL to be solved by means of similar (even, the same) methods.
We propose the Manitest method for quantifying the invariance of classifiers to geometric transformations, built on the efficient Fast Marching algorithm.
This paper proposes to apply semantic technologies in a new domain, Field research. Firstly, we introduce our approach of LOD content generation, and its application for a specific domain.
We build a system capable of answering open-ended text-based questions about images, which is known as Visual Question Answering (VQA).
A noisy adversarial attack which searches among semantic variations of the question for which a model erroneously predicts the same answer, and with even higher probability.
We propose a compromise approach that prefers stereo depth estimates but can replace estimates in textureless regions with planes in a principled manner at near real-time rates.
We propose semantic role labeling to enhance text comprehension and inference through specifying verbal arguments and their corresponding semantic roles.
We proposed a light-weighted hybrid neural network which consists of a modified PCANet cascaded with a simplified DenseNet.
ReasoNets make use of multiple turns to effectively exploit and then reason over the relation among queries, documents, and answers for machine comprehension tasks.
Multi-task Part-aware Network solves the body part misalignment problem via multi-task learning (MTL) in the training stage, which is designed to extract semantically aligned part-level features from pedestrian images.
We investigate the trade-off between the encoding bitrate and the achievable accuracy of CNN-based video classification models that directly ingest AVC/H.264 and HEVC encoded videos.
We propose a novel multi-modal interaction module for few-shot object segmentation that utilizes a co-attention mechanism using both visual and word embedding, and a novel setup, Temporal Object Segmentation for Few-shot Learning, for videos.
We propose a new method for learning the structure of convolutional neural networks (CNNs) that is more efficient than recent state-of-the-art methods based on reinforcement learning and evolutionary algorithms.
We introduce a method for learning to generate the surface of 3D shapes that naturally infers a surface representation of the shape.
We propose a pedestrian detection framework that extends proposals to enrich the context and relieves the confusions caused by contextual information through a supervised attention module, achieving first places among all methods.
Active learning can increase the efficiency of the labeling process in terms of time and cost. We describe combinations of an incremental learning scheme and methods of active learning.
In this paper we propose a new semi-supervised GAN architecture that leverages information from few labels (as little as 0.22%, max. 10% of the dataset) to learn semantically meaningful and controllable data representations where latent variables correspond to label categories.
We propose Ontology Generative Adversarial Networks (O-GAN) for fashion image synthesis that is conditioned on an hierarchical fashion ontology in order to improve the image generation fidelity.
An end-to-end lip-reading system based on fully-connected layers and Long-Short Memory networks which is suitable for small-scale datasets.
We present several methodologies for use in hypothesis-based and exploratory studies, explain how to select the computer algorithms that best fit to the requirements of our experimental design, and detail whether the automatic annotations provided by existing algorithms are trustworthy.
We propose a fully convolutional one-stage object detector (FCOS) to solve object detection in a per-pixel prediction fashion, analogue to semantic segmentation.
We propose a two-stream fully convolutional network, named MIML-FCN+, unified by a novel PI loss to solve the problem of M IML learning with privileged bags.
Novelty enhancement of recommendations is typically achieved through a post-filtering process applied on a candidate set of items.
Novelty detection using voting-based scheme that leverages the estimated uncertainty of the individual classifiers in their predictions to measure the novelty of a new input sample.
We investigate dependency parsing of Singlish by constructing a dependency treebank under Universal Dependencies scheme, and then training a neural network model by integrating English syntactic knowledge into a state-of-the-art parser trained on the Singlish treebank.
We propose Adversarial Metric Attack, a parallel methodology to adversarial classification attacks for person re-identification.
This paper proposes a generic framework that enables a multiscale interaction in the cost aggregation step of stereo matching algorithms.
We propose a supervised multi-task learning framework which considers attribute label information with joint identification-verification network to simultaneously learn an attribute-semantic and identity-discriminative feature representation.
We enrich the state-of-the-art neural natural language inference models with external knowledge to achieve the state of the art performance on SNLI and MultiNLI datasets.
We propose SqueezeDet, a fully-convolutional neural network for object detection that aims to simultaneously satisfy all of the above constraints.
We explored the use of the active-state NOP receptor homology model for structure-based virtual screening to discover NOP ligands containing new chemical scaffolds.
We present AVOD, an Aggregate View Object Detection network for autonomous driving scenarios using LIDAR point clouds and RGB images.
It has been shown repeatedly that iterative relevance feedback is a very efficient solution for content-based image retrieval. However, no existing system scales gracefully to hundreds of thousands of images.
We postulate that the objective function optimized by RNN language models, which amounts to the overall perplexity of a text, is not expressive enough to capture the notion of communicative goals described by linguistic principles such as Grice's Maxims.
We propose a method to decompose a single image into multiple layers that approximates effects such as shadow, diffuse illumination, albedo, and specular shading, and use them for photo retouching.
We present SEGCloud, an end-to-end framework to obtain 3D point-level segmentation that combines the advantages of NNs, trilinear interpolation(TI) and fully connected Conditional Random Fields (FC-CRF)
We propose a new middle-level representation called dynamic pose that couples the local motion information directly and independently with human skeletal pose, and present an appropriate distance function on the dynamic poses.
We systematically analyzed all the proteins encoded by SARS-CoV-2 genes, compared them with proteins from other coronaviruses, predicted their structures, and built 19 structures that could be done by homology modeling.
We propose an approach to learn relations that couples class embeddings with their corresponding attributes. Given only the name of an unseen class, the relationship model is used to automatically predict the classattribute associations.
This chapter tries to cast the Combinatorial Optimization methods into the Artificial Intelligence framework, particularly with respect Decision Tree Induction, which is considered a powerful instrument for knowledge extraction and the decision making support.
We introduce QApedia, a question-answering system for (web-based) content repositories with an on-line mechanism for user feedback and a dynamic framework for continuous learning.
This paper proposes a pooling strategy for local descriptors to produce a vector representation that is orientation-invariant yet implicitly incorporates the relative angles between features measured by their dominant orientation.
We describe SICK-BR, a Brazilian Portuguese corpus annotated with inference relations and semantic relatedness between pairs of sentences, which preserves its original inference and relatedness relation labels.
We propose Tomato, a framework designed to automate the process of generating efficient CNN accelerators for FPGA-based networks.
Convolutional Neural Networks could encode and decode face images as points in a shape-appearance parameter space, in agreement with the recent discovery in primate IT face neurons.
We analyze the bias extent in the SNLI and the MultiNLI datasets, discuss its implication, and propose a simple method to reduce the biases in the datasets.
Learning the spatial-temporal representation of motion information is crucial to human action recognition. To address this problem, this paper proposes a long-term motion descriptor called sequential deep trajectory descriptor (sDTD), a CNN-RNN network is employed to learn an effective representation for long-Term motion.
Combining Siamese networks and RNNs to exploit temporally varying appearance and motion information for real time multi-object tracking.
Proof of work (PoW), the most popular consensus mechanism for Blockchain, requires ridiculously large amounts of energy but without any useful outcome beyond determining accounting rights among miners. To tackle the drawback of PoW, we propose a novel energy-recycling consensus algorithm, namely proof of federated learning (PoFL), where the energy originally wasted to solve difficult but meaningless puzzles in PoW is reinvested to Federated learning.
This paper proposes a recurrently controlled recurrent network (RCRN) for expressive and powerful sequence encoding.
CASIA-SURF is a large-scale multi-modal dataset for face anti-spoofing in terms of both subjects and visual modalities.
We present a method for storing multiple models within a single set of parameters within the superposition of parameters.
Memory is increasingly often the bottleneck when training neural network models. Using appropriate combinations of these techniques, we show that it is possible to reduce the memory required to train a WideResNet-28-2 on CIFAR-10 by up to 60.7x with a 0.4% loss in accuracy.
The expert based question and answering forums are crowdsourced and rely on people to provide answers for questions. This paper focuses on technology based Q&A systems like StackOverflow and Reddit.
We propose two approaches for generating a backdoor that is hardly perceptible yet effective in poisoning the model. We carry out extensive experimental evaluations under various assumptions.
We propose an adaptive pooling approach based on the concepts of information entropy to test the effect of whitening on pooling in convolutional autoencoders.
We establish a natural product, koningic acid (KA), to be a selective inhibitor of GAPDH, an enzyme we characterize to have differential control properties over metabolism during the WE, leading to a therapeutic window in vivo.
We propose an attribute-based three stage face synthesis method based on a combination of deep Conditional Variational Autoencoder (CVAE) and Generative Adversarial Networks.
Variational Autoencoders learn a latent representation of image data that allows natural image generation and manipulation. To address this problem, we propose a hierarchy of VAEs analogous to a Laplacian pyramid.
We present a novel algorithm for illumination normalization of color face images that takes into account both Lambertian and specular reflections as well as attached and cast shadows.
We propose a new Spherical CNNS, with the concept of the rotation-equivariant spherical correlation, aiming to achieve rotation invariance.
We provide a comprehensive survey on deep FER, including datasets and algorithms that provide insights into these intrinsic problems. We then extend our survey to additional related issues and application scenarios.
In visual place recognition (VPR), map segmentation (MS) is a preprocessing technique used to partition a given view-sequence map into place classes so that each class has good place-specific training images for a visual place classifier.
We present a lightweight adaptable neural TTS system with high quality output that can adapt to unseen voices.
We propose an adversarial GAN-based framework that learns video representations and dynamics through a self-supervision mechanism in order to perform dense and global prediction in videos.
In this paper we deal with the offline handwriting text recognition (HTR) problem with reduced training datasets. Our proposal is based on the transfer learning (TL) from the parameters learned with a bigger database.
This paper investigates the effect of using Lower Central Periocular Region for identification.
This paper presents a novel fixation prediction and saliency modeling framework based on inter-image similarities and ensemble of Extreme Learning Machines (ELM)
We propose a real-time fusion semantic segmentation network termed RFNet that efficiently exploits complementary features from depth information to enhance the performance in an attention-augmented way, while running swiftly that is a necessity for autonomous vehicles applications.
We propose a novel method that allows two networks to learn from each others’ adversarial examples and become resilient to black-box attacks.
We present a new AI task - Embodied Question Answering (EmbodiedQA) - where an agent is spawned at a random location in a 3D environment and asked a question ('What color is the car?'). In order to answer, the agent must first intelligently navigate to explore the environment, gather necessary visual information through first-person (egocentric) vision, and then answer the question ('orange').
We propose a novel curriculum learning approach for image classification that adapts the loss function by changing the label representation, where the class probabilities reflect the similarity to the true label.
In this paper, we propose a novel framework for joint video semantic segmentation and optical flow estimation, which improves existing methods under the same settings in both settings.
A model compression algorithm utilizing reinforcement learning with architecture search and knowledge distillation can answer these questions in the affirmative.
We used small RNA sequencing and systematic bioinformatic analysis to characterize the regulatory networks of differentially expressed miRNAs after the p53 activation in hepatocellular carcinoma.
We propose a method to reduce the communication overhead of distributed deep learning that achieves very high compression ratio while maintaining the result model accuracy.
We investigate the potential of phase locking analysis, a technique to study the synchrony patterns, in the transcription network modeling of time course gene expression data, and propose a new phase locking metric for network reconstruction.
We have developed a novel deep learning method for segmentation and centerline extraction of retinal blood vessels from fundus image data using the Capsule network in combination with the Inception architecture.
We propose an encoder-decoder network with shared encoder and two separate decoders to fully exploit the edge and semantic information of a room image for layout estimation.
In this paper, we propose a collaborative filtering method designed to improve the current memory-based prediction times without worsening and even improving the existing accuracy results.
In this paper, motivated by the observation that negative triplets with large scores are important but rare, we propose to directly keep track of them with cache. In this way, our method acts as a "distilled" version of previous GAN-based methods, which does not waste training time on additional parameters to fit the full distribution ofnegative triplets.
We strive to reduce the energy cost during training, by dropping unnecessary computations, from three complementary levels: stochastic mini-batch dropping on the data level; selective layer update on the model level; and sign prediction for low-cost, low-precision back-propagation, on the algorithm level.
We propose the first Multi-target Adversarial Network (MAN), which can generate multi-target adversarial samples with a single model and can attack any category of the target classification model during runtime.
We present a neural network that predicts HDR outdoor illumination from a single LDR panorama under any weather condition.
We propose discriminative pooling, based on the notion that among the deep features generated on all short clips, there is at least one that characterizes the action. Our pooling scheme is end-to-end trainable within a deep learning framework.
We propose TVNet, a novel end-to-end trainable neural network, to learn optical-flow-like features from data.
This paper is the first work to perform spatio-temporal mapping of human activity using the visual content of geo-tagged videos.
In this work, a novel high-speed single object tracker that is robust against non-semantic distractor exemplars is introduced; BOBBY2.
We investigate the impact of psychopathic traits on cooperation in an iterated Prisoner's Dilemma game with emotional facial feedback, and how being informed about the opponent’s identity influenced cooperative behaviour.
We propose a novel learning framework called convolutional prototype learning (CPL), a generative model based on the Gaussian assumption of different classes, which improves the robustness.
Automatic localization of 3D facial features is important for face recognition, tracking, modeling and expression analysis.
Learning Efficient H-CNN Regressors (KEPLER) for Keypoint Estimation and Pose Prediction of unconstrainedfaces.
In this paper, we propose a binarized neural network learning method called BiDet for efficient object detection.
In object detection, offset-guided and point-guided regression dominate anchor-based and anchor-free method separately. However, we observe points predicted by this way are misaligned with matched region of proposals and score of localization, causing a notable gap in performance. In this paper, we propose CPM R-CNN which contains three efficient modules to optimize Anchor-based Point-guided method.
We introduce an online multitask objective into unsupervised learning of behavioral interactions and show that sentence embeddings generated through this process increases performance of affective tasks.
We extend the Blum and Chawla graph min-cut algorithm to structured problems, achieving up to 34.8% relative error reduction.
Object Permanence allows people to reason about the location of non-visible objects, by understanding that they continue to exist even when not perceived.
A non-uniqueness problem exists in the DCNN-based modelling of image object representations in primate inferotemporal cortex.
We propose a conceptually simple framework that uses an experience memory to help exploration by prioritizing the starting states from which the agent starts acting in the environment in a fashion that is also compatible with on-policy algorithms.
We introduce a novel extrinsic self-calibration algorithm, which is fully automatic and completely data-driven and is able to extrinsically calibrate Mobile Mapping Systems with different combinations of mapping and pose estimation sensors.
We proposed a triplet deep hashing method with joint supervised loss based on the convolutional neural network for fast retrieval of large-scale data.
We present a new network architecture which focuses on utilizing the front view images and frustum point clouds to generate 3D detection results.
We propose a bidirectional semantic attention-based guiding of long short-term memory model for image captioning.
Attributes possess appealing properties and benefit many computer vision problems, such as object recognition, learning with humans in the loop, and image retrieval. However, attribute detectors should generalize well across different categories, including those previously unseen.
We frame Question Answering (QA) as a Reinforcement Learning task, and propose an agent that learns to reformulate questions to elicit the best possible answers.
In this paper, we introduce a long-short term motion feature that generates descriptors from video blocks with multiple lengths, thus covering motions with large speed variance.
We introduce a hybrid distributed cloud framework with a unified view to multiple clouds and an on-premise infrastructure for processing tasks using both CPU and GPU compute instances at scale.
Our proposed methods exploit variational adversarial active learning (VAAL), that considered data distribution of both label and unlabeled pools, by incorporating learning loss prediction module and RankCGAN concept into VAAL.
In recent years, retinal vessel segmentation technology has become a challenging task due to complex distribution of blood vessels, relatively low contrast between target and background, and potential presence of illumination and pathologies. In this paper, we propose an automatic retinal vessels segmentation network using deep supervision and smoothness regularization.
This work presents CascadeCNN, an automated toolflow that pushes the quantisation limits of any given CNN model, to perform high-throughput inference by exploiting the computation time-accuracy trade-off.
A strategy for the rehabilitation of cisapride, a gastroprokinetic agent withdrawn from the market due to its high hERG1 blocking affinity, using molecular docking and Molecular Dynamics simulations.
We propose a novel recurrent neural network to reconstruct videos from a stream of events and train it on a large amount of simulated event data.
We introduce Neural Data Server (NDS), a large-scale search engine for finding the most useful transfer learning data to the target domain.
We present a combination of techniques that harness external knowledge to improve performance on the NLI problem in the science questions domain.
A simple yet effective Context Embedding with Edge Perceiving (CE2P) framework for single human parsing.
We introduce a novel approach named Highly-economized Scalable Scalable Image Clustering (HSIC) that radically surpasses conventional image clustering methods via binary compression.
We use level set propagation with local phase information to capture the boundaries of vessels and drive a contour robustly towards the vessel edges.
We propose a joint source and channel coding (JSCC) technique for wireless image transmission that does not rely on explicit codes for either compression or error correction.
We present a novel image reconstruction method, in which the pixel values of an image are optimized to make its DNN features similar to those decoded from human brain activity at multiple layers.
An end-to-end convolutional neural network trained for saliency prediction.
We divide semantic image segmentation methods based on Deep Neural Network into two categories: traditional and recent DNN method.
In this paper, we develop relational neural networks (RelNNs) by adding hidden layers to relational logistic regression, which learn latent properties for objects both directly and through general rules.
This paper presents a model-free, setting-independent method for online detection of dynamic objects in 3D lidar data using a motion-compensated freespace querying algorithm and compensation for pointcloud motion distortion.
In this paper, we introduce dilated convolution and occlusion reasoning into unsupervised optical flow estimation to address these issues.
We propose a retrieval-augmented convolutional network and propose to train it with local mixup, a novel variant of the recently proposed mixup algorithm that addresses the adverse effect of off-manifold adversarial examples.
We propose a general loss function that can handle several different DA scenarios without any extra modifications, outperforming state-of-the-art methods in all of the existing scenarios.
We show that we can obtain bounding box annotation from weakly-supervised single-point clicks through interactive segmentation through time-ordered online training.
We evaluate the robustness of state-of-the-art neural acoustic emotion recognition models in human-robot interaction scenarios in noisy conditions.
Stat3 blunts rather than supports antitumor immunity in carcinogen-induced lung tumorigenesis in epithelium-specific knockout mice (Stat3(Δ/Δ))
The goal of our work is to complete the depth channel of an RGB-D image. To address this problem, we train a deep network that predicts dense surface normals and occlusion boundaries.
We propose a new deep learning based method for monocular 3D human pose estimation that shows high accuracy and generalizes better to in-the-wild scenes.
This paper proposes an Efficient Channel Attention (ECA) module, which only involves a handful of parameters while bringing clear performance gain.
As a lightweight deep neural network, MobileNet has fewer parameters and higher classification accuracy. In order to further reduce the number of network parameters and improve the classification accuracy, dense blocks that are proposed in DenseNets are introduced.
In this paper, we propose an I ncremental S elf- L abeling strategy for SSL based on G enerative A dversarial N ets (ISL-GAN), which functions by constantly assigning unlabeled data with virtual labels for promoting the training process.
We propose a conditional transfer network (cTransNet) that conditionally implement viewpoint transfer, which transfers person image to the viewpoint with the biggest domain gap before matching.
We propose a framework called TripleNet to deeply boost these two tasks at different scales and refine their features.
We propose a multi-bias non-linear activation (MBA) layer to explore the information hidden in the magnitudes of responses, thus generating more patterns in the feature space at a low computational cost.
Knowledge graph (KG) completion using recurrent neutral network to model triples in a KG as sequences.
Res-SE-Net is proposed to further strengthen the contribution from the bridge-connections by quantifying the importance of each feature map and weighting them accordingly.
We propose a novel Spatial-transformed Regional Quality Estimation Network (SRQEN) for video-based person re-identification. The proposed method can learn complementary region-based information between different frames in a sequence to compensate for the influence of an image region with poor quality.
We learn how to transform filters for use in the group convolution, focussing on roto-translation.
In this paper, we propose an automatically Gaussian weighted deep model to achieve improved solutions for the problem of monocular depth estimation.
Robust Learning Method for Semantic Segmentation in Adversary Weather Conditions .
Our goal is to learn control policies for robots that provably generalize well to novel environments given a dataset of example environments.
We propose a new benchmark to experimentally investigate the scalability and limitations of behavior cloning, including in unseen environments, executing complex lateral and longitudinal maneuvers without these reactions being explicitly programmed.
This paper presents a novel approach for predicting contours which advances the state of the art in two fundamental aspects, i.e. multi-scale feature generation and fusion.
We tested computational models of representations in ventral-stream visual areas. Early visual areas were best explained by shallow – and higher by deep – models. Unsupervised shallow models performed better without linear remixing of their features.
An improved method for estimating the distance of a monocular vision vehicle based on the detection and segmentation of the target vehicle is proposed to address the vehicle attitude angle problem.
We propose a new supervised nonlinear multi-view laplacian eigenmaps (MvLE) approach and a multi-hidden-layer out-of-sample network (MHON) that make full use of RGB view and Depth view of the two datasets.
We show that using DBN-based active learning strategies make it possible to selectively annotate data, thereby reducing the required amount of labeled training in surgical workflow-related tasks.
In this paper we propose a new mixture model that associates a weight with each observed point. We introduce the weighted-data Gaussian mixture and derive two EM algorithms.
We introduce RNNPool, a novel pooling operator based on Recurrent Neural Networks (RNNs), that efficiently aggregate features over large patches of an image and rapidly downsamples its size.
We build on recent SRL models to address textual relational problems, showing that they are more expressive, and can alleviate issues from simpler compositions.
We propose a progressive algorithm for differentiable architecture search, which can transfer across different types of tasks.
This paper proposes a new model for extracting an interpretable sentence embedding by introducing self-attention, with each row of the matrix attending on different part of the sentence.
We propose a convex radius-margin-based SVM model for joint learning of feature transformation and the SVM classifier, i.e., F-SVM.
We show that explanations can be manipulated arbitrarily by applying visually hardly perceptible perturbations to the input that keep the network's output approximately constant.
Improving weight sparsity is a common strategy for producing light-weight deep neural networks. However, pruning models with residual learning is more challenging. In this paper, we introduce Variance-Aware Cross-Layer, a novel approach to address this problem.
We introduce a new normalization technique that exhibits the fast convergence properties of batch normalization using a transformation of layer weights instead of layer outputs.
We prove a generalization bound dominated by a ratio of the margin standard deviation to the margin mean, where the huge magnitude of spectral norms is reduced.
We propose a novel, two-stage pipeline for generating synthetic medical images from a pair of generative adversarial networks, tested in practice on retinal fundi images.
In this paper, we propose a novel disentanglement approach to invariant representation problem by enforcing orthogonality constraints as a proxy for independence.
We propose a probabilistic domain division algorithm of learning to split the testing instances into known, unknown and uncertain domains, and then conduct recognize tasks in each domain.
We propose a data-driven approach for recognizing fashion attributes using Faster R-CNN model.
We propose a transform-based framework for anomaly detection and it significantly outperforms state-of-the-arts.
We propose an adversarial feature learning strategy that improves the generalization capability of a few-shot learning model.
We present an alternative approach which can complement the disparity energy model, based on the multiscale coding of lines and edges, and use it to create a 3D wireframe representation.
This paper proposes an end-to-end object relation module for CNN based detection. It processes a set of objects simultaneously through interaction between their appearance feature and geometry, thus allowing modeling of their relations.
Automatic image description systems typically produce generic sentences that only make use of a small subset of the vocabulary available to them. In this paper, we use established metrics and two new metrics that frame image description as a word recall task.
We propose a multiple-partial-hypothesis-based framework for the problem of estimating a 3D human pose from a single image, which can be fine-tuned in an end-to-end fashion.
We extend the existing approaches to generate grid saliencies, which provide spatially coherent visual explanations for (pixel-level) dense prediction networks.
We introduce a Causal And-Or Graph (C-AOG) to represent the causal-effect relations between an object's visibility fluent and its activities, and develop a probabilistic graph model to jointly reason the visibility fluent change (e.g., from visible to invisible) and track humans in videos.
Spatio-temporal action detection in videos requires localizing the action both spatially and temporally in the form of an"action tube".
We explore an asymmetric encoder-decoder structure for unsupervised context-based sentence representation learning that is simple and fast while also achieving better performance.
Federated Learning enables visual models to be trained in a privacy-preserving way using real-world data from mobile devices. Given their distributed nature, the statistics of the data across these devices is likely to differ significantly. In this work, we look at the effect such non-identical data distributions has on visual classification via Federated Learning.
We propose a meta-modeling approach to support automated hyper parameter optimization, with the goal of providing practical tools to replace hand-tuning with a reproducible and unbiased optimization process.
We train a convolutional neural network in an adversarial way, exploiting a pixel-wise disharmony discriminator to achieve more realistic harmonized results and introducing a temporal loss to increase temporal consistency.
In this paper, we present a novel ranking-selection framework for low-length but highly correlated instances.
We propose the Attention-based Temporal Weighted CNN (ATW), which embeds a visual attention model into a temporal weighted multi-stream CNN.
A near real-time multiscale search on a deep CNN feature map that exploits local semantic information preserved in the outermost convolutional layer.
We propose Multi-Net, a fast and scalable embedding technique for multiplex networks, which captures detailed representations of complex networks.
We address the problem of recognizing the genre (subject) in digitized paintings using Convolutional Neural Networks (CNN) as part of the more general dealing with abstract and/or artistic representation of scenes.
We propose a general CSC model capable of dealing with complicated unknown noise. We use the expectation-maximization algorithm to solve the problem.
We propose a retriever-reader model that learns to attend on essential terms during the question answering process in an open-domain QA task.
We propose an effective method to tackle the problem for person re-identification in camera sensor networks that learns contextual information in a local manner.
We describe a clustering approach with the emphasis on detecting coherent structures in a complex dataset, and illustrate its effectiveness with computer vision applications.
In this paper, a direct computational method is presented which combines optical flow and structure from motion (SfM) by putting the SfM problem in the framework of optical flow estimation, achieving state-of-the-art performance in optical flow.
We propose a novel gradient called P2SGrad (Probability-to-Similarity Gradient), which leverages a cosine similarity instead of classification probability to control the gradients for updating neural network parameters.
We propose a supervised non-parametric Generalized Linear Model for continuous-time relationship prediction in dynamic and heterogeneous information networks.
We propose a process that enforces pair-wise domain invariance while training a feature extractor over a diverse set of domains, and introduce an adversarial approach to the problem.
A meta-learning framework to facilitate user-level adaptive model selection in recommender systems.
This paper introduces the largest and most diverse collection of rectified stereo image pairs to the research community, consisting of tens of thousands of stereographs of historical people, events, objects, and scenes between 1860 and 1963.
We propose an end-to-end trainable network architecture with motion and content separation to model the spatiotemporal dynamics for pixel-level future prediction in natural videos.
In this paper, transfer learning is applied on multi-labeling convolutional neural network architectures for object localization and recognition in monocular visual, infrared and multispectral dynamic images.
We define a probabilistic similarity model of all the items based on Random Fields and introduce a recurrent neural network based recommender based on the generative model.
This paper presents a novel classifier based on collaborative representation (CR) and multiple one-dimensional (1D) embedding for face recognition.
In this paper, we propose a structured image inpainting method employing an energy-based structured prediction method.
We have incorporated an unsupervised style extraction module into a model to learn outfits while controlling its styles.
In this paper, we propose a novel visual tracking algorithm, namely VDCFNet, and combine DCF with a vector convolutional network (VCNN).
In this paper, we explore three alternative methods to approximate gradients, with an efficient GPU kernel implementation for one of them.
We present a competitive approach for 3D data classification that is related to Implicit Shape Models and Naive-Bayes Nearest Neighbor algorithms with the goal to eliminate redundant and ambiguous feature descriptors.
In this paper, we propose TensorClog—a poisoning attack technique that is designed for privacy protection against neural networks.
We consider the compilation of a binary neural network's decision function into tractable representations such as Ordered Binary Decision Diagrams (OBDDs) and Sentential Decision Diiamonds (SDDs) and propose a more efficient approach for compiling neural networks, based on pseudo-polynomial time algorithm for compiling a neuron.
We investigate four types of soft assignment of visual words to image features. We demonstrate that explicitly modeling visual word assignment ambiguity improves classification performance.
We introduce the concept of dynamic image, a novel compact representation of videos useful for video analysis especially when convolutional neural networks (CNNs) are used.
We propose a novel pose invariant deep metric learning method under an improved triplet loss for person re-ID.
In this work, we propose to jointly learn the encoding and decoding processes using a new discrete variational autoencoder model. We obtain codes that are competitive against several separation schemes.
We propose an orthogonal method, called memory regularization in vivo to exploit the intra-domain knowledge and regularize the model training.
We show that human annotation tends to be non-smooth and is prone to partial visibility and deformation. We propose a smoothing trajectory strategy with ability to handle moving scenes.
We propose attentive group equivariant convolutions, a generalization of the group convolution, in which attention is applied during the course of convolution to accentuate meaningful symmetry combinations and suppress non-plausible, misleading ones.
We propose a function-based temporal pooling method that captures the latent structure of the video sequence data - e.g., how frame-level features evolve over time in a video.
We expose the weakness of today's one-trick pony and demonstrate that training general models equipped to handle arbitrary levels of corruption is indeed non-trivial. Then, we propose an on-demand learning algorithm for training image restoration models that generalize across difficulty levels.
We extend the Gauss–Newton framework for AAMs and derive a second order method that can be used for generative models of shape and appearance in the wild.
We enhance the scene graph representation with heuristic-based relations and use extreme points representation to supervise the learning of the scene composition network.
We propose Object-driven Attentive Generative Adversarial Newtorks (Obj-GANs) that allow object-centered text-to-image synthesis for complex scenes in high quality.
We motivate and present feature selective anchor-free (FSAF) module, a simple and effective building block for single-shot object detectors.
Domain adaptation aims to leverage knowledge from a well-labeled source domain to a poorly labeled target domain. We propose a novel approach to jointly exploit feature adaptation with distribution matching and sample adaptation with landmark selection.
The nearest neighbor search algorithm can be interrupted if some criteria are satisfied. Three different heuristics are studied towards enhancing the nearest neighbor algorithm with an early-break capability.
The $k$-means clustering algorithm is popular but has the following main drawbacks: 1) the number of clusters, $k$, needs to be provided by the user in advance, 2) it can easily reach local minima with randomly selected initial centers, 3) it is sensitive to outliers, and 4) it only deals with well separated hyperspherical clusters.
We propose an approach for semantifying web extracted facts. In this paper, we focus on the mapping of the relational phrases in the context of the overall work ow.
This paper presents a photometric stereo network that directly learns relationships between the Photometric stereo input and surface normals of a scene, especially when scenes are highly non-convex.
We propose a simple domain adaptation method for recurrent neural networks trained with a cross-entropy loss in a supervised setting.
We propose an asymmetric binary code learning framework based on inner product fitting to exclusively handle the MIPS problem.
A deep multi-facial patches aggregation network for Face Expression Recognition (FER).
This paper proposes a Copy and Paste Generative Adversarial Network (CPGAN) to recover authentic high-resolution (HR) face images while compensating for low and non-uniform illumination.
We propose a unified framework for multi-person pose estimation and tracking. We extend spatial grouping of keypoints to temporal grouping of human instances.
We propose to distill the internal representations of a large model such as BERT into a simplified version of it.
We propose a new approach for tracking the importance of a given input to the LSTM for a given output.
We propose hybrid semi-Markov conditional random fields for neural sequence labeling in natural language processing.
We set up classic and learning-based navigation systems in common simulated environments and thoroughly evaluate them in indoor spaces of varying complexity, with different sensory modalities.
We show that removing regularization after an initial transient period has little effect on generalization, even if the final loss landscape is the same.
We propose an architecture based on graph networks that jointly optimizes feature extraction, graph connectivity, and feature propagation and aggregation to unlabeled data in an end-to-end manner for state-of-the-art performance.
We propose SlimYOLOv3 with fewer trainable parameters and floating point operations for real-time object detection on UAVs.
In this work, we present a new network design paradigm that parametrizes populations of networks that work well across a wide range of settings.
We propose our Pointing and Justification (PJ-X) model which can justify its decision with sentence and point to the evidence by introspecting its decision and explanation process using an attention mechanism.
We introduce TensorPipe, a pipeline parallelism library that allows scaling any network that can be expressed as a sequence of layers.
We propose a generative model to synthesize face photo from simple line drawing controlled by face attributes such as hair color and complexion.
We perform an extensive survey of decoding-time strategies for generating diverse outputs from conditional language models and show how diversity can be improved without sacrificing quality.
We propose a deep progressive quantization (DPQ) model for large scale image retrieval. DPQ learns the quantization codes sequentially and approximates the original feature space progressively.
We present a Parallel Iterative Edit (PIE) model for the problem of local sequence transduction arising in tasks like Grammatical error correction (GEC)
We find that simpler classifiers, formed by reducing the number of output classes, are less susceptible to adversarial perturbations of the input.
We propose a novel 3D map from lidar data and images, based on a 3D mesh, and refine it photometrically.
We describe methods to construct contextual acoustic word embeddings directly from a supervised acoustic-to-word speech recognition model using the learned attention distribution. On a suite of 16 standard sentence evaluation tasks, we show competitive performance against a word2vec model trained on the speech transcriptions.
We provide a novel method for sample frame construction that identifies residential gridded aerial units, thus reducing manual labor and eliminating the need for simplifying assumptions.
We propose a fully connected CRF auto-encoder incorporating the rich object features and a novel human-object interaction representation for co-segmentation.
We introduce canonical correlation forests (CCFs), a new decision tree ensemble method for classification and regression, delivering both improved predictive accuracy and faster training times.
Neural Tangents is a library for working with infinite-width neural networks. It provides a high-level API for specifying complex and hierarchical neural network architectures.
We implement a Transformer-based model for Video captioning, utilizing 3D CNN architectures like C3D and Two-stream I3D for video extraction.
We have developed a set of inexpensive paper cards, called Paper Analytical Devices (PADs), which can efficiently classify drugs based on their chemical composition, as a potential solution to the problem.
We address a problem of estimating pose of a person’s head from its RGB image. The employment of CNNs for the problem has contributed to significant improvement in accuracy in recent works.
 SPLITFACE, a deep convolutional neural network-based method that is explicitly designed to perform attribute detection in partially occluded faces.
We propose STAR, a novel approach to perform follow-up query analysis, aiming to restate context-dependent natural language queries with contextual information.
We propose a general framework, called hierarchical surface prediction (HSP), which facilitates prediction of high resolution voxel grids.
This paper introduces channel gating, a dynamic, fine-grained, and hardware－efficient pruning scheme to reduce the computation cost for convolutional neural networks.
In this paper, we propose a novel maximum causal Tsallis entropy (MCTE) framework for imitation learning which can efficiently learn a sparse multi-modal policy distribution from demonstrations.
We present an efficient approach for image retrieval from millions of images based on user-drawn sketches using similarity-invariant variable length descriptors.
We propose a self-supervised learning framework for 3D pose disentanglement from unlabeled video frames and demonstrate state-of-the-art performance on both Human3.6M and MPI-INF-3DHP.
Autoencoder networks are unsupervised approaches aiming at combining generative and representational properties by learning simultaneously an encoder-generator map. We introduce an autoencoders that tackle these issues jointly.
We propose Geo-CNN, a generic convolution-like operation dubbed as GeoConv to capture geometric relationships among points in a local region and its local neighborhood for 3D point cloud analysis.
This paper presents a Bayesian approach to resolving the configuration of vascular junctions to correctly construct the vascular trees.
Spatio-temporal interest points serve as an elementary building block in many modern action recognition algorithms, and most of them exploit the local spatio-Temporal volume features using a Bag of Visual Words representation.
We present a novel approach to solve the problem of reconstructing perceived stimuli from brain responses by combining probabilistic inference with deep learning.
We present an unconstrained face verification algorithm that uses a low-dimensional discriminative embedding learnt using triplet similarity constraints in a large margin fashion.
We use physical interactions with the world to learn visual representations unlike current vision systems.
We optimize caching policy with the knowledge of user preference and active level to maximize the offloading probability, and develop a low-complexity algorithm.
We propose a lightweight architecture named Context-Integrated and Feature-Refined Network (CIFReNet) for lightweight urban scene parsing.
Rest tremor is one of the cardinal signs of Parkinson's disease. As disease progresses, both raphe serotonergic dysfunction and putamen dopamine depletion could contribute to the occurrence of rest tremor.
We investigate different data augmentation techniques that can be used to generate sufficient data for training CNN-based facial landmark localisation systems.
This paper proposes an exploration method for deep reinforcement learning based on parameter space noise based on directional exploration in parameter space with regard to obtained rewards.
We introduce QT-Opt, a scalable self-supervised vision-based reinforcement learning framework that can leverage over 580k real-world grasp attempts to train a deep neural network Q-function that generalizes to 96% grasp success on unseen objects.
We use a large dataset of geo-tagged photos and user temporal-location-familiarity to highlight unique characteristics photos capture of location, which vary significantly if taken by locals versus tourists.
We propose a new methodology for facial landmark detection using a cascade of regressors and multiple initialisations, which improve robustness to poor initialisations.
This paper describes LIMSI’s submission to the CoNLL 2017 UD Shared Task, which is focused on small treebanks, and how to improve low-resourced parsing only by ad hoc combination of multiple views and resources.
Neural Module Networks, originally proposed for the task of visual question answering, are a class of neural network architectures that involve human-specified neural modules, each designed for a specific form of reasoning. In current formulations of such networks only the parameters of the neural modules and/or the order of their execution is learned.
In this paper, we investigate a novel deep-model reusing task. Our goal is to train a lightweight and versatile student model, without human-labelled annotations, that amalgamates the knowledge and masters the expertise of two pretrained teacher models working on heterogeneous problems.
In this paper, we propose a new depth super-resolution and completion method implemented in a deep learning framework and build a high-quality 3D reconstruction system.
We propose an extensible deep learning method that uses reinforcement learning to train neural networks for offline ranking in information retrieval (IR) by directly optimizing a task-specific measure using gradient descent.
IQGAP proteins are not functional interactors of H-, K-, or N-Ras and challenge the rationale for targeting the interaction of Ras for the development of therapeutic agents.
We propose a multi-level CF-based tracking approach named MLCFT which further explores the potential capacity of CF with two-stage detection: primal detection and oriented re-detection.
We propose an end-to-end DCNN called the multi-component fusion network (MCFN) to improve the accuracy of small object detection in such cases.
This paper proposes a scheme combined transfer learning and sample expansion in feature space to enrich intra-class variation information for a single-sample face feature.
We propose a system called DriCare, which detects the drivers’ fatigue status, such as yawning, blinking, and duration of eye closure, using video images, without equipping their bodies with devices.
OpenFace is the first open source tool capable of facial landmark detection, head pose estimation, facial action unit recognition, and eye-gaze estimation.
We investigate the performance impact of additional prediction targets, using a variety of suitable convolutional neural network architectures, on polyphonic piano transcription.
In this paper, we propose an internal transfer learning strategy adapted to this framework, by incorporating the sub-data classification method into transfer learning.
This paper presents Generative Adversarial Talking Head (GATH), a novel deep generative neural network that enables fully automatic facial expression synthesis of an arbitrary portrait with continuous action unit (AU) coefficients.
In this paper we present architectures based on deep neural nets for gesture recognition in videos, which are invariant to local scaling.
Paraphrasing is rooted in semantics. Transformers are fast and effective, and semantic augmentation for both transformers and LSTMs leads to sizable 2-3 point gains in BLEU, METEOR and TER.
The purpose of this work is to show how the correct scale factor can be estimated in planar motion cases by exploiting range measurements from a single station. The proposed method is independent of VSLAM algorithm used for ego-motion estimation of the vehicle.
This paper develops and evaluates a novel method that allows for the detection of affordances in a scalable and multiple-instance manner on visually recovered pointclouds.
We propose a light-weight video frame interpolation algorithm using flow-based warping and instance-level supervision that can generate state-of-the-art results across different datasets.
We propose learning to impute the labels of unlabeled samples such that a network achieves better generalization when it is trained on these labels.
This paper investigates the factors which affect clustering performance from both clustering accuracy and stability of the approaches based on existing algorithms.
We develop an automated pipeline capable of transporting texture information from images of real objects to 3D models of similar objects, providing high quality virtual objects for 3D scene design or photo editing applications.
We design a theorem prover for Natural Logic, a logic whose terms resemble natural language expressions.
We propose a method for recognizing objects in artistic modalities (such as paintings, cartoons, or sketches), without requiring any labeled data.
We present a fast and reliable method based on PCA to select the number of dimensions for word embeddings while retaining optimal performance.
We introduce Language-Model-based Commonsense Reasoning (LMCR), a new method which enables a robot to listen to a natural language instruction from a human, observe the environment around it, and automatically fill in information missing from the instruction using environmental context and a new commonsense reasoning approach.
We present a collaborative computational model for active learning with multiple human oracles that captures the inherent correlations among the labelers through shared data among them.
We propose a generative model, UP-GAN, that provides effective face obscuration, while preserving utility.
This paper presents a method for learning a feature representation that is invariant to pose without requiring extensive pose coverage in training data.
We propose an approach for dealing with simulation to real world model discrepancy in reinforcement learning, where the sequence of states traversed in simulation remains reasonable for the real world, even if the details of the controls are not.
User-generated content presents many challenges for its automatic processing. In this work we present a French three-domain data set made up of question headlines from a cooking forum, game chat logs and associated forums from two popular online games.
We propose hierarchical feature hashing to effectively reduce dimensionality of parameter space without sacrificing classification accuracy, and at the same time exploit information in semantic taxonomy among categories.
Based on the importance of relative disparity between objects for accurate hand-eye coordination, this paper presents a biological approach inspired by the cortical neural architecture.
This paper presents an image segmentation strategy using histograms of oriented gradients (HOG), color features and Louvain method, a community detection on graphs algorithm, to tackle theImage segmentation problem.
We extend the clustering-based image segmentation approach into a temporal one, where hierarchical supervoxel levels for action segmentation are generated accordingly. We propose a streaming approach to flatten the hierarchical levels into one based on uniform entropy slice, in order to preserve important information in the video.
This review presents an overview of the applications of deep learning inophthalmic diagnosis using retinal images and a review of the available retinalimage datasets.
In this paper, based on attention mechanism and convolutional long short-term memory (ConvLSTM), we propose a temporal single shot detector (TSSD) for real-world detection.
This paper proposes a novel approach called Semantic Visual Odometry (SemVO) which incorporates class-level consistency priors into the problem of 6-DoF Visual Odometric.
We propose robust methods for estimating camera egomotion in noisy, real-world monocular image sequences in the general case of unknown observer rotation and translation with two views and small baseline.
Face quality assessment aims at estimating the utility of a face image for the purpose of recognition. However, this could lead to a bias transfer towards the face quality assessment leading to discriminatory effects during enrolment.
In this paper, we propose to perform a revised LDA objective over deep networks to learn efficient hashing codes in a truly end-to-end fashion.
Batch Normalization (BN) has proven to be an effective algorithm for deep neural network training by normalizing the input to each neuron and reducing the internal covariate shift. Following the intrinsic geometry of this manifold provides a new learning rule that is faster and easier to analyze.
We propose a spectral regularization term to improve generative neural networks that can reproduce spectral distributions of natural training data correctly.
We propose a novel tracking architecture, consisting of dedicated target estimation and classification components. High level knowledge is incorporated into the target estimation through extensive offline learning.
We use some of the largest order statistics of the random projections of a reference signal to construct a binary embedding that is adapted to signals correlated with such signal.
A multi-scale deeply supervised network with short connections for vessel segmentation in fundus images.
We present a novel framework for hallucinating faces of unconstrained poses and with very low resolution (face size as small as 5pxIOD) in a unified framework.
We present Batch-Instance Normalization (BIN) to explicitly normalize unnecessary styles from images, improving the recognition performance in various scenarios.
We propose score-level and representation-level fusion models to incorporate VQA knowledge in an existing state-of-the-art VQa-agnostic image-caption ranking model.
We introduce sequential greedy architecture search (SGAS), an efficient method for neural architecture search. We apply SGAS to search architectures for CNN and Graph Convolutional Networks.
We propose to extend the training datasets of virtual humans to be used with machine learning techniques for pedestrian detection and counting.
We introduce a new model which uses stacked autoencoders to learn higher-level embeddings from textual and visual input.
In this paper, we present a novel approach of human activity prediction. The goal is to enable early recognition of unfinished activities as opposed to the after-the-fact classification of completed activities.
In this paper, we propose a novel uncertainty-aware model-based policy optimization framework which solves those issues.
We study the task of action recognition in surveillance video under a more realistic generalized zero-shot setting, where testing data contains both seen and unseen classes.
A Drosophila systems model of PTZ induced locomotor plasticity that is responsive to AEDs.
In this paper, we propose a novel method, SingleGAN, to perform multi-domain image-to-image translations with a single generator.
We propose a sample efficient reinforcement learning approach for adapting the loss dynamically during training. We empirically show how this formulation improves performance.
This paper presents a system for the offline recognition of large vocabulary unconstrained handwritten texts using statistical language models.
We extend the classical uncertainty measure and extend the page-rank algorithm for graph convolution networks, and we show that the latter is optimal when the fraction of tagged nodes is low, and the former is optimal.
We address the problem of mid-air finger writing using web-cam video as input. We propose a robust fingertip detection and tracking approach using a new signature function called distance-weighted curvature entropy.
We propose a novel network architecture of Resolution Adaptation and re-Identification Network (RAIN) to solve cross-resolution person re-ID.
In computer vision, one is often confronted with problems of domain shifts, which occur when one applies a classifier trained on a source dataset to target data sharing similar characteristics (e.g. same classes), but also different latent data structures. We explore a solution, named DeepJDOT, to tackle this problem: through a measure of discrepancy on joint deep representations/labels based on optimal transport, we not only learn new data representations aligned between
We propose a novel cascaded regression framework for face alignment based on a deep convolutional neural network (CNN), which demonstrates outstanding performance.
 GSANet improves the state-of-art semantic segmentation accuracy on both the ADE20k and the Cityscapes datasets.
This paper introduces DeepSover, a novel approach to constraint solving with deep learning for symbolic execution.
We apply ADMM (alternating direction method of multipliers) for solving the optimization problem of the fault sneaking attack with two constraints: 1) the classification of the other images should be unchanged and 2) the parameter modifications should be minimized.
I propose new architectures inspired by fuzzy logic that combine several alternative design elements. The new models are shown to be more local, better at rejecting noise samples, and more robust against adversarial examples.
We propose a new training strategy which achieves state-of-the-art results across three evaluation datasets while using \(20\times\) less annotated data than competing methods.
We present Poly-GAN, a novel conditional GAN architecture that is motivated by Fashion Synthesis, an application where garments are automatically placed on images of human models at an arbitrary pose, and perform image alignment, image stitching, and inpainting.
An intuition on human segmentation is that when a human is moving in a video, the video-context (e.g., appearance and motion clues) may potentially infer reasonable mask information for the whole human body .
We propose an approach to address the object recognition problem directly with raw temporal pulses utilizing the spiking neural network (SNN), while achieving remarkable time efficiency.
We present a new dataset for natural language inference, InferSent, that cannot be solved using only word-level knowledge and requires some compositionality.
A method is proposed for the representation of localised features using disjoint sub-images taken from several datasets of retinal images for use within an incremental learning system.
A sparse reconstruction-based discrimination method for contour detection in colour images.
We propose a PRiOr-enlightened and MOTION-robust video deblurring model (PROMOTION) suitable for challenging blurs.
In this study, we investigate in-shop clothing retrieval performance of densely-connected Capsule Networks with dynamic routing.
We propose a deep semi-supervised VErification Network (SEVEN) to address these challenges, where thousands or millions of categories are present but each category has scarce labeled examples.
We propose an alternative approach which makes no such assumptions. We introduce training-value as an objective measure of the contribution each training example makes to the validation loss. We then present the Training-Value approximation network (Training-ValueNet) which learns a mapping between each image and its Training-value.
We propose a formal definition of an ABox module, such that it guarantees complete preservation of facts about a given set of individuals, and thus can be reasoned independently w.r.t. the ontology TBox.
We propose a multi-task deep network for person re-identification and propose a cross-domain architecture for the task.
Autonomous Driving benefits strongly from a 3D reconstruction of the environment in real-time, often obtained via stereo vision. Current methods generate strong temporal noise, many disparity outliers and false positives on a segmentation level. We formulate a temporal prior and a scene prior, which we apply to SGM and Graph Cut.
We present a metric localization method for the monocular camera, using the Signed Distance Field (SDF) as a global map representation.
We study the problem of visual question answering (VQA) in images by exploiting supervised domain adaptation, where there is a large amount of labeled data in the source domain but only limited labeled data for the target domain.
Unsupervised asymmetric metric learning for unsupervised Person re-identification .
Automated recognition of human-human interactions from video, based on convolutional neural networks.
In recent years, a variety of proposed methods based on deep convolutional neural networks (CNNs) have improved the state of the art for large-scale person re-identification (ReID). While a large number of optimizations and network improvements have been proposed,
We propose a new salient region clustering approach for image-to-video person re-identification, in which the gallery consists of videos and the pedestrian appears in a continuous video sequence.
We describe an efficient neural network method to automatically learn sentiment lexicons without relying on any manual resources.
In this paper, we propose an approach of image classification based on ontology and HMAX features using merged classifiers.
We developed a novel computer-aided decision support system for lung nodule detection based on a 3D Deep Convolutional Neural Network (3DDCNN) for assisting radiologists.
AutoML for Loss Function Search (AM-LFS) which leverages REINFORCE to search loss functions during the training process.
We propose a novel joint learning approach where alignment learning is controllable with respect to its strength and driven by recognition.
We present a new spatio-temporal action localization detector that can temporally pinpoint the starting/ending frame of each action category in the presence of preceding/subsequent interference actions.
We propose an adaptive hierarchical network structure composed of DCNNs that can grow and learn as new data becomes available.
Deep Adaptive Temporal Pooling (DATP) applies a self-attention mechanism to adaptively pool the classification scores of different video segments.
We present the first approach for 3D point-cloud to image translation based on conditional Generative Adversarial Networks (cGAN)
In this paper we introduce a method for learning latent structured rankings that improves over existing methods by providing the right blend of predictions at the top of the ranked list.
In this paper, a new cost aggregation method is proposed, where a Per-Column Cost matrix is combined with a feature-vector-based weighting strategy to achieve both matching accuracy and computational efficiency.
We propose an exemplar-based approach that transfers knowledge from previously `Known' concepts to answer questions about the `Unknown', which improves on state-of-the-art VQA models on the proposed Open-world dataset.
We show how a malicious user can force a pre-trained generator to reproduce arbitrary data instances by feeding it suitable adversarial inputs.
We propose PrivyNet, a flexible framework to enable DNN training on the cloud while protecting the data privacy simultaneously.
We develop an adversarial method to arrive at a computationally-affordable solution called Adversarial AutoAugment, which can simultaneously optimize target related object and augmentation policy search loss.
This paper establishes a Markov chain model as a unified framework for describing the evolution processes in complex networks.
This paper aims to quantify and reduce biases exhibited by language models. We quantify these biases by adapting individual and group fairness metrics from the fair machine learning literature.
We propose a unified iterative anaglyph stereo matching and colorization framework for obtaining accurate depth maps and colorized stereo images.
We propose a conditioning scheme which learns the controller and its conditioning in an end-to-end manner, enabling us to efficiently perform complex pushing and pick-and-place tasks from raw image observations without predefined control primitives.
We use faster Region based-CNN (R-CNN) for extracting image features with an extra fully connected ::: layer.
We propose new metrics to evaluate Bayesian Deep Learning for semantic segmentation and compare and evaluate their improved uncertainty quantification.
We show that dense pixel embeddings that can separate object instances cannot be constructed using convolutional operators. At the same time, we show that simple modifications, which we call semi-convolutional, have a much better chance of succeeding at this task.
In this paper, we propose a teacher-student learning framework that transfers the knowledge gained by a heavy and better performed segmentation network (i.e. teacher) to guide the learning of fast segmentation networks.
We present a new model for manipulating images to change the distribution of human fixations in a controlled fashion in a supervised fashion.
We propose a novel end-to-end network, RegNet, to learn the optimization of photometric error metrics, which improves the convergence range and sensitivity to lighting conditions.
We present a novel approach for unsupervised learning of depth and ego-motion from monocular video. We combine this novel 3D-based loss with 2D losses based on photometric quality of frame reconstructions using estimated 3D point clouds.
We introduce a new algorithm for semi-supervised learning with very few labelled instances that can exploit the power of transfer learning.
This paper proposes a probabilistic approach to stereo visual odometry based on the combination of both point and line segment that works robustly in a wide variety of scenarios.
In this paper we consider parallelization for applications whose objective can be expressed as maximizing a non-monotone submodular function under a cardinality constraint. Our main result is an algorithm whose approximation is arbitrarily close to $1/2e$ in adaptive rounds, where $n$ is the size of the ground set.
In this paper we train models with varying number of convolutional layers to mimic a state-of-the-art CIFAR-10 model.
In this paper, we propose a Multiple Human Tracking method using multi-cues including Primitive Action Features (MHT-PAF)
Our research is focused on making a human-like question answering system which can answer rationally. We infer facts not told explicitly by using our common sense.
We propose a novel method, termed Deep Descriptor Transforming (DDT), for evaluating the correlations of descriptors and then obtaining the category-consistent regions, which can accurately locate the common object in a set of unlabeled images, i.e., unsupervised object discovery.
We propose to modify the common training protocols of optical flow, leading to sizable accuracy improvements without adding to the computational complexity of the training process.
We introduce FPConv, a novel surface-style convolution operator designed for 3D point cloud analysis and achieve compatible performance with existing volumetric convolutions.
Gaussian latent Dirichlet allocation could recover the ability to capture polysemy by introducing a hierarchical structure in the set of topics that the model can use to represent a given document.
We introduce a novel method to combat label noise when training deep neural networks for classification. We propose a loss function that permits abstention during training thereby allowing the DNN to abstain on confusing samples while continuing to learn.
In this paper, we propose an embarrassingly simple yet very efficacious approach to estimating the transferability of deep networks, especially those handling vision tasks.
AU R-CNN uses regional convolutional neural networks with expert prior knowledge to directly observe different regions, where various AUs are located.
We use a nonparametric measure of strangeness in the space of holistic image representations, and perform an iterative feature elimination algorithm to remove the most strange examples from the category.
We present a bundle-adjustment-based algorithm for recovering accurate 3D human pose and meshes from monocular videos from Kinetics.
Neural networks trained to be more robust to adversarial attacks exhibit more interpretable saliency maps than their non-robust counterparts.
This paper presents an online multiple-speaker localization and tracking method, as the INRIA-Perception contribution to the LOCATA Challenge 2018.
Convolutional neural networks with harmonic blocks can be efficiently compressed in a straightforward manner by truncating high-frequency information in harmonic blocks which is possible due to redundancies in spectral domain.
An adaptive pixel ternary coding mechanism is proposed and a contrast invariant and noise resistant interest point detector is developed on the basis of this mechanism.
A hybrid of genetic algorithm (GA) and particle swarm optimization (PSO) for CNN training optimization.
We introduce the MBS CNN training approach that significantly reduces memory traffic by partially serializing mini-batch processing across groups of layers.
We study the implicit regularization of gradient-based optimization over deep linear neural networks for matrix completion and sensing, a model referred to as deep matrix factorization.
We propose a novel adaptive batch selection algorithm called Recency Bias that exploits the uncertain samples predicted inconsistently in recent iterations to accelerate the training step.
In this paper, we propose a simple yet efficientinstance segmentation approach based on the single-stage anchor-free detector, termed SAIS.
ScaleNet is a scale aggregation network that learns the neuron allocation for aggregating multi-scale information in different building blocks of a deep network.
An important focus of current research in the field of Micro Aerial Vehicles (MAVs) is to increase the safety of their operation in general unstructured environments. In this paper, we compare vision-based real-time capable methods for localization and mapping.
We consider the problem of unsupervised learning of disentangled representations from large pool of unlabeled observations, and propose a variational inference based approach to infer Disentangled latent factors.
We propose a generative adversarial network, dubbed EnlightenGAN, that can be trained without low/normal-light image pairs, yet generalize very well on various real-world test images.
Learning rate schedule has a major impact on the performance of deep learning models. We aim to develop a precise understanding of the effects of different learning rate schedules and the appropriate way to select them.
We present EAT2seq: a novel method to architect automatic linguistic transformations for a number of tasks, including controlled grammatical or lexical changes, style transfer, text generation, and machine translation.
We introduce an interactive approach to learn a person-specific hand segmentation model that does not require any manually labeled training data.
We propose to exploit an additional big dataset with different categories to improve the accuracy of few-shot learning over our target dataset.
In this work we report on the progress of building a system that enables fully automated fast and robust facial expression recognition from face video. We analyse subtle changes in facial expression by recognizing facial muscle action units and analysing their temporal behavior.
We present a filter pruning approach for deep model compression, using a multitask neural network with binary outputs.
We investigate the problem of online feature selection (OFS) in which an online learner is only allowed to maintain a small and fixed number of features. We attempt to tackle this challenge by studying sparsity regularization and truncation techniques.
We propose a Multi-Task model to map pedestrians in different resolutions to a common space, where a shared detector is constructed to distinguish pedestrians from background.
In this work, we propose a cross-view learning approach, in which images captured from a ground-level view are used as weakly supervised annotations for interpreting overhead imagery. The outcome is a convolutional neural network for overhead imagery that captures semantically meaningful features, despite being trained without manual annotations.
This paper presents an approach to open set recognition based on an elaborate distance-like computation provided by a weightless neural network model.
This paper presents a teamed classifier framework for video analytics in heterogeneous many-camera networks with adversarial conditions such as multi-scale, multi-resolution cameras capturing the environment with varying occlusion, blur, and orientations.
We summarized state-of-the-art DNN models being used for person re-identification and provide a detailed comparison and evaluation.
This paper highlights a methodology for speaker recognition under different emotional states based on the mul-ticlass Support Vector Machine (SVM) classifier.
In this paper, an inexpensive (less than 70 USD) and portable platform with binocular stereo vision is established, which can be controlled by a laptop. By applying disparity refinement, the proposed methodology generates dense and accurate point clouds of crops in different environments including indoor lab, an outdoor field, and a greenhouse.
A DenseNet incorporating dilated convolutions excels at relational reasoning on Sort-of-CLEVR dataset, allowing us to forgo this relational module and its associated expense.
We introduce a federated multi-view matrix factorization method that extends the federated learning framework to Matrix factorization with multiple data sources.
We propose a SimRank-based join query to evaluate the similarity of two vertices in a large graph, based on which, the SimRank score of any vertex pair can be computed.
We propose a set of quality metrics for evaluating and analyzing the vision & language datasets and categorize them accordingly.
In this paper, a novel evolving CNN (ECNN) is proposed, which can efficiently utilize the limited clearly labeled images and a large number of weakly labeled images.
We propose a temporal block, including a motion excitation module and a multiple temporal aggregation (MTA) module, specifically designed to capture both short- and long-range temporal evolution.
In this paper, we propose a novel VAE semi-parametric modeling framework, named DeepCoder, which combines the modeling power of parametric (convolutional) and nonparametric (ordinal GPs) VAEs, for joint learning of latent representations at multiple levels in a task hierarchy, and classification of multiple ordinal outputs.
This paper proposes an alternating back-propagation algorithm for learning the generator network model.
We study the problem of mapping an input image to a tied pair consisting of a vector of parameters and an image that is created using a graphical engine from the vectors of parameters.
In this paper, we propose a new framework for constructing the global social service network following linked social service-specific principles based on linked data principles for publishing services on the open Web as linked social services.
The reasons behind good DNN generalisation remain an open question. In this paper we explore the problem by looking at the Signal-to-Noise Ratio of nodes in the network and identify the qualities of weight sets that promote good SNR behaviour and hence promote good generalisation.
Discriminant Projective Non-Negative Matrix Factorization with Discriminant Power .
In this work, we propose a confidence oriented decoder that assigns a confidence score to each target position, and use this score to promote more faithful generation.
We improve the performance of domain adaptation using a discriminative discrepancy measure which takes advantage of auxiliary information available in the source and the target domains to better align them.
We propose E/PI-Control, a conditional learning rate strategy that combines a feedback PI controller based on the CNN loss function, with an exponential control signal to smartly boost the learning and adapt the PI parameters.
Semantic segmentation was seen as a challenging computer vision problem few years ago. Due to recent advancements in deep learning, relatively accurate solutions are now possible.
In this paper, we propose a supervised algorithm called DNA-GAN trying to disentangle different attributes of images and also disentangled latent representations.
We explore a new security model for secure computation on large datasets. We build a protocol that leaks some information in the form of access patterns to memory, while also providing a formal bound on what is learned.
A model where a shared latent space of image features and class embeddings is learned by modality-specific aligned variational autoencoders, on which we train a softmax classifier.
With WEADE we present a free web application that offers an integrated workflow for the exploration of genomic data combining enrichment analysis with a versatile set of tools to directly compare and intersect experiments or candidate gene lists of any size or origin including cross-species data.
In this paper, we study watermarking methods to prove the ownership of an ontology using provably tight probability bounds.
A residual networks family with hundreds or even thousands of layers dominates major image recognition tasks, but building a network by simply stacking residual blocks inevitably limits its optimization ability. This paper proposes a novel residual network architecture, residual networks of residual networks (RoR), to improve the optimization ability of residual network.
This paper proposes an extension to the Generative Adversarial Networks (GANs), namely as ARTGAN to synthetically generate more challenging and complex images such as artwork that have abstract characteristics.
We present Flip-Flop Spectrum-Revealing QR, a faster and more reliable variant of the QLP factorization of Stewart, for low-rank matrix approximations.
In this paper, we introduce a discrete wavelet transform (DWT)-based methodology for a state-of-the-art disparity estimation algorithm that resulted in significant performance improvement in terms of speed and computational complexity.
In supervised learning, smoothing label/prediction distribution in neural network training has been proven useful in preventing the model from being over-confident, and is crucial for learning more robust visual representations.
We introduce a new benchmark, gSCAN, for evaluating compositional generalization in models of situated language understanding.
We propose a face manifold learning method for synthetic diverse face dataset generation, capable of denoising highly corrupted faces.
We consider the initial situation where a dataset has been over-partitioned into $k$ clusters and seek a domain independent way to merge those initial clusters in parallel.
We propose a unified object representation built from pose-aligned regions of varied spatial sizes that is robust to variations in pose, scale and viewing angle.
We study how to train a student deep neural network for visual recognition by distilling knowledge from a blackbox teacher model in a data-efficient manner. We propose an approach that blends mixup and active learning.
This paper proposes a robust method for Generalized Low Rank Approximations of Matrices (RGLRAM) which can recover both the low rank and sparse components while it may be difficult for previous state-of-the-art algorithms.
We propose a framework for semi-supervised vocabulary-informed learning to address problems of supervised, zero-shot and open set recognition using a unified framework.
Semantic image parsing, which refers to the process of decomposing images into semantic regions and constructing the structure representation of the input, has recently aroused widespread interest in the field of computer vision.
We propose to set the head size of an attention unit to input sequence length, and independent of the number of heads, resulting in multi-head attention layers with provably more expressive power.
Citation recommendation describes the task of recommending citations for a given text. In this article, we give a thorough introduction into automatic citation recommendation research.
This paper proposes a reinforcing method that refines the output layers of existing Recurrent Neural Network (RNN) language models.
A novel online action recognition method for fast detection of compound actions. A key contribution is a transfer learning strategy to allow the tasks of action segmentation and whole body modelling to be performed on a related but simpler dataset, combined with automatic hierarchical body model adaption on a more complex target dataset.
We present an integrated framework for using Convolutional Networks for localization, classification, localization and detection.
Convolutional Neural Networks are capable of learning the semantics of training data, but not on negative images.
Domain adaptation (DA) aims to generalize a learning model across training and testing data despite the mismatch of their data distributions. In light of theoretical estimation of the upper error bound, we argue, in this article, that an effective DA method for classification should: 1) search a shared feature subspace where the source and target data are not only aligned in terms of distributions as most state-of-the-art DA methods do but also discrim
We extend two popular object recognition systems (i.e., the Hmax hierarchical model of visual processing and a sift-based bag-of-words approach) to incorporate color information along with shape information.
This paper presents a novel approach to control the SGD learning rate, that uses two statistical tests to detect catastrophic learning episodes.
Disparity estimation is an ill-posed ::: problem in computer vision. In this paper, we propose a hybrid disparity generation algorithm which uses census based and segmentation based approaches which achieves high accuracy, efficiency and ::: robustness.
We propose a new learning method to infer a mid-level feature representation that combines the advantage of semantic attribute representations with the higher expressive power of non-semantic features.
Object classification with 3D data is an essential component of any scene understanding method. While the advent of deep learning has progressed the field of 3D object classification, most work using this data type are solely evaluated on CAD model datasets.
We address the issue of domain gap when making use of synthetic data to train a scene-specific object detector and pose estimator through the use of appearance randomization.
Source separation is the task of separating an audio recording into individual sound sources. In this work, we propose a source separation framework trained with weakly labelled data.
In this work, we investigate the application of trainable and spectrally initializable matrix transformations on the feature maps produced by convolution operations.
A unified span-extraction approach leads to superior performance in multi-task learning, low-data and supplementary supervised pretraining experiments on several text classification and question answering benchmarks.
We propose a novel method for online action prediction in streaming 3D skeleton sequences using dilated convolutional networks and a hierarchy of tree convolutions.
This paper focuses on image classification and proposes to iterate between filtering out noisy web labels and fine-tuning the CNN model using the crawled web images to improve the discriminative ability of CNNs and the accuracy of web image selection.
We describe the class of convexified convolutional neural networks (CCNNs), which capture the parameter sharing of convolutionAL neural networks in a convex manner, achieving performance competitive with CNNs trained by backpropagation.
We propose a new neural network module, Deformable Cost Volume, for learning large displacement optical flow.
We propose a novel deep 3D Morphable Model (3DMM) conditioned Face Frontalization Generative Adversarial Network (GAN), termed as FF-GAN, to generate neutral head pose face images.
In this paper, we propose a spatial shortcut network for pose estimation task, where information is easier to flow spatially.
For training fully-connected neural networks (FCNNs), we propose a practical second-order method including: 1) an approximation of the Hessian matrix and 2) a conjugate gradient (CG) based method.
We investigate the use of deep neural networks for the novel task of class generic object detection.
We propose a Visibility-aware Part Model (VPM) for partial re-ID, which learns to perceive the visibility of regions through self-supervision.
This work proposes a weighted joint sparse representation (WJSR)-based classification method for robust alignment-free face recognition, in which an image is represented by a set of scale-invariant feature transform descriptors.
We consider a new setting of online clustering of contextual cascading bandits, an online learning problem where the underlying cluster structure over users is unknown and needs to be learned from a random prefix feedback.
In this paper, we propose a novel deep fully convolutional network model for accurate salient object detection.
We propose an approach for unsupervised adaptation of object detectors from label-rich to label-poor domains which can significantly reduce annotation costs associated with detection.
We introduce a hierarchical neural network that applies PointNet recursively on a nested partitioning of the input point set, which can learn deep point set features efficiently and robustly.
A new structure "residual feature pyramid" is proposed in this paper. It is bidirectional to fuse both deep and shallow features towards more effective and robust object detection.
We propose a data motif-based proxy benchmark generating methodology by means of machine learning method, which combine data motifs with different weights to mimic the real-world big data and AI workloads.
We introduce several datasets based on synthetic transformations of natural entailment examples in SNLI or FEVER, to teach aspects of grammar and word order.
In this paper, we propose a novel image captioning architecture, termed Recurrent Image Captioner (\textbf{RIC}), which allows visual encoder and language decoder to coherently cooperate in a recurrent manner.
We propose a multi-task deep model that uses an element-wise multiplication layer to extract more comprehensive feature representations, and introduce a weighted-sum term to the loss function that not only relativizes the contribution of each task (kind of attributed) but also is crucial for performance improvement in multiple-attribute inference settings.
Image caption enables computers to generate a text description of images automatically. However, the generated description is not good enough.
In this work we propose a method for estimating disparity maps from very few measurements that recovers the disparity map efficiently.
We address this limitation and improve the state-of-the-art performance of two-stream CNNs for multi-person, multi-label action detection and recognition.
In this paper, we introduce a novel human interaction detection approach, based on CALIPSO (Classifying ALl Interacting Pairs in a Single shOt), a classifier of human-object interactions.
An end-to-end framework for learning parameters of min-cost flow multitarget tracking problem with quadratic trajectory interactions including suppression of overlapping tracks and contextual cues about co-occurrence of different objects.
A semi-supervised method for learning deep metrics from unlabeled stereo images, given coarse information about the scenes and the optical system.
We propose a framework for predicting future trajectories of traffic agents in highly interactive environments using multiple input modalities that are complementary to each other.
This paper proposes a correlation filter based tracking method which aggregates historical features in a spatial-aligned and scale-aware paradigm which improves performance compared to single static image.
We propose an unsupervised prior-based domain adversarial object detection framework for adapting the detectors to hazy and rainy conditions.
The goal of network representation learning is to learn low-dimensional node embeddings that capture the graph structure and are useful for solving downstream tasks. However, despite the proliferation of such methods there is no study of their robustness to adversarial attacks.
We propose a dual convolutional LSTM network for referring image segmentation and achieve superior performance compared with state-of-the-art methods.
In this paper, we propose a novel high-level image representation which utilizes image attributes as features for scene classification.
This paper presents a semi-supervised algorithm for heading direction estimation problem for Autonomous aerial filming of a moving actor.
The growing explosion in the use of surveillance cameras in public security highlights the importance of vehicle search from large-scale image databases. To address this problem, we propose the Repression Network (RepNet), a novel multi-task learning framework, to learn discriminative features for each vehicle image from both coarse-grained and detailed level simultaneously.
We explore the role of fine-tuning the pretrained model in adaptation and propose a set of adaptation guidelines for the NLP practitioner.
We address temporal action localization in untrimmed long videos. We propose a novel loss function for the localization network to explicitly consider temporal overlap and therefore achieve high temporal localization accuracy.
We apply the random decision forest framework to a large set of diverse stereo confidence measures and obtain consistently improved area under curve values.
We introduce the first approach to predict the future popularity of styles discovered from fashion images in an unsupervised manner in a data-driven vision perspective.
We propose a universal universal representation for face analysis, where a client transmits the signature of a face to be analyzed to the server, and, in return, the server sends back various information describing the face.
We propose two aleatoric uncertainty estimation algorithms for state-of-the-art deep learning based object detectors. We show that these methods are able to assign high uncertainty values to false positives and visualize these in uncertainty maps.
The artistic stylization transformation of images is an important part in the research of Non-Photorealistic Rendering (NPR) and it can express the artistic pursuit of researchers very well.
We propose a method to automatically extract entity-video frame pairs from a collection of instruction videos by using speech transcriptions and videos.
We propose a two-step approach for personalized modeling of facial AU intensity from spontaneously displayed facial expressions.
In this paper, a novel neural network named CRSum for the video summarization task is proposed. The proposed network integrates feature extraction, temporal modeling, and summary generation into an end-to-end architecture.
We propose a comprehensive set of definitions of knowledge and reasoning types necessary for answering the questions in the AI2 Reasoning Challenge (ARC) dataset.
We present our approach to unsupervised domain adaptation for single-stage object detectors on top-view grid maps in automated driving scenarios.
We construct a mapping between visual features and a semantic descriptor of each action category, allowing new categories to be recognised in the absence of any visual training data.
This work develops a multi-resolution hierarchy of patch-based feature descriptors for periocular recognition - recognition based on the soft tissue surrounding the eye orbit.
We propose two autoencoders that learn a generative model for regular motion patterns using multiple sources with very limited supervision.
We develop a predictive framework based on the multivariate point process, which employs a stochastic parametric model to solve the relations between image occurrence and the covariates that influence it, in a flexible, scalable, and globally optimal way.
We propose a novel unsupervised monocular video depth estimation method in natural scenes by taking advantage of the state-of-the-art method of Zhou et al. which jointly estimates depth and camera motion.
We applied transfer learning techniques for image recognition, automatic categorization, and labeling of nanoscience images obtained by scanning electron microscope (SEM).
We propose an approach that jointly learns representations for the different similarity conditions and their contributions as a latent variable without explicit supervision, improving upon state-of-the-art methods.
We propose a multi-task deep saliency model based on a fully convolutional neural network with global input (whole raw images) and global output (Whole saliency maps), which investigate the intrinsic correlations between saliency detection and semantic image segmentation.
We study an image denoising problem: Given a set of image denoisers, each having a different Denoising capability, can we design a framework that allows us to integrate the individual denoiser to produce an overall better result?
This paper proposes a novel deep learning based framework for facial expression recognition with facial images.
MeSH indexing is the task of assigning relevant MeSH terms based on a manual reading of scholarly publications by human indexers. We propose MeSH Now, an integrated approach that first uses multiple strategies to generate a combined list of candidate terms for a target article.
We present a general approach to video understanding, inspired by semantic transfer techniques that have been successfully used for 2D image analysis. We use our method for video captioning on the LSMDC16 benchmark, video summarization on the SumMe and TV-Sum benchmarks, Temporal Action Detection on the Thumos2014 benchmark, and sound prediction on the Greatest Hits benchmark.
In this paper, we introduce a novel object detection method, based on synthetic energy maps and the watershed transform, called Deep Watershed Detector (DWD)
We present a joint 3D pose and focal length estimation approach for object categories in the wild.
We address the problem of video moment localization with natural language, i.e. localizing a video segment described by a natural language sentence, where a tree attention network first automatically decomposes a sentence into three descriptions with respect to the main event, context event and temporal signal.
In the context of building an intelligent tutoring system (ITS), which improves student learning outcomes by intervention, we set out to improve prediction of student problem outcome from a video feed by analyzing their face and gestures.
We investigated multiple ensemble methods, including unweighted averaging, majority voting, the Bayes Optimal Classifier, and the (discrete) Super Learner, for image recognition tasks, with deep neural networks as candidate algorithms.
In this paper, a novel idea is proposed and an effective framework based Generative Adversarial Nets named APE-GAN is implemented.
We propose an approach for annotating object classes using free-form text written by undirected and untrained annotators. We first collect 729 labels on 15k images using 124 different annotations. Then we automatically enrich the structure of these freeform annotations by discovering a natural vocabulary of 4020 classes within them.
In this paper, we propose to transfer knowledge from some important discourse markers to augment the quality of the NLI model.
Self-supervised learning aims to learn representations from the data itself without explicit manual supervision. In this work, we revisit this principle and scale two popular self-super supervised approaches to 100 million images.
In this paper, we propose to employ semantic segmentation-based pooling and gating, respectively denoted as SSP and SSG, for person-related attribute prediction.
We introduce an implicit self-regularization into OR to push the mean and variance of filter angles in a network towards 90 and 0 simultaneously to achieve (near) orthogonality.
We propose a weakly-supervised transfer learning method that uses mixed 2D and 3D labels in a unified deep neutral network that presents two-stage cascaded structure.
In this paper, a fast dynamic visual tracking algorithm combining CNN based MDNet(Multi-Domain Network) and RoIAlign was developed. The results show the target localization precision has been improved and it hardly increases the computational cost.
We develop a language-guided navigation task set in a continuous 3D environment where agents must execute low-level actions to follow natural language navigation directions.
The focus in machine learning has branched beyond training classifiers on a single task to investigating how previously acquired knowledge in a source domain can be leveraged to facilitate learning in a related target domain, known as inductive transfer learning.
A meta-path based Mutual Information Index for link prediction in heterogeneous complex networks.
We propose a temporal brain network for emotion recognition and dynamic functional connectivity in temporal brain.
We pose the problem of learning motion primitives as one of temporal clustering, and derive an unsupervised hierarchical bottom-up framework called hierarchical aligned cluster analysis (HACA), a dynamic time alignment kernel to cluster time series data.
We present TMI, a bipartite graphical model for joint type-mention inference in Wikipedia but not Freebase, and we broaden our goal to a second task: assigning types to entities in Freebase but not Wikipedia.
This paper proposes a new neural network design for unsupervised learning through video prediction, which captures the entire available past context for each pixel using Parallel Multi-Dimensional LSTM units and aggregates it using context blending blocks.
We propose to formulate the attribute based person Re-ID as a joint space learning problem and apply a novel adversary training strategy to generate homogeneous features for both modalities.
In recent years, deep learning models have resulted in a huge amount of progress in various areas, including computer vision.
We investigated how these features are processed in a top-down manner when task instructions determine the relevance of features, and in a bottom-up manner when the stimulus features themselves determine process priority.
We aim to learn an unsupervised embedding space under which the robot can measure progress towards a goal for itself, enabling autonomous reinforcement learning.
Fine-tuning pre-trained CNN models on domain-specific low quality imagery for traffic flow analysis under social events and extreme weather conditions.
This paper presents a new method for parallel training of CNNs that can be considered as a particular instantiation of model parallelism, where only the convolutional layer is distributed.
We propose a novel model called adversarially regularized U-net-based generative adversarial networks (ARU-GANs), which enables the facial attribute modification and generation tasks to learn together during training.
In this paper, we tackle the problem of unsupervised segmentation in the form of superpixels in terms of the number of updates by an order of magnitude.
The Masked ConditionaL Neural Network extends upon the CLNN for environmental sound recognition.
In this paper, we propose the spatio-temporal representation matching (STRM) for video-based action recognition under the open-set condition.
 Probabilistic scene grammars capture relationships between objects using compositional rules that provide important contextual cues for inference with ambiguous data.
Amanifold adaptive kernel semisupervised discriminant analysis algorithm for gait recognition in manifold adaptive kernel space.
A number of researchers have recently questioned the necessity of increasingly complex neural network (NN) architectures for text generation from structured and unstructured data. We show that simpler, properly tuned models are at least competitive across several NLP tasks.
We propose a novel concept called Dynamic Distribution Adaptation (DDA), which is capable of quantitatively evaluating the relative importance of each distribution, which leads to better transfer learning performance.
We propose a novel viewpoint-aware metric learning approach for vehicle re-identification.
This paper presents Quasimodo, a methodology and tool suite for distilling commonsense properties from non-standard web sources, and using statistical cues from encyclopedias, books and image tags in a corroboration step.
We focus on solving the univariate times series point forecasting problem using deep learning. We propose a deep neural architecture based on backward and forward residual links and a stack of fully-connected layers.
We propose an algorithm for link-based classification, by which samples are classified using the relations or links that are present among them. The notable feature of our algorithm is the ability to invent several indices that are well studied in sociology.
The IKEA Furniture Assembly Environment is one of the first benchmarks for testing and accelerating the automation of complex manipulation tasks.
A basic, and still largely unanswered, question in the context of Generative Adversarial Networks (GANs) is whether they are truly able to capture all the fundamental characteristics of the distributions they are trained on. In this paper, we develop quantitative and scalable tools for assessing the diversity of GAN distributions.
We propose a novel and general framework called the multithreading cascade of Speeded Up Robust Features (McSURF), which is capable of processing multiple classifications simultaneously and accurately.
We present an approach that learns a semantic parser in the form of a lexicon and an inventory of syntactic patterns from ambiguous training data which is applicable to spoken utterances.
In this paper, we propose to improve the inference speed and visual quality of GAN based unsupervised semantic inpainting with consideration to temporal cues.
In this paper, we will investigate the contribution of color names for salient object detection.
Human motion analysis and understanding has been the focus of attention of many disciplines which is considered an obvious indicator of the wide and massive importance of the subject. The purpose of this article is to shed some light on this very important subject, so it can be a good insight for a novice computer vision researcher in this field.
We propose a novel model for multi-modal pretraining in Chinese, and we develop the Chinese InterBERT which is the first Chinese multi- modal pretrained model.
A comparison of several approaches that use graph matching and cascade filtering for landmark localization in 3D face data. Our best system, which uses a novel pose-invariant shape descriptor, scores 99.77% successful localization of the nose tip.
We address the problem of finding realistic geometric corrections to a foreground object such that it appears natural when composited into a background image. To achieve this, we propose a novel Generative Adversarial Network (GAN) architecture that utilizes Spatial Transformer Networks (STNs) as the generator.
We propose a ZSL framework that maps semantic embeddings to a discriminative representation space, which are learned in two different ways: Kernelized Linear Discriminant Analysis and Central-loss based Network.
A survey of the deep hashing algorithms for nearest neighbor search.
This paper presents our techniques for collection, interpretation and clustering of perceived visual similarities, and discusses the transition from pre-defined categorisation to similarity comparisons between subjects.
We propose an accelerator for mixed-signal, cellular neural networks that can improve energy and delay performance compared to state-of-the-art DNNs.
We introduce the mutual information maximization constraint on both the local feature's level and the global sequence's level to enhance the relations of the features with the speech content for effective lip reading.
We use a multi-layer recurrent highway network to model the temporal nature of spoken speech, and show that it learns to extract both form and meaning-based linguistic knowledge from the input signal.
We developed UnMask, an adversarial detection and defense framework based on robust feature alignment that detects and defends against adversarial attacks.
C2D-CNN combines the features learnt from the original pixels with the image representation learnt by CNN, and then makes decision-level fusion, which can significantly improve the performance of face recognition.
Fashion retrieval is the challenging task of finding an exact match for fashion items contained within an image. Inspired by recent advancements in Person Re-Identification research, we adapt leading ReID models to be used in fashion retrieval tasks.
The properties (or labels) of nodes in networks can often be predicted based on their proximity and their connections to other labeled nodes. So-called "label propagation algorithms" predict the labels of unlabeled nodes by propagating information about local label density iteratively through the network. We introduce a new algorithm, 3Prop, that retains all their advantages but is much more adaptive.
We propose an attribute-embedded image translation network by exploiting attributes with the generated adversarial network.
We found that using correlation-based loss function with a concordance correlation coefficient (CCC) loss resulted in better performance than error-based Loss function with mean squared error (MSE) loss.
The state-of-the-art semantic segmentation tasks can be achieved by the variants of the fully convolutional neural networks (FCNs), which consist of the feature encoding and the deconvolution.
Mesh R-CNN is a 3D shape prediction system that detects objects in real-world images and produces a triangle mesh giving the full3D shape of each detected object.
In this paper, we propose the joint learning attention and recurrent neural network (RNN) models for multi label classification.
In this study, we used genetic interaction (GI/GCI) and gene–chemical interaction (GCI data to compare mutations with different dominance phenotypes.
For bidirectional joint image-text modeling, we develop variational hetero-encoder (VHE) randomized generative adversarial network (GAN) that integrates a probabilistic text decoder and GAN into a coherent end-to-end multi-modality learning framework.
Zero-shot learning by using Logic Tensor Networks, a novel Statistical Relational Learning framework that exploits both the similarities with other seen relationships and background knowledge, expressed with logical constraints between subjects, relations and objects.
Long Short-Term Memory with Copying Mechanism (LSTM-C) for describing novel objects in captions.
The widespread adoption of deep learning models places demands on their robustness. To measure robustness, we study the maximum safe radius problem, which computes the minimum distance from the optical flow sequence obtained from a given input to an adversarial example in the neighbourhood of the input.
We utilize ideas from two growing but disparate ideas in computer vision-shape analysis using tools from differential geometry and feature selection using machine learning-to select and highlight salient geometrical facial features that contribute most in 3-D face recognition and gender classification.
In this paper, we propose a novel deep convolutional network (DCN) that achieves outstanding performance on FDDB, PASCAL Face, and AFW.
We propose an algorithm for a family of optimization problems where the objective, validation error, can be decomposed as monotonic functions of the hyperparameters of machine learning algorithms.
In this technique report, we aim to mitigate the overfitting problem of natural language by applying data augmentation methods that perturb the input word embedding.
We propose an approach for layer-wise training of a deep network for the supervised classification task where a subsequent layer builds its representation on top of the features produced by a previous layer.
We present MonoPSR, a monocular 3D object detection method that leverages proposals and shape reconstruction to improve 3D localization accuracy.
Lifelong learning is the problem of learning multiple consecutive tasks in a sequential manner where knowledge gained from previous tasks is retained and used for future learning.
We propose a method that can convert speech into a voice that matches an input face image and generate a face image that matches the voice of the input speech by leveraging the correlation between faces and voices.
We propose a method for unsupervised domain adaptation that uses task-specific classifiers as discriminators to detect target samples that are far from the support of the source.
We propose a novel Segmentation Guided Generative Adversarial Networks (SGGAN), which leverages semantic segmentation to further boost the generation performance and provide spatial mapping.
We generalize the learning with privileged information (LUPI) framework, which requires additional information to be defined per image, to the setting where additional information is a data collection about the task of interest.
We investigate the impact of ultrasound image reconstruction method on breast lesion classification with neural transfer learning and propose a method of data augmentation.
We propose a self-adaptive network pruning method for CNNs, which learns to predict saliency scores and applies pruning for each channel, such that computation cost meets the budget.
A novel random subspace two-dimensional LDA method for face recognition.
We propose a method for completing sparse depth images in a semantically accurate manner by training a novel morphological neural network using a novel fusion U-Net architecture.
We explore whether VQA is solvable when images are captured in a sub-Nyquist compressive paradigm. We develop a series of deep-network architectures that exploit available compressive data to increasing degrees of accuracy.
We tackle the problem of optimizing over all possible positive definite radial kernels on Riemannian manifolds for classification and demonstrate the benefits of our kernel learning algorithm on object, face, action and shape recognition.
This paper presents SO-Net, a permutation invariant architecture for deep learning with orderless point clouds.
We introduce a framework based on bilevel programming that unifies gradient-based hyperparameter optimization and meta-learning for few-shot learning.
We propose a two-phase citation probability learning approach, based on meta-path based prediction model on topic discriminative search space, in order to predict citation relationship effectively and efficiently.
We introduce a new method for category-level 3DOF pose estimation which produces a distribution over predicted poses by integrating 3D shape estimates from a generative object model with segmentation information.
The recent trend in action recognition is towards larger datasets, an increasing number of action classes and larger visual vocabularies. In this work we provide a critical evaluation of various approaches to building a vocabulary and show that good practises do have a significant impact.
Exploring robustness of multimedia representation and its impact on the performance of multimedia recommendation.
Community structure plays a significant role in the analysis of social networks and similar graphs, yet this structure is little understood and not well captured by most models. We use tools of combinatorics to show that any community must contain a dense Erdős-Rényi subgraph.
We propose an Identity Regression Space (IRS) based on embedding different training person identities (classes) and formulate re-id as a regression problem solved by identity regression in the IRS.
A GAN-based architecture for image completion and enhancement .
We investigate a transferable BERT (TransBERT) training framework, which can transfer not only general language knowledge from large-scale unlabeled data but also specific kinds of knowledge from various semantically related supervised tasks for a target task.
We propose a method named label embedded dictionary learning (LEDL), which embeds label information into l1 regularized dictionary learning algorithm to improve the performance of image classification tasks.
We propose a learning to teach approach that leverages the feedback from the student model to optimize its own teaching strategies by means of reinforcement learning, so as to achieve teacher-student co-evolution.
Feature selection seeks a curated subset of available features such that they contain sufficient discriminative information for a given learning task. Online streaming feature selection (OSFS) further extends this to the streaming scenario where both the features and the samples are simultaneously streamed.
We demonstrate an approach to face attribute detection that retains or improves attribute detection accuracy across gender and race subgroups by learning demographic information prior to learning the attribute detection task.
In this paper, we propose two new ideas to improve self-supervised monocular trained depth estimation: 1) self-attention, and 2) discrete disparity prediction. We extend the state-of-the-art Monodepth2 with these two ideas.
We propose the first automatic construction of deformable models using images captured in totally unconstrained conditions.
We propose an unsupervised superpixel segmentation method by optimizing a randomly-initialized convolutional neural network (CNN) in inference time.
We propose a novel learning based discriminative evaluation metric that is directly trained to distinguish between human and machine-generated captions. We further propose a data augmentation scheme to explicitly incorporate pathological transformations as negative examples during training.
We propose sparsemax, a new activation function similar to the traditional softmax, but able to output sparse probabilities.
A study of the robustness of four state of the art algorithms and a multi-matcher framework to face model degradations such as Gaussian noise, decimation, and holes.
In this paper, we propose content-enhanced network embedding (CENE), which is capable of jointly leveraging the network structure and the content information, capable of learning low-dimensional vector representation of nodes in networks.
We propose a new network structure, known as Redundancy Reduction Attention (RRA), which learns to focus on multiple discriminative patterns by sup- pressing redundant feature channels.
In this paper, we propose a discriminative metric learning framework, Information Divergence and Dictionary Learning (IDDL), that not only learns application specific measures on SPD matrices, but also embeds them as vectors using a learned dictionary.
In this paper, we propose a novel approach to video captioning based on adversarial learning and Long-Short Term Memory (LSTM) system architecture.
We propose a Patient Knowledge Distillation approach to compress an original large model (teacher) into an equally-effective lightweight shallow network (student) and encourage the student model to patiently learn from and imitate the teacher through a multi-layer distillation process.
We employ random image stylization to augment the training dataset and propose a training procedure that facilitates texture underfitting to improve the performance of domain adaptation.
We show that existing state-of-the-art 3D models are extremely vulnerable to isometry transformations. We develop a black-box attack on top of spectral norm based perturbation.
In many practical applications, it is often difficult and expensive to obtain enough large-scale labeled data to train deep neural networks to their full capability. Therefore, transferring the learned knowledge from a separate, labeled source domain to an unlabeled or sparsely labeled target domain becomes an appealing alternative.
In this paper, a novel video based action recognition framework utilizing complementary cues is proposed to handle this complex problem.
We propose the USIP detector: an Unsupervised Stable Interest Point detector that can detect highly repeatable and accurately localized keypoints from 3D point clouds under arbitrary transformations without the need for any ground truth training data.
We propose to generate attention maps that rank each spatio-temporal region's importance to a detected actor, and these maps serve as weights to the features extracted from the whole scene.
A novel unsupervised Robust Flexible Auto-weighted Local-coordinate Concept Factorization framework for clustering high-dimensional data.
We introduce a self-attention based neural network that latently learns to rank documents by their importance related to a given question, whilst optimizing the objective of predicting the correct answer.
A novel neural machine translation (NMT) architecture associating visual and textual features for translation tasks with multiple modalities.
In this paper we propose a new approach, the inclusive-NRF approach, to learning NRFs for continuous data (e.g. images), by developing inclusive-divergence minimized auxiliary generators and stochastic gradient sampling.
We propose modality-specific cross-modal similarity measurement (MCSM) approach by constructing independent semantic space for each modality, which adopts end-to-end framework to directly generate modalities-specificCross-Modal similarity without explicit common representation.
This paper aims to discover the principles to design effective ConvNet architectures for action recognition in videos and learn these models given limited training samples.
We propose a novel 3D Feature Pyramid Attention (3D-FPA) module to jointly improve the representation power of features in both the spatial and temporal domains for lipreading.
We propose to convert image-based depth maps to pseudo-LiDAR representations and apply these representations to existing LiDAR-based detection algorithms, achieving state-of-the-art results.
IASSL combines batch-based active learning and bin-based semi-supervised learning to overcome noisy and biased labels for unseen object detection in streaming images.
In this paper, we address the problem of imposing desired modal properties on the generated space using a latent distribution, engineered in accordance with the Modal properties of the true data distribution.
In this project, competition-winning deep neural networks with pretrained weights are used for image-based gender recognition and age estimation.
An action should remain identifiable when modifying its speed: consider the contrast between an expert chef and a novice chef each chopping an onion. We explore the erratic behavior caused by this phenomena on state-of-the-art deep network-based methods for action recognition in terms of maximum performance and stability in recognition accuracy.
We propose a new zero-shot learning benchmark, a new dataset, and an analysis of state-of-the-art methods.
We present a novel active learning algorithm that queries consecutive points from the pool using farthest-first traversals in the space of neural activation over a representation layer.
In this paper, we had improved on the existing best HMAX neural network in terms of structural simplicity and performance.
Generating realistic images with fine details are still challenging due to difficulties of training GANs and mode collapse. To resolve this problem, our main idea is that leveraging the knowledge of an image classification network, which is pre-trained by a large scale dataset (e.g. ImageNet), would improve a GAN and control the feedback of the added discriminator.
We propose a novel three-layered neural network-based architecture for predicting the Sixteen Personality Factors from facial features analyzed using Facial Action Coding System.
In this paper, we adopt a hybrid approach that combines logic-based and distributional semantics through probabilistic logic inference in Markov Logic Networks (MLNs).
We propose BinaryRelax, a simple two-phase algorithm, for training deep neural networks with quantized weights.
We propose a novel method that estimates the contribution of a neuron (filter) to the final loss and iteratively removes those with smaller scores.
This paper sets out to provide a principled approach, dubbed Cloak, that finds optimal stochastic perturbations to obfuscate the private data before it is sent to the cloud.
Automatic analysis of group-work collaboration using R-CNN method .
We propose D3NN, a Distributed, Decoupled, and Dynamically tuned GPU acceleration framework for scale-out CNN-based big data processing.
We propose a novel and scalable approach for multi-relational factorization based on consensus optimization based on the Alternating Direction Method of Multipliers framework.
In this paper, we develop a face recognition system with a string grammar nearest neighbor (sgNN) to cope with the problem.
The automation of classification and grading of horticultural products attending to different features comprises a major challenge in food industry. Thus, focused on the olive sector, which boasts of a huge range of cultivars, it is proposed a methodology for olive-fruit variety classification.
We propose an attention embedded spatio-temporal network (ASTN) to adaptively exploit diverse factors that influence dynamic saliency prediction within a unified framework.
We have explored transferability of existing deep convolutional neural network (CNN) models for age and gender classification in the wild.
We present an algorithm for estimating a sequence of articulated upper-body human pose in unconstrained videos and improve the detection precision of certain body parts with high degree of freedom.
We provide a simple and effective method that leverages external commonsense knowledge base such as ConceptNet to answer questions that require commonsense reasoning.
In this paper, a combination of the deep and hand-crafted descriptor is utilized to learn patterns from the handwritten images for writing identification task.
We develop a novel deep learning method for transferring the labelled information of an existing dataset to a new unseen (unlabelled) target domain for person re-id without any supervised learning in the target domain.
Facial expression recognition by exploiting explainable fuzzy models over sequences of frontal face images.
In this paper, we present the Hierarchy-of-Visual-Words (HoVW), a novel trademark image retrieval (TIR) method that decomposes images into simpler geometric shapes and defines a descriptor for binary trademark image representation by encoding the hierarchical arrangement of component shapes.
We present a simple and general framework for feature learning from point clouds. The proposed method is a generalization of typical CNNs to point clouds, thus we call it PointCNN.
We propose an end-to-end semantic adversarial approach for zero-shot sketch-based image retrieval.
Person re-identification uses a small number of fixed cameras, which create a small account of similar backgrounds, leading to the majority of background pixels becoming non-discriminative (this is expanded in the feature map).
We propose Background Hallucination Generative Adversarial Network (BachGAN), which first selects a set of segmentation maps from a large candidate pool, then encodes these candidate layouts via a background fusion module to hallucinate a suitable background for the given objects.
The Web offers a corpus of over 100 million tables [6], but the meaning of each table is rarely explicit from the table itself.
Clustering-driven deep embedding with PAirwise Constraints for nonparametric clustering using a Siamese network.
This paper proposes a dynamic graph matching method for cross-camera label estimation, which can be subsequently used in feature learning to learn robust re-ID models.
This work presents an approach to category-based action recognition in video using sparse coding techniques that captures relative similarity relations among key-sequences.
We propose automatic image denoising method based on Hermite functions using Hessian matrix analysis.
We present a robust, unsupervised (rule-based) method for providing a scale-continuous, bounded arousal rating operating on the vocal signal that generalizes across different social contexts.
We propose a novel cascaded framework, namely deep deformation network (DDN), for localizing landmarks in non-rigid objects. The hallmarks of DDN are its incorporation of geometric constraints within a convolutional neural network framework, ease and efficiency of training, as well as generality of application.
In this paper, we propose a novel network, called Spatio-Temporal Completion network (STCnet), to explicitly handle partial occlusion problem.
We proposed an approach for human activity analysis based on motion energy template (MET), a new high-level representation of video that is competitive and promising.
Exemplar GANs are a type of conditional GAN that utilize exemplar information to produce high-quality, personalized in-painting results that are both perceptually and semantically plausible.
In this paper, we propose an efficient stereo matching method using a hierarchical disparity prediction (HDP) framework to dramatically reduce the disparity search range so as to speed up the tree-based non-local stereo matching.
The paper addresses for the first time the sensor interoperability issue in 3D face recognition systems, analysing the performance of popular and well known techniques for 3D facial authentication.
We focus on multiple-choice question answering (QA) tasks in subject areas such as science, where we require both broad background knowledge and the facts from the given subject-area reference corpus.
We introduce the Fairness GAN, an approach for generating a dataset that is plausibly similar to a given multimedia dataset, but is more fair with respect to protected attributes in allocative decision making.
We conduct the first large-scale systematic study of candidate pretraining tasks for natural language understanding, comparing 19 different tasks both as alternatives and complements to language modeling.
We analyze the behavior of pruning over the course of training, finding that pruning's effect on generalization relies more on the instability generated by pruning than the final size of the pruned model, allowing us to account for the generalization benefits of modern pruning techniques.
We have constructed the first deeplearning neural network for reflection and rotation symmetry detection (Sym-NET), trained on MS-COCO (Microsoft-Common Object in COntext) dataset with nearly 11K consistent symmetry-labels from more than 400 human observers.
We introduce dodecaDialogue: a set of 12 tasks that measure if a conversational agent can communicate engagingly with personality and empathy, ask questions, answer questions by utilizing knowledge resources, discuss topics and situations, and perceive and converse about images.
We introduce multiple classifiers on top of multiple layers to enhance the discriminative capability of a deep network by allowing its layers to work collaboratively for classification.
We propose a CNN architecture that can reconstruct the whole 3D facial geometry from a single 2D image, bypassing the construction (during training) and fitting (during testing) of a 3D Morphable Model.
We propose an algorithm to generate realistic face images of both real and synthetic identities (people who do not exist) with different facial yaw, shape and resolution without any privacy concerns.
We developed and validated a deep learning algorithm that classified clinically important abnormalities in chest radiographs at a performance level comparable to practicing radiologists. Once tested prospectively in clinical settings, the algorithm could expand patient access to chest radiograph diagnostics.
We present a method for human action anticipation by predicting the most plausible future human motion. We represent human motion using Dynamic Images.
We propose a domain-specific language (DSL) for use in automated architecture search which can produce novel RNNs of arbitrary depth and width and perform well on their targeted tasks.
We propose a new DCNN-based depth map super-resolution method that can handle large up-sampling factors.
We propose an absorbing Markov chain based saliency detection method considering both boundary information and foreground prior cues through bidirectional Markov Chain.
We present an unsynchronized camera network able to estimate the motion and the structure with accurate absolute scale.
We propose MSGVF, a mean shift based GVF segmentation algorithm that can successfully locate the correct borders of the objects of interest.
We propose a lightweight network named DABNet, which employs Depth-wise Asymmetric Bottleneck (DAB) and Point-wise Aggregation Decoder (PAD) module to tackle the challenging real-time semantic segmentation in urban scenes.
Cascade R-CNN is proposed to address these problems. It consists of a sequence of detectors trained with increasing IoU thresholds, to be sequentially more selective against close false positives. The cascade procedure is applied at inference, enabling a closer match between the hypotheses and the detector quality.
We introduce a unified solution to KG characterization by formulating the problem as unsupervised KG summarization with a set of inductive, soft rules, which describe what is normal in a KG, and thus can be used to identify what is abnormal, whether it be strange or missing.
We propose a novel end-to-end trainable framework, called Dual ATtention Matching network (DuATM), to learn context-aware feature sequences and perform attentive sequence comparison simultaneously.
Single image view synthesis allows for the generation of new views of a scene given a single input image. We propose a novel end-to-end model for this task.
In this paper, we propose a novel approach based on multi-orientation scores augmented with a contextual affinity matrix, which both are inspired by the geometry of the primary visual cortex (V1) and their contextual connections.
This paper introduces the use of fluid-dynamic modeling to determine the connectivity of overlapping venous and arterial vessels in fundus images.
We propose an octree grouping-based network structure for PointNet++, an extension of PointNet, which performs better than PointNet in processing irregular point cloud data.
We introduce a new optimization procedure, which allows training for 3D detection with raw 3D scans while using as little as 5% of the object labels and still achieve comparable performance.
We introduce a simple and efficient lossless image compression algorithm for lossless super-resolution based Compression.
We participated in the M4 competition for time series forecasting and describe here our methods for forecasting daily time series. We used an ensemble of five statistical forecasting methods and a method that we refer to as the correlator.
We investigate learning to probabilistically bypass computations in a network architecture, where some layers are nearly always bypassed and some almost never.
In this paper, we propose an effective and reliable insulator detection method based on a deep learning technique for aerial images. Inspired by transfer learning, a two-stage fine-tuning strategy is implemented using separate training sets.
We introduce fake sentence detection as a new training task for learning sentence encoders. We automatically generate fake sentences by corrupting original sentences from a source collection and train the encodes to produce representations that are effective at detecting fake sentences.
CNN, a convolutional neural network trained for the purpose of recognizing revisited locations under severe appearance changes, which maps images to a low dimensional space where Euclidean distances represent place dissimilarity.
In this paper, we propose an iterative hard thresholding (IHT) approach to train Skinny Deep Neural Networks (SDNNs) which can achieve competitive or even better performance than its full CNN counterpart.
Video object codiscovery can leverage the weak semantic constraint implied by sentences that describe the video content, improving upon those of the previous state-of-the-art methods by significant margins.
We propose a new approach motivated by the global precedent hypothesis of the human brain's cognitive mechanisms of perception. An automatic modeling of SIFT keypoint descriptors using a Gaussian mixture model (GMM)-based universal background model method.
We improve generative models that generate high-dimensional samples conditional on low-dimensional descriptors by matching their distributions using maximum mean discrepancy in the decoder layer.
This paper shows that the successively evaluated features used in a sliding window detection process to decide about object presence/absence also contain knowledge about object deformation.
We present a filter-based approach to reduce variational energies that contain generic data-fitting terms, but are restricted to specific regularizations.
We propose an unsupervised learning framework, which can accelerate the initialization process of ORB-SLAM system and effectively improve the performance of the SLAM system.
We review 156 papers that apply DL to EEG, published between January 2010 and July 2018, and highlight interesting approaches in order to inform future research and formulate recommendations.
We propose a more effective method to preprocess 3D shapes also based on a panoramic view, similar to DeepPano, which can deal with more complex 3D shape recognition problems.
We propose a weakly supervised temporal action localization algorithm on untrimmed videos using convolutional neural networks using temporal pooling of video segments.
Automatic body part recognition for CT slices using unsupervised body part regressor .
AntisymmetricRNN captures long-term dependencies thanks to the stability property of its underlying differential equation, which improves trainability.
We develop a novel affinity measure for pairs of proteins in PPI networks, which uses personalized PageRank, a random walk based method used in context-sensitive search on the Web, and show that our measure is more biologically significant than other commonly used methods.
In this paper, we propose a novel Partition-Controlled GAN to generate human images according to target pose and background.
DLGFF establishes a framework integrating multi-level semantics from the global texture feature–based method, the BoVW model, and a pre-trained convolutional neural network (CNN).
We propose Stochastic Neural Architecture Search (SNAS), an economical end-to-end solution that trains neural operation parameters and architecture distribution parameters in same round of back-propagation, while maintaining the completeness and differentiability of the NAS pipeline.
We explore the use of recurrent Deep Neural Networks for learning high-level shape information from low-resolution depth images for person re-identification.
We extend a recently proposed Deep Alignment Network (DAN), that achieves state-of-the-art results in the recent facial landmark recognition challenge, with a term related to facial features.
In this paper we propose a novel Temporal Attentive Relation Network (TARN) for the problems of few-shot and zero-shot action recognition.
In this notebook paper, we describe our approach in the submission to the temporal action proposal (task 3) and temporal action localization (task 4) of ActivityNet Challenge hosted at CVPR 2017.
In this paper, we investigate the adoption of a stream-based on-line learning approach to relational data in both an infinite-attribute and fixed-attribute setting, and develop implementations that use ILP engines in combination with on- line model-constructors.
SPECTRA integrates gene expression and protein interaction data from the most authoritative online repositories, in order to build and compare tissue-specific PPI networks.
We combine model-based and model-free reinforcement learning to achieve state-of-the-art performance on complex locomotion benchmark tasks.
We propose a segmentation infusion network to enable joint supervision on semantic segmentation and pedestrian detection, achieving state-of-the-art performance on pedestrian detection.
Knowledge distillation (KD) is a technique to derive optimal performance from a small student network (SN) by distilling knowledge of a large teacher network (TN) and transferring it to the small SN.
We propose a novel random forest algorithm to minimize prediction error for a user-specified {\it average} feature acquisition budget.
In this paper, we propose a novel Deep Hyper-Network Embedding (DHNE) model to embed hyper-networks with indecomposable hyperedges.
A database for the 3D structures of available compounds is essential for the virtual screening by molecular docking. We have developed the LigandBox database containing four million available compounds, collected from the catalogues of 37 commercial suppliers, and approved drugs and biochemical compounds taken from KEGG_DRUG and PDB databases.
We investigate the performance of BioBERT, a pre-trained biomedical language model, in answering biomedical questions including factoid, list, and yes/no type questions.
In this paper, we generate a matching volume leveraging both data with ground truth and conventional wisdom using random forest classifiers.
We propose a novel measure based on local centrality with a coefficient, which ranks influential nodes that have the same number of four-layer neighbors.
In this work, we tackle the problem of person search, which is a challenging task consisted of pedestrian detection and person re-identification (re-ID). Instead of sharing representations in a single joint model, we find that separating detector and re-ID feature extraction yields better performance.
We propose a novel approach that acts by transforming an input hierarchy into a new saliency map highlighting regions having some specific characteristics.
We propose a novel co-training method for semi-supervised facial AU recognition utilizing a large number of web face images without AU labels and a small face dataset with AU labels inspired by the co- training methods.
We identify the need for a gamified self-driving simulator where game mechanics encourage high-quality data capture, and design and apply such a simulator to collecting lane-following training data.
We propose to use image-to-image translation models for thermal infrared (TIR) data tracking, on which we provide a large labeled dataset of synthetic TIR data.
In this paper we propose to use a search strategy that adaptively directs computational resources to sub-regions likely to contain objects.
We present a domain flow generation(DLOW) model to bridge two different domains by generating a continuous sequence of intermediate domains flowing from one domain to the other.
We address the problem of long tail recognition wherein the training set is highly imbalanced and the test set is kept balanced. We propose an ensemble of experts technique that decomposes the imbalanced problem into multiple balanced classification problems.
Adaptive inference networks for deep SISR with efficient sparse convolution .
We present a memory augmented neural network for natural language understanding.
The analysis of dynamical transcriptional response to TGF-β treatment experiments in different human and murine cell systems revealed commonly affected biological processes and pathways, which could be linked to T GF-β1 via network analysis.
Influence functions estimate the effect of removing a training point on a model without the need to retrain. Are influence functions accurate in this setting?
We propose the Super-Resolution CliqueNet (SRCliqueNet) to reconstruct the high resolution image with better textural details in the wavelet domain.
Combining OMP codes with maximum coordinate detection could achieve state-of-the-art performance on the UCSD dataset.
We consider the problem of space-time super-resolution (ST-SR), increasing spatial resolution of video frames and simultaneously interpolating frames to increase the frame rate, and propose a novel model that super-resolves jointly in space and time.
The Quick, Draw! Dataset is a Google dataset with a collection of 50 million drawings, divided in 345 categories, collected from users of the game Quick, draw!.
In this paper, we tackle the classification of gender in facial images with deep learning using VGG-16 architecture.
We propose metric-scale truncation-robust volumetric heatmaps, whose dimensions are defined in metric 3D space near the subject, instead of being aligned with image space. We train a fully-convolutional network to estimate such heatmaps from monocular RGB in an end-to-end manner.
We propose an Attentive Recursive Tree model (AR-Tree), where the words are dynamically located according to their importance in the task.
We propose a unified any-shot detection model, that can concurrently learn to detect both zero-shot and few-shot object classes.
We propose an efficient deep model, called MotionNet, to jointly perform perception and motion prediction from 3D point clouds, which outperforms the state-of-the-arts.
In this paper, we firstly propose a new adaptive similarity measure which is consistent with k-NN search, and prove that it leads to a valid kernel. Then we propose a hashing scheme which uses binary codes to preserve the kernel function.
We propose a novel data-driven feature extraction framework that represents facial expression variations as a linear combination of localised basis functions, whose coefficients are proportional to movement intensity.
A new challenge in Super-resolution (SR) problem is how to utilize the pros of internal and external learnings to further enhance the result. We propose a low-rank solution which effectively integrates them together.
We propose a tandem learning framework for training efficient, low latency and high accuracy deep spiking neural networks with low computing resources.
We find that the parameters of LayerNorm, including the bias and gain, increase the risk of over-fitting and do not work in most cases. We propose a new normalization method, Adaptive Normalization, which demonstrates better results than LayerNorm.
OpenNRE is an open-source and extensible toolkit that provides a unified framework to implement neural models for relation extraction (RE) and an online system for real-time extraction.
We address the problem of 3D rotation equivariance in convolutional neural networks by implementing exact convolutions on the sphere by realizing them in the harmonic domain.
We introduce BioBERT (Bidirectional Encoder Representations from Transformers for Biomedical Text Mining), which is a domain-specific language representation model pre-trained on large-scale biomedical corpora.
We present BlockGAN, an image generative model that learns object-aware 3D scene representations directly from unlabelled 2D images, without the need for 3D geometry.
We propose a new bottom-up method for multi-person 2D human pose estimation that is particularly well suited for urban mobility such as self-driving cars and delivery robots.
We introduce FreeLabel, an intuitive open-source web interface that allows users to obtain high-quality segmentation masks with just a few freehand scribbles, in a matter of seconds.
We propose an efficient quality measure for hash functions, based on an information-theoretic quantity, mutual information, and use it successfully as a criterion to eliminate unnecessary hash table updates. We thus develop a novel hashing method, MIHash, that can be used in both online and batch settings.
This paper aims to "purify" any comprehensive training set, which consists of data annotated by various observers, via refining low-quality manual labels in the dataset.
We propose a Hierarchical fusion strategy for multimodal emotion recognition that incorporates global or more abstract features at higher levels of its knowledge-inspired structure.
This paper proposes an algorithm for recognizing slab identification numbers in factory scenes using weakly annotated GTD.
We introduce Deep Local Shapes (DeepLS), a deep shape representation that enables encoding and reconstruction of high-quality 3D shapes without prohibitive memory requirements.
We propose a novel OPEC-Net framework for occlusion and a new Occluded Pose dataset with 9k annotated images.
In this paper, group decision-making (GDM) theory is introduced for comprehensive decision.
We propose a method for the localization of multiple facial features on challenging face images without resorting to explicit facial shape models.
We study the problem of multiset prediction by viewing this problem from the perspective of sequential decision making, and propose a novel loss function for the problem.
We present an approach to iteratively cluster images and video in an efficient and intuitive manor. We introduce an "image signature" descriptor and use min-Hash and greedy clustering to efficiently present the user with clusters of the dataset.
Train and compare two different Deep Convolutional Neural Network models, regarding their application for road friction estimation and describe the challenges for training the classifier in terms of available training data and the construction of suitable datasets.
We propose a bio-inspired foveated technique to detect cars in a long range camera view using a deep convolutional neural network (DCNN) for the IARA self-driving car.
We propose CornerNet, a new approach to object detection where we detect an object bounding box as a pair of keypoints, the top-left corner and the bottom-right corner, using a single convolution neural network.
This paper carries out an empirical analysis of various dropout techniques for language modelling, such as Bernoulli dropout, Gaussian drop out, Curriculum Dropout, Variational Dropout and Concrete Dropout.
We present the first study in the literature that has aimed to determine Depression Anxiety Stress Scale levels by analyzing facial expressions using Facial Action Coding System (FACS) by means of a unique noninvasive architecture on three layers designed to offer high accuracy and fast convergence.
Constructing a powerful graph that can effectively depict the intrinsic connection of data points is the critical step to make the graph-based semisupervised learning algorithms achieve promising performance.
This paper introduces a novel ground truth generation method that combines human supervision with pre-trained neural networks to generate per-instance 3D point cloud segmentation, 3D bounding boxes, and class annotations.
We propose a novel teleoperation system that combines the replication of facial expressions of emotions (neutral, disgust, happiness, and surprise) and head movements on the fly on the humanoid robot Nao.
We propose to develop an algorithm based on BoVW for facial expression analysis which goes beyond those limitations.
We present UnityEyes, a novel method to rapidly synthesize large amounts of variable eye region images as training data. The model is based on high-resolution 3D face scans and uses real-time approximations for complex eyeball materials and structures.
We define vulnerability at the latent feature space and propose a Bayesian framework to prioritize features based on their contribution to both the original and adversarial loss, to prune vulnerable features and preserve the robust ones.
We combine the advantages of the two views by inducing a mapping from distributional vectors of words (or sentences) into a Boolean structure of the kind in which natural language terms are assumed to denote.
We tackle the problem of learning a rotation invariant latent factor model when the training data is comprised of lower-dimensional projections of the original feature space, from a training set of 2-D projected poses.
We present a simple alternative approach based on dense vector spaces and recurrent neural networks (RNNs), in particular Long Short Term Memory (LSTM) networks, for Machine Translation evaluation.
We analyze the ideal loss function properties for heatmap regression in face alignment problems. Then we propose a novel loss function, named Adaptive Wing loss, that can adapt its shape to different types of ground truth heatmap pixels.
We address the problem of pose entanglement in learned shape space from only single-view images, and propose an effective adversarial domain confusion method to solve the problem.
We propose a new algorithm to measure the importance of gradients on large-scale cluster implementing ring all-reduce based on the size of the ratio of parameter calculation gradient to parameter value.
We propose a policy improvement scheme for model predictive control in the iterative learning setting, where the same task can be repeated several times, and propose a longer horizon plan for MPC.
We present a method for tracking Maximally Stable Homogeneous Regions (MSHR) in images with an arbitrary number of channels while remaining extremely efficient.
We present an optimal transport (OT) framework for generalized zero-shot learning (GZSL of imaging data, seeking to distinguish samples for both seen and unseen classes, with the help of auxiliary attributes.
This paper presents a pose-invariant 3D-aided 2D face recognition system (UR2D) that is robust to pose variations as large as 90? by leveraging deep learning technology.
This paper proposes a novel latent semantic learning method for extracting high-level latent semantics from a large vocabulary of abundant mid-level features (i.e. visual keywords) with structured sparse representation.
We propose a trainable Generalized-Mean pooling layer that generalizes max and average pooling and use it to fine-tune CNNs for image retrieval.
This paper investigates the evaluation of dense 3D face reconstruction from a single 2D image in the wild using real, accurate and high-resolution 3D ground truth face scans.
In this paper, we propose gcForest, a decision tree ensemble approach with performance highly competitive to deep neural networks in a broad range of tasks.
We present a method of generating item recommendations by learning item feature vector embeddings that can be used to drive product recommendations.
We propose an image-level supervised approach for common object counting that provides both the global object count and the spatial distribution of object instances by constructing an object category density map.
We train a zero-bias CNN on facial expression data and achieve, to our knowledge, state-of-the-art performance on two expression recognition benchmarks and introduce an approach to decipher which portions of the face influence the CNN's predictions.
We propose an image re-sampling compression method by learning virtual codec network (VCN) to resolve the non-differentiable problem of quantization function for image compression.
We present Layrub, a runtime data placement strategy that orchestrates the execution of the training process. It achieves layer-centric reuse to reduce memory consumption for extreme-scale deep learning.
This paper aims to classify and locate objects accurately and efficiently, without using bounding box annotations, using convolutional neural networks.
We investigate video classification via a 3D deep convolutional neural network that directly ingests compressed bitstream information.
We define the problem of feature selection and parameters determination in SVM as a combinatorial problem and we use a stochastic method that guarantees to reach the global optimum.
We present a novel rough-fuzzy clustering method to detect overlapping protein complexes in protein-protein interaction (PPI) networks.
We propose Progressive One-shot Neural Architecture Search (PONAS) that combines advantages of progressive NAS and one-shot methods for efficient neural network deployment.
This paper presents a comprehensive survey of approaches and techniques in action evaluation research, including motion detection and preprocessing using skeleton data, handcrafted feature representation methods, and deep learning-based feature representation Methods.
We show that single generator GANs are unable to correctly model a distribution supported on a disconnected manifold, and propose a novel approach for learning the necessary number of generators without any supervision.
We present a robotic system for picking a target from a pile of objects that is capable of finding and grasping the target object by removing obstacles in the appropriate order.
We introduce a novel Aggregated Local Flow Descriptor (ALFD) that encodes the relative motion pattern between a pair of temporally distant detections using long term interest point trajectories and propose an efficient and accurate online multiple target tracking algorithm.
Generative adversarial networks can be leveraged for image generation, image segmentation and audio source separation when additional incomplete data are available.
This paper revisits recognition of natural image pleasantness by employing deep convolutional neural networks and affordable eye trackers and evaluates features from eye movements, visual features, and their combination.
A graph representing relations between a set of objects is a structure where each node delineates an individual element and the similarity between them is represented as a weight on the connecting edge.
Gait is a unique perceptible biometric feature at larger distances, and the gait representation approach plays a key role in a video sensor-based gait recognition system. In this paper, we reviewed the expressions and meanings of Class Energy Image approaches, and analyzed the information in the Class Energy Images.
We develop an image compression framework tailored for DNN applications, named “DeepN-JPEG”, to embrace the nature of deep cascaded information process mechanism of DNN architecture.
We propose a decentralized method for federated learning of deep networks based on iterative model averaging, and conduct an extensive empirical evaluation.
We propose a novel single face image super-resolution method, which named Face Conditional Generative Adversarial Network, based on boundary equilibrium generative adversarial networks.
Preprocessing methods such as the Union-Without-Background-and-with-Binary-mask (Union-WB- and-B) method yields significantly better results than the widely used Union method.
We introduce a multi-labeled dataset related to Mediter-ranean diet called FoodCAT, an objective tool for the analysis of the patient's behavior, allowing specialists to discover unhealthy food patterns and understand the user's lifestyle.
We propose Rectified Local Phase Volume (ReLPV) block, an efficient alternative to the standard 3D convolutional layer. The ReLPV block extracts the phase in a 3D local neighborhood of each position of the input map to obtain the feature maps.
We boost CNN-based optical flow estimation in real scenes with the help of the freely available self-supervised task of next-frame prediction, which yields favorable results.
We propose a novel positive-unlabeled learning method named DDI-PULearn for large-scale drug-drug-interaction predictions.
A model of disparity at scotopic luminance levels can be used to match binocular disparity of a photopic stereo scene to the disparity that would be perceived if the scene was actually scotopia.
We present a point-based approach for modeling the appearance of real scenes and obtaining photorealistic views, while avoiding explicit surface estimation and meshing.
We show that it is possible to learn semantic segmentation from very limited amounts of manual annotations, by enforcing geometric 3D constraints between multiple views.
In this paper, we describe an architecture that enables relationships to be determined from a stream of entities obtained by an attention mechanism over the input field, and train end-to-end.
We propose a densely semantically aligned person re-identification (re-ID) framework that addresses body misalignment problem caused by pose/viewpoint variations, imperfect person detection, occlusion, etc.
We propose an embedding method to model a topic as a vector in a latent space to interpret its deep semantics.
In this paper, we present novel techniques that improve the computational and memory efficiency of algorithms for solving multi-label energy functions arising from discrete MRFs or CRFs.
An integrated approach/solution for vessel detection and diameter measurement for ocular retinal images and its validation.
Post-estimation smoothing is a fast and effective method for incorporating structural index data into prediction tasks.
We propose a Saliency-Adaptive Sparsity Learning (SASL) approach for further optimization, which is effective and efficient.
Using FPGAs to accelerate ConvNets has attracted significant attention in recent years. In this work, we adopt an algorithm-hardware co-design approach to develop a ConvNet accelerator called Synetgy and a novel ConvNet model called DiracDeltaNet, both tailored to FPGA requirements.
We propose a novel semi supervised, Multi Level Sequential Generative Adversarial Network (MLS-GAN) architecture for group activity recognition.
A novel adaptive warping layer for motion estimation and compensation driven neural network for video frame interpolation.
Our hypothesis is that an effective trained occlusion detector can be generated on the basis of i) a broad spectrum of visual features, and ii) representative but synthetic training sequences.
We rethink a well-know bottom-up approach for multi-person pose estimation and propose an improved one that surpasses the baseline.
We propose a new deep model, termed Gabor Convolutional Networks (GCNs or Gabor CNNs), which incorporates Gabor filters into DCNNs to enhance the resistance of deep learned features to the orientation and scale changes.
In this paper, we propose a new deep framework which predicts facial attributes and leverage it as a soft modality to improve face identification performance.
This study presents an efficient approach for automatic face recognition based on Spectral Graph Wavelet Theory.
We define the task of salient structure (SS) detection to unify the saliency-related tasks like fixation prediction, salient object detection, and other detection of structures of interest.
Docking Approach using Ray Casting (DARC) for use on Graphics Processing Units (GPUs), leading to a speedup of approximately 27-fold in typical-use cases over the corresponding calculations carried out using a CPU alone.
Face attributes are interesting due to their detailed description of human faces. Instead of manipulating the whole image, we propose to learn the corresponding residual image defined as the difference between images before and after the manipulation.
Fully convolutional neural network (FCN) has been dominating the game of face detection task for a few years with its congenital capability of sliding-window-searching with shared kernels, which boiled down all the redundant calculation, and most recent state-of-the-art methods such as Faster-RCNN, SSD, YOLO and FPN use FCN as their backbone.
We propose USim, a semantic measure for Grammatical Error Correction that measures the semantic faithfulness of the output to the source, thereby complementing existing reference-less measures (RLMs) for measuring the output's grammaticality.
In order to investigate the protection of human self-determination within algorithmic sociotechnical systems, we study the relationships between the concepts of mutability, bias, feedback loops, and power dynamics, in order to question the dynamics in our interactions with RSs.
We present One Hand Clapping (OHC), a method for the detection of condition-specific interactions between transcription factors (TFs) from genome-wide gene activity measurements.
Neural networks need big annotated datasets for training. A remedy for this is synthetic data with perfect ground truth. We explore two variations of synthetic data for this challenge.
We propose a Multiple Scale Learning (MSL) framework to learn the optimal spatial pyramid representation for the given image data and the associated object category.
We propose a generative adversarial training mechanism for improving the performances of variational autoencoder (VAE) trained with our new method.
We propose factorized spatio-temporal convolutional networks (FstCN) that factorize the original 3D convolution kernel learning as a sequential process of learning 2D spatial kernels in the lower layers, followed by learning 1D temporal kernels.
We exploit recurrent networks for real-time self-supervised monocular depth estimation and completion.
This paper serves the following two main purposes. First, examine the state of the art for low-power solutions to detect objects in images. Second, suggest directions for research as well as opportunities forlow-power computer vision.
In this work, we introduce a new video representation for action classification that aggregates local convolutional features across the entire spatio-temporal extent of the video.
We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers, designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers.
Temporal Deformable Convolutional Encoder-Decoder networks for video captioning.
We propose zero-shot deep domain adaptation, which uses privileged information from task-irrelevant dual-domain pairs to perform domain adaptation without access to task-relevant target-domain training data.
This dissertation research will explore region-based and interest points based image representations, two of the most-used image models for object detection, image classification, and visual search among other applications.
We introduce Nonpher, a computational method for the construction of a hard-to-synthesize virtual library using a molecular morphing algorithm.
A deep learning technique-based method to solve large-scale 0-1 knapsack problems where the number of products (items) is large and/or the values of products are not necessarily predetermined but decided by an external value assignment function during the optimization process.
We introduce a large-scale "Holistic Video Understanding Dataset"~(HVU) for multi-label and multi-task video understanding.
We propose to improve emotion recognition by combining acoustic information and conversation transcripts, using a multi-resolution CNN.
The world we see is ever-changing and it always changes with people, things, and the environment. A research problem is characterized as domain transfer adaptation when it needs knowledge correspondence between different moments.
ShellConv uses statistics from concentric spherical shells to define representative features and resolve the point order ambiguity in point cloud data for point cloud deep learning.
We propose a novel method for generating natural language sentences from probabilistic language models, selecting from a beam search using a range voting procedure, selecting the most representative output.
This paper provides a review of relevant localization and tracking algorithms and, within the context of the existing literature, a detailed evaluation and dissemination of the LOCATA submissions.
We propose an end-to-end trainable VQA model which considers both answers and their reasons jointly.
A multi-cue correlation particle filter for robust visual tracking in complex tracking scenarios.
We propose new architectures for cross-view image synthesis using conditional generative adversarial networks (cGAN).
We propose a novel Single Shot Action Detector (SSAD) network based on 1D temporal convolutional layers to skip the proposal generation step via directly detecting action instances in untrimmed video.
We propose a multi-turn dialog system aimed at learning and generating emotional responses that so far only humans know how to do.
We propose a plan view network for end-to-end control of monocular dash cam videos and use it to leverage advances in 3D object detection.
We propose a deep latent variable model that attempts to perform source separation on parallel sentences, isolating what they have in common in a latent semantic vector, and explaining what is left over with language-specific latent vectors.
A list of free and open datasets for the scientific community.
We propose a novel framework called AC-BLSTM for modeling sentences and documents, which combines the asymmetric convolution neural network (ACNN) with the Bidirectional Long Short-Term Memory network ( BLSTM), which achieves state-of-the-art results on five tasks.
We consider the problem of learning textual entailment models with limited supervision (5K-10K training examples), and present two complementary approaches for it.
Periocular region can be exploited to examine the existence of uniqueness as there are many nodal points in this region.
Feature extraction-based subspace learning based on pixel-level adaptively selects the most active and discriminative feature for representation and classification.
We propose to boost AT via incorporating hypersphere embedding (HE), which can regularize the adversarial features onto compact hyperspherical manifolds, which tunes up the learning dynamics of AT from several aspects.
We propose a new domain adaptation method for Combinatory Categorial Grammar (CCG) parsing, based on the idea of automatic generation of CCG corpora exploiting cheaper resources of dependency trees.
Neural language representation models such as BERT pre-trained on large-scale corpora can well capture rich semantic patterns from plain text, and be fine-tuned to consistently improve the performance of various NLP tasks. However, the existing language models rarely consider incorporating knowledge graphs (KGs), which provide rich structured knowledge facts for better language understanding.
Robust dictionary learning algorithms seek to learn a dictionary while being robust to the presence of outliers in the training set.
We propose Genetic Binary Convolutional Networks (GBCNs) to optimize 1-bit DCNNs, by introducing a new balanced Genetic Algorithm (BGA) to improve the representational ability in an end-to-end framework.
This work uses a neural network to directly sense the aircraft attitude of an aircraft from monocular imagery.
We propose a novel network with purificatory mechanism and structural similarity loss to better locate preliminary salient objects and restore error-prone regions.
This paper gives the first attempt to relax the need of manual balancing by proposing the concept of decoupled learning, where a novel network structure is designed that explicitly disentangles the backpropagation paths of the two losses.
Word segmentation is a low-level NLP taskt hat is non-trivial for a considerable number of languages. In this paper, we present asequence tagging framework and apply it to word segmentation.
In this paper, we propose a self-learning Visual Attention Model (VAM) to extract attention maps from clothing images.
We propose a new framework for sparse and structured attention, building upon a smoothed max operator, which allows for interpretable attention mechanisms that focus on entire segments or groups of an input.
We propose a dual adversarial inference framework for text-to-image synthesis that learns style representations from a given text description.
This paper presents a novel system that uses two synchronous optimization processes to recover 3D structure from stereo image pairs.
This paper elaborates on the possibility to leverage the highly parallel nature of GPUs to implement more efficient stereo matching algorithms. Different algorithms have been implemented and compared on the CPU and the GPU.
We propose a new task, Stylistic Headline Generation (SHG), to enrich the headlines with three style options (humor, romance and clickbait), in order to attract more readers.
We examine different auxiliary tasks in a MTL setup, amongst which a novel setup, and correlate their impact to data-dependent conditions.
We combine robust illumination normalization, local texture-based face representations, distance transform based matching, kernel-based feature extraction and multiple feature fusion for state-of-the-art face recognition under difficult illumination conditions.
We propose iW-Net, a deep learning model that allows for both automatic and interactive segmentation of lung nodules in computed tomography images.
Deformable objects have changeable shapes and they require a different method of matching algorithm compared to rigid objects.
We propose an encoder-decoder generative adversarial network that can learn pose-invariant and expression-discriminative representations from facial expression images.
In this work, we introduce Video Question Answering in the temporal domain to infer the past, describe the present and predict the future.
CondenseNet combines dense connectivity with a novel module called learned group convolution, allowing for efficient computation in practice.
We propose a weakly-supervised approach that learns to estimate 3D poses from unlabeled multi-view data, which can be acquired easily in in-the-wild environments.
We use self-supervised pretraining to learn general and effective features for both audio and video analysis from temporal synchronization of audio-video pairs.
In this paper, we present a novel deep learning approach, deeply-fused nets. The central idea of our approach is deep fusion, where the fused output serves as the input of the remaining part of each base network, and perform such combinations deeply over several intermediate representations.
We present local ensembles, a method for detecting extrapolation at test time in a pre-trained model.
We propose an additional transformation for cross-lingual word embeddings which improves the integration of the monolingual spaces as well as the quality of the Monolingual Spaces themselves.
We propose to utilize the structure of the space spanned by the attributes using a set of relations to induce semanticity to the embedding space, thereby improving zero-shot learning.
We propose a novel method called Latent Adversarial Defence (LAD) which improves the robustness of a DNN model through adversarial training on generated adversarial examples.
This paper presents a simple yet principled approach to boosting the robustness of the residual network (ResNet) that is motivated by the dynamical system perspective.
We propose to generalize both BN and cBN using a Whitening and Coloring based batch normalization using conditional Generative Adversarial Networks.
We propose an architecture for capsule networks fit for audio classification tasks and study the impact of various parameters on classification accuracy.
In this paper, we propose a novel convolutional network named Efficient Dense modules with Asymmetric convolution (EDANet), which employs an asymmetric Convolution structure and incorporates dilated convolution and dense connectivity to achieve high efficiency at low computational cost and model size.
This paper proposes a flexible pipeline to adopt any 2D detection network and fuse it with a 3D point cloud to generate 3D information with minimum changes of the2D detection networks.
We present a methodology for extracting the vascular network in the human retina using Dijkstra’s shortest-path algorithm, which preserves vessel thickness and follows vessel branching naturally and efficiently.
The interaction between language and visual information has been emphasized in visual question answering (VQA) with the help of attention mechanism. However, the relationship between words in question has been underestimated, which makes it hard to answer questions that involve a relationship between multiple entities, such as comparison and counting. In this paper, we develop the graph reasoning networks to tackle this problem.
We explore methods for performing semantic segmentation on the discrete cosine transform (DCT) representation defined by the JPEG standard.
In this paper, we propose a simple but effective semantic-based aggregation (SBA) method that utilizes the discriminative filters of deep convolutional layers as semantic detectors.
We present a novel approach for learning to predict sets using deep learning, where the output is permutation invariant and the input is cardinality invariant.
An end-to-end generative approach from the encoding of features to the structural modeling of complex human activities by applying Fisher vectors and temporal models for the analysis of video sequences.
This paper explores an effective way to exploit both techniques into the collaborative filtering task for the accurate recommendation. We extend the conventional GAN-based recommenders for collaborative filtering.
We investigate the expressive power of graph CNNs by analyzing their asymptotic behaviors as the layer size tends to infinity.
Our approach converts a category-specific object detector into a generic object-specific detector efficiently, on the fly, resulting in a unified approach for the two tasks.
This paper introduces SIGNet, a novel framework that provides robust geometry perception without requiring geometrically informative labels.
In this paper, we introduce a continuous variable to model the relevance degree between queries and multiple candidates, and propose to learn a coherent embedding space where candidates with higher relevance degrees are mapped closer to the query than those with lower relevance degrees.
In this paper, we perform automated analysis on a large-scale historical image dataset of 168,055 (37,921) American high school yearbook portraits.
We propose convolutional networks with adaptive inference graphs (ConvNet-AIG) that adaptively define their network topology conditioned on the input image, improving efficiency and overall classification quality.
In this work, we build on recent advances in distributional reinforcement learning to give a generally applicable, flexible, and state-of-the-art distributional variant of DQN.
We propose a specific search space based on encoder-decoder framework and apply neural architecture search (NAS) to retinal vessel segmentation and reduce the workload of manually designing neural network.
Comparison of fine and coarse ground truth annotations of Cityscapes dataset for semantic segmentation accuracy .
We study this problem with a variation, where a set of nodes are designated as target nodes, each of them is assigned with a benefit value, that can be earned by influencing them, and our goal is to maximize the earned benefit by initially activating a subset of the nodes within an allocated budget for initial activation, such that due to the cascading effect, influence in the network is maximized.
We propose to use semantic segmentation to improve facial attribute prediction and localize the attributes.
We collect a large scale airborne person ReID dataset named as Person ReID for Aerial Imagery (PRAI-1581), which consists of 39,461 images of 1581 person identities.
In this paper, we propose a novel end-to-end unsupervised deep domain adaptation model for adaptive object detection by exploiting multi-label object recognition as a dual auxiliary task.
In this paper, we provide an in-depth evaluation of the existing image captioning metrics and their relative robustness by means of extensive correlation, accuracy and distraction based evaluations.
We investigate an approach to this problem called random-pair selection, and evaluate its effectiveness compared to other published methods of subset selection. We show that our method outperforms other methods in many cases.
In this paper, we address the issue of how to enhance the generalization performance of convolutional neural networks (CNN) in the early learning stage for image classification, especially during the early stage of training.
In this paper, we propose a learning-based supervised discrete hashing method that can be simplified without performance degradation and is easier to implement.
We describe a class of recurrent convolutional architectures which are end-to-end trainable and suitable for large-scale visual understanding tasks, and demonstrate the value of these models for activity recognition, image captioning, and video description.
We present an end-to-end system that generates videos of a talking head using only a still image of a person and an audio clip containing speech, without relying on handcrafted intermediate features.
We aim to tackle a novel vision task called Weakly Supervised Visual Relation Detection (WSVRD) to detect "subject-predicate-object" relations in an image with object relation groundtruths available only at the image level.
We formalize the construction of decentralized data markets by introducing the mathematical construction of tokenized data structures, a new form of incentivized data structure.
We propose a new elastic net hypergraph learning model, which consists of two steps. In the first step, the robust matrix elastic net model is constructed to find the canonically related samples in a somewhat greedy way, achieving the grouping effect by adding the l_{2}$ penalty to the $l_{1}$ constraint.
We present a binarized CANDECOMP/PARAFAC(CP) decomposition algorithm, which we refer to as B-CP, where real-valued parameters are replaced by binary values to reduce model size.
We propose a part-level differentiable renderer for 3D pose estimation and part segmentation in 3D human body recovery.
We present a novel gradient compression framework derived from insights of real gradient distributions, and which strikes a balance between compression ratio, accuracy, and computational overhead. We prove that our techniques guarantee the convergence with diminishing compression ratio.
We propose a novel single-shot based detector, called RefineDet, that achieves better accuracy than two-stage methods and maintains comparable efficiency of one-Stage methods.
We propose a Rank Persistence Curve for real-world person re-identification, which can be used to evaluate the temporal performance of different re-id algorithms.
We propose a Saak transform based preprocessing method to defend against adversarially perturbed images.
Automatic stereo-matching based on a hierarchical, local optimization scheme for 3D reconstruction.
We propose a novel knowledge representation learning framework based on Generative Adversarial Networks (GAN).
We propose a new neural network module, contrast association unit (CAU), which explicitly models the relations between two sets of input variables and tackle it with neural networks.
This paper addresses the problem of 3D human pose estimation from depth maps employing a Deep Learning approach. We propose a model, named Deep Depth Pose (DDP), which receives a depth map containing a person and a set of predefined 3D prototype poses and returns the 3D position of the person.
We compare pretrained visual encoders that enable precomputation of visual embeddings to achieve a throughput of tens of thousands of transitions per second at training time.
We apply a block-based inference flow, network model, instruction set, and processor design jointly to optimize hardware performance and image quality for power-hungry convolutional neural networks.
Crossbar re-mapping strategies to mitigate line-resistance induced accuracy degradation in DNNs, without having to re-train the learned weights, unlike most prior works.
We propose a novel funnel-structured cascade (FuSt) detection framework for multi-view face detection with high accuracy and low time-cost.
We introduce an automatic method for generating object shapes with desired functionalities, using shape arithmetic functions.
We propose a stable method for using the validation set for training, which allows for a continuous, controlled trade-off between performance and overfitting of model selection.
Image search systems based on local descriptors typically achieve orientation invariance by aligning the patches on their dominant orientations. Albeit successful, this choice introduces too much invariance.
We propose a novel Attribute-Aware Attention Model ($A^3M$), which can learn local attribute representation and global category representation simultaneously in an end-to-end manner.
We present an incremental method, which sequentially updates the principal subspace considering weighted influence of individual images and pixels within an image.
We present a statistical parsing framework for sentence-level sentiment classification in a probabilistic way.
We use attention-based models to take into account the word saliency and propose an asymmetric architecture that focuses on the most important words of the question or the possible answers.
We propose simple approaches to improve machine interpretability of processed images: optimizing the recognition loss directly on the image processing network or through an intermediate transforming model, a process which we show can also be done in an unsupervised manner.
We study the Cross-Entropy Method (CEM) for the non-convex optimization of a continuous and parameterized objective function and introduce a differentiable variant (DCEM) that enables us to differentiate the output of CEM with respect to the objective function's parameters.
We explored the efficacy of tendon-driven limbs for autonomous learning and control across different tendon stiffness values. We demonstrate that increasing stiffness of the simulated muscles can require more iterations for the inverse map to converge but can then perform more accurately.
SteReFo interrelates stereo-based depth estimation and refocusing efficiently. We propose a physically motivated pipeline to mimic this effect from all-in-focus stereo images.
In this paper, we propose a novel graph node embedding (named PINE) via a novel notion of partial permutation invariant set function, to capture any possible dependence.
A yeast two hybrid screen identified 37 potential interacting partners of Replication Protein A, including the cell cycle regulatory protein and DNA damage clamp loader Rad24.
This paper proposes a new algorithmic framework, predictor-verifier training, to train neural networks that are verifiable, i.e., networks that provably satisfy some desired input-output properties.
We introduce a random forest semantic hashing scheme that embeds tiny convolutional neural networks into shallow random forests, with near-optimal information-theoretic code aggregation among trees, and introduce a principled and robust procedure to train and deploy in parallel an ensemble of light-weight CNNs.
We show that the problem we intend to solve can be cast as factoring a nonlinear transform of the (partially) observed matrix and develop an efficient coordinate descent based algorithm for the same.
This paper presents a novel neural model - Dynamic Fusion Network (DFN), for machine reading comprehension (MRC), in which passages, questions and answer candidates are jointly fused into attention vectors, along with a dynamic multi-step reasoning module for generating answers.
We study unsupervised learning by developing introspective generative modeling (IGM), capable of introspection: being able to self-evaluate the difference between its generated samples and the given training data.
We propose four new approaches to diversity-driven multi-net ::: ensembling, one based on fast correlation measure and three ::: incorporating a DNN-based combiner.
We find that shortest path sampling, which is used by both the R2R benchmark and existing augmentation methods, encode biases in the action space of the agent which we dub as action priors. To mitigate such priors, we propose a path sampling method based on random walks to augment the data.
In this paper we introduce BusyHands, a large open dataset of pixel-level annotated images of hands performing 13 different tool-based assembly tasks, from both real-world captures and virtual-world renderings.
We substantially improve Wu et al. (2019) in two significant ways: 1) we incorporate the energy cost of splitting different neurons to better guide the splitting process, thereby discovering more energy-efficient network architectures; 2) we substantially speed up the splittingprocess of Wu et. ( 2019), which requires expensive eigen-decomposition.
We introduce a novel 8-bit floating point training method for training deep neural networks using shifted and squeezed FP8 numbers.
We propose improved word coding schemes that can effectively reduce the vocabulary size and hence relieve the memory and computation burden of MoS without performance losses.
We propose a measure of semantic richness of Linked Data concepts and we demonstrate our hypothesis that the more a concept is reused, the less semantically rich it becomes.
LabelRank is an efficient algorithm for detecting cohesive groups in large-scale networks through label propagation.
Noisy labels are ubiquitous in real-world datasets, which poses a challenge for robustly training deep neural networks (DNNs) as DNNs have high capacity to memorize the noisy labels.
This paper proposes the control of an autonomous vehicle using a Lyapunov-based technique with a LQR-LMI tuning.
We propose a novel memory-augmented GAN module for synthesizing high-quality talking face video with personalized head movements, expressions and good lip synchronization.
In this paper, a generalized Lp-norm 2DLDA framework with regularization for an arbitrary $p>0$ is proposed, named G2DLDA.
In this work, we propose to model the interaction between visual and textual features for multi-modal neural machine translation through a latent variable model. This latent variable can be seen as a stochastic embedding.
We propose new module-based approaches to identify differentially regulated network sub-modules combining temporal trajectories of expression profiles with static network skeletons, using non-paramettric Bayesian methods.
We build on a recent hash-based technique for large-scale fusion and an efficient mean-field inference algorithm for densely-connected CRFs to present what to our knowledge is the first system that can perform dense, large- scale, outdoor semantic reconstruction of a scene in (near) real time.
A system that could enable fast and robust facial expression recognition by classifying facial muscle action units (AUs).
In this paper, we propose a deep multi-task cross-domain hashing termed \textit{DMCH}, in whichcross-domain embedding and sequential attribute learning are modeled simultaneously.
We demonstrate that large-scale unsupervised language modeling combined with finetuning offers a practical solution to this task on difficult datasets, including those with label class imbalance and domain-specific context.
CNN-based optical flow estimation in real scenes with the help of the freely available self-supervised task of next-frame prediction.
We present four cases of minimal solutions for two-view planar relative pose estimation by exploiting the affine transformation between feature points and we demonstrate efficient solvers for these cases.
We propose a framework to improve over these challenges using adversarial training. On one hand, we impose domain confusion between natural and synthetic image representations to reduce the distribution gap.
We target the most time-consuming step of the VR video creation process, high-quality flow estimation with the bilateral solver, that enables faster runtimes than existing algorithms of similar quality.
We propose a novel yet simple framework called GaterNet, which involves a backbone and a gater network for dynamic filter selection in CNNs.
We propose a novel framework termed tree branch network (TBN) for person re-identification that combines global and local feature learning.
We propose entropy regularization based on the marginal state distribution, to encourage the policy to have a more uniform distribution over the state space for exploration.
We propose a new type of convolutional autoencoders, termed as Soft-Autoencoder (Soft-AE), in which the activations of encoding layers are implemented with adaptable soft-thresholding units while decoding layers are realized with linear units. Consequently, Soft-AE can naturally interpreted as a learned cascaded wavelet shrinkage system.
In this paper, we propose Long Short-Term Memory Multi-Seasonal Net (LSTM-MSNet), a decompositionbased, unified prediction framework for time series with multiple seasonal patterns.
We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime.
In this paper, we propose a model-agnostic human pose refinement network that estimates a refined pose from a tuple of an input image and input pose, improving state-of-the-art pose estimation methods.
We propose and evaluate three novel fusion techniques, each of which is designed to ensure the utilization of visual context at different stages of the Sequence-to-Sequence transduction pipeline, even under full linguistic context.
In this paper, we analyze the epistemic requirements for Visual Intelligence, both in a top-down fashion, using existing frameworks for human-like Visual Intelligence in the literature, and from the bottom up, based on the errors emerging from object recognition trials in a real-world robotic scenario.
We explore the inconsistency issue among the attributes computed from each single image. Then, we develop two approaches to address the inconsistencies issue.
We propose PointRGCN: a graph-based 3D object detection pipeline based on graph convolutional networks (GCNs) which operates exclusively on 3D LiDAR point clouds.
In this paper, we propose a very efficient yet powerful deep neural network for driving scene semantic segmentation termed as Driving Segmentation Network (DSNet). DSNet achieves state-of-the-art balance between accuracy and inference speed.
We introduce and share SemanGit which provides a resource at the crossroads of both Semantic Web and git web-based version control systems to help developers collaborating together in the same projects.
MetaL-TDVS aims to excavate latent mechanism for summarizing video by reformulating video summarization as a meta learning problem and promote generalization ability of the trained model.
This paper employs a formal connection of machine learning with thermodynamics to characterize the quality of learnt representations for transfer learning.
We propose a deep learning framework that incorporates temporal and contextual information from tubelets obtained in videos, which dramatically improves the baseline performance of existing still-image detection frameworks when they are applied to videos.
We present our contribution to the SIGMORPHON 2019 Shared Task: Crosslinguality and Context in Morphology, Task 2: contextual morphological analysis and lemmatization.
This paper provides a comprehensive survey on works that employ Deep Learning models to solve the task of Multiple Object Tracking on single-camera videos.
We propose a multi-scale voxelization method and a decomposable dynamic convolutional layer for 3D detection networks with point clouds.
A deep learning approach based on attentional convolutional network, which is able to focus on important parts of the face, and achieves significant improvement over previous models on multiple datasets, including FER-2013, CK+, FERG, and JAFFE.
This paper proposes a novel unified framework which decomposes the detection problem into a structured polygon prediction task and a depth recovery task and achieves state-of-the-art detection accuracy.
Self-supervised research improved greatly over the past half decade, with much of the growth being driven by objectives that are hard to quantify. Consequently, the field has settled on a handful of measurements that depend on linear probes to adjudicate which approaches are the best.
We introduce a new encoder-decoder GAN model, FutureGAN, that predicts future frames of a video sequence conditioned on a sequence of past frames.
In this paper, we propose a novel computational saliency model, i.e., deep spatial contextual long-term recurrent convolutional network (DSCLRCN), to predict where people look in natural scenes.
We train a CNN to estimate the 3D face shape, which not only aligns limited facial landmarks but also fits face contours and SIFT feature points.
We propose a principled and scalable method for leveraging external background knowledge during the learning process, by imposing a set of model-dependent soft constraints on the predicate embeddings.
In this paper, we propose a deep Modular Co-Attention Network (MCAN) that consists of MCA layers cascaded in depth. Experimental results demonstrate that MCAN significantly outperforms the previous state-of-the-art.
Feature selection is an important problem in high-dimensional data analysis and classification. Conventional feature selection approaches focus on detecting the features based on a redundancy criterion using learning and feature searching schemes.
We aim to tackle a novel task in action detection - Online Detection of Action Start (ODAS) in untrimmed, streaming videos.
We propose a CNN architecture, Layer Reuse Network (LruNet), where the convolutional layers are used repeatedly without the need of introducing new layers to get a better performance.
We propose a framework to generate adversarial networks based on the gradient information in Graph Convolutional Network (GCN) and perform Fast Gradient Attack (FGA), achieving state-of-the-art attack performance.
We propose a novel method to improve the monocular 3D object detection by considering the relationship of paired samples, which improves state-of-the-art competitors by wide margins.
Protein complex formed by a group of physical interacting proteins plays a crucial role in cell activities. Great effort has been made to computationally identify protein complexes from protein-protein interaction network.
The increasing demand for higher resolution images and higher frame rate videos will always pose a challenge to computational power when real-time performance is required to solve the stereo-matching problem in 3D reconstruction applications. Therefore, the use of asymptotic analysis is necessary to measure the time and space performance.
We generate transferable adversarial samples from original ones in ImageNet, which can be used for zero-query adversarial attack.
In this paper we tackle the problem of scene flow estimation in the context of self-driving. We formulate the problem as energy minimization in a deep structured model, which can be solved efficiently in the GPU by a Gaussian-Newton solver.
We present a convolutional neural network for semantic segmentation and object recognition with 3D point clouds.
We propose an algorithm that integrates SLAM with multi-target tracking (SLAMMTT using a robust feature-tracking algorithm for dynamic environments.
We introduce UDepLambda, a semantic interface for UD, which maps natural language to logical forms in an almost language-independent fashion and can process dependency graphs, which allow handling complex phenomena such as control.
We introduce a novel, bi-directional neural network architecture for the task of matching vectors from two data sources. We use Euclidean loss for correlation maximization.
We present an ON-the-fly Native Ensemble strategy for one-stage online distillation while simultaneously establishing a strong teacher on the fly.
This paper proposes a method that uses feature fusion to represent images better for face detection after feature extraction by deep convolutional neural network (DCNN).
We propose a new neural generative model which combines variational auto-encoders and holistic attribute discriminators for effective imposition of semantic structures.
An intuitive graph optimization face recognition approach called Harmony Search Oriented-EBGM inspired by the classical Elastic Bunch Graph Matching graphical model.
In this paper, we consider the problem of building learning agents that can efficiently learn to navigate in constrained environments using high-dimensional inputs, while following feasible paths that avoid obstacles in obstacle-cluttered environment.
We propose a new abstraction, model assertions, that adapts the classical use of program assertions as a way to monitor and improve ML models.
We apply quantization techniques to FCNs for accurate biomedical image segmentation, improving state-of-the-art segmentation performance.
Visual Question Answering (VQA) presents a unique challenge as it requires the ability to understand and encode multi-modal inputs - in terms of image processing and natural language processing.
We propose a CNN-based model to give two coordinates for each event denoting the beginning and end and use receptive fields as anchors.
We propose central biasing normalization (CBN) to replace existing latent code injection for multi-mapping networks.
This paper presents an empirical study on the weights of neural networks, where we interpret each model as a point in a high-dimensional space -- the neural weight space -- and use a machine learning approach for analyzing and extracting information from this space.
We present a new approach to learning sparse, spatiotemporal codes in which the number of basis vectors, their orientations, velocities and the size of their receptive fields change over the duration of unsupervised training.
This paper presents a novel polynomial constraint for homographies compatible with the general planar motion model, which significantly reduces the execution time of obtaining a compatible homography, with accuracy and robustness comparable to that of the minimal solver.
We explore five different sets of weights for the popular ResNet-50 architecture to find out whether iris-specific feature extractors perform better than models trained for non-iris tasks. We show that the optimal training strategy is to fine-tun an off-the-shelf set of weights to the iris recognition domain.
We propose a multi-affinity spectral clustering algorithm which extends the SC algorithm with multiple affinities available.
In this paper, we propose a joint attentive spatial-temporal feature aggregation network (JAFN) for the video-based person Re-identification, simultaneously learning the quality- and frame-aware model to obtain attention-based spatial- temporal feature aggregation.
We propose a novel MTL architecture that first combines 3D convolutional neural networks (3D CNN) plus the long short-term memory (LSTM) networks together with the MTL mechanism, tailored to information sharing of video inputs.
A generative adversarial network based approach for age progression that simulates aging effects while simultaneously keeping personalized properties stable.
We propose a generative model trained with synthetic images rendered from 3D models which can reduce the burden on collecting real training data and make the background conditions more realistic.
In this paper a semi-supervised deep framework is proposed for 3D shape inverse rendering from a single 2D input image.
This document describes the findings of the Third Workshop on Neural Generation and Translation, held in concert with the annual conference of the Empirical Methods in Natural Language Processing (EMNLP 2019).
We present an approach and a benchmark for visual reasoning in robotics applications, in particular small object grasping and manipulation. We propose a reasoning system based on symbolic program execution.
We propose Matrix-LSTM, a grid of Long Short-Term Memory cells to learn end-to-end a task-dependent event-surfaces.
An attention mechanism improves facial forgery detection and localizes manipulated regions.
We present Babelfy, a unified graph-based approach to EL and WSD based on a loose identification of candidate meanings coupled with a densest subgraph heuristic which selects high-coherence semantic interpretations.
We propose a new design of efficient convolutional layers based on three schemes that utilize a convolution-projection-deconvolution pipeline to improve accuracy/complexity ratio.
We propose IROF, a new approach to evaluating explanation methods that circumvents the need for manual evaluation, making it accessible to lower resource groups and robust to human bias.
We improve SA from two aspects to promote the performance of image captioning. First, we propose Normalized Self-Attention (NSA), a reparameterization of SA that brings the benefits of normalization inside SA. Second, to compensate for the major limit of Transformer that it fails to model the geometry structure of the input objects, we extend SA to explicitly and efficiently consider the relative geometry relations between the objects.
A majority of stock 3D models in modern shape repositories are assembled with many fine-grained components. The main cause of such data form is the component-wise modeling process widely practiced by human modelers. We propose to generate part hypotheses from the components based on a hierarchical grouping strategy and perform labeling on those part groups instead of directly on the components.
This paper questions the value of these common practices and develops a simple alternative model based on binary classification for VQA, which performs competitively.
We tackle the problem of estimating optical flow from a monocular camera in the context of autonomous driving, using instance-level segmentation and convolutional nets.
We propose an end-to-end Progress Regression Recurrent Neural Network for online spatial-temporal action localization, which learns to infer the action by temporal progress regression.
We propose Stereo Visual Inertial LiDAR (VIL) SLAM that performs better on degenerate cases and has comparable performance on all other cases.
We propose SESS, a self-ensembling semi-supervised 3D object detection framework that uses only 50% labeled data and achieves competitive performance compared to state-of-the-art Fully-Supervised methods.
Stereo algorithm is important for robotics applications, such as quadcopter and autonomous driving. It needs to be robust enough to handle images of challenging conditions such as raining or strong lighting.
This paper presents an extension to the popular fuzzy c-means clustering method by introducing an additional disparity cue. The creation of the clusters is driven by a degree of the stereo match.
We employ a fully convolutional network to simultaneously segment arterioles and venules from the retinal image, rather than using a vessel segmentation-arteriovenous classification strategy as reported in most literature.
This paper proposes a novel approach to train deep neural networks by unlocking the layer-wise dependency of backpropagation training, which is used to obtain error gradients without complete feedforward and backward propagation processes.
This paper presents an algorithm called Enhanced Population-Based Training (EPBT) that interleaves the training of a DNN's weights with the metalearning of optimal hyperparameters and loss functions.
We analyze human’s disagreements about the validity of natural language inferences. We show that, very often, disagreements are not dismissible as annotation “noise”, but rather persist as we collect more ratings.
We consider the uncertainty of pedestrian representation for small-scale person re-identification. We design an improved Monte Carlo strategy that considers both the average distance and shortest distance for matching and ranking.
We probe the human visual perception of materials and build a set of classifiers for attributes that, while unnamed, function similarly to the attributes with which we describe materials.
We study the 3D volumetric modeling problem by adopting the Wasserstein introspective neural networks method (WINN) which enjoys the same properties as WINN in the 2D case: being simultaneously generative and discriminative.
We introduce a novel and efficient LRMR-based saliency detection model under a coarse-to-fine framework that integrates a l1-norm sparsity constraint and a Laplacian regularization smooth term.
In this paper, we propose a novel deep learning architecture which incorporates ConvLSTM and optical flow for recovering missing regions of video frames.
Dropout, a simple and effective way to train deep neural networks, has led to a number of impressive empirical successes and spawned many recent theoretical investigations. However, the gap between dropout's training and inference phases, introduced due to tractability considerations, has largely remained under-appreciated. In this work, we first formulate dropout as a tractable approximation of some latent variable model, leading to a clean view of parameter sharing and enabling
We propose a novel Targeted Acceleration and Compression (TAC) framework to improve the performance of 1 bit deep neural networks.
We introduce Hierarchical Cellular Automata (HCA), a temporally evolving model to intelligently detect salient objects in an image.
This paper presents a novel algorithm for ensemble-based video object segmentation in a crowd-sourcing setting.
We propose a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding.
We show that ReLU type neural networks which yield a piecewise linear classifier function fail in this regard as they produce almost always high confidence predictions far away from the training data.
We propose a novel deep network for image reconstruction. The architecture of this network is inspired by our proposed accelerated extra proximal gradient algorithm.
This paper introduces domain generalization using a mixture of multiple latent domains as a novel and more realistic scenario, where we try to train a domain-generalized model without using domain labels.
We propose a generative model, referred to as the MultiCascades model (MCM), to address the challenge of data scarcity by exploring the commonality between multiple related diffusion networks.
A variety of machine learning applications expect to achieve rapid learning from a limited number of labeled data. Meta-learning addresses this problem by extracting common knowledge across different tasks that can be quickly adapted to new tasks.
In this paper we show that canonical correlation analysis (CCA) can be adapted to bidirectional retrieval by a simple task dependent asymmetric weighting, which solves optimally the retrieval problem in a least squares sense.
In this paper a novel method for computing parallax maps from monocular and uncalibrated video sequences is described. Acquired frames are processed pairwise, starting from a first reference and progressively integrating information coming from subsequent frames in temporal order.
We propose an algorithm, guided variational autoencoder (Guided-VAE), that is able to learn controllable generative model by performing latent representation disentanglement learning.
The quality of training data is one of the crucial problems when a learning-centered approach is employed. This paper proposes a new method to investigate the quality of a large corpus designed for the recognizing textual entailment (RTE) task.
In this paper we first propose a method of incorporating high-level concepts into the successful CNN-RNN approach, and show that it achieves a significant improvement on the state-of-the-art in both image captioning and visual question answering.
We proposed an edge-based sparse disparity estimation algorithm with a novel similarity metric for real-time quality control of 3D videos.
We introduce a novel structure-aware sample consensus algorithm to solve the robust estimation problem in stereo visual odometry algorithm in underground scenario.
Feature pyramids are a basic component in recognition systems for detecting objects at different scales. In this paper, we exploit the inherent multi-scale, pyramidal hierarchy of deep convolutional networks to construct feature pyramids with marginal extra cost.
We introduce OmniSource, a novel framework for leveraging web data to train video recognition models, and establish new records with different pretraining strategies.
This paper presents a learning algorithm to simplify and speed up CNNs while maintaining performance at a desired level.
We propose a general learning framework for modeling agent behavior in any multiagent system using only a handful of interaction data.
We present a simple and efficient way to extract from a single training a large number of complementary LSTM RNN, called cohort, combined in a cascade architecture with a lexical verification, achieved state of the art results for isolated word recognition with very large lexicon.
We present a visual localization framework aided by novel deep attention aware features for autonomous driving that achieves centimeter level localization accuracy.
The focus of this paper is using a convolutional machine learning model with a modified U-Net structure for creating land cover classification mapping based on satellite imagery and assessing their usability in increasing land cover mapping accuracy and change detection.
We propose a new watermarking technology for ownership authorization of deep neural networks. We show that our framework can embed a watermark during the training of a deep neural network from scratch, and during fine-tuning and distilling.
We present Jack the Reader, a framework for Machine Reading that allows for quick model prototyping by component reuse, evaluation of new models on existing datasets as well as integrating new datasets and applying them on a growing set of implemented baseline models.
In this paper, we describe our contributions and efforts to develop Turkish resources, which include a new treebank (BOUN Treebank) with novel sentences, along with guidelines we adopted and a new annotation tool we developed (BoAT)
This paper proposes a residual learning model for inverse halftoning and image expanding.
This work studies the problem of learning appropriate low dimensional image representations. We propose a generic algorithmic framework, which leverages two classic representation learning paradigms, i.e., sparse representation and trace quotient criterion.
We present an algorithm for realtime anomaly detection in low to medium density crowd videos using trajectory-level behavior learning.
We propose a biologically supported graph neural network for EEG-based emotion recognition, which captures both local and global inter-channel relations.
We explore the role of object relations in VOG and propose a novel framework VOGNet to encode multi-modal object relations via self-attention with relative position encoding.
We aim at determining when and why the 1D and 2D recurrent models have different results. We also compare the results with a language model to assess if linguistic constraints do level the performance of the different networks.
In this paper we took inspiration from curriculum learning to progressively remove low level signals and show that it significantly increase the speed of convergence of the downstream task.
We propose SITUP: Scale Invariant Tracking using Average Peak-to-Correlation Energy.
We present a new model DRNET that learns disentangled image representations from video. Our approach leverages the temporal coherence of video.
This paper introduces an adaptive complementary tracker by online learning dynamic complementary weights.
We propose an effective yet efficient approach named Vortex Pooling to effectively utilize contextual information for semantic segmentation.
We propose ADEC (Adversarial Deep Embedded Clustering) a novel autoencoder-based clustering model, which addresses a dual problem, namely, Feature Randomness and Feature Drift, using adversarial training.
We propose Convolutional Block Attention Module (CBAM), a simple yet effective attention module for feed-forward convolutional neural networks.
We evaluate the current state-of-the-art model extraction attack (Knockoff nets) against complex models and introduce a defense based on distinguishing queries used for Knockoff nets from benign queries.
We propose Partial Matching Net (PMN) that detects body joints, aligns partial views and hallucinates missing parts based on the information present in the frame and a learned model of a person.
Preconditioned Model Building is adapted to factorize movie ratings in MovieLens data sets with 1, 10, and 20 million entries.
We explore definition modeling task and propose a novel framework (Semantics-Generator) to generate more reasonable and understandable context-dependent definitions of word embeddings.
Facial landmark detection in real world images is a difficult problem due to the high degree of variation in pose, facial expression and illumination, and the presence of occlusions and background clutter. We propose a system that addresses the problem of head pose and facial expressions in a guided unsupervised learning approach to establish mode specific models.
A semi-supervised method based on generative adversarial networks for remote sensing scene classification.
The meaning of a sentence is a function of the relations that hold between its words. We instantiate this relational view of semantics in a series of neural models based on variants of relation networks (RNs) which represent a set of objects in terms of representations of pairs of objects.
We identify eight big data dwarfs, each of which captures the common requirements of each class of unit of computation while being reasonably divorced from individual implementations among a wide variety of big data analytics workloads. We implement the eight dwarfs on different software stacks as proxy benchmarks.
We present a method for improving segmentation tasks on images affected by adherent rain drops and streaks. We train a denoising generator using this dataset and show that it is effective at removing the effect of real water droplets.
We propose a weighted multiple instances based deep correlation filter for visual tracking processing, which utilizes the importance of instances for training of deep learning model and correlation filter.
This paper assigns different weights to the patches at different levels of SPM, and then proposes a new spatial pyramid matching kernel, which improves the classification accuracy.
This paper presents a novel biometric identification system with high performance based on the features obtained from human retinal images.
We find that a greedy algorithm that recursively splits the set of categories into the two minimally confused subsets achieves 5-20 fold speedups at a small cost in classification performance.
Facial expressions are an important demonstration of humanity’s humors and emotions. Algorithms capable of recognizing facial expressions and associating them with emotions were developed and employed to compare the expressions that different cultural groups use to show their emotions.
A solution to the degeneracy problem of the Zhang's algorithm while dealing with parallel planar patterns and using the calibration data to estimate vehicle's speed.
We propose a framework which exploits the output stream of event cameras to synthesize RGB frames, relying on an initial or a periodic set of color key-frames.
We propose Temporal Alignment Module (TAM), a novel few-shot learning framework that can learn to classify a previous unseen video through temporal alignment.
We have developed a novel method, termed modified chromatin immunopurification, that allows for the efficient purification of protein-DNA macromolecules, enabling subsequent protein identification by mass spectrometry.
We propose a novel multimodal pattern mining approach towards constructing a high-level "event" schema semi-automatically, which has the capability to extend text only methods for schema construction.
We develop a generative HMM-LDA model to trace user evolution, where the Hidden Markov Model (HMM) traces her latent experience progressing over time -- with solely user reviews and ratings as observables over time.
In this paper we introduce a generic variational inference framework for generative and conditional models of text. We validate this framework on two very different text modelling applications.
We present an efficient segmentation proposal method which employs a box-hypotheses generation step followed by a lightweight segmentation strategy.We diversify segmentation strategies using class agnostics features.
We propose Dynamic Variable Effort Deep Neural Networks (DyVEDeep), which exploit the heterogeneity in the characteristics of inputs to DNNs to improve their compute efficiency while maintaining the same classification accuracy.
We develop a knowledge framework capable of modeling and interconnecting drug actions and disease mechanisms across diverse biological systems contexts, formalized in OWL, that integrates multiple ontologies, controlled vocabularies, and data schemas and interlinks these with diverse datasets.
We show that deep neural networks, during testing, also exhibit a remarkable robustness to distortions beyond quantization, including additive and multiplicative noise, and a class of non-linear projections.
This paper presents a novel recursive unit for super-resolution that adaptively recalibrates the channel importance of input features to improve performance.
Sparsity-inducing dictionaries as an effective representation for action classification in videos.Constructed dictionaries are distinct for a large number of action classes resulting in a significant improvement in classification accuracy.
Transformer is a powerful architecture that achieves superior performance on various sequence learning tasks, including neural machine translation, language understanding, and sequence prediction. In this paper, we present a new formulation of attention via the lens of the kernel.
We propose a novel framework, learning to transfer learn (L2TL), to improve transfer learning on a target dataset by judicious extraction of information from a source dataset, and employ adaptive weights for scaling of constituent loss terms.
In binocular vision, occlusion of one object by another gives rise to monocular occlusions—regions visible only in one eye. The phenomenon of depth perception from monocular Occlusions, known as da Vinci stereopsis, is intriguing.
We explore training tweaks that apply to various models including Faster R-CNN and YOLOv3 that improve their accuracies.
We build a neural-based approach to answer questions about images using a combination of LSTM and CNN.
We present YOWO, a unified CNN architecture for real-time spatiotemporal action localization in video streams.
In this paper, we investigate whether fusing depth information on top of normal RGB data for camera-based object detection can help to increase the performance of current state-of-the-art single-shot detection networks.
In this paper we propose introspective classifier learning (ICL) that emphasizes the importance of having a discriminative classifier empowered with generative capabilities.
We propose a novel dataset which contains transcribed ADs, which are temporally aligned to full length movies and propose a challenge to automatically generate descriptions for the movie clips.
A new image description algorithm ML-RCroW based on multilayer multiregion cross-weighted aggregational deep convolutional features is proposed.
This work introduces a novel method for improving answer selection on long documents through weighted global normalization of predictions over portions of the documents.
We propose Dynamically Pruned Message Passing Networks (DPMPN) for knowledge graph reasoning.
We employ word/subword-level based models that adopt large-scale data-driven methods such as pre-trained language models and transfer learning in analyzing text for the clinical domain.
In this paper, we present LaserNet, a computationally efficient method for 3D object detection from LiDAR data in the native range view of the sensor, where the input data is naturally compact.
We propose an end-to-end neural model that enables those answer candidates from different passages to verify each other based on their content representations.
We propose a graph-based recursive neural network framework for collective vertex classification in a graph based on both vertex attributes and link structure.
In this paper we propose a novel detector-tracker feedback loop for information exchange based on spatio-temporal similarity of detections and tracklets based on positive feedback principle.
We explore the question of whether the representations learned by classifiers can be used to enhance the quality of generative models.
We propose a Geometry-Contrastive Generative Adversarial Network (GC-GAN) for transferring continuous emotions across different subjects.
We have developed Utopia Documents, a novel PDF reader that semantically integrates visualization and data-analysis tools with published research articles.
We propose a novel keyword extraction method for Visual Question Answering (VQA), which can extract the keyword without any keyword annotations.
We leverage the query-response-future turn triples to induce the generated responses that consider both the given context and the future conversations, which effectively boosts the informativeness and coherence of the generated response on both automatic and human evaluation.
We show that increasing the number of parameters in adversarially-trained models increases their robustness, and in particular that ensembling smaller models while adversarically training the entire ensemble as a single model is a more efficient way of spending said budget than simply using a larger single model.
This paper describes a representation of speech based on an unsupervised triplet-loss objective, which exceeds state-of-the-art performance on a number of transfer learning tasks drawn from the non-semantic speech domain. The model will be publicly released.
We explore the use of both RNNs and Temporal-ConvNets for extracting spatiotemporal information within video sequences without requiring extensive temporal augmentation.
This paper proposes an affinity aggregation spectral clustering (AASC) algorithm for multiple affinities available.
We propose the first weakly-supervised body part parsing framework that uses existing weak labels such as poses and full body masks.
We propose a novel multi-head self-attention network to capture various components of visual and textual data by attending to important parts in data and achieve state-of-the-art results in image-text retrieval tasks.
Intensity-trained multiclass and regression models outperformed binary-trained classifier decision values on smile intensity estimation across multiple databases and methods.
We provide the first evidence for co-occurrences of Alu-mediated events at transcriptome-wide scale through integrative analysis of data sets across diverse experimental platforms and tissues.
A whole-head myographic recorder of head and face muscle activity using magnetoencephalography as a whole- head electromyographic recorder.
We show that existing upsampling operators can be unified using the notion of the index function, and introduce a novel index-guided encoder-decoder framework where indices are self-learned adaptively from data and are used to guide the pooling and upsampler operators, without extra training supervision.
We propose DAWN-RPN, where we simply augment our memory and attention LSTM modules to the state-of-the-art SiamRPN and report immediate performance gain.
We propose a framework for training robust neural networks that induces invariance to nuisances through learning to discover and separate predictive and nuisance factors of data.
This paper considers the resource and accuracy trade-off for resource-restricted usages during designing the whole object detection framework. Based on the deeply supervised object detection (DSOD) framework, we propose Tiny-DSOD dedicating to resource restricted usages.
We present a joint learning approach for obtaining dense correspondences and discovering object landmarks from semantically similar images that addresses the lack of training data in a principled manner.
Automatic diagnosis of diabetic retinopathy using deep convolutional neural network models .
Automated temporal segmentation of human motion data into distinct actions and compositing motion primitives based on self-similar structures in the motion sequence.
We hypothesise that iterative processing of the input, together with shifting attention between the iterations will be needed to efficiently and reliably solve real world relational concept learning.
We present a proof-of-concept system that demonstrates the utility of linked data for enhancing the application of Music Information Retrieval (MIR) workflows, both when curating collections of music signal data for analysis, and publishing results that can be simply and readily correlated to these, and other, collection sets.
In this paper we address the problem of generating person images conditioned on a given pose. We introduce deformable skip connections in the generator of our Generative Adversarial Network.
A survey of the databases created for ocular recognition, detailing their protocols and how their images were acquired, highlighting the submitted algorithms that achieved the best results using only iris trait.
We validate which parts of questions are essential for obtaining valid answer. In order to conclude that, we take advantage of LIME - a framework that explains prediction by local approximation.
We use a network-based transfer learning strategy to effectively utilize all useful information, including category labels and bounding-box information of all objects and valid generated masks.
We present a pixel recursive super resolution model that synthesizes realistic details into images while enhancing their resolution.
This paper presents a novel end-to-end framework for monocular VO by using deep Recurrent Convolutional Neural Networks.
We introduce a multi-camera database of 46 people recorded while driving a simulator in two conditions, baseline and induced cognitive load, where we use features extracted from AU values and their cross-correlations in order to exploit recurring synchronization and causality patterns.
The interaction of the pathways to get more appropriated results has been investigated in biological movements.
We present a new perspective on form understanding and deep Web data acquisition that does not require any domain-specific knowledge.
In this paper, we present a new paradigm to zero-shot learning (ZSL) that is trained by utilizing additional information (such as attribute-class mapping) for specific set of unseen classes, while restricting cross-group correlations.
We propose a novel Global Context Instructive Network (GCINet), which devotes to making full use of extracted features and obtaining precise counts.
A novel Multimodal Encoder-Decoder Attention Networks for Visual Question Answering .
This paper provides a critical review of visual descriptors used for scene categorization, from both methodological and experimental perspectives.
This paper introduces a generic framework to train deep networks, end-to-end, with no supervision.
Sample mixing methods are used to test how neural networks learn and infer from mixed samples to illustrate how mixups work as a data augmentation method and how it regularizes neural networks.
This paper presents a novel Robust Deep Appearance Models to learn the non-linear correlation between shape and texture of face images.
We propose a novel framework for abnormal event detection in video that requires no training sequences. Our framework is based on unmasking, a technique previously used for authorship verification, which we adapt to our task.
We build a semantically enriched model for modal sense classification by novelly applying features that relate to lexical, proposition-level, and discourse-level semantic factors.
This paper tackles the problem of novel view synthesis from a single image by exploiting the 3D geometry of the scene to synthesize a novel view.
In this paper, we explore visual attention mechanism for video analysis and propose a novel 3D-CNN model, dubbed AE-I3D (Attention-Enhanced Inflated-3D Network), for learning attention-enhanced spatiotemporal representation.
BERT-based architectures currently give state-of-the-art performance on many NLP tasks, but little is known about the exact mechanisms that contribute to its success.
A multiple window correlation algorithm for stereo matching which addresses the problems associated with a fixed window size.
The changes in retinal blood vessels Structure and progression of diseases such as diabetes, hypertension and retinopathy of prematurity (ROP) has been the subject of several large scale clinical studies. Proposed algorithm for the detection and measurement of blood vessels of the retina and finding the bifurcation points of blood vessel is general enough that it can be applied to high resolution fundus photographs.
We propose a multi-resolution convolutional neural network for lung nodule candidate classification.
We address a learning-to-normalize problem by proposing Switchable Normalization (SN), which learns to select different normalizers for different normalization layers of a deep neural network.
In this paper, we present RegNet, the first deep convolutional neural network (CNN) to infer a 6 degrees of freedom (DOF) extrinsic calibration between multimodal sensors, exemplified using a scanning LiDAR and a monocular camera.
We propose a method to address multiple object tracking problem by defining a dissimilarity measure based on object motion, appearance, structure, and size.
We propose a novel architecture for recommender systems that can utilize rich data collected about the user (possibly through other services) to produce more accurate recommendations, while allowing its users to manage and gain control over their own data.
We present an automated FF parameterization method which can utilize either DFT calculations or approximate QM energies produced by different neural network potentials (NNPs), to obtain improved parameters for molecules.
In this paper, we present a general method of deep learning for the human action recognition.
This paper addresses 360-degree road scene semantic segmentation using surround view cameras using Restricted Deformable Convolution, which can effectively model geometric transformations.
In this paper, we propose to extract the non-textual contents from the videos themselves to enhance the personalized video recommendation.
We examine the effect of different types of label noise on the performance of an object detector. We then show how co-teaching, a method developed for handling noisy labels and previously demonstrated on a classification problem, can be improved.
We present a model for the joint estimation of disparity and motion. The model is based on learning about the interrelations between images from multiple cameras, multiple frames in a video, or the combination of both.
We propose a novel 3D Cylindrical Trace transform for 3D action recognition, extending the capabilities of the Trace transform to the 3D domain.
We present an adversarial domain invariant feature learning framework (ADIN) that explicitly learns to separate identity-related features from challenging variations, where free annotations in ReID data such as video timestamp and camera index are utilized.
We use the synchronisation confidence score as a proxy for audio-visual correlation and based on it we can detect adversarial attacks.
This paper researches how to apply the convolutional neural network (CNN) based algorithm on a chest X-ray dataset to classify pneumonia.
We propose a generative approach, referred to as multimodal stochastic recurrent neural networks (MS-RNNs), which models the uncertainty observed in the data and generate multiple sentences to describe a video considering different random factors.
We present a simple enhancement of CP (which we call SimplE) to allow the two embeddings of each entity to be learned dependently. We show empirically that, despite its simplicity, SimplE outperforms state-of-the-art tensor factorization techniques.
Neural network-based dependency parser for universal dependency parsing of multilingual text .
We propose a novel optimization method, the Kalman Optimization for Value Approximation (KOVA), based on the Extended Kalman Filter, which minimizes the regularized objective function by adopting a Bayesian perspective over both the value parameters and noisy observed returns.
We propose a new implementation for back-propagation that significantly reduces memory usage, by enabling the use of approximations with negligible computational cost and minimal effect on training performance.
A hybrid-based method based on semi-global matching and shape-adaptive cross-based matching for dense stereo matching.
Binary representation is desirable for its memory efficiency, computation speed and robustness. In this paper, we propose adjustable bounded rectifiers to learn binary representations for neural networks.
A novel circular and structural operator tracker (CSOT) for visual tracking, it not only possesses the powerful discriminative capability of SOSVM but also efficiently inherits the superior computational efficiency of DCF.
We introduce an object-centered graph network model for lift-the-flap games and demonstrate its usefulness in context-aware object recognition and target priming.
In this work, we aim to solve data-driven optimization problems, where the goal is to find an input that maximizes an unknown score function given access to a dataset of inputs with corresponding scores.
We address all three issues. First, we leverage a large-scale but noisy landmark dataset and develop an automatic cleaning method that produces a suitable training set for deep retrieval. Second, we build on the recent R-MAC descriptor, show that it can be interpreted as a deep and differentiable architecture, and present improvements to enhance it. Last, we train a siamese architecture that combines three streams with a triplet loss.
We present the first membership inference attacks against generative models: given a data point, the adversary determines whether or not it was used to train the model.
We propose and evaluate a novel protocol to evaluate low-shot learning on complex images where the learner is permitted to first build a feature representation.
We present novel end-to-end attacks on autonomous driving in simulation, using simple physically realizable attacks: the painting of black lines on the road.
In this paper, a novel supervised learning method, called Sparsity Preserving Discriminant Projections (SPDP), is proposed to preserve the sparse representation structure of the data and maximize the between-class separability simultaneously.
We use a modified softmax function, termed Sphere Softmax, to solve the classification problem and learn a hypersphere manifold embedding simultaneously and achieve state-of-the-art performance on four challenging datasets.
We propose symbolic learning as extensions to standard inductive learning models such as neural nets as a means to solve few shot learning problems. By augmenting neural nets with them, we develop and evaluate a tool that solves few shot visual discrimination puzzles with interpretable concepts.
We present a sequence-to-action parsing approach for the natural language to SQL task that incrementally fills the slots of a SQL query with feasible actions from a pre-defined inventory.
Generative adversarial networks do not generalize outside the lab. We study their ability to fit simple transformations such as camera movements and color changes.
We propose a new adaptive downsampling technique that learns to favor sampling locations near semantic boundaries of target classes improving balance between accuracy and computational efficiency.
The rise of deep learning technique has raised new privacy concerns about the training data and test data. In this work, we investigate the model inversion problem in the adversarial settings, where the adversary aims at inferring information about the target model's training Data and test Data from the model's prediction values.
We leverage existing translations of WordNet in other languages to identify contextual information for wordnet senses from a large set of generic parallel corpora, which improves on translation without any contextual information.
In this paper, we propose a method for segmenting blood vessels from retinal images using Gabor wavelet and line operator.
We propose a novel, self-supervised training scheme for obtaining high-quality, pre-trained networks from unlabeled, cross-modal medical imaging data, which will allow for creating accurate and efficient models.
In this paper we propose a novel iterative approach for adapting-weights aggregation which produces better results and out-performs most previous adaptations-weights methods.
We propose a framework to tackle the Video-Fill-In-the-Blank (VFIB) problem and introduce an extended and generalized version of VFIB, which is not limited to a single blank.
We propose an approach to detect attacks on recommender systems using Random Forest Classifier and find that, when tested at 10% attack, our approach outperformed earlier proposed approaches.
We propose a cross-modal message passing mechanism to fuse two-stream network for action recognition, which composes of an appearance modal network (RGB image) and a motion modal (optical flow image) network.
In this paper, we propose Efficient Progressive Neural Architecture Search (EPNAS), a neural architecture search that efficiently handles large search space through a novel progressive search policy with performance prediction based on REINFORCE.
We proposed four new feasible network schemes, and the best network model fully dilated convolution combining U-Net is obtained by training and testing on the same datasets.
[Rogmans, Sammy; Dumont, Maarten; Cuypers, Tom; Bekaert, Philippe] Hasselt Univ tUL IBBT, Expertise Ctr Digital Media, B-3590 Diepenbeek, Belgium.
This paper is about the efficient generation of dense, colored models of city-scale environments from range data and in particular stereo cameras.
We introduce two novel approaches, Knowledge Adjustment (KA) and Dynamic Temperature Distillation (DTD), to penalize bad supervision and improve student model.
This paper presents a fully automatic parallel software for the localization of the optic disc in retinal fundus color images.
This paper proposes an end-to-end trainable network, SegFlow, for simultaneously predicting pixel-wise object segmentation and optical flow in videos.
An end-to-end generative approach from the encoding of features to the structural modeling of complex human activities by applying Fisher vectors and temporal models for the analysis of video sequences.
In this paper, quadratic connections of LSTM model is proposed in terms of RvNNs (abbreviated as qLSTM-RvNN) in order to attack the problem of representing compositional semantics.
We propose a hybrid representation, which leverages the discriminative capacity of CNNs and the simplicity of descriptor encoding schema for image recognition, with a focus on scene recognition.
This paper presents a Bayesian framework for 3D facial reconstruction. The framework iteratively deforms a generic face mesh to fit a set of range points.
In this paper we propose a new computational model where the configuration and the size of the core become a part of the decisions to be optimized.
We introduce a novel network, called CO-attention Siamese Network (COSNet), to address the unsupervised video object segmentation task from a holistic view. We emphasize the importance of inherent correlation among video frames.
We discuss relations between Residual Networks (ResNet), Recurrent Neural Networks (RNNs) and the primate visual cortex. We begin with the observation that a shallow RNN is exactly equivalent to a very deep ResNet.
A comprehensive study on the performance of the Completed Local Ternary Pattern (CLTP) for face recognition task.
We propose to represent a solver for each task as a neural module that calls existing modules (solvers for simpler tasks) in a functional program-like manner in order to learn a new solution.
A key initial step in several natural language processing (NLP) tasks involves embedding phrases of text to vectors of real numbers that preserve semantic meaning. In this paper we investigate the effects of word substitution errors on several state-of-the-art sentence embedding methods.
We propose a novel method for using compressed video data for video understanding, by using the data from the compressed stream as a one unit clip and using the residual frames to replace the original RGB frames.
We propose a real-time framework that can accurately detect, track and predict the intended actions of pedestrians based on a tracking-by-detection technique in conjunction with a novel spatio-temporal DenseNet model.
A simple extension to the back-propagation method that adds an adversarial gradient to the training, that increases the resistance to adversarial examples and boosts the classification performance.
Combining saliency models that identify the important parts of the source text with the pre-trained seq-to-seq models can improve the fluency of abstractive summarization.
We propose a data-free substitute training method to obtain substitute models for adversarial black-box attacks without the requirement of any real data.
We propose a novel disturbance-immune training scheme for neural architecture search that alleviates the performance disturbance issue.
We propose a unified framework, named Memory Aggregation Networks (MA-Net), to address the challenging iVOS in a more efficient way.
The goal of this work is to segment the objects in an image that are referred to by a sequence of linguistic descriptions (referring expressions) using a deep neural network with recurrent layers.
This paper describes the systems that we submitted to the WMT19 Machine Translation robustness task, and proposes solutions for robustness to noise and domain adaptation.
We propose a keyword controlled network (KCN) which can be used as an assistant paraphrase generation tool.
Batch normalized recurrent highway networks are proposed to control the gradient flow in an improved way for network convergence.
We present Generative Adversarial Capsule Network (CapsuleGAN), a framework that uses CapsNets instead of the standard convolutional neural networks (CNNs) as discriminators within the generative adversarial network (GAN) setting.
We propose a 3D Constrained Local Model framework for deformable face alignment in depth image by utilizing robust histogram-based 3D geometric features that further improves the facial landmark localization accuracy.
We propose a general model for predicting sets from feature vectors that respects the structure of sets and avoids this problem.
We propose a color image segmentation approach based on rough set theory elements, which achieves state-of-the-art performance.
We address plausible hole filling in depth images in a computationally lightweight ::: methodology that leverages recent advances in semantic scene segmentation.
This paper proposes a novel model that learns how to both generate and modify the facial image from high-level semantic attributes from a semi-Latent space.
We show how a set of kernel functions that we refer to as rotation invariant kernels can be used to convert the original nonlinear problem into a linear one.
We propose a novel Hierarchical Long Short-Term Concurrent Memory (H-LSTCM) to model the long-term inter-related dynamics among a group of persons for recognizing human interactions.
We improve the temporal relocalization method by using a network architecture that incorporates Kalman filtering in the context of Bayesian learning.
We present NoScope, a system for querying videos that can reduce the cost of neural network video analysis by up to three orders of magnitude via inference-optimized model search.
In this paper, we propose an iterative rigid registration framework that estimates the misalignment with trained regressors and performs coarse-to-fine registration efficiently.
We investigate architectures of discriminatively trained deep Convolutional Networks (ConvNets) for action recognition in video.
We propose a scale-Aware Multi-resolution method for pedestrian detection which can adaptively select multi-resolution convolutional features according to pedestrian sizes.
In this paper, we analyze how increasing the number of these interactions affects link prediction performance, and utilize our observations to propose InteractE, a novel feature reshaping method that captures rich interactions between their components.
We present a system that reformulates a given question into queries that are used to retrieve supporting text from a large corpus of science-related text. We use a generalizable decision methodology over the retrieved evidence to select the best answer.
We use instance isolation to transform this multi-instance segmentation problem into binary labeling problem, and use weighted cross entropy loss and dice coefficient loss as our loss function.
We propose an approach for open set domain adaptation where the target domain contains instances of categories that are not present in the source domain.
In this paper, we contend that it is actually better to ignore the labels of some of the data points than to keep them if the labels are incorrect, especially when the noisy rate is high.
Spatial-Temporal Synergic Residual Network (STSRN) for person re-identification in video setting.
Generating adversarial 3D meshes from objects that have rich shape features but minimal textural variation.
We propose a new method of designing activation functions within a neural network at each layer to allow for multiple activation functions to be active at each neuron.
We explore the problem of training one-look regression models for counting objects in datasets comprising a small number of high-resolution, variable-shaped images. To reduce overfitting, we propose to use global sum pooling (GSP) instead of global average pooling.
We propose an online shortest-path meta-learning framework for domain adaptation that is both computationally tractable and practically effective for improving DA performance.
We propose a generalization of group representation theory and noncommutative harmonic analysis that uses the Clebsch--Gordan transform as its only source of nonlinearity.
The current trend of pushing CNNs deeper with convolutions has created a pressing demand to achieve higher compression gains on CNNs where convolutions dominate the computation and parameter amount (e.g., GoogLeNet, ResNet and Wide ResNet).
We propose Sparsity aware Core Extensions (SparCE), a set of micro-architectural and ISA extensions that leverage sparsity and are minimally intrusive and low-overhead.
We propose Deep Triplet Quantization (DTQ), a compact coding solution, focusing on deep learning to quantization approach that has shown superior performance over hashing solutions for similarity retrieval.
We introduce the CODAH dataset, an adversarially-constructed evaluation dataset for testing commonsense knowledge using sentence-completion questions.
We propose a novel GAN based method that makes an explicit use of the discriminator in test-time, in a feedback manner in order to improve the generator results.
We propose a self-supervised network (SSL-Net) to generate 3D point clouds from a single RGB image, unlike the existing work which requires multiple views of the same object to recover the full 3D geometry.
We propose a Smooth Adaptive Activation Function (SAAF) with piecewise polynomial form which can approximate any continuous function to arbitrary degree of error. NNs with SAAFs are Lipschitz continuous given a bounded magnitude of the NN parameters.
We present a novel approach for recognizing human action categories in videos by combining information from appearance and motion of human body parts.
Dense crowd counting aims to predict thousands of human instances from an image, by calculating integrals of a density map over image pixels. In this paper, we propose a simple yet effective approach to tackle this problem.
We address the task of single depth image inpainting. We propose a low gradient regularization method in which we reduce the penalty for small gradients while penalizing the nonzero gradients.
We present an analysis of possible adversarial models, and propose an evaluation framework for comparing different defense mechanisms. Furthermore, we propose a new defense mechanism called Random Spiking.
This paper focuses on the crowd-annotation of an ancient Maya glyph dataset derived from the three ancient codices that survived up to date.
A method, system, and storage device storing a computer program, for generating questions based on provided content, such as, for example, a document having words.
Deep multi-task learning is extended in this paper to the setting where there is no obvious overlap between task architectures, and the results confirm that sharing learned functionality across diverse domains and architectures is indeed beneficial, thus establishing a key ingredient for general problem solving in the future.
Top-down probabilistic visual attention model for manipulated object recognition in egocentric video content.
We review a ten-year biometric sampling effort that enabled the creation of several key biometrics challenge problems.
We present a principled approach to federated domain adaptation, which aims to align the representations learned among the different nodes with the data distribution of the target node.
In this paper, we propose a special long short-term memory (LSTM) architecture for natural language inference. This LSTM is able to place more emphasis on important word-level matching results.
A comparison of chord diagrams and bar charts for understanding blind-spots in consumption profiles.
We introduce SpERT, an attention model for span-based joint entity and relation extraction. The model is trained using strong within-sentence negative samples, which are efficiently extracted in a single BERT pass.
We address the issue of developing a convolution method in the context of a computational model of the visual cortex, exploring quadratic forms through the Volterra kernels, yielding results competitive with state-of-the-art on CIFAR-10 and CIFar-100.
We propose TAL-Net, an improved approach to temporal action localization in video that is inspired by the Faster RCNN object detection framework. We improve receptive field alignment using a multi-scale architecture that can accommodate extreme variation in action durations.
 jiant enables modular and configuration-driven experimentation with state-of-the-art models and implements a broad set of tasks for probing, transfer learning, and multitask training.
We describe an end-to-end framework for learning parameters of min-cost flow multi-target tracking problem with quadratic trajectory interactions including suppression of overlapping tracks and contextual cues about co-occurrence of different objects.
In this paper, a flow-based interpolation method (FI-Net) is proposed.
We propose a novel multi-task learning of cas- caded convolutional neural network method for predicting multiple facial attributes simultaneously.
We present a recurrent neural network based system for automatic quality estimation of natural language generation (NLG) outputs, which jointly learns to assign numerical ratings to individual outputs and to provide pairwise rankings of two different outputs.
We show how to improve LM-GEC by applying modelling techniques based on finite state transducers.
We propose an extension of SemanticKITTI with strong baselines for LiDAR-based panoptic segmentation and propose a state-of-the-art detector enriching the segmentation with temporally consistent instance information.
We used automated face analysis to assess treatment response to deep brain stimulation (DBS) in two patients with intractable obsessive-compulsive disorder (OCD) with parametric variation of DBS.
We propose a fully differentiable unsupervised deep clustering approach to learn semantic classes in an end-to-end fashion without individual class labeling using only unlabeled object proposals.
We propose an automatic semantic concept discovery scheme for video event detection by exploiting Internet images and their associated tags.
We propose Greedy NTPs, an extension to Neural Theorem Provers addressing their complexity and scalability limitations, thus making them applicable to real-world datasets, achieving competitive link prediction results on large datasets.
This paper presents a simple yet effective approach for character segmentation of such difficult slanted cursive words without using any slant correction.
Communication on heterogeneous edge networks is a fundamental bottleneck in Federated Learning (FL), restricting both model capacity and user participation. To address this issue, we introduce two novel strategies to reduce communication costs: (1) the use of lossy compression on the global model sent server-to-client; and (2) Federated Dropout.
In this paper, we propose a novel method for determining the configuration of the 2D-3D geometric constraints which is based on the well-known two stage object detection framework.
The Visual Question Answering (VQA) task combines challenges for processing data with both Visual and Linguistic processing and enabling robustness of the machine-learning models.
We propose an adaptive adaptive graph representation learning scheme for video person Re-ID, which enables the contextual interactions between the relevant regional features for robustness to many complicated situations.
In this paper our objectives are, first, networks that can embed audio and visual inputs into a common space that is suitable for cross-modal retrieval, and second, a network that can localize the object that sounds in an image, given the audio signal. We achieve both these objectives by training from unlabelled video using only audio-visual correspondence (AVC) as the objective function.
Texture synthesis techniques based on matching the Gram matrix of feature activations in neural networks have achieved spectacular success in the image domain. In this paper we extend these techniques to the audio domain and introduce an audio analogue to the Inception loss which we term VGGish loss.
We propose a new paradigm, HyperDef, for hypernymy detection -- expressing word meaning by encoding word definitions, along with context driven representation.
We propose a data-dependent upsampling (DUpsampling) to replace bilinear, which takes advantages of the redundancy in the label space of semantic segmentation and is able to recover the pixel-wise prediction from low-resolution outputs of CNNs.
We present an approach for distantly supervised road segmentation that only requires image-level annotations at training time, while using orders of magnitude less annotation work.
This paper presents a novel method for analyzing the robustness of semantic segmentation models and provides a number of metrics to evaluate the classification performance over a variety of environmental conditions.
We focus on using large-batch data-parallelism synchronous SGD without losing accuracy in the fixed epochs.
This work addresses the problem of automatically summarizing egocentric photo streams captured through a wearable camera by taking an image retrieval perspective by taking a CNN-based filter.
We propose DOPS, a fast single-stage 3D object detection method for LIDAR data that both detects objects in 3D and estimates their shapes.
We propose a new L1 regularizer for Complex Embeddings, which promotes symmetry or antisymmetry of the scoring function on a relation-by-relation basis, in accordance with the observed data.
We propose a multi-view representation learning approach, which promotes the collaboration of different views and lets them vote for the robust representations across different views.
We take a standard neural architecture for this task, and show that by providing rich contextualized word representations from a large pre-trained language model as well as allowing the model to choose between context-dependent and context-independent word representations, we can obtain dramatic improvements and reach state-of-the-art performance.
We propose a novel multi-perspective framework for cloze-style reading comprehension, which can be seen as the joint training of heterogeneous experts and aggregate context information.
We show that landmark weighting is instrumental to improve the accuracy of shape reconstruction and propose a novel 3D Morphable Model Fitting method for 3D face reconstruction by 3DMM.
We propose a novel algorithm for stereo matching using a dynamical systems approach.
We propose a joint graphical model for point trajectories and object detections whose Multicuts are solutions to motion segmentation {\it and} multi-target tracking problems at once.
We propose a novel semi-supervised method based on the theory of the low-rank matrix recovery for face recognition, which can simultaneously learn discriminativelow-rank and sparse representations for both training and testing images.
This paper addresses a challenging problem -- how to generate multi-view cloth images from only a single view input. We propose a new image generation model termed VariGANs that combines the strengths of variational inference and the Generative Adversarial Networks (GANs).
Novel Change-Point Methods for detecting possible changes in stationarity in graphs generated by stochastic processes.
In this paper, we propose a self-attentive bidirectional long short-term memory network to predict multiple emotions for the EmotionX challenge.
We try not only to present a deep review of the different approaches/techniques used in the previous works to estimate the size of the crowd but also to describe the different datasets used.
We present a method for decomposing the 3D scene flow observed from a moving stereo rig into stationary scene elements and dynamic object motion.
We propose unitary group convolutions (UGConvs), a building block for CNNs which compose a group convolution with unitary transforms in feature space to learn a richer set of representations than groupconvolution alone, and propose HadaNet, a UGConv network using Hadamard transforms.
We build a highly scalable deep learning training system for dense GPU clusters with three main contributions: a mixed-precision training method that significantly improves the training throughput of a single GPU without losing accuracy.
In this paper, we describe DeFactoNLP, the system we designed for the FEVER 2018 Shared Task that can not only automatically assess the veracity of a claim but also retrieve evidence supporting this assessment from Wikipedia.
Gaze direction is a strong attentional cue in guiding eye movements, complementing low-level saliency cues, and derived from both face and eyes of actors in the scene.
We provide a detailed analysis of convolutional neural networks which are pre-trained on the task of object detection on large datasets like OpenImagesV4, ImageNet Localization and COCO.
The ability to detect and classify rare occurrences in images has important applications - for example, counting rare and endangered species when studying biodiversity, or detecting infrequent traffic scenarios that pose a danger to self-driving cars.
We present a regularization based method for limiting network sensitivity to its inputs, inspired by ideas from computer vision, thus learning models that are more robust to noise and adversarial attacks.
We study automatic question generation for sentences from text passages in reading comprehension. We introduce an attention-based sequence learning model for the task.
In this paper, we propose a novel approach to detect GAN generated fake images using a combination of co-occurrence matrices and deep learning.
We apply descriptor learning to construct line segment descriptors optimized for matching tasks. We construct a new line based SLAM pipeline built upon a state-of-the-art point only system.
In this paper, we formulate the deblurring task on traditional cameras directed by events to be a residual learning one, and we propose corresponding network architectures for effective learning of deblring and high frame rate video generation tasks.
The best solution of structured prediction models in NLP is often inaccurate because of limited expressive power of the model or to non-exact parameter estimation. One way to mitigate this problem is to improve the parameter estimation .
Knowledge base plays an important role in machine understanding and has been widely used in various applications, such as search engine, recommendation system and question answering.
We propose a practical object detection method with scale-sensitive network, which is fast and efficient.
We explore the use of unsupervised sparse coding applied to stereo-video data to help alleviate the need for large amounts of labeled training data in domains where such datasets are available.
We propose structural model distillation for memory reduction using a strategy that produces a student architecture that is a simple transformation of the teacher architecture: no redesign is needed, and the same hyperparameters can be used.
This paper presents a new method to extract tubular structures from bi-dimensional images using geodesic curves over a four-dimensional space.
We adapt the best performing guaranteed algorithm, FrequentDirections, in a way that preserves the guarantees, and nearly matches iSVD in practice.
This paper aims to obtain effective and compact action representation with length-variable edge trajectory (LV-ET) and spatio-temporal motion skeleton (STMS), a novel edge-based trajectory extracting strategy.
We propose a novel structure-aware convolutional network to implicitly take priors about the structure of human bodies into account during training of the deep network.
We introduce a novel mixed-size training regime that mixes several image sizes at training time, which allows faster inference by using smaller images at test time.
We propose a self-supervised network that is competitive with supervised methods on standard evaluation metrics of dense tracking, and achieves performance comparable to supervised methods.
We propose analog signal processing as a solution to this problem. We propose novel modifications to the algorithms and new imaging architectures to address these requirements.
We describe a way of reducing the noise associated with distant IE by identifying coupling constraints between potential instance labels, which improves performance substantially.
We propose to learn how to quickly and effectively adapt online to new situations as well as to perturbations.
This review clarifies the definition of multimodal retrieval requirements and some related concepts, then introduces some representative hashing methods, mainly supervised methods that make full use of label information.
We present a neural network tailored for Digital Surface Model generation from satellite imagery, a training scheme which maximizes available hardware, and a comparison to existing methods.
We extend previous work in unsupervised text-only disambiguation with methods that integrate text and images, as this sort of data is common.
In crowd counting datasets, each person is annotated by a point, which is usually the center of the head. Most of the state-of-the-art methods are based on density map estimation, which convert the sparse point annotations into a "ground truth" density map through a Gaussian kernel, and then use it as the learning target to train a density map estimator.
We propose a new biometric identification system based on Fourier transform and angular partitioning of the spectrum for retinal image.
We propose the probability-based detection quality (PDQ) measure which evaluates both spatial and label probabilities, requires no thresholds to be predefined, and optimally assigns ground truth objects to detections.
We have developed a novel feature selection method, called saliency-based feature selection (SFS), based on deep-learning saliency techniques, which works under any architecture that is trained by gradient descent techniques.
In this paper, a cooling-shrinking attack method is proposed to deceive state-of-the-art SiameseRPN-based trackers.
We propose subspace alignment based domain adaptation of the state of the art RCNN based object detector. The aim is to be able to achieve high quality object detection in novel, real world target scenarios without requiring labels from the target domain.
We exploit a Dynamic Feature Generation Network (DFGN) to exploit a variety of attention mechanisms for textual mining.
We propose a novel method based on our attention long short-term memory network for fine-grained age estimation in the wild, inspired by the fine- grained categories and the visual attention mechanism.
We introduce the cross-channel intragroup (CCI) sparsity structure that can avoid the inference inefficiency of fine-grained pruning while maintaining outstanding model performance.
We present SirenAttack, a new class of attacks to generate adversarial audios that can deceive a range of end-to-end acoustic systems under both white-box and black-box settings, achieving 99.45% attack success rate on the IEMOCAP dataset.
In this paper, we present a generative model based approach to solve the multi-view stereo problem.
We propose using a multimodal learning and object identification framework with an alternative platform, called High Performance Computing Cluster (HPCC Systems®), to speed up the optimization stages and to handle data of any dimension.
We propose the DEeP Attribution gRAph (DEPARA) to investigate the transferability of knowledge learned from PRe-trained Deep Neural Networks.
We investigate the use of standard pruning methods, developed primarily for supervised learning, for networks trained without labels, for self-supervised learning.
We propose a knowledge-incentive approach for entity annotation in biomedicine, and present Me Detect, a prototype system that we developed based on this approach.
Stereo matching is a challenging issue in computer vision field. To address the poor accuracy behavior of local algorithms, we propose an improved stereo matching algorithm based on guided image filter.
In this paper we propose a novel approach to tracking by detection that can exploit both cameras as well as LIDAR data to produce very accurate 3D trajectories.
We explore the problem of intersection classification using monocular on-board passive vision, with the goal of classifying traffic scenes with respect to road topology.
Unsupervised video object segmentation without online supervision using non-local temporal dependencies .
In this paper, we propose a novel method, Conditional Gaussian Distribution Learning (CGDL), for open set recognition.
In this paper, we propose a pedestrian attribute recognition approach and a CNN-based person re-identification framework enhanced by pedestrian attributes.
We study the problem of post-processing of depth maps degraded by improper estimation or by block-transform-based compression. We present experimental results demonstrating high-quality filtered depth maps.
The scientific literature is a large information network linking various actors (laboratories, companies, institutions, etc.). The vast amount of data generated by this network constitutes a dynamic heterogeneous attributed network (HAN), in which new information is constantly produced and from which it is increasingly difficult to extract content of interest. A common approach consists in learning representations of the nodes and attributes of this HAN and use them as features for a variety of recommendation tasks
This paper introduces the first fully automated caricature-based face recognition approach capable of working with data acquired in the wild and achieves competitive results with state-of-the-art face recognition methods.
In this project, we worked on speech recognition, specifically predicting individual words based on both the video frames and audio.
We design a cluster loss, which can lead to the model output with a larger inter- class variation and a smaller intra-class variation compared to the triplet loss.
In this paper, we propose to utilize contrastive representation that embeds a distinctive expressive factor for a discriminative purpose.
We provide a comprehensive overview of a variety of object detection methods in a systematic manner, covering the one-stage and two-stage detectors.
We explore how to arrive at dense semantic pixel labels given both the input image and an initial estimate of the output labels. We propose a parallel architecture that exploits the context information through a LabelPropagation network to propagate correct labels from nearby pixels to improve the object boundaries.
F-DENSER++ enables the training time of the candidate solutions to grow continuously as necessary, and are ready for deployment after evolution, without the need for further training.
Emotion recognition in conversation (ERC) is becoming increasingly popular as a new research frontier in natural language processing (NLP) due to its ability to mine opinions from the plethora of publicly available conversational data in platforms such as Facebook, Youtube, Reddit, Twitter, and others.
We propose a novel Spatio-Temporal Adaptive Pooling (STAP) network for micro-expression AU detection in micro-expressions.
We show that the problem of pixel-wise hand detection can be effectively solved, by posing the problem as a model recommendation task.
We propose an extension to real-time style transfer that allows direct control of style strength at inference, still requiring only a single transformer network.
We present a neuro-symbolic model which learns entire rule systems from a small set of examples.
We show that a recurrent model trained on spoken sentences implicitly segments its input into word-like units and reliably maps them to their correct visual referents in a recurrent neural model of visually grounded speech.
We propose two novel trackers, A3CT, which exploits demonstrations of a state-of-the-art tracker to learn an effective tracking policy, and A3 CTD, that takes advantage of the same expert tracker to correct its behaviour during tracking.
This paper presents a novel subject-dependent deep aging path (SDAP), which inherits the merits of both generative probabilistic modeling and inverse reinforcement learning to model the facial structures and the longitudinal face aging process of a given subject.
We propose a Winograd-aware formulation of convolution layers which exposes the numerical inaccuracies introduced by the winograd transformations to the learning of the model parameters, enabling the design of competitive quantized models without impacting model size. We also address the source of the numerical error and propose a relaxation on the form of the transformation matrices.
We study the problem of automatically detecting if a given multi-class classifier operates outside of its specifications (out-of-specs), i.e. on input data from a different distribution than what it was trained for.
We propose a novel CNN-based action recognition method called SAST including three important modules, which effectively learn semantic action-aware spatial-temporal features with a faster speed.
We investigate the impact of search strategies in neural dialogue modeling. We evaluate these strategies in realistic full conversations with humans and propose a Bayesian calibration to address annotator bias.
We propose an advanced normalization technique based on adaptive convolution (AdaCoN), in order to properly impose style information into the content of an input image.
In this paper, we introduce a novel unsupervised domain adaptation technique for 3D keypoint prediction from a single depth scan or image.
We propose a unified algorithm framework for structure-enforced matrix factorization and propose a strategy to adaptively adjust the penalty parameters which is the key to achieving good performance for ADMM.
We propose a method to jointly model the unstructured sentence and the structured answer-relevant relation (extracted from the sentence in advance) for question generation and achieve significant improvements on automatic evaluation metrics.
This paper proposes to construct a strong lightweight network architecture, termed PLR-OSNet, based on the idea of Part-Level feature Resolution over the Omni-Scale Network (OSNet) for achieving feature diversity.
We propose a Tree-structured Kronecker convolutional network which captures partial information and enlarge the receptive field of filters simultaneously without introducing extra parameters.
We use an existing optimized CNN model to automatically build a competitive CNN for an IoT application whose objects of interest are a fraction of categories that the original CNN was designed to classify, such that the resource requirement is proportionally scaled down.
This paper proposes a statistical approach to 2D pose estimation from human images by integrating a deep generative model of poses and images.
We find that, as long as they bring about competition between words, constraints in both learning and referent selection can improve success in tasks where mutual exclusivity is advantageous.
We develop a phase retrieval algorithm that utilizes two DNNs together with the hybrid input-output method for state-of-the-art performance.
We define a reference methodology for combining semantic information available in the web under the form of logical theories, with statistical methods for NLP.
We address the problem common space learning approach that maps all related multimodal information into a common space for multimodAL data.
We propose a new single-shot panoptic segmentation network that leverages dense detections and a global self-attention mechanism to operate in real-time with performance approaching the state of the art.
We exploit general corpus information to automatically select and subsequently classify web images into semantic rich (sub-)categories.
We design an online algorithm for scheduling the arriving jobs and deciding the number of concurrent workers and parameter servers for each job over its course, to maximize overall utility of all jobs, contingent on their completion times.
We propose a new neural network architecture that represents a class of intra order-preserving functions that can preserve the top-k predictions of any deep network while maintaining the network's accuracy.
In this work, we introduce the challenging problem of joint multi-person pose estimation and tracking of an unknown number of persons in unconstrained videos, and propose a novel method that jointly models multi- person pose estimation in a single formulation.
We introduce a simple, yet effective Convolutional Random Walk Network that addresses the issues of poor boundary localization and spatially fragmented predictions with very little increase in model complexity.
We demonstrate that model-based derivative free optimisation algorithms can generate adversarial targeted misclassification of deep networks using fewer network queries than non-model-based methods.
We explore a relation network architecture for the discriminator and design a triplet loss which performs better generalization and stability of GANs.
This letter proposes a DNN-based feature extraction scheme for acoustic event classification.
We propose a multi-stream Convolutional Neural Network (CNN) architecture that encodes appearance, motion, and the captured tubes of the human-related regions.
We propose an efficient end-to-end incremental object detector using knowledge distillation for RPN-based detectors based on Faster RCNN.
The complementarity of gene expression and protein–DNA interaction data led to several successful models of biological systems. However, recent studies in multiple species raise doubts about the relationship between these two datasets.
This paper proposes a novel architecture and a training algorithm, which are able to produce multi-domain outputs using a single network.
A Siamese Multiple Granularity Network model for person re-identification .
We propose a novel algorithm for discriminative codeword selection, which can be used for image retrieval and clustering.
This paper presents an effective feature selection algorithm that explores the class imbalance issue by optimizing F-measures.
In this paper, we propose a novel representation, calledMultiscale Block Local Binary Pattern, and apply it to face recognition.
We propose a sketch based image synthesis system which allows users to scribble over the sketch to indicate preferred color for objects and generate convincing images that satisfy both the color and the sketch constraints of user.
This paper introduces an efficient unsupervised approach to salient object detection from the perspective of recursive sparse representation, by which the shortcomings of the object integrity can be effectively improved.
We propose a general framework for image classification using the attention mechanism and global context, which could incorporate with various network architectures to improve their performance.
A working group to study empirical methodology in navigation research.
We use similarity measures to rank the candidates extracted from pharmacovigilance data to improve the detection of dangerous interactions.
We found a marker of real-world scene size, i.e. spatial layout processing, at ~250 ms indexing neural representations robust to changes in unrelated scene properties and viewing conditions.
We formulate the learning of OOV embeddings as a few-shot regression problem, and address it by training a representation function to predict the oracle embedding vector (defined as embedding trained with abundant observations) based on limited observations.
This work addresses the automatic reconstruction of objects useful for BIM, like walls, floors and ceilings, from meshed and textured mapped 3D point clouds of indoor scenes.
We propose a new, flexible, and scalable way for generating training data that only requires a set of stereo images as input.
We propose a dynamic tensor completion framework for Incremental Tensor Analysis which incorporates side information and works for general incremental tensors.
This paper proposes a novel framework which formulates CGRL as a convex optimization problem, enables transductive learning using both labeled and unlabeled tuples, and offers a scalable algorithm that guarantees the optimal solution and enjoys a linear time complexity with respect to the sizes of input graphs.
The appearance of an attribute can vary considerably from class to class (e.g., a "fluffy" dog vs. a "striped" towel), making standard class-independent attribute classifiers impractical, and defeats the purpose of using attributes to bridge category boundaries. We propose a novel form of transfer learning that addresses this dilemma.
We propose contextualized non-local neural networks (CN3), which can both dynamically construct a task-specific structure of a sentence and leverage rich local dependencies within a particular neighbourhood.
We leverage the natural temporal coherency of color to create a model that learns to colorize gray-scale videos by copying colors from a reference frame.
We describe a computational methodology allowing to systematically and quantitatively characterize a Boolean mathematical model of a biological network in terms of genetic interactions between all loss and gain of function mutations with respect to all model phenotypes or outputs.
This paper explores the use of convolutional LSTMs to simultaneously learn spatial- and temporal-information in videos.
We propose a knowledge transfer based generative adversarial network (SC-GAN), which is an annotation-free approach that uses the knowledge from publicly available annotated fundus dataset to segment coronary arteries.
We propose a simple yet effective structural similarity loss (SSL) to encode the structure information of objects, which only requires a few additional computational resources in the training phase.
In this paper, we propose a "Divide and use" re-ranking framework for person re-identification. It exploits the diversity from different parts of a high-dimensional feature vector for fusion-based re- ranking, while no other features are accessible.
 RandAugment can be used uniformly across different tasks and datasets and works out of the box, matching or surpassing all previous learned augmentation approaches on CIFAR-10 and ImageNet.
Person re-identification (Re-ID) using metric embedding trained with the use of the triplet loss function.
We perform a first study to compare the usefulness of non-content evidences to Web archive search, where the evidences are mined from the metadata of file headers, links and URL strings only.
We propose a machine learning method that can continuously gain structured visual knowledge by learning structured facts in a never ending process.
We explore a new class of end-to-end learnable models wherein data processing nodes (or network layers) are defined in terms of desired behavior rather than an explicit forward function.
We propose a deep learning-based framework to automatically: (1) tag the images available in a review dataset, (2) generate a caption for each image that does not have one, (3) enhance each review by recommending relevant images that might not be uploaded by the corresponding reviewer.
This paper presents a fully automatic framework for extracting editable 3D objects directly from a single photograph.
We propose a new framework for precisely segmenting retinal vasculatures, constructing retinal vascular network topology, and separating the arteries and veins. The vascular topology information significantly improves the accuracy on arteries/veins classification.
We propose a new method to improve the performance of nearly every DNN model including pre-trained models by reassigning model parameter values based on the probabilistic distribution of these parameters, calculated towards the end of the training process.
We investigate the models' capability of content understanding on QuAC and CoQA for conversational comprehension research. The experimental results indicate some potential hazards.
We propose a comparative approach, nearest neighbor overlap (N2O), that quantifies similarity between embedders in a task-agnostic manner and use it to show the effects of different design choices and architectures.
We investigate the robustness to adversarial attacks of new Convolutional Neural Network architectures providing equivariance to rotations.
We demonstrate the first hardware-based attack on quantized deep neural networks-DeepHammer-that deterministically induces bit flips in model weights to compromise DNN inference by exploiting the rowhammer vulnerability.
We propose a Federated learning based Proactive Content Caching (FPCC) scheme, which does not require to gather users' data centrally for training, and it outperforms other learning-based caching algorithms such as m-epsilon-greedy and Thompson sampling in terms of cache efficiency.
Pose estimation in the wild is a challenging problem, particularly in situations of (i) occlusions of varying degrees and (ii) crowded outdoor scenes. To tackle this problem, we propose a novel multi-task framework for end-to-end training towards the entire pose estimation of pedestrians.
Hypernymy, textual entailment, and image captioning can be seen as special cases of a single visual-semantic hierarchy. In this paper we advocate for explicitly modeling the partial order structure of this hierarchy.
We developed two simple systems for dependency parsing: ::: darc, a transition-based parser, and mstnn, a graph- based parser.
We propose a novel DNN-based framework for video inpainting that takes advantage of additional information in other frames of the video.
We present an approach for reconstructing vehicles from a single (RGB) image, in the context of autonomous driving, using shape priors learnt over a small dataset.
We propose a hierarchical clustering-guided re-identification method which just trains on the unlabeled target dataset and evaluate on the target dataset.
The proposed approach employs particle swarm optimization for finding optimal filter parameters of the multiscale Gaussian matched filter for achieving improved accuracy of retina vessel segmentation.
We introduce a new open set recognition model called compact abating probability (CAP), where the probability of class membership decreases in value (abates) as points move toward open space.
We introduce a new differentiable layer for 3D data deformation and use it in DeformNet to learn a model for3D reconstruction-through-deformation. We evaluate our approach on the ShapeNet dataset and show that -
Word embeddings carry stereotypical connotations from the text they are trained on, which can lead to invalid inferences in downstream models that rely on them. We develop a mechanism for measuring stereotypes using the task of natural language inference.
In this paper, contrary to current state-of-the-art techniques in pain assessment, which are based on facial features only, we suggest that the performance can be enhanced by feeding the raw frames to deep learning models, outperforming the latest state- of- the-art results while also directly facing the problem of imbalanced data.
We propose a novel harmonious attention network (HAN) framework to jointly learn soft pixel attention and hard region attention alongside simultaneous deep feature representation learning, enabling more discriminative re-id matching by efficient networks with more scalable model inference and feature matching.
Conditional generative adversarial networks can be used to solve phase retrieval problems.
Adaptive holons representation for pose estimation in a 2D still image .
We present ADMM-NN, the first algorithm-hardware co-optimization framework of DNNs using Alternating Direction Method of Multipliers (ADMM), a powerful technique to solve non-convex optimization problems with possibly combinatorial constraints.
We present a novel Markov Random Field (MRF) structure-based approach to the problem of facial action unit (AU) intensity estimation.
We explore the possibility of using a single monocular camera to forecast the time to collision between a suitcase-shaped robot being pushed by its user and other nearby pedestrians. We develop a purely image-based deep learning approach that directly estimates theTime to collision.
We propose an approach that hallucinates the unobserved future motion implied by a single snapshot to help static-image action recognition.
This paper proposes a method based on repulsive forces and sparse reconstruction for the detection and location of abnormal events in crowded scenes.
This paper investigates the visual quality of the adver-sarial examples. Recent papers propose to smooth the perturbations to get rid of high frequency artefacts. This operation relies on Laplacian smoothing, well-known in graph signal processing, which we integrate in the attack pipeline.
We propose Spatial Aggregation Net for point cloud semantic segmentation using multi-directional convolution scheme that utilizes the spatial structure information of point cloud.
We reduce redundancy regularization problem to generic energy minimization, and propose a minimum hyperspherical energy (MHE) objective as generic regularization for neural networks.
We analyze the crystal structures of p38α MAPK in complex with ATP competitive type I inhibitors, getting insights into ATP binding site conformation and its influence on automated molecular docking results.
In this paper, we introduce a new framework based on differentiable Change of Representation (CoR) modules that allow the entire PL pipeline to be trained end-to-end.
We propose to use joint Identification-Verification network to reduce intra-action variations and enlarge inter-action differences for temporal action detection.
We show that knowledge distillation can be used to encourage a model that generates claim independent document encodings to mimic the behavior of a more complex model which generates claim dependent Encodings.
We propose localization models that leverage the presence of the hand as the contextual information for priming the center area of the object of interest in egocentric vision.
This paper proposes a novel Attribute-Guided Network (AGNet), which could learn global representation with the abundant attribute features in an end-to-end manner.
We propose a transfer learning method for deep neural networks, which enables the transfer of all parameters of a DNN, which improves on conventional transfer learning methods for image classification.
In statistical relational learning, the link prediction problem is key to automatically understand the structure of large knowledge bases. As in previous studies, we propose to solve this problem through latent factorization.
Deep Priority Hashing (DPH), an end-to-end architecture that generates compact and balanced hash codes from training data with pairwise similarity information.
We use a small amount of labeled samples to add discriminant information in the basic dictionary learning for person re-identification.
Max-plus operators can be used to select important filters and reduce redundancy in its previous layer, without incurring performance loss.
We present an image segmentation method that iteratively evolves a polygon from its vertices, making the process fully differentiable.
An image quality assessment based label smoothing method, which aims at regularizing the label distribution of training images, is further proposed to tune the objective functions in learning the neural network.
We introduce a novel objective term for sparse coding and propose a non-linear local SSC framework which can represent the nonlinear structure of data.
We propose a new hashing scheme so that hash functions are selected dependently on the properties of the normal training data for reliable anomaly detection.
The random Fourier embedding methodology can be used to approximate the performance of non-linear kernel classifiers in linear time on the number of training examples. We propose an asymptotically convergent analytic series of the χ2 measure, which improves the classification accuracy.
This paper proposes noisy U-Net (NU-Net), which can enhance the neural network's sensitivity to small nodules by adding a special noise to the hidden layers in training.
We show that the multi-branch architecture is less non-convex in terms of duality gap than the linear activation function and $\ell_2$ loss.
We present a system for training deep neural networks for object detection using synthetic images. To handle the variability in real-world data, the system relies upon the technique of domain randomization.
We propose a new graph-based structurally interacting elastic net method for feature selection that can incorporate pairwise relationship between samples into the feature selection process.
We develop a geometry-consistent generative adversarial network (Gc-GAN), which enables one-sided unsupervised domain mapping.
We introduce a data structure for answering approximate furthest neighbor queries in high-dimensional Euclidean space, improving on Indyk's approximation factor.
We introduce a task augmentation method by rotating, which increases the number of classes by rotating the original images 90, 180 and 270 degrees, different from traditional augmentation methods which increase theNumber of images.
We propose to use a novelty-prepared loss function, called self-compacting softmax loss, for few-shot classification. The SSL can prevent the full occupancy of the embedding space.
We introduce risk extrapolation (REx) as a simpler, yet effective alternative to previous approaches that encourages robustness over affine combinations of training risks.
This paper revisits conventional sequential modeling approaches, aiming to address the problem of capturing time-varying temporal dependency patterns. We propose a different formulation of HMMs, whereby the dependence on past frames is dynamically inferred from the data.
The influence of deep learning is continuously expanding across different domains, and its new applications are ubiquitous. The question of neural network design thus increases in importance, as traditional empirical approaches are reaching their limits. We propose a probabilistic representation of a neural network structure under the assumption of independence between layer types, inspired by the estimation of distribution algorithms.
We compare different word embeddings, language models, and embedding augmentation steps on five common VL tasks: image-sentence retrieval, image captioning, visual question answering, phrase grounding, and text-to-clip retrieval.
We present a new method for 3D shape reconstruction from a single image, in which a deep neural network directly maps an image to a vector of network weights.
We consider the problem of unsupervised domain adaptation for semantic segmentation by easing the domain shift between the source domain (synthetic data) and the target domain (real data) in this work.
Does computer vision matter for action? We probe this question and its offshoots via immersive simulation, which allows us to conduct controlled reproducible experiments at scale.
We empirically investigate the behavior of soft labels and classifiers in average fusion and propose a better baseline for classifier fusion.
Trust region methods, such as TRPO, are often used to stabilize policy optimization algorithms in RL while exploiting off-policy data to improve sample efficiency.
We introduce a novel approach, based on a combination of segmentation and BP, for the stereo correspondence problem, and apply it to stereo images.
Dependency parsing of conversational input can play an important role in language understanding for dialog systems by identifying the relationships between entities extracted from user utterances. Additionally, effective dependency parsing can elucidate differences in language structure and usage.
In this paper, we extend the concept of moment-based normalization of images from digit recognition to the recognition of handwritten text.
Policy gradient methods have enjoyed great success in deep reinforcement learning but suffer from high variance of gradient estimates. To mitigate this issue, we derive a bias-free action-dependent baseline which fully exploits the structural form of the stochastic policy itself and does not make any additional assumptions about the MDP.
This paper proposes an adapted structure of MapReduce programming model using MPI for multimedia indexing.
A review of the state of the art in video classification and captioning.
We propose reconstruction-free methods for action recognition from compressive cameras at high compression ratios of 100 and above.
We propose the Least Squares Generative Adversarial Networks (LSGANs) which adopt the least squares loss function for the discriminator and perform better than regular GANs.
We explore the impact of weight sharing with a recurrent connection matrix between consecutive predictions, and compare it to a formulation where these weights are not tied.
This paper demonstrates the effectiveness of our customized deep learning based video analytics system in various applications focused on security, safety, customer analytics and process compliance.
We propose VRMPO algorithm, a variance reduction implementation of mirror policy optimization by estimating the policy gradient via dynamic batch-size of gradient information.
We present Location Field Descriptors, a novel approach for single image 3D model retrieval in the wild. They explicitly capture 3D shape and pose information without appearance variations which are irrelevant for the task.
We present a novel approach to classifying retinal vessels extracted from fundus camera images which combines an Orthogonal Locality Preserving Projections for feature extraction and a Gaussian Mixture Model with Expectation-Maximization unsupervised classifier.
In this paper, we propose a deep neural network architecture for object recognition based on recurrent neural networks that sweep horizontally and vertically in both directions across the image.
We showcase a family of common failures of state-of-the art object detectors. These are obtained by replacing image sub-regions by another sub-image that contains a trained object.
In this paper, we study the instance-level variation,and demonstrate that instance-awareness is an important yet currently missing component of NAS. Based on this observation, we propose InstaNAS for searching toward instance- level architectures, which reduces the inference latency without compromising classification accuracy.
We propose a near lossless method for encoding long sequences of texts as well as all of their sub-sequences into feature rich representations.
This paper addresses the issue of event recognition from images and proposes an effective method with deep neural networks for event recognition.
This paper proposed a new convolutional neural network (CNN) structure, P_VggNet, comprising the following parts: P_Net and VggNet with 16 layers, for the use of attention maps in every image type.
We propose a method to address challenges in unconstrained face detection, such as arbitrary pose variations and occlusions in cluttered scenes.
This paper presents Point Convolutional Neural Networks (PCNN): a novel framework for applying convolutional neural networks to point clouds.
We present an unsupervised embedding of natural image patches, avoiding the need for annotated images, in which the Euclidean distance reflects patch similarity.
Image captioning is the process of generating a natural language description of an image. Towards developing a model that can produce human-like captions incorporating these, we use facial expression features extracted from images including human faces, with the aim of improving the descriptive ability of the model.
We propose a statistical method for automatic facial-landmark localization based on Gabor wavelet features.
Using large datasets is essential for machine learning. In this paper, we present a novel system to decrease the effort of annotating those large image sets using minimal 3D annotations.
We study the skip-thought model with neighborhood information as weak supervision. We propose a skip- thought neighbor model to consider the adjacent sentences as a neighborhood.
In this empirical paper, we investigate how learning agents can be arranged in more efficient communication topologies for improved learning.
We explore two main areas of quality assessment related to evolving knowledge bases: (i) identification of completeness issues using knowledge base evolution analysis, and identification of consistency issues based on integrity constraints, such as minimum and maximum cardinality, and range constraints.
We propose relevance-based topic models that have the advantages of previous models while taking the concept of relevance into account.
This paper proposes a new 3D face recognition approach, Collective Shape Difference Classifier (CSDC), to meet practical application requirements, i.e., high recognition performance, high computational efficiency, and easy implementation.
Object tracking has been a hot computer vision topic for many years. In this work, we improve the object tracking performance in two ways. First, a sequential scoring model is proposed to integrate the optical flow information of history video frames into the feature map of current frame.
We propose hybrid attacks that combine optimization-based attacks and transfer attacks to efficiently find black-box adversarial examples with only a handful of queries.
This paper deals with possible sensor faults by defining a federated sensor data fusion architecture that detects a faulty sensor using SVM models for fault detection and diagnosis.
We investigate learning 3D human shape and pose from dense correspondences of body parts and propose a Decompose-and-aggregate Network (DaNet) to address these issues.
This paper investigates the accuracy of translations of English labels that are available in ImageNet, a database of images labeled in English that is commonly used in computer vision research, to Arabic.
In recent years, regression trackers have drawn increasing attention in the visual-object tracking community due to their favorable performance and easy implementation. In this paper, we propose a novel effective distractor-aware loss function to balance this issue by highlighting the significant domain and by severely penalizing the pure background.
This paper solves the multi-class classification problem for Parkinson's disease (PD) analysis by a sparse discriminative feature selection framework.
We exploit Local Intrinsic Dimensionality (LID) to measure, in deep feature space, the alignment between data submanifolds learned by GAN-based generative inpainting models and those of the original data, from a perspective of both images (denoted as iLID).
Deep learning methods for 3D human pose estimation from RGB images require a huge amount of domain-specific labeled data for good in-the-wild performance.
In this paper, we propose to denoise corrupted images by finding the nearest point on the GAN manifold, recovering latent vectors by minimizing distances in image space, recovering the latent vector and denoise the image.
We present a conceptually simple and general yet novel framework for few-shot temporal activity detection which detects the start and end time of the few- shot input activities in an untrimmed video.
The figure-ground segmentation of humans in images captured in natural environments is an outstanding open problem due to the presence of complex backgrounds, articulation, varying body proportions and partial views. In this work we propose class-specific segmentation models that leverage parametric max-flow image segmentation and a large dataset of human shapes.
We use transferable features to enable model adaptation from multiple source domains, given the sparseness of speech emotion data and the fact that target domains are short of labeled data.
We propose a novel method to make deep convolutional neural networks produce supervised, compact, structured binary codes for visual search.
We introduce a novel approach to incorporate syntax into natural language inference (NLI) models and show consistent benefit to accuracy across three NLI benchmarks.
In this paper, we propose a hybrid network model for the Tibetan QA, which combines the convolutional neural network and long short memory network (LSTM) to extract effective features from small-scale corpora.
We introduce Locality-promoting Regularization (LOCO-REG) for locating and defining features in CNN.
We propose an optimal combination scheme for image denoising by leveraging the deep neural networks and convex optimization.
We apply a method developed in the context of domain adaptation to address this problem, where we request a classifier to make a decision in a way that is entirely 'agnostic' to a given protected concept (e.g. gender, race, background etc.), even if this could be implicitly reflected in other attributes via unknown correlations.
We present a novel attention-based deep reinforcement learning method in a multi-view environment in which each view can provide various representative information about the environment. We evaluate the performance of our method on TORCS racing car simulator and three other complex 3D environments.
We propose an approach that considers the internal color and saliency properties of the image and uses patch-based manipulation using only patches from within the same image to maintain its appearance characteristics.
The recursive autoconvolutional operator, adopted from physics, boosts existing unsupervised methods to learn more powerful filters.
This paper presents an approach for human action recognition by finding the discriminative key frames from a video sequence and representing them with the distribution of local motion features and their spatiotemporal arrangements.
Expansion algorithm is a popular optimization method for labeling problems. For many common energies, each expansion step can be optimally solved with a min-cut/max flow algorithm. Recently, Dynamic Programming (DP) was shown to be useful for 2D labeling problems via an approximate expansion step.
Rv0678 regulates the expression of MmpS5-MmpL5, a mycobacterial efflux system in Mycobacterium tuberculosis.
Instance Segmentation is an interesting yet challenging task in computer vision. In this paper, we conduct a series of refinements with the Hybrid Task Cascade Network, and empirically evaluate their impact on the final model performance through ablation studies.
We present Olympus, a privacy framework that limits the risk of disclosing private user information by obfuscating sensor data while minimizing the functionality the data are intended for.
 syntax-infused Transformer with multiple features achieves an improvement of 0.7 BLEU when trained on the full WMT 14 English to German translation dataset.
We introduce an explicit modularization technique on policy representation to alleviate this optimization issue. We name this approach soft modularization.
This paper presents SegMap: a map representation solution to the localization and mapping problem based on the extraction of segments in 3D point clouds.
We propose our MTL with Selective Augmentation (MTL-SA) method to select the training samples in unlabeled datasets with confident pseudo labels and close data distribution to the labeled dataset.
In this paper we challenge the common assumption that convolutional layers in modern CNNs are translation invariant. We show that CNNs can exploit the absolute spatial location by learning filters that respond exclusively to particular absolute locations.
In this paper, we propose DeepBbox, an algorithm that "corrects" loose object labels into right bounding boxes to reduce human annotation efforts.
We propose a plug-and-play PickNet to perform informative frame picking in video captioning and achieve competitive performance.
We introduce KALM-QA (KALM for Question Answering) that achieves 100% accuracy on a suite of movie-related questions, called MetaQA.
In this paper, we propose attaching a feedback CNN to a pretrained feedforward CNN as a means of learning how recognition is performed by the feedforwardCNN.
We propose a novel structure-aware fully convolutional network to implicitly take such priors into account during training of the deep network for pose estimation.
We propose a Discriminative Feature Network (DFN), which contains two sub-networks: Smooth Network and Border Network.
We propose the mid-level CNN features for face attribute prediction in the wild.
We propose a new graph-based learning algorithm that captures the manifold structure of the input data and optimizes edge weights through a local linear reconstruction error minimization.
We organize large shape collections into parameterized shape templates to capture the underlying structure of the objects. We employ a deep neural network that matches the partial scan with one of the shape templates, then match and fit it to complete and detailed models.
Panda faces can be used for panda recognition in a noninvasive manner by using image-based panda face recognition method.
This paper presents a phenomenon in neural networks that we refer to as local elasticity, after the classifier is updated via stochastic gradient descent at a (labeled) feature vector x that is dissimilar to x.
We propose a new KG-QA approach, leveraging the rich domain context in the knowledge graph. We incorporate the new approach with question and answer domain context descriptions.
This paper describes a new approach to compute bifurcation angles in retinal images by means of multiple orientations at each pixel of a gray retinal image.
We propose a unified network to parameterize the interest frame position and therefore infer interpolated/extrapolated frames within the same framework. We introduce a transitive consistency loss and train the network with adversarial training.
We propose a novel fully convolutional network, named as CoupleNet, to couple the global structure with local parts for object detection.
In this paper, we propose a mutual visibility deep model that jointly estimates the visibility statuses of overlapping pedestrians.
We propose a novel approach for class-agnostic object proposal generation, which is efficient and especially well-suited to detect small objects, which are often missed by recent models.
We present PointGroup, a new end-to-end bottom-up architecture for 3D instance segmentation, specifically focused on better grouping the points by exploring the void space between objects.
SynGeNet, a computational method that integrates transcriptomics data characterizing disease and drug z-score profiles with network mining algorithms in order to predict synergistic drug combinations.
In this paper, instead of convolving with a dictionary shared by all samples, we propose a sample-dependent dictionary in which filters are obtained as linear combinations of a small set of base filters learned from the data.
We address the challenging task of foreground object discovery and segmentation in video. We introduce an efficient solution, suitable for both unsupervised and supervised scenarios, based on a spacetime graph representation of the video sequence.
We extend this method to drive conclusions about a model's ability to learn and generalize a target phenomenon rather than to "learn" a dataset, by controlling additional aspects in the adversarial datasets.
We introduce algorithms to visualize feature spaces used by object detectors, allowing us to analyze object detection systems in new ways.
In this paper, we propose a novel set of features for offline writer identification based on the path signature approach, which provides a principled way to express information contained in a path.
We address the problem of text segmentation in natural scenes from a hierarchical perspective, aiming directly to the detection of region groupings corresponding to text within a hierarchy produced by an agglomerative similarity clustering process.
We release SciBERT, a pretrained language model based on BERT to address the lack of high-quality, large-scale labeled scientific data in the scientific domain.
Exploring deep convolutional neural networks of high efficiency and low memory usage in online inference using instance-wise feature pruning.
Fusing low level and high level features is a widely used strategy to provide details that might be missing during convolution and pooling. We propose a new fusion mechanism called FillIn which takes advantage of prior knowledge described with superpixel segmentation.
We propose a novel framework for training efficient deep neural networks by exploiting generative adversarial networks (GANs) without any training data.
We propose an elegant and powerful Temporal Preservation Convolutional (TPC) Network that equips 3D ConvNets with TPC filters, enabling frame-level temporal action localization.
The learning-to-search approach benefits from choosing the costs related to the test metrics. We propose a way to construct a reference policy based on an alignment between the model output and ground truth.
In this paper, we demonstrate a comprehensive method for segmenting the retinal vasculature in camera images of the fundus using a spectral clustering technique based on morphological features.
We present the first study of image model robustness to the minute transformations found across video frames, which captures a more diverse set of common image transformations that occur in the natural environment.
We developed a Stereo Matching Squeeze neural network architecture capable of providing disparity maps with a highly reduced network size without a significant impact on quality and execution time compared with state of the art architectures.
We improve the standard encoder-decoder model by introducing a variable alignment mechanism that enables it to align variables across predicates in the predicted FOL.
In this study, a set of 12 compounds, predicted to interact with the active center of nsP2 protease, was designed using target-based modeling. The majority of these compounds were shown to inhibit the ability of ns P2 to process recombinant protein and synthetic peptide substrates, and suppress CHIKV replication using more than one mechanism.
We propose the temporal graph attention (TGAT) layer to efficiently aggregate temporal-topological neighborhood features as well as to learn the time-feature interactions.
We demonstrate that in residual neural networks dynamical isometry is achievable irrespectively of the activation function used, in the large network width and depth limit.
Incorporation of new knowledge into neural networks with simultaneous preservation of the previous knowledge is known to be a nontrivial problem. We propose and test two methods of combining knowledge contained in separate networks.
We develop a non-monotone alternating updating method based on a potential function for non-negative matrix factorization which can be used for machine learning and imaging sciences.
We address this question in the context of learning to recognize 3D shapes from a collection of their rendered views on 2D images on a CNN architecture trained to recognize the shapes.
We propose the Deep Active Curve Network (DACN) which combines powerful ResNet models with GCN-based active curves for accurate object instance segmentation.
This paper presents a learning by teaching (LBT) approach to learning implicit models, which intrinsically avoids the mode collapse problem by optimizing a KL-Divergence rather than the JS-divergence in GANs.
We propose a convolutional network with hierarchical classifiers for per-pixel semantic segmentation, which is able to be trained on multiple, heterogeneous datasets and exploit their semantic hierarchy.
This paper addresses the person re-identification (PReID) problem by combining global and local information at multiple feature resolutions with different loss functions.
We propose LUTNet, an end-to-end hardware-software framework for the construction of area-efficient FPGA-based neural network accelerators using the native LUTs as inference operators.
We identify a fundamental problem in policy gradient-based methods in continuous control. As policy gradient methods require the agent's underlying probability distribution, they limit policy representation to parametric distribution classes. We propose a generative scheme, trained using an off-policy actor-critic paradigm, which we call the Generative Actor Critic.
We present in this work the first end-to-end deep learning based method that predicts both 3D hand shape and pose from RGB images in the wild.
This paper proposes a novel cost function, called mixture separability loss (MSL), which updates the weights of the network even when most of the training images are accurately predicted.
The backpropagation (BP) algorithm is often thought to be biologically implausible in the brain. To address this"weight transport problem"(Grossberg, 1987), two biologically plausible algorithms, proposed by Liao et al. (2016) and Lillicrap (2018), relax BP's weight symmetry requirements and demonstrate comparable learning capabilities to that of BP on small datasets.
We study the effects of increasing the batch size on training time, as measured in the number of steps necessary to reach a goal out-of-sample error.
This paper presents a novel noise robust edge detector based upon the automatic anisotropic Gaussian kernels (ANGKs), which also addresses the current problem that the seminal Canny edge detector may miss some obvious crossing edge details.
An automated method for segmentation of blood vessels in retinal images using multidirectional morphological bit plane slicing .
We propose a novel SGG framework based on causal inference but not the conventional likelihood for unbiased scene graph generation.
We introduce an auxiliary network to generate adversarial examples, which is used in a min-max formulation to build robust image reconstruction networks, which improves robustness using the proposed approach over other methods.
We introduce ShapeMask, which learns the intermediate concept of object shape to address the problem of generalization in instance segmentation to novel categories.
We can use multiscale features to detect small objects that have low resolution.
We propose a novel end-to-end sequence- to-sequence model to generate captions for videos that exploit temporal structure and allow both input and output of variable length.
We developed HIPPIE2 that analyzes raw reads from high-throughput chromosome conformation experiments to identify precise loci of DNA physically interacting regions (PIRs) with high resolution and reproducibility.
The field of transparent Machine Learning (ML) has contributed many novel methods aiming at better interpretability for computer vision and ML models in general. But how useful the explanations provided by transparent ML methods are for humans remains difficult to assess. We investigate the quality of interpretable computer vision algorithms using techniques from psychophysics.
This paper proposes a novel framework to regularize the highly ill-posed and non-linear Fourier ptychography problem using generative models.
In this paper, we propose a novel meta-learning method in a reinforcement learning setting, based on evolution strategies (ES), exploration in parameter space and deterministic policy gradients, which achieves good results compared to gradient-based meta- learning.
We study the problem of mapping between domains, where either the source or the target domain are defined by a single sample, far surpassing existing solutions.
This paper proposes an effective and robust approach for facial landmark detection by combining data- and model-driven methods for global estimation of facial landmarks.
We propose a novel adaptive graph convolutional network with attention graph clustering for co-saliency detection.
A study investigating the effect of preprocessing, model initialization and architecture choice on gender recognition performance.
We propose a novel face attribute transfer model which receives two images of opposite attributes as inputs and can transfer them simultaneously.
We show how to reduce the computational complexity of belief propagation by applying the Four Color Theorem to limit the maximum number of labels in the underlying image segmentation to at most four.
We describe the Yeast Kinase Interaction Database (KID, http://www.moseslab.csb.utoronto.ca/KID/), which contains high- and low-throughput data relevant to phosphorylation events.
In this paper, we propose a novel net framework to tackle semantic Segmentation and image Restoration in adverse environmental conditions (SR-Net)
We propose a model to take into account both the similarities and dissimilarities by decomposing and composing lexical semantics over sentences, and achieve state-of-the-art performance.
We propose a Resetting-Label Network based on Fast Group Loss for Person Re-Identification (RLFGL-ReID)
Pairwise Confusion reduces overfitting by intentionally introducing confusion in the activations, leading to state-of-the-art performance.
An architecture combining a hierarchical temporal model for predicting human poses and encoder-decoder convolutional neural networks for rendering target appearances is proposed.
We present a novel deep reinforcement learning based framework for automatic question generation. The generator of the framework is a sequence to sequence model, enhanced with the copy mechanism to handle the rare-words problem and the coverage mechanism to solve the word repetition problem.
In this paper, we introduce 3D-GMNet, a deep neural network for single-image 3D shape recovery using a Gaussian mixture model.
This paper strives to find amidst a set of sentences the one best describing the content of a given image or video. We propose Word2VisualVec for video caption retrieval.
We propose a one-stage method, named EmbedMask, that unifies both proposal-based and segmentation methods by taking advantages of them.
This study proposes a deep network for vessel segmentation, whose architecture is inspired by inception modules.
This work presents a hybrid and hierarchical deep learning model for mid-term load forecasting. The model combines exponential smoothing, advanced Long Short-Term Memory (LSTM) and ensembling.
The ability to reason with natural language is a fundamental prerequisite for many NLP tasks such as information extraction, machine translation and question answering. To quantify this ability, systems are commonly tested whether they can recognize textual entailment, i.e., whether one sentence can be inferred from another.
In this chapter we present our approach to analyzing such semantic social networks and capturing collective intelligence from collaborative interactions to challenge requirements of Enterprise 2.0.
We propose a simple but powerful color attenuation prior for haze removal from a single input hazy image.
This paper presents a novel intermediate feature representation named skeleton map for regression. It is simple, clean and can be easily generated via deconvolution network.
We present a robust pothole detection algorithm that is both accurate and computationally efficient.
In this paper, we present hierarchical relationbased latent Dirichlet allocation (hrLDA), a data-driven hierarchical topic model for extracting terminological ontologies from a large number of heterogeneous documents.
A novel mixed variant of the recently introduced maxout unit called a mixout unit improves the pooling ability and achieves better feature learning and classification performance.
The condition assessment of road surfaces is essential to ensure their serviceability while still providing maximum road traffic safety. This paper presents a robust stereo vision system embedded in an unmanned aerial vehicle.
We propose a monocular 3D object detection framework in the domain of autonomous driving in order to exploit 3D contexts explicitly.
In this paper, we aim for generic feature learning and present an approach for training a convolutional network using only unlabeled data.
We present Kronecker Factors for Convolution (KFC), a tractable approximation to the Fisher matrix based on a structured probabilistic model for the distribution over backpropagated derivatives. KFC captures important curvature information while still yielding comparably efficient updates.
In this paper, we explore models that incorporate visual information into the text representation. Based on comprehensive ablation studies, we propose a conceptually simple, yet well performing architecture.
We train a standard object detector on a small, normally packed dataset with data augmentation techniques. We also create a varied benchmark for generic SKU product detection.
We propose a hardware-friendly training method that progressively binarizes a singular set of fixed-point network parameters, yielding notable reductions in power and resource utilizations.
We quantitatively investigate the stochasticity of different whitening transformations and show that it correlates well with the optimization behaviors during training.
We propose an end-to-end deep learning approach for part-based attribute recognition. Both key point estimation and attribute recognition are learnt jointly.
Using error-feedback improves both convergence and generalization of signSGD.
We investigate neural network training and generalization using the concept of stiffness. We measure how stiff a network is by looking at how a small gradient step on one example affects the loss on another example, and measure stiffness as a function of distance between data points and learning rate.
We introduced an automated framework to detect relative afferent pupillary defect (RAPD), which is based on difference between the reactions of the eyes when they are exposed to light stimuli.
We propose a semi-automated, ablation-based methodology for this challenge; By checking whether questions can be solved even after removing features associated with a skill requisite for language understanding.
We propose modified cycle-consistent generative adversarial network that generates an even distribution of heterogeneous face data, and an age-estimation method that is effective for heterogeneous data based on comparative CNN for age estimation.
We propose a cascaded context mixer (CCM), which efficiently integrates spatial and channel context information and progressively refines them for keypoint detection.
We study the regularizing effects of variational distributions on learning in generative models from two perspectives, and propose an approximation consisting of a deterministic autoencoding objective plus analytic regularizers.
We explore a novel way of conceptualising the task of polyphonic music transcription, using so-called invertible neural networks, and investigate its properties.
We propose a deep SISR network that works for blur kernels of different sizes, and different noise levels in an unified residual CNN-based denoiser network, which significantly improves a practical CNN- based super-resolver for real applications.
We integrate standard bottom-up reconstruction and top-down understanding for better stereo reconstruction.
We propose a comprehensive study that systematically evaluates FVs and CNNs for image instance retrieval. We show that no descriptor is systematically better than the other and that performance gains can be obtained by using both types together.
We propose a novel convex model to learn the structured doubly stochastic matrix by imposing low-rank constraint on the graph Laplacian matrix, which improves the clustering results.
We extend an existing action recognition model by incorporating scene graphs as spatio-temporal feature banks, enabling few-shot action recognition.
We propose extreme point annotations for object bounding boxes and show that they are faster than the traditional way of drawing box coordinates.
We construct a dataset for movie understanding and develop a framework for matching synopsis paragraphs and movie segments, based on a graph-based formulation.
We propose ESSOP, an efficient and scalable stochastic outer product architecture based on the SC paradigm for DNN training.
We propose a method for reconstructing 3D shapes from 2D sketches in the form of line drawings using a deep neural network.
This paper proposes the Global-Local Temporal Representation (GLTR) to exploit the multi-scale temporal cues in video sequences for video person Re-Identification.
We evaluate three modifications of BiLSTM-CRF for BioNER to alleviate overfitting and improve generalization: improved regularization via variational dropout, transfer learning, and multi-task learning.
We conduct a thorough examination of typical MTL methods on a broad range of representative NLP tasks for their strong performance in-depth.
We present RingNet, which learns to compute 3D face shape from a single image without any 2D-to-3D supervision.
In this paper, we propose a novel objective for one-class learning. Our key idea is to use a pair of orthonormal frames -- as subspaces -- to "sandwich" the labeled data via optimizing for two objectives jointly.
This paper studies the problem of stance detection which aims to predict the perspective (or stance) of a given document with respect to a given claim.
We introduce the relative Intersection over Union (rIoU) accuracy measure that normalizes the IoU with the optimal box for the segmentation to generate an accurate measure that ranges between 0 and 1.
We exhaustively research skip connections of state-of-the-art deep convolutional networks and investigate the characteristics of each intermediate layer for semantic segmentation through skip connection.
A new method for Simultaneous Localisation and Mapping (SLAM) based on Transferable Belief Model (TBM) for urban environment.
This paper addresses the problem of facial landmark localization and tracking from a single camera. We propose a cascaded deformable shape model to effectively and efficiently localize facial landmarks with large head pose variations.
We use reinforcement learning to learn tree-structured neural networks for computing representations of natural language sentences. We analyze the induced trees and show that while they discover linguistically intuitive structures (e.g., noun phrases, simple verb phrases), they are different than conventional English syntactic structures.
We propose an end-to-end trainable style retention network for editing text in natural images, which aims to replace or modify a word in the source image with another one while maintaining its realistic look.
We present an approach for learning attribute representations with Convolutional Neural Networks (CNNs) for segmentation-based word spotting.
We introduce universal adversarial networks, generative networks capable of fooling a target classifier when it's generated output is added to a clean sample from a dataset.
We explore the use of Evolution Strategies (ES), a class of black box optimization algorithms, as an alternative to popular MDP-based RL techniques such as Q-learning and Policy Gradients.
We propose GI-Dropout, a novel dropout method integrating with global information to improve neural networks for text classification.
We address the problem of 3D rotation equivariance in convolutional neural networks by implementing exact convolutions on the sphere by realizing them in the harmonic domain.
We study the cold-start link prediction problem where edges between vertices is unavailable by learning vertex-based similarity metrics. We propose to learn community-specific similarity metrics via joint community detection.
We study more informative novelty detection schemes based on a hierarchical classification framework, and propose two different approaches termed top-down and flatten methods, and their combination.
This paper presents a new action recognition approach based on local spatio-temporal features. The main contributions of our approach are twofold.
In this paper we present practical semi-supervised and self-super supervised models that support training and good generalization in real-world images and video.
We propose a semi-supervised generative model for human body analysis where the pose and appearance are disentangled in the latent space, allowing for pose estimation.
We investigate the benefits of integrating CNNs and LSTMs and report obtained improved accuracy for Arabic sentiment analysis on different datasets.
We propose an iterative pick-place action space that encodes the conditional relationship between picking and placing on deformable objects and use this space to accelerate learning.
In this paper, we propose guiding depth estimation to favor planar structures that are ubiquitous especially in indoor environments, using a novel attention mechanism called depth-attention volume.
We extend our convolutional RNN model with a frame-level attention mechanism for environmental sound classification.
We define a criterion which minimizes the probability of overlap between the classification hyperplane and the subspace of solutions in class 1, because we do not know which values in this subspace a test vector can take.
Large-scale user/item interaction data sets by expanding pre-existing public data sets for recommender system research.
We present the first method to perform automatic 3D pose, shape and texture capture of animals from images acquired in-the-wild.
We propose a Hotspot Network (HotSpotNet) that performs 3D object detection via firing of hotspots without setting the predefined bounding boxes.
We propose a novel text generation task, namely Curiosity-driven Question Generation. We investigate several automated metrics to measure the different properties of Curious Questions, including model pre-training and reinforcement learning.
We introduce a graph-based RKD method, in which graphs are used to capture the geometry of latent spaces, allowing for dimension-agnostic transfer of knowledge.
We propose Generalized Hidden Parameter MDPs where both dynamics and reward can change as a function of hidden parameters that vary across tasks, enabling efficient generalization.
Microsoft Kinect, a low-cost motion sensing device, enables users to interact with computers or game consoles naturally through gestures and spoken commands without any other peripheral equipment.
In this study, I analyze the DBLP bibliographic database to study role of single author publications in computer science literature between 1940 and 2019.
We propose a second-order minimum energy filter with a generalized kinematic model that copes with the full geometry of SE(3) as well as with the nonlinear dependencies between the state space and observations.
We explored the role of recurrence in improving classification performance in biological visual systems, and identified novel local recurrent cells and long-range feedback connections useful for object recognition.
In this paper, we explore two alternative data sources to improve aerial action classification when only a few training aerial examples are available.
We develop experimental systems to conduct this analysis, showing results with modern deep learning algorithms and recent overhead image data and comparing them to standard image quality measurements based on human visual perception.
We show event-based car detection under ego-motion in a real environment at 100 frames per second with test average precision of 40.3% relative to our annotated ground truth.
A new training paradigm that maximizes the likelihood of the groundtruth class while neutralizing the probabilities of the complement classes can be effective in improving model performance.
We investigate the limits and performance tradeoffs of memory-efficient adaptively preconditioned gradient methods, showing that an optimizer needs very little memory to benefit from adaptive preconditionsing.
We introduce a hierarchical structure on top of fc7 features, which can capture the temporal variation in a video and achieve superior results compared to other state-of-the-arts methods.
EgoReID is a first-of-its-kind Re-Identification dataset for egocentric videos. Considering the unique nature of our dataset, we propose a new framework which takes advantage of both visual and sensor meta data to successfully perform Person ReID.
In this paper, we describe a low-rank matrix completion method based on matrix decomposition. The divide-and-conquer approach can significantly reduce computation complexity and storage requirement.
We explore using contextualized word embeddings to compute more accurate relatedness scores, thus better evaluation metrics.
We proposed an algorithm which combines the general pre-trained word embedding vectors with those generated on the task-specific training set to address the large number of out-of-vocabulary words.
We propose SynGCN, a Graph Convolution based method for learning word embeddings without increasing the vocabulary size.
This paper proposes a novel embedding model, TorusE, to solve the regularization problem for knowledge graph embedding.
This paper introduces a novel method for realtime portrait animation in a single photo. The core of our method is a warp-guided generative model that instantly fuses various fine facial details (e.g., creases and wrinkles) onto a pre-warped image.
The advance algorithms like Faster Regional Convolutional Neural Network (Faster R-CNN) models are suitable to identify moving objects, due to the efficiency in learning the training dataset superior than ordinary CNN algorithms and the higher accuracy of labeling correct classes in the validation and testing dataset.
A flask for attachment to a life preserver is provided with a coiled straw inside the flask and a valve mechanism which pinches the end portion of the straw shut to prevent the entrance of sea water in the flask.
This paper presents a statistical approach to the preprocessing of degraded handwritten forms including the steps of binarization and form line removal.
We first provide a new perspective to divide existing high performance object detection methods into direct and indirect regressions.
We propose a new framework for domain adaptation in which deep neural networks can be used to match both marginal and conditional distributions.
This paper proposed a practical and robust features selection algorithm of visual navigation which avoids using the feature points on dynamic objects in the dynamic environment.
We hypothesize that the curvature and the diameter of blood vessels are Gaussian processes (GPs) and propose an approach for blood vessel tracking and diameter estimation.
We propose a more holistic approach, which considers the entire shape of the object of interest by leveraging higher-level image analysis and learnt global shape priors, and use the resulting P-maps to generate an accurate object cutout mask.
We present a self-supervised approach to estimate flow in camera image and top-view grid map sequences using fully convolutional neural networks in the domain of automated driving.
This paper proposes the novel question-aware sentence gating networks that directly incorporate the sentence-level information into word-level encoding processes for QA tasks.
Spatial pyramid pooling module or encode-decoder structure are used in deep neural networks for semantic segmentation task. We propose to combine the advantages from both methods for faster and stronger encoder-decode network.
We propose a novel model that supports the multi-domain image-to-image translation using one single model.
In this paper, we propose a benchmark for expert finding in document networks by leveraging data extracted from a scientific citation network and three scientific question&answer websites.
We explore a number of memory-light model reduction strategies that do not require model pre-training from scratch, while maintaining up to 98% of their original performance.
In this paper, we present novel techniques that improve the computational and memory efficiency of algorithms for solving multi-label energy functions arising from discrete MRFs or CRFs.
We present an alternate view to explain the success of LSTMs: the gates themselves are powerful recurrent models that provide more representational power than previously appreciated.
We explore the possibility of using a single monocular camera to forecast the time to collision between a suitcase-shaped robot being pushed by its user and other nearby pedestrians.
We introduce the Dynamic Coattention Network (DCN) for question answering.
In this paper, we propose using 3D Convolutional Neural Networks for large scale user-independent continuous gesture recognition.
We propose an effective multi-task learning network EdgeStereo composed of a disparity estimation sub-network and an edge detection sub- network, which enables end-to-end predictions of both disparity map and edge map.
Strong theoretical guarantees of robustness can be given for ensembles of classifiers generated by input randomization, where the adversary is bounded.
We propose an efficient spatio-temporal prior, that when conditioned on a geographical location and time, estimates the probability that a given object category occurs at that location.
We introduce Gluon Time Series (GluonTS, available at this https URL), a library for deep learning-based time series modeling.
We propose an SSL method named MixGDA by combining various mixup methods and GDA that achieves state-of-the-art performance for consistency regularization.
We present discriminative Gaifman models, a novel family of relational machine learning models that learn feature representations bottom up from representations of locally connected and bounded-size regions of knowledge bases.
This paper proposes a new supervised method for blood vessel segmentation using Zernike moment-based shape descriptors.
We propose a model that fully synthesizes multiple input signals from the multimodal world|the environment's scene context and interactions between multiple surrounding agents|to best model all diverse and admissible trajectories.
In this work we present In-Place Activated Batch Normalization (InPlace-ABN) - a novel approach to drastically reduce the training memory footprint of modern deep neural networks in a computationally efficient way.
In this paper we explore two ways of using context for object detection. The first model focusses on people and the objects they commonly interact with, such as fashion and sports accessories. The second model considers more general object detection and uses the spatial relationships between objects and scenes.
In this paper, we propose a new approach for retrieval of video segments using natural language queries using image captioning model.
We propose a feature mask network for person re-identification from a multi-camera system that uses ResNet high-level features to predict a feature map mask and dynamically reweight different object parts for a locally aware feature representation.
In this paper, we propose an approach for Facial Expressions Recognition (FER) based on a deep multi-facial patches aggregation network that achieves state-of-art FER deep learning approaches performance.
In this paper, we propose an omnivorous model that takes parallel data and formality-classified data jointly to alleviate the data sparsity issue.
We propose Circulant Binary Embedding (CBE) which generates binary codes by projecting the data with a circulant matrix. The challenge here is to show that the dependencies in the entries of the circulan matrix do not lead to a loss in performance.
In this paper research on a compact deep convolutional neural network for age and gender estimation from facial images.
In this paper, we propose the first class of dynamic backdooring techniques: Random Backdoor, Backdoor Generating Network (BaN), and conditional Backdoor Generation Network (c-BaN)
We propose an extended and unified neural network architecture for multi-task learning and use it for part-of-speech tagging, image captioning, visual question answering and video activity recognition.
We present a novel deep architecture that performs new view synthesis directly from pixels, trained from a large number of posed image sets, and achieve high quality results on traditionally difficult scenes.
Head magnetomyography as a whole head electromyographic recorder for head and face muscle activity.
We study basic-level categories for describing visual concepts, and empirically observe context-dependant basic level names across thousands of concepts.
We propose a simple and efficient method for creating realistic targeted synthetic datasets in the remote sensing domain, leveraging the opportunities offered by game development engines.
We reformulate a common logistic regression CTR model by putting it back into its subsequent bidding context: rather than minimizing the prediction error, the model parameters are learned directly by optimizing campaign profit.
We introduce SalGAN, a deep convolutional neural network for visual saliency prediction trained with adversarial examples.
We tackle the problem of transferring an existing pre-trained model from English to other languages under a limited computational budget under a single GPU.
We explore the approach of registering the new facial sur- face to an average face model (AFM), which automatically estab- lishes correspondence to the preregistered gallery faces.
We describe our entry, C2L2, to the CoNLL 2017 shared task on parsing Universal Dependencies from raw text. Our system features three global parsing paradigms, one graph-based and two transition-based.
RDF2vec is a technique for creating vector space embeddings from an RDF knowledge graph, i.e., representing each entity in the graph as a vector.
We study a number of ways of fusing ConvNet towers both spatially and temporally in order to best take advantage of this spatio-temporal information, and propose a new ConvNet architecture for spatiotemporal fusion of video snippets.
This paper aims to evaluate the performance of twelve state-of-the-art ResNet-based FENs in a DCF-based framework to determine the best for visual tracking purposes.
We present a new optimization technique, namely gradient centralization (GC), which operates directly on gradients by centralizing the gradient vectors to have zero mean.
In this paper, we propose a novel color-texture image segmentation method based on local histograms.
FABIR achieves competitive results in the Stanford Question Answering Dataset while having fewer parameters and being faster at both learning and inference than rival methods.
A spatially adaptive tensor total variation-Tikhonov model is proposed to solve this problem.
We introduce a novel word vector post-processing technique based on matrix conceptors, a family of regularized identity maps, which can be used to suppress latent features of word vectors having high variances.
We present a generic multi task learning (MTL) based framework which handles the evidence as the output of one or more secondary tasks, while modeling the original problem as the primary task of interest.
We propose ViewAL, a novel active learning strategy for semantic segmentation that exploits viewpoint consistency and exploits inherently localized signal in the segmentation task, directly lowering the annotation costs.
In this paper, we present a novel deep method to reconstruct a point cloud of an object from a single still image.
We propose a two-step pipeline for accurate and consistent tracing of retinal blood vessel tree structures from fundus images in an automated manner in a probabilistic graphical model.
A first exploration on the use of an epoch-dependent distribution, starting with a higher probability of bypassing deeper layers and then activating them more frequently as training progresses.
In this paper, to address the problem of depth from stereo in nighttime, we introduce a joint translation and stereo network that is robust to nighttime conditions.
We propose a novel real-time algorithm for estimating the local scale correction of a monocular SLAM system, to obtain a correctly scaled version of the 3D map and of the camera trajectory.
Knowledge bases (KBs) of real-world facts about entities and their relationships are useful resources for natural language processing tasks. However, because knowledge bases are typically incomplete, it is useful to be able to perform knowledge base completion or link prediction, i.e., predict whether a relationship not in the knowledge base is likely to be true.
In this paper, we introduce a novel ordered representation of consecutive optical flow frames as an alternative and argue that this representation captures the action dynamics more efficiently than RGB frames.
We empirically demonstrate the effectiveness of two diversity models for training-data subset selection and reducing labeling effort.
We propose a 3D object detection system with multi-sensor refinement in the context of autonomous driving.
A global tensor descriptor based on orientation tensors is proposed for videos.
The goal of the present study is to explore the application of deep convolutional network features to emotion recognition.
In recent years, several automatic segmentation methods have been proposed for blood vessels in retinal fundus images, ranging from using cheap and fast trainable filters to complicated neural networks and even deep learning. In this paper we discuss and evaluate several of these vessel segmentation method.
In this paper, we aim to automatically render aging faces in a personalized way. Basically, a set of age-group specific dictionaries are learned, where the dictionary bases corresponding to the same index yet from different dictionaries form a particular aging process pattern cross different age groups.
We propose an iterative algorithm to learn pairwise relations for weakly-supervised semantic segmentation, which performs favorably against state-of-the-art methods.
A novel online adaptation algorithm for deep models, based on batch-normalization layers, which allows to continuously adapt a model to the current working conditions in unconstrained scenarios.
We propose an image steganographic algorithm called EncryptGAN, which disguises private image communication in an open communication channel. We ensure the image communication remain secret except for the intended recipient.
We study the generalization error of neural networks for classification problems in terms of data distribution and neural network smoothness, and derive a quantitative bound.
We introduce a multimodal variational autoencoder (MVAE) that uses a product-of-experts inference network and a sub-sampled training paradigm to solve the multi-modal inference problem.
We introduce a simple (one line) modification to the Generative Adversarial Network (GAN) training algorithm that materially improves results with no increase in computational cost.
This paper presents a novel multiple attention network that simulates humans’ coarse-to-fine visual attention to improve expression recognition performance.
Adversarial images aim to change a target model's decision by minimally perturbing a target image. In the black-box setting, the absence of gradient information often renders this search problem costly in terms of query complexity.
We explore the impact of feature selection in model fine-tuning by introducing a transfer module, which assigns weights to features extracted from pre-trained models and achieve state-of-the-art results.
In this review, we examine the recent progress in saliency prediction and proposed several avenues for future research.
In this paper we introduce the TorontoCity benchmark, which covers the full greater Toronto area (GTA) with 712.5km2 of land, 8439km of road and around 400, 000 buildings.
This paper presents QUEST, a method that can answer complex questions directly from textual sources on-the-fly, by computing similarity joins over partial results from different documents.
We propose an Attribute-guided Face Recovery from Portraits (AFRP) that utilizes a Face Recovery Network (FRN) and a Discriminative Network (DN) and achieves state-of-the-art results.
We propose to learn temporal embeddings of video frames by associating frames with the temporal context that they appear in.
We derive adversarial examples in terms of the hypothesis-only bias and explore eligible ways to mitigate such bias in NLI debiasing tasks.
We introduce an architecture, the Tensor Product Recurrent Network (TPRN), in which internal representations learned by end-to-end optimization in a deep neural network performing a textual QA task can be interpreted using basic concepts from linguistic theory.
Leveraging over 30,000 images each with up to 89 labels collected by Recology---an integrated resource recovery company with both residential and commercial trash, recycling and composting services---the authors develop ContamiNet, a convolutional neural network, to identify contaminating material in residential recyclingand compost bins.
We propose a simple learning-based approach for generic, moving object detection, and show that our model matches top-down methods on common categories, while significantly out-performing both top- down and bottom-up methods on never-before-seen categories.
We analyze SGD from a geometrical perspective by inspecting the stochasticity of the norms and directions of minibatch gradients, and propose a model of the directional concentration for minib batch gradients through von Mises-Fisher distribution.
A novel propagation algorithm employing the teaching-tolearn and learning-to-teach strategies is proposed to explicitly improve the propagation quality.
We propose three multimodal deep fusion strategies to maximize the benefits of visual-audio resonance information and achieve the state-of-art performance.
The SAMPL4 challenges were used to test current automated methods for solvation energy, virtual screening, pose and affinity prediction of the molecular docking pipeline DOCK 3.7.
We propose a novel extremely separated convolutional block (XSepConv), which fuses spatially separable convolutions into depthwise convolution to further reduce both the computational cost and parameter size of large kernels.
This paper proposes a new method for stereo matching based on generalized Fourier descriptors using a robust cost function.
In this paper ECA is proposed by extracting features in PCA (2DPCA) based on Renyi entropy contribution.
We propose two data augmentation methods that create additional training examples to help improve model explainability of existing sentiment classifiers.
We propose a multi-task learning framework to learn a joint Machine Reading Comprehension (MRC) model that can be applied to a wide range of MRC tasks in different domains.
We propose to use motion vectors and residuals from modern video compression techniques to effectively learn the representation of raw frames and greatly remove the temporal redundancy, giving a faster video processing model.
We propose a flexible end-to-end model of Universal Successor Features that capture the underlying dynamics of the environment while allowing generalization to unseen goals and can effectively transfer knowledge to new tasks.
We leverage the WordNet hierarchy to define semantic distance between any two categories and use this semantic distance to share labels.
We present an end-to-end network which stores short- and long-term video sequence information preceding the current frame as the temporal memories to address the temporal modeling in VOS.
We show that the current state of the art in single-view object reconstruction does not actually perform reconstruction but image classification and retrieval.
In this paper we present, to the best of our knowledge, the first method to learn a generative model of 3D shapes from natural images in a fully unsupervised way.
This paper proposes an unsupervised bottom-up saliency detection approach based on complementary background template with refinement.
We propose the Recurrent Attended Variation Embedding Network (RAVEN) that models the fine-grained structure of nonverbal subword sequences and dynamically shifts word representations based on the accompanying nonverbal behaviors.
This paper contributes to solving problems related to ambiguity in PICO sentence prediction tasks, as well as highlighting how annotations for training named entity recognition systems are used to train a high-performing but nevertheless flexible architecture for question answering in systematic review automation.
We address the problem of measuring the relative goodness of fit of the two models. We propose two new statistical tests which are nonparametric, computationally efficient (runtime complexity is linear in the sample size), and interpretable.
We explicitly model the key instances assignment as a hidden variable and adopt an Expectation-Maximization framework to solve the weakly-supervised action localization problem.
We introduce dynamic meta-embeddings, a simple yet effective method for supervised learning of embedding ensembles, which leads to state-of-the-art performance within the same model class on a variety of tasks.
This work presents and evaluates a novel compact scene representation based on Stixels that infers geometric and semantic information in a sound global energy minimization formulation.
We devise a multi-modal solution for spatial regression using mixture density networks for dense object detection and human pose estimation that converges faster and yields higher accuracy.
We propose a novel framework for 6D object pose estimation of unseen objects using an end-to-end neural network.
We propose a novel loss function, i.e., Conservative Loss, which penalizes the extreme good and bad cases while encouraging the moderate examples.
ImageNet is a large-scale hierarchical database of object classes. We propose to automatically populate it with pixelwise segmentations, by leveraging existing manual annotations in the form of class labels and bounding-boxes.
A birds-eye view of the applicability of contemporary VPR research to aerial robotics and lays down the nature of challenges for aerial-VPR.
We present a comparison of word-based and character-based sequence-to sequence models for data-to-text natural language generation, which generate natural language descriptions for structured inputs.
This paper introduces filters that are full-stack and can be used to generate many more sub-filters for a minimum viable CNN.
PixelCNN achieves state-of-the-art results in density estimation for natural images. We propose a parallelized PixelCNN that allows more efficient inference by modeling certain pixel groups as conditionally independent.
We develop an innovative image synthesis technique that composes annotated training images by realistically embedding foreground objects of interest (OOI) into background images and use these images in deep network training.
We propose a method which scores each candidate window in the context of all other windows in an image, taking into account their similarity in appearance space as well as their spatial relations in the image plane.
Self-attention can be a stand-alone primitive for vision models instead of serving as just an augmentation on top of convolutions.
We propose a simple and efficient method for exploiting synthetic images when training a Deep Network to predict a 3D pose from an image.
We propose a novel subset selection technique that leverages supervision in the form of human-created summaries to perform automatic keyframe-based video summarization.
We propose an end-to-end trainable recurrent and convolutional network model that jointly learns to process visual and linguistic information and produce quality segmentation output from the natural language expression.
We propose a highly automatic method for calibrating sports cameras from a single image using synthetic data.
We explore whether transformers can learn rule-based reasoning, but using rules expressed in language, thus bypassing a formal representation. We provide the first demonstration that this is possible.
We present the next generation of MobileNets based on a combination of complementary search techniques as well as a novel architecture design.
We propose MAsked Sequence to Sequence pre-training (MASS) for the encoder-decoder based language generation tasks, achieving state-of-the-art accuracy and fine-tuning.
We propose a method to revise the neural network to construct the quaternion-valued neural network (QNN), in order to prevent intermediate-layer features from leaking input information.
We explore the effectiveness of self-attention networks for sentiment analysis and explore the effects of various SAN modifications.
We examine the capabilities of a unified, multi-task framework for three information extraction tasks: named entity recognition, relation extraction, and event extraction.
In this paper, we formalize such inconsistency as a generalization of prediction error. We propose a learning framework using logic rules to regularize them away from inconsistency.
We propose a flexible audiovisual model that introduces a soft-clustering module as the audio and visual content detector, and regards the pervasive property of audiovISual concurrency as the latent supervision for inference of correlation among detected contents.
We use one of the best generative models of natural images–a gated MRF–as the lowest level of a deep belief network (DBN) that has several hidden layers that produce features that perform comparably to SIFT descriptors for discriminating different types of scene.
We introduce Indiscapes, the first ever dataset with multi-regional layout annotations for historical Indic manuscripts at scale.
This paper provides a detailed study on the convergence properties of the cubic regularized symmetric rank-1 method (CuREG-SR1) proposed in <xref ref-type="bibr" rid="ref2">[2]
We address the challenging problem of efficient deep learning model deployment, where the goal is to design neural network architectures that can fit different hardware platform constraints. Most of the traditional approaches either manually design or use Neural Architecture Search to find a specialized neural network and train it from scratch.
We propose a novel bootstrapping approach, Neural Snowball, to learn new relations with few-shot instances by transferring semantic knowledge about existing relations.
In this paper, we propose PopEval, a novel evaluation approach for the recent OCR interests.
We propose a novel technical approach that augments a Bayesian non-parametric regression mixture model with multiple elastic nets to extract generalizable insights for a target model through a global approximation.
In this paper, we present a new regularized training approach: Shakeout. Instead of randomly discarding units as Dropout does at the training stage, Shakeout randomly chooses to enhance or reverse each unit's contribution to the next layer.
We propose a novel method for real-time tracking based on keypoint consensus clustering and improved DCF trackers with competitive accuracy and performance.
We propose StartNet to address Online Detection of Action Start (ODAS) where action starts and their associated categories are detected in untrimmed, streaming videos.
We define a nonsecond order statistical measure in kernel space, called the kernel mean-p power error (KMPE), including the correntropic loss (CLoss) as a special case, and develop two robust learning algorithms that achieve consistently better performance when compared with some existing methods.
We introduce the Spatial-/Channel-wise Attention Models into the traditional Regression CNN to estimate the density map, which is named as “SCAR”.
We propose a straightforward technique to constrain discrete ordinal probability distributions to be unimodal via the use of the Poisson and binomial probability distributions, obtaining promising results on two large ordinal image datasets.
This paper shows that simply prescribing "none of the above" labels to unlabeled data has a beneficial regularization effect to supervised learning.
In this paper, we propose a novel feature type to recognize human actions from video data. By combining the benefit of Volume Local Binary Patterns and Optical Flow, a simple and efficient descriptor is constructed.
We propose a deep generative adversarial network (FCSR-GAN) for performing joint face completion and face super-resolution via multi-task learning.
In this paper, we propose a method of extracting feature descriptors from discrete spherical images using convolutional neural networks (CNNs) using an unsupervised CNN.
Robust Block-Diagonal Adaptive Locality-constrained Latent Representation for Unsupervised Representation Learning .
We propose a framework to encode the geometric structure of the special Euclidean motion group SE(2) in convolutional networks to yield translation and rotation equivariance via the introduction of SE( 2)-group convolution layers.
The recent "Lottery Ticket Hypothesis" paper by Frankle & Carbin showed that a simple approach to creating sparse networks (keep the large weights) results in models that are trainable from scratch, but only when starting from the same initial weights.
We propose a latent classification model that generalizes the naive Bayes model to hybrid domains and uses latent variables to model class-conditional dependencies.
Discriminative Subspace Clustering solves the subspace clustering problem by using a quadratic classifier trained from unlabeled data.
The visual saliency detection model simulates the human visual system to perceive the scene and has been widely used in many vision tasks. With the development of acquisition technology, more comprehensive information, such as depth cue, inter-image correspondence, or temporal relationship, is available to extend image Saliency detection to RGBD saliency Detection, co-saliency detection, or video saliency detecting.
In this paper we propose a framework which extracts sparse features invariant under significant rotations and scalings, and proved to be robust under transformed data.
We introduce a general feedback-based propagation approach (feedback-prop) that allows us to boost the prediction accuracy of an existing CNN model for an arbitrary set of unknown image labels when a non-overlapping set of labels is known.
We propose to leverage denoising autoencoder networks as priors to address image restoration problems. We use the magnitude of this mean shift vector, that is, the distance to the local mean, as negative log likelihood of our natural image prior.
We propose MRU (Multi-Range Reasoning Units), a new fast compositional encoder for machine comprehension (MC), achieving state-of-the-art results.
We propose Spatio-Temporal Instance Learning, which enables weakly-supervised action localization in videos, using only the supervision from video-level class labels.
Superpixel segmentation is used to partition an image into perceptually coherence atomic regions. Based on a solution derived from the expectation-maximization method, a well designed algorithm is proposed.
This paper studies how weight repetition ---when the same weight occurs multiple times in or across weight vectors--- can be exploited to save energy and improve performance during CNN inference.
We investigate the problem of person search in the wild in this work. Instead of comparing the query against all candidate regions generated in a query-blind manner, we propose to recursively shrink the search area from the whole image till achieving precise localization of the target.
We propose a two-layer fusion method which takes advantage of global and local cues and ranks database images from coarse to fine (C2F).
We introduce two extensions to the DDPG, which make it significantly more data-efficient and scalable.
We present a method for constructing a mixture of meta-learners, where mixing parameters are determined by the weight prediction network (WPN) optimized to improve the few-shot classification performance.
We investigate the geometric properties of the functions learned by trained ConvNets in the preactivation space of their convolutional layers, by performing an empirical study of hyperplane arrangements induced by a Convolutional layer.
In this paper, we propose a novel approach which turns the ZSL problem into a conventional supervised learning problem by synthesizing samples for the unseen classes.
We propose a novel approach for online action detection based on 3D skeleton sequences extracted from depth data. It identifies the sub-interval with maximum classifier score in linear time.
We develop an analytical framework that extends linear scaling to match the parallel computing capacity of a resource, allowing for faster training time on given hardware.
We propose a framework which combines the strengths of a 3DMM model fitted online with a prior-free reconstruction of a3D full head model providing support for pose estimation from any viewpoint.
In this survey we present a complete landscape of joint object detection and pose estimation methods that use monocular vision.
We utilize the hierarchical features of convolutional neural networks (CNNs) and learn a discriminative correlation filter to improve the robustness of visual tracking.
Using sequence to sequence algorithms for query expansion has not been explored yet in Information Retrieval literature nor in Question-Answering's.
We present an information theoretic framework for one-class classification, which allows for deriving several new novelty scores and detecting outliers not belonging to a learnt distribution.
Our proposed CNN provides an end-to-end framework with convolutional architectures for learning not only the image and question representations, but also their inter-modal interactions to produce the answer.
In this paper, we propose a novel convolution-deconvolution network for facial keypoint detection which captures the relationships between keypoints at feature level.
We propose a memory-efficient network for salient object segmentation by training it only on salient object detection datasets that uses only 0.048% of the number of parameters.
We present a 3D capsule architecture for processing of point clouds that is equivariant with respect to the $SO(3)$ rotation group, translation and permutation of the unordered input sets, and a dynamic routing procedure.
We introduce an actor-supervised architecture that exploits the inherent compositionality of actions in terms of actor transformations, to localize actions in videos.
This paper is the first work to propose a network to predict a structured uncertainty distribution for a synthesized image, which permits efficient sampling and likelihood evaluation.
This paper presents a robust single-stage face detector, named RetinaFace, which performs pixel-wise face localisation on various scales of faces by taking advantages of joint extra-supervised and self-Supervised multi-task learning.
We give general guidelines on system design for MRS by proposing a simple yet effective pipeline system with special consideration on hierarchical semantic retrieval at both paragraph and sentence level, and their potential effects on the downstream task.
We propose a dual-source approach that combines 2D pose estimation with efficient 3D pose retrieval.
We extend the framework of natural policy gradient and propose to optimize both the actor and the critic using Kronecker-factored approximate curvature with trust region; hence we call our method Actor Critic using KrONEcker-Factored Trust Region.
We present Siam R-CNN, a Siamese re-detection architecture which unleashes the full power of two-stage object detection approaches for visual object tracking.
We propose a novel recurrent criss-cross attention module for obtaining full-image dependencies in a more effective and efficient way.
We propose a data-driven learned sky model, which we use for outdoor lighting estimation, solving both problems end-to-end.
We address the problem of learning predictive models from multiple large, distributed, autonomous, and hence almost invariably semantically disparate, relational data sources from a user's point of view, without the need for a centralized data warehouse.
Scene segmentation is the well-known task of identifying the image regions corresponding to the different scene elements or segments, k = 1, 2...,N belonging to a predefined set S partitioning the scene in N subsets, each one corresponding to a scene object or to a region of interest.
This paper addresses the problem of learning the optimal control policy for a nonlinear stochastic dynamical system with continuous state space, continuous action space and unknown dynamics using decoupled data-based control.
A nonparametric Bayesian contextual focused topic model (cFTM) infers a sparse ("focused") set of topics for each document, while also leveraging contextual information about the author(s) and document venue.
We propose a tree ensemble based auto-encoder that can do backward reconstruction by utilizing the equivalent classes defined by decision paths of trees.
We propose a novel adversarial encoder-decoder-classifier framework to learn a modality-invariant embedding space for multimodal fusion.
We present an exhaustive study of robustness of DeepLabv3+ for semantic segmentation, based on the state-of-the-art model.
Part-level representations are essential for robust person re-identification. However, common errors that arise during pedestrian detection frequently result in severe misalignment problems for body parts, which degrade the quality of part representations. Accordingly, to deal with this problem, we propose a novel model named Convolutional Deformable Part Models.
In this paper, we describe the system for generating textual descriptions of short video clips using recurrent neural networks (RNN), which we used while participating in the Large Scale Movie Description Challenge 2015 in ICCV 2015.
We address the question of how to select an optimal subset of the set of classes, subject to a budget constraint, that will more likely generate good features for other tasks. We empirically validate our submodular model.
We propose a unified robust cascade regression framework that can handle both images with severe occlusion and images with large head poses.
Learning generic and robust feature representations with data from multiple domains for the same problem is of great value, especially for the problems that have multiple datasets but none of them are large enough.
We propose an approach to cope with the problem of 2D face image recognition system by using 1D Discrete Hidden Markov Model (1D-DHMM).
We propose a novel end-to-end deep network model for reading comprehension, which we refer to as Episodic Memory Reader (EMR) that sequentially reads the input contexts into an external memory, while replacing memories that are less important for answering questions.
This paper focuses on structured-output learning using deep neural networks for 3D human pose estimation from monocular images.
We propose a novel diverse feature selection method based on determinantal point processes (DPPs), employing a variational approximation to the true spike and slab posterior distribution.
We trained function-specific classifiers to optimize the influence of different biological datasets for each functional category.
We propose a novel Asymptotic-Quantized Estimator (AQE), a quantized neural network with 1-3 bits weights and activations trained by AQE, which achieves comparable classification accuracy as 32-bit counterparts on CIFAR test sets.
We propose a general framework for self-supervised learning of transferable visual representations based on Video-Induced Visual Invariances (VIVI) and achieve state-of-the-art results on the VTAB benchmark.
We develop a new relationship detection model that embeds objects and relations into two vector spaces where both discriminative capability and semantic affinity are preserved. Benefiting from that, our model can achieve superior performance even when the visual entity categories scale up to 80,000.
We show that label misalignment can cause considerably degraded edge learning quality, and propose a probabilistic model where edge alignment is treated as latent variable optimization, and is learned end-to-end.
We propose a framework, trained on synthetic image-depth pairs and unpaired real images, that comprises an image translation network for enhancing realism of input images, followed by a depth prediction network.
This paper addresses real-world challenges in the motion segmentation problem, including perspective effects, missing data, and unknown number of motions. It first formulates an over-segment and merge approach, and then combines the point correspondence information across multiple image frames via a collaborative clustering step.
This paper proposes a system that first computes the geometrical location of objects in a generic scene and then efficiently constructs scene graphs from video by embedding such Geometrical reasoning.
We present a systematic and scalable approach to creating KonIQ-10k, the largest IQA dataset to date, consisting of 10,073 quality scored images. Through the use of crowdsourcing, we obtained 1.2 million reliable quality ratings.
We present a pipeline that requires minimal human intervention and circumvents the reliance on the availability of 3D models by a fast data acquisition method and a synthetic data generation procedure.
We propose a novel batch mode structure from motion based technique for robust SLAM in egocentric videos, wherein we exploit short loop closures arising out of to-and-fro motion of wearer's head.
We study tensor regression networks using various low-rank tensor approximations, aiming to compare the compressive and regularization power of differentlow-rank constraints.
The analysis of spatial relations between objects in digital images plays a crucial role in various application domains related to pattern recognition and computer vision. Classical models for the evaluation of such relations are usually sufficient for the handling of simple objects.
Depth information using the biological Disparity Energy Model can be obtained by using a population of complex cells. We use a new model for encoding disparity information implicitly by employing a trained binocular neuronal population.
In this paper, we propose a novel activation scheme called concatenated ReLU (CRelu), a generic method to improve the performance of CNN architectures.
We propose an unsupervised approach to learn a style-coherent representation of fashion images by using probabilistic polylingual topic models.
We solve the problem of unstable energy dissipation that might damage the quality of the synthesized samples during the maximum likelihood learning of energy-based generative models.
We present a generative framework for zero-shot action recognition where some of the possible action classes do not occur in the training data.
We propose the A-GCN, which leverages the popular Graph Convolutional Networks with an Adaptive label correlation graph to model label dependencies for multi-label image classification.
We perform preliminary studies on a large longitudinal face database MORPH-II, which is a benchmark dataset in the field of computer vision and pattern recognition, and propose a new subsetting scheme for evaluation protocol.
We explore the idea of weight sharing over multiple scales in convolutional networks. Inspired by traditional computer vision approaches, we share the weights of convolution kernels over different layers of the network.
We propose discriminative pooling, based on the notion that among the deep features generated on all short clips, there is at least one that characterizes the action. We use the separating hyperplane as a descriptor for the full video segment.
In this paper, we propose Unsupervised Triplet Hashing (UTH), a fully unsupervised method to compute extremely compact binary hashes --in the 32-256 bits range-- from high-dimensional global descriptors.
A new framework based on deep learning methods for the detection of embryonic neurodevelopmental disorders from embryonic MRI images of various gestational ages.
This paper introduces a novel methodology that combines the multi-resolution feature of the Gabor wavelet transformation (GWT) with the local interactions of the facial structures expressed through the Pseudo Hidden Markov model (PHMM) for face recognition.
We introduce a novel and flexible meta-critic that observes the learning process and meta-learns an additional loss for the actor that accelerates and improves actor-Critic learning.
In this paper, we introduce a unified attention block -- X-Linear attention block, that fully employs bilinear pooling to selectively capitalize on visual information or perform multi-modal reasoning.
In this paper, we propose a set of improvements, which together result in both quantitatively and qualitatively improved depth maps compared to competing self-supervised methods. We demonstrate the effectiveness of each component in isolation.
The causative agent of Legionnaires' disease, Legionella pneumophila, grows in environmental amoebae and mammalian macrophages within a distinct compartment, the 'Legionella-containing vacuole' (LCV). Intracellular bacteria are protected from many antibiotics, and thus are notoriously difficult to eradicate. To identify novel compounds that restrict intracellular bacterial replication, we previously developed an assay based on a coculture of
We use a data-driven computer-aided synthesis planning program to quantify how often molecules proposed by state-of-the-art generative models cannot be readily synthesized.
We present an analysis of three possible strategies for exploiting the power of existing convolutional neural networks (ConvNets) in different scenarios from the ones they were trained.
Collaborative filtering CAPTCHAs allow us to ask questions that have no absolute answer; instead, they are graded by comparison to other people’s answers.
We develop a new multi-cue pedestrian detector that exploits LiDAR data, in addition to visual information, for autonomous vehicles.
We study the benefit of using dynamically increasing batch sizes in parallel SGD for stochastic non-convex optimization and propose a Catalyst-like algorithm to achieve the fastest known convergence rate with linear speedup using only $\log(T$ communication rounds.
Neuro-Evolution is a field of study that has recently gained significantly increased traction in the deep learning community. It combines deep neural networks and evolutionary algorithms to improve and/or automate the construction of neural networks.
We present an unsupervised and unrestricted approach to discovering an infobox like ontology by exploiting the inter-article links within Wikipedia.
We address the problem of semi-supervised video object segmentation (VOS), where the masks of objects of interests are given in the first frame of an input video, until a global view can be established.
This paper presents a novel method which enables decoupled dissimilarity measure in the aggregation, further improving the accuracy and robustness of stereo correspondence and improving the state-of-the-art algorithms.
We compared the processing time required to complete object categorization and localization by varying presentation duration and complexity of natural scene stimuli. We hypothesized that performance would be asymptotic at shorter presentation durations when feed-forward processing suffices.
Fine-tuned BERT learns how keywords lead to correct prediction, instead of learning semantic understanding and reasoning. Under un-answerable data training, BERT achieves unexpectedly high performance.
We introduce multi-step knowledge distillation which employs an intermediate-sized network (a.k.a. teacher assistant) to bridge the gap between the student and teacher.
This paper presents a novel approach for weakly-supervised action localization that leverages the large amount of annotated humans available today and outperforms state of the art by an order of magnitude.
We formulate the problem of detecting the short-term skews online and exploiting models based on it as a sequential decision making problem dubbed the Online Bandit Problem, and present a new algorithm to solve it.
We introduce a new weak comparison oracle model, where a non-malicious user responds to a pairwise comparison query only when she is quite sure about the answer.
A novel end-to-end crowd counting framework, named DecideNet (DEteCtIon and Density Estimation Network) is proposed. It can adaptively decide the appropriate counting mode for different locations on the image based on its real density conditions.
The tool presence detection challenge at M2CAI 2016 consists of identifying the presence/absence of seven surgical tools in the images of cholecystectomy videos. Here, we propose to use deep architectures that are based on our previous work where we presented several architectures to perform multiple recognition tasks on laparoscopic videos.
We present a novel approach to tackle domain adaptation between synthetic and real data that leverages the task network as its own adversarial guide toward useful augmentations that maximize the uncertainty of the output.
We introduce their functional representation, where an image is represented by a neural network, which maps point from the plane (representing positions of pixel) into its corresponding color in the image.
We propose a generic framework for robust dictionary learning based on concave loss function and introduce an initialization heuristic based on undercomplete dictionary learning.
This paper presents a novel end-to-end graph model, named Point2Node, to represent a given point cloud, to explore correlation among nodes from different levels, and adaptively aggregate the learned features.
We attempt to get an understanding of this category of problems by extensive empirical evaluation of 19 different deep learning architectures (specifically on different ways of handling context) for various problems originating in natural language processing like debating, textual entailment and question-answering.
We present SS3D, a single-stage monocular 3D object detector that achieves SOTA accuracy and achieves 20 fps in a straightforward implementation.
Language models have become a key step to achieve state-of-the art results in many different Natural Language Processing (NLP) tasks. In this paper, we introduce and share FlauBERT, a model learned on a very large and heterogeneous French corpus.
In this paper, we present a comprehensive review of the imbalance problems in object detection and present a unifying yet critical perspective on the solutions in the literature.
We propose the Projection and Rejection Product (PR Product) to make the direction gradient of w independent of the angle and consistently larger than the one in standard inner product while keeping the forward propagation identical.
The growth of detection datasets and the multiple directions of object detection research provide both an unprecedented need and a great opportunity for a thorough evaluation of the current state of the field of categorical object detection.
We propose an adversarial training framework that leverages unlabeled data to improve model performance. We introduce a LaplaceKL objective that penalizes for a low confidence.
In the application of learning to rank, we provide a hierarchy of rank-breaking mechanisms ordered by the complexity in thus generated sketch of data.
We propose a new data augmentation technique called random image cropping and patching (RICAP) which randomly crops four images and patches them to create a new training image.
We employ an input processing technique based on denoising autoencoders as a defense that cannot be trivially trained end-to-end.
In this paper, we present a simple yet effective approach that for the first time enables arbitrary style transfer in real-time using a single feed-forward neural network.
An indoor scene constrained method for indoor localization using deep learning and multi-sensor fusion.
We study the problem of organizing a collection of objects - images, videos - into clusters, using crowdsourcing. We develop cost-efficient, accurate algorithms for identifying the consensus organization (i.e., the organizing perspective most workers prefer to employ), and incorporate these algorithms into a cost-effective workflow.
A novel graph-to-tree conversion mechanism called the deep-tree generation (DTG) algorithm is first proposed to predict text data represented by graphs. Then, a Deep-Tree Recursive Neural Network (DTRNN) method is used to classify vertices that contains text data in graphs.
We propose Consensus-Driven Propagation to tackle this challenging problem with two modules, the "committee" and the "mediator", which select positive face pairs robustly by carefully aggregating multi-view information.
We propose Progressive Structure-conditional Generative Adversarial Networks (PSGAN), a new framework that can generate full-body and high-resolution character images based on structural information based on progressive training.
This paper proposes a new local directional relation pattern descriptor for face recognition.
We present an approach to segment vehicle tracks in coherent change detection images, a product of combining two synthetic aperture radar images taken at different times.
In person re-identification (Re-ID), supervised methods usually need a large amount of expensive label information, while unsupervised ones are still unable to deliver satisfactory identification performance. To address this situation, we propose a novel Adversarial Camera Alignment Network (ACAN), which only needs the within-camera label information but not cross-camera labels which are more expensive to obtain.
We propose a RL policy that can learn composite manipulations using no intermediate rewards and no demonstrations of full tasks.
We propose ConfusionFlow, an interactive, comparative visualization tool that combines the benefits of class confusion matrices with the visualization of performance characteristics over time.
We provide a method derived from the seed-and-grow method for Dense Image Matching without Geometric Constraints.
We introduce PathGAN, a deep neural network for visual scanpath prediction trained on adversarial examples.
Learning-based approaches for human action recognition from a single clip using a patch based motion descriptor and matching scheme.
A CUDA kernel will utilize high-latency local memory for storage when there are not enough registers to hold the required data or if the data is an array.
We train a Convolutional Neural Network (CNN) model that distinguishes natural photographs from automatically generated composite images.
Multi-Granularity Reference-aided Attentive Feature Aggregation (MG-RAFA) for video-based person re-identification .
We propose a novel and efficient method that combines these two methods by a series connection, which searches for the most reasonable similar patch using the coarse image generated by the deep generative model.
We propose a fully automated method that integrates instance segmentation and image matting processes to generate high-quality semantic mattes that can be used for image editing task.
We propose an efficient policy to deal with moving points in the manifold estimation process in a 3D Delaunay triangulation.
This paper investigates the performance degradation of facial recognition systems due to the influence of age. A comparative analysis of subspace projection techniques combined with four different distance metrics.
This study proposes a regional CNN-LSTM model consisting of two parts: regional CNN and LSTM to predict VA ratings of texts.
In this paper, we analyze the effects of contact models on contact-implicit trajectory optimization for manipulation. We compare these models in simulation in terms of physical accuracy, quality of motions, and computation time.
We propose the probabilistic Logic Neural Network (pLogicNet), which combines the advantages of both methods for knowledge graph reasoning, which is able to leverage domain knowledge with first-order logic.
Predicting superpixels on a regular image grid using a convolutional network .
We report the first all-to-all sequence-based computational screen of protein–protein interaction in yeast, Saccharomyces cerevisiae in which we identify 29589 high confidence interactions of ~210 7 possible pairs.
We propose a novel easy-to-implement divide and conquer approach for deep metric learning, which significantly improves the state-of-the-art performance of metric learning.
We investigate the advantages and disadvantages of several popular CNN architectures in terms of speed, storage and segmentation accuracy. Through detailed experiments, we pick up the favorable components from the existing architectures and construct a light-weight network architecture based on the DenseNet.
Thundervolt enables aggressive voltage underscaling of high-performance DNN accelerators without compromising classification accuracy even in the presence of high timing error rates.
We propose a cloud-based filter trained to block third parties from uploading privacy-sensitive images of others to online social media.
Pre-trained Transformers are now ubiquitous in natural language processing, but despite their high end-task performance, little is known empirically about whether they are calibrated.
This paper proposes a Direct Sparse Optimization NAS (DSO-NAS) method to solve Neural Architecture Search.
We evaluate the cross-lingual effectiveness of representations from the encoder of a massively multilingual NMT model on 5 downstream classification and sequence labeling tasks covering a diverse set of over 50 languages.
We study the problem of person re-identification by proposing a novel sampling to mine suitable positive samples within a local range to improve the deep embedding in the context of large intra-class variations.
GAMENet integrates the drug-drug interactions knowledge graph by a memory module implemented as a graph convolutional networks, and models longitudinal patient records as the query. It is trained end-to-end to provide safe and personalized recommendation of medication combination.
In this paper, we propose a geometry-contrastive generative adversarial network GC-GAN for generating facial expression images conditioned on geometry information.
Ensembles with Shared Representations reduce the remaining residual generalization error on large-scale datasets of facial expressions and outperform state-of-the-art methods on AffectNet and FER+.
We propose a structure-aware regression approach for human pose estimation that exploits the joint connection structure to define a compositional loss function that encodes the long range interactions in the pose.
We evaluate the usefulness of audio transformations (i.e., prosodic modifications) for voice-only question answering. We introduce a crowdsourcing setup evaluating the quality of our proposed modifications.
We propose a new approach, called self-motivated pyramid curriculum domain adaptation (PyCDA), to facilitate the adaptation of semantic segmentation neural networks from synthetic source domains to real target domains.
We propose an automatic way to combine black-box systems for Grammatical Error Correction (GEC).
We present a conceptually simple yet effective semi-supervised algorithm based on self-Supervised learning to combine semantic feature representations from unlabeled data in a single stage.
In this paper, we propose an efficient exploration method, Multi-Path Policy Optimization (MPPO), which does not incur high computation cost and ensures stability.
In this paper, we study the challenging problem of predicting the dynamics of objects in static images. We define intermediate physical abstractions called Newtonian scenarios and introduce Newtonian Neural Network that learns to map a single image to a state in a Newtonian scenario.
We introduce the concept of extremal perturbations, which are theoretically grounded and interpretable. We extend perturbation analysis to the intermediate layers of a network.
We present an overview and evaluation of a new, systematic approach for generation of highly realistic, annotated synthetic data for training of deep neural networks in computer vision tasks.
In this paper, we utilize a closed-set speaker-identification approach to convey the ratings needed for collaborative filtering-based recommendation. The algorithm limits the degree to which unwanted ratings negatively affect the integrity of the ratings information.
We propose a new scheme for FER system based on hierarchical deep learning. The proposed method combines the result of softmax function of two features by considering the error associated with the second highest emotion (Top-2) prediction result.
We explore the suitability of Faster R-CNN for instance retrieval of image- and region-wise representations pooled from an object detection CNN.
We propose a simple, yet very effective approach which works seamlessly for both offline and online action recognition using the skeletal joints.
We develop a unified model, known as MgNet, that simultaneously recovers some convolutional neural networks (CNN) for image classification and multigrid (MG) methods for solving discretized partial differential equations (PDEs).
Hierarchical explanations for neural networks by detecting feature interactions .
We propose a new metric called FLAME for video-segmentation networks, that compares the output segmentation of the network with the ground truth segmentation in the current video frame at the time the network finishes the processing.
We introduce Talk to Papers, which exploits the recent open-domain question answering (QA) techniques to improve the current experience of academic search.
We use discriminative correlation filter-based trackers for visual tracking to address the key causes of object occlusion and drift in a tracking-by-detection framework.
We propose a transductive learning method, which we refer to as a Selective Transfer Machine (STM), to personalize a generic classifier by attenuating person-specific mismatches.
We prove tight bounds on the distortion of well-known voting rules for distributed elections both from a worst-case perspective as well as from a best-case one.
In this paper, we propose a novel object-adaptive LSTM network, which can effectively exploit sequence dependencies and dynamically adapt to temporal object variations via constructing an intrinsic model for object appearance and motion.
In this paper, a novel Context-and-Spatial Aware Network (CSANet), which integrates both a Context Aware Path and Spatial Aware Path, is proposed to obtain effective features involving both context information and spatial information.
A novel network architecture is proposed to render realistic images of both scenes based on adversarial learning.
We propose four efficient feature extractors based on convolutional neural networks for stereo matching cost computation.
This paper explores domain adaptation for enabling question answering (QA) systems to answer questions posed against documents in new specialized domains.
We introduce a new reinforcement learning approach combining a planning quasi-metric (PQM) that estimates the number of actions required to go from a state to another, with task-specific planners that compute a target state to reach a given goal.
This paper focuses on the detection of retinal blood vessels which play a vital role in reducing the proliferative diabetic retinopathy and for preventing the loss of visual capability.
We propose a foreground-aware image inpainting system that explicitly disentangles structure inference and content completion, and achieves superior results on challenging cases with complex compositions.
In this paper, we propose a new model called EnsNet which is composed of one base CNN and multiple Fully Connected SubNetworks (FCSNs) which improves the performance of CNNs.
We study the problem of semantic query suggestion , a special type of query transformation based on identifying semantic concepts contained in user queries. We use a feature-based approach in conjunction with supervised machine learning, augmenting term-based features with search history-based and concept-specific features.
SALIC, an active learning method for selecting the most appropriate user tagged images to expand the training set of a binary classifier, without the cost of manual annotation.
We present a new architecture for end-to-end sequence learning of actions in video, we call VideoLSTM. We introduce motion-based attention.
In object detection, the intersection over union (IoU) threshold is frequently used to define positives/negatives. A multi-stage object detection architecture, the Cascade R-CNN, composed of a sequence of detectors trained with increasing IoU thresholds, is proposed to address these problems.
We introduce a weakly supervised system that automatically learns to temporally segment and label actions in a video, where the only supervision that is used are action sets.
We propose a trimmed convolutional network for arithmetic encoding (TCAE) to model large context while maintaining computational efficiency.
We present novel method for image-text multi-modal representation learning. We only use category information in contrast with most previous methods using image- text pair information for multi- modal embedding.
This work explores methods to optimize pose estimation for human crowds, focusing on challenges introduced with larger scale crowds like people in close proximity to each other, mutual occlusions, and partial visibility of people due to the environment.
We present a new approach for knowledge graph embedding called RotatE, which is able to model and infer various relation patterns including: symmetry/antisymmetry, inversion, and composition.
We propose Purifying Variational Autoencoder (PuVAE), a method to purify adversarial examples. We experimentally illustrate the robustness of PuVAE against various attack methods.
This paper proposes a hybrid supervised-unsupervised method combining a pre-trained AlexNet with Latent Dirichlet Allocation (LDA) to extract image topics from both an unlabeled life-logging dataset and the COCO dataset.
In this paper, a new deep learning architecture for stereo disparity estimation is proposed. A stacked atrous multiscale network is proposed to aggregate rich multiscALE contextual information from the cost volume which allows for estimating the disparity with high accuracy at multiple scales.
We propose a novel convolutional neural network architecture to address the fine-grained recognition problem of multi-view dynamic facial action unit detection.
This paper proposes a novel approach to learning category-specific part detectors in a weakly supervised setting in which the training images are only annotated with category labels without part/object location information.
We extend this hard-mining improvement of binary cross entropy to point-cloud-based object detection and conduct experiments to show its performance based on two different 3D detectors: 3D-FCN and VoxelNet.
We present the global deep video representation learning to video-based person reidentification (re-ID) that aggregates local 3-D features across the entire video extent.
Comparison of six appearance based face recognition algorithms with diverse distance metric combinations under equal working conditions.
We advance the use of a latent representation based on a product space of Orthogonal Spheres PrOSe, which improves the quality of disentanglement significantly.
AlphaX explores the exponentially grown search space with a distributed Monte Carlo Tree Search (MCTS) and a Meta-Deep Neural Network (DNN)
In this paper we propose a novel iterative procedure for multichannel image and data reconstruction using Bregman distances, which generalizes the Bregmann iteration proposed by Osher et al.
This paper proposed the multi-view subspace clustering model based on self-representation, and its convergence without any additional assumption is proved.
This work introduces Fully Convolutional Attention Networks (FCANs), a reinforcement learning framework to optimally glimpse local discriminative regions adaptive to different fine-grained domains.
We present a random cascaded-regression copse for robust facial landmark detection.
In this paper, we propose an interactive method to direct classifiers paying attentions to regions that are manually specified by the users, in order to mitigate the influence of co-occurrence bias.
In this paper we introduce RRPN, a Radar-based real-time region proposal algorithm for object detection in autonomous driving vehicles.
We propose the Link Stream Graph (LSG) which allows to combine long- and short-term preferences in a graph-based recommender system by considering time continuously.
Unpaired Image-to-Image Translation (UIT) with semi-supervised learning and disentangled transfer.
We propose a novel hashing method, called deep multi-index hashing (DMIH), to improve both efficiency and accuracy for person re-identification.
We propose a Siamese GAN (SiGAN) to reconstruct HR faces that visually resemble their corresponding identities.
We propose a classification method based on multi-structure deep features fusion (MSDFF) that achieves better performance than state-of-the-art scene classification methods.
This paper investigates DARTS, the currently most popular differentiable search algorithm, and points out an important factor of instability, which lies in its approximation on the gradients of architectural parameters. We propose an amending term for computing architectural gradients by making use of a direct property of the optimality of network parameter optimization.
We propose a novel image outlier detection method by combining autoencoder with Adaboost that captures statistical correlations among the features of normal data than the single autoencoders.
A method for learning local affine-covariant regions with hard negative-constant loss .
We propose a novel ROI pooled correlation filter (RPCF) algorithm for robust visual tracking.
We propose to use language as the abstraction, as it provides unique compositional structure, enabling fast learning and combinatorial generalization.
We propose the Deep Compositional Captioner (DCC) to address the task of generating descriptions of novel objects which are not present in paired imagesentence datasets.
A real-time running event detection method for the community patrol robot.
A novel approach for regularizing adversarial models by enforcing diverse feature learning. Results indicate our regularizer enforces diverse features, stabilizes training, and improves image synthesis.
We evaluate whether features extracted from the activation of a deep convolutional network trained in a fully supervised fashion on a large, fixed set of object recognition tasks can be repurposed to novel generic tasks.
We evaluate the performance of custom and pretrained CNNs and construct an optimal model ensemble toward the challenge of classifying parasitized and normal cells in thin-blood smear images.
We propose M3D-RPN, a standalone 3D region proposal network for monocular 3D object detection and Bird's Eye View tasks within the KITTI urban autonomous driving dataset.
Point Recurrent Neural Network (PointRNN) for moving point cloud processing.
We analyse and micro evaluate the behaviour of 29 available QA components for DBpedia knowledge graph that were released by the research community since 2010.
A novel real-time stereo matching method that uses a two-pass approximation of adaptive support-weight aggregation, and a low-complexity iterative disparity refinement technique.
This article proposes an in-hardware moving computation to data model (MC) that pins shared data at dedicated cores in a spatial setting to enable data locality optimizations.
We study two top recent facial landmark detectors and devise confidence models for their outputs. We validate our failure detection approaches on standard benchmarks.
We introduce a new Shuffle-Exchange neural network model for sequence to sequence tasks which have O(log n) depth and O(n log n) total complexity.
We propose an approach to instance-level image segmentation that is built on top of category-level segmentation and achieve state-of-the-art results.
We adopt a large margin principle and define a Hamming margin to formulate such relationship and propose a binary hash function in the same manner.
We propose two effective structured learning based approaches for person re-identification which explore the adaptive effects of visual features in recognizing persons in different benchmark data sets.
We explore a mixture of experts (MoE) approach to deep dynamic routing that increases the representational power of standard convolutional networks by adaptively sparsifying and recalibrating channel-wise features in each Convolutional layer.
We propose the Golf Optimizer, a novel but simple form of network that learns deep priors from data with better propagation behavior.
We propose a new end-to-end method for extending a Knowledge Graph (KG) from tables. Our method aims to find more novel facts.
We explore how to use keypoint models to improve instance-level person segmentation task within a deep neural network within a constrained environment.
In this paper, we propose a new approach to identify gender from frontal facial images that is robust to background, illumination, intensity, and facial expression.
We propose a novel end-to-end learnable feature aggregation scheme, dubbed temporal correlation pooling that generates an action descriptor for a video sequence by capturing the similarities between the temporal evolution of clip-level CNN features computed across the video.
We propose a weakly-supervised approach that takes image-sentence pairs as input and learns to visually ground (i.e., localize) arbitrary linguistic phrases, in the form of spatial attention masks.
We propose a population-based approach using grammatical evolution to generate high-affinity molecules whose diversity is better than that of known inding molecules in DUD-E.
This paper presents a motorcycle classification system for urban scenarios using Convolutional Neural Network (CNN)
We introduce a novel inference procedure for appropriate for use with GPUs which allows us to dramatically increase both the training set size and the amount of latent factors that S3C may be trained with. We demonstrate that this approach improves upon the supervised learning capabilities of both sparse coding and the spike-and-slab Restricted Boltzmann Machine.
We propose a new detection model based on multitask rotational region convolutional neural network to solve the problems above.
We evaluate BERT-based models on their generalizability to out-of-domain examples, responses to missing or incorrect information in datasets, and ability to handle variations in questions.
We analyze the invariance properties of models when surrounding context is removed, when an object is placed in an incongruent background, and when images are blurred or flipped vertically, and find that context is more important for detecting small objects than larger ones.
We propose to improve text-generation GAN via a novel approach inspired by optimal transport, overcoming mode-collapsing and brittle-training problems in existing methods.
Lidar-Monocular Visual Odometry (LIMO), an odometry estimation algorithm, combines camera and LIght Detection And Ranging sensor for visual localization and motion estimation.
We investigate training image captioning methods based on actor-critic reinforcement learning in order to directly optimise non-differentiable quality metrics of interest.
We propose UOLO, a novel framework for the simultaneous detection and segmentation of structures of interest in medical images.
We propose a novel weakly supervised approach to the salient object detection in a video, which can learn a robust saliency prediction model by using very limited manually labeled data and a large amount of weakly labeled data that could be easily generated in a supervised approach.
We propose a unified unsupervised/weakly supervised learning framework for video object segmentation that addresses object pattern learning from unlabeled videos, unlike most existing methods which rely heavily on extensive annotated data.
Learning a better representation with neural networks is a challenging problem, which is tackled extensively from different prospectives in the past few years. We propose two novel loss components that substantially improve the quality of produced clusters, are simple to apply to an arbitrary model and cost function, and do not require a complicated training procedure.
We present a deep sampling network (DSN) for down-Sampling and up-sampling without any cheap interpolation. DSN can be used to generate photo-realistic low-resolution images.
Federated learning reduces accuracy of federated learning when local data is non-IID. As a solution, we propose a strategy to improve training on non- IID data by creating a small subset of data which is globally shared.
We investigate the problem of error detection in relation assertions of knowledge graphs, and propose an error detection method which relies on path and type features used by a classifier for every relation in the graph.
We present a computationally efficient approach to semantic segmentation, while achieving a high mean intersection over union (mIOU), 70.33% on Cityscapes challenge.
A VLR method based on enhanced matching, constrained region extraction and SSFPD network is proposed in this paper to solve the aforementioned problems.
We present the Industrial and Professional Occupations Dataset (IPOD), a comprehensive corpus that consists of over 190,000 job titles crawled from over 56,000 profiles from Linkedin.
In this paper, we improve the performance of means of gradient method in low resolution images, which could locate the eye center more accurately.
We introduce a suite of diagnostics drawn from human language experiments, which allow us to ask targeted questions about information used by language models for generating predictions in context.
We study the problem of learning similarity functions over very large corpora using neural network embedding models. We propose new efficient methods to train these models without having to sample unobserved pairs, using a global quadratic penalty.
Deep Learning is arguably the most rapidly evolving research area in recent years. As a result it is not surprising that the design of state-of-the-art deep neural net models proceeds without much consideration of the latest hardware targets, and neural net accelerators are co-designed.
This work presents a method that integrates the Patch Match stereo algorithm into a variational smoothing formulation using quadratic relaxation for sub-pixel accurate disparity estimation.
This paper presents an end-to-end multi-scale deep encoder (convolution) and decoder (deconvolution) network for single image super-resolution (SISR) guided by phase congruency (PC) edge map.
We use the association of topological features of nodes with their class to predict their class, without no textual or content information.
In this paper, we address the problem of referring expression comprehension: localizing an image region described by a natural language expression in an end-to-end framework.
This paper addresses the question of the detection of small targets (vehicles) in ortho-images in VEDAI dataset.
A recurrent clustering and pooling module for multi-view 3D object recognition, when inserted in an off-the-shelf pretrained CNN, boosts performance.
We comprehensively study how semi-supervised learning methods starting from pretrained models perform under varying conditions, including training strategies, architecture choice and datasets.
This paper proposes a simple yet effective and efficient method for video object segmentation using a ResNet backbone and a cascade module.
We present the first large-scale study of state-of-the-art English-to-German NMT on real grammatical noise, by evaluating on several Grammar Correction corpora.
We propose a generative model based method for surface completion and inpainting of 3D shapes using local patches.
We propose to learn 3D local descriptors by directly processing unstructured 3D point clouds without needing any intermediate representation.
Discriminative (d) PCA for discriminative analytics of multiple datasets.
In this work, we present a novel approach to face recognition which considers both shape and texture information to represent face images.
Bags-of-visual-Words (BoW) and Spatio-Temporal Shapes (STS) are two very popular approaches for action recognition from video. Despite the popularity of these methods, no comparison between them has been done.
We propose a novel translational distance-based approach for knowledge graph link prediction, which effectively improves prediction accuracy on the difficult N-1, 1-N and N-N cases.
This work explores the feasibility of two popular human-objects detection schemes, Harr-Cascade and HOG feature extraction and SVM classifier, at the edge and introduces a lightweight Convolutional Neural Network (L-CNN) leveraging the depthwise separable convolution for less computation, for human detection.
We formulate a new regression method for continuous estimation of intensity of facial behavior interpretation, called Doubly Sparse Relevance Vector Machine (DSRVM)
Generic instance search from one example where the instance can be an arbitrary object like shoes, not just near-planar and one-sided instances like buildings and logos.
We systematically compare a set of simple strategies for improving low-resource parsers: data augmentation, which has not been tested before; cross-lingual training; and transliteration.
We exploit existing annotations in source images and transfer such visual information to segment videos with unseen object categories. Without using any annotations in the target video.
Uncertainty estimation in deep neural networks is essential for designing reliable and robust AI systems. Our contribution is to apply Bayesian deep learning framework to visual activity recognition application and quantify model uncertainty along with principled confidence.
We present Dynamic Self-Attention Network (DySAT), a novel neural architecture that learns node representations to capture dynamic graph structural evolution.
In this paper we explore the bi-directional mapping between images and their sentence-based descriptions. We propose a novel recurrent visual memory that automatically learns to remember long-term visual concepts to aid in both sentence generation and visual feature reconstruction.
We consider the task of weakly supervised one-shot detection, when training only using weak binary labels that indicate the existence of a class instance in a given example.
We address two fundamental limitations of VLAD: its requirement for the local descriptors to have vector form and its restriction to linear classifiers due to its high-dimensionality. We propose an approximate formulation that allows us to accelerate the coding process while still benefiting from the properties of kernels.
We propose DPP-Net: Device-aware Progressive Search for Pareto-optimal Neural Architectures, optimizing for both device-related (e.g., inference time and memory usage) and device-agnostic (E.G., accuracy and model size) objectives.
We propose a self-supervised framework for learning facial attributes by watching videos of a human face speaking, laughing, and moving over time.
Using Lower Central Periocular Region (LCPR) for Biometric Identification .
We propose a novel GRAph PYramid Mutual Learning (Grapy-ML) method to address the cross-dataset human parsing problem where the annotations are at different granularities.
In this paper, we propose a variational inference framework for unsupervised non-Gaussian feature selection, in the context of finite generalized Dirichlet (GD) mixture-based clustering.
We propose a new method for analyzing the dynamics of facial expressions to identify persons using Active Appearance Models and accurate facial feature point tracking.
The optic disc (OD) in retinal fundus images is widely used as a reference in computer-based systems for the measurement of the severity of retinal disease. A number of algorithms have been published in the past 5 years to locate and measure the OD. Our proposed algorithm, automatically, uses the three channels (RGB) of the digital colour image to locate the region of interest (ROI) where the OD lies.
In this article, we propose a new approach for facial expression recognition using deep covariance descriptors.
This paper proposes a deep neural architecture, PlaneRCNN, that detects and reconstructs piecewise planar regions from a single RGB image. The paper also presents a new benchmark with fine-grained plane segmentations in the ground-truth.
We describe a robust method to estimate egomotion in highly dynamic environments, and compare the results of the direct, 6 DoF estimate with our plane-based approach, with and without the IMU.
We present an analytic framework to visualize and understand GANs at the unit-, object-, and scene-level. We quantify the causal effect of interpretable units by measuring the ability of interventions to control output.
We propose a new approach for sketch-based 3D object retrieval that describes a 2D shape by the visual protruding parts of its silhouette. We quantify the extent of part occlusion of the projected silhouettes.
We analyse perception and memory using mathematical models for knowledge graphs and tensors to gain insights in the corresponding functionalities of the human mind.
We observe a phenomenon that part detectors emerge within CNN trained to classify attributes from uncropped face images, without any explicit part supervision.
This paper presents a novel approach for synthesizing facial affect; either in terms of the six basic expressions (i.e., anger, disgust, fear, joy, sadness and surprise) and a pair of valence-arousal (VA) emotional state descriptors, or a path of affect in the 2D VA space to be generated as an image sequence.
In this paper, we develop a high-level video understanding module which can encode interactions between actors and objects both in space and time.
We present a new autoencoder-type architecture that is trainable in an unsupervised mode, sustains both generation and inference, and has the quality of conditional and unconditional samples boosted by adversarial learning.
We propose a novel approach for incorporating prior knowledge into the perceptron, in the form of soft polyhedral advice, so as to make increasingly accurate predictions on subsequent rounds.
We propose a model-based scattering removal method for stereo vision for robot manipulation in indoor scattering media where the commonly used ranging sensors are unable to work.
We introduce a method to generate videos of dynamic virtual objects plausibly interacting via collisions with a still image's environment via a neural network.
We propose the first secure image retrieval scheme that simultaneously solves these two problems. To improve search speed and reduce the cost of image owners, we build a secure hierarchical index graph by using the encrypted image features.
Fine-tuning large pre-trained models is an effective transfer mechanism in NLP. As an alternative, we propose adapter modules. Adapters attain near state-of-the-art performance, whilst adding only a few parameters per task.
We propose a novel residual dense network to exploit the hierarchical features from all the convolutional layers for image super-resolution.
We propose a Collective Learning Framework (CLF), which enables learning from diverse datasets in a unified way.
In this paper, we present a novel adaptive similarity measure which is consistent with k-nearest neighbor search, and prove that it leads to a valid kernel if the original similarity function is a kernel function.
One-shot gesture recognition using a human-centered approach and its potential application to fields such as human-robot interaction where the user's intentions are indicated through spontaneous gesturing (one-shot).
We introduce an extremely computation-efficient CNN architecture named ShuffleNet, designed specially for mobile devices with very limited computing power (e.g., 10-150 MFLOPs).
We generalize the 1 x 1 convolutions proposed in Glow to invertible d x d convolutions, which are more flexible since they operate on both channel and spatial axes.
We propose a learning to learn approach for domain generalisation, where the auxiliary loss that helps generalisation is itself learned.
We propose a novel algorithm for the joint refinement of structure and motion parameters from image data directly without relying on fixed and known correspondences.
A long-term visual object tracking performance evaluation methodology and a benchmark are proposed. The new measures outperform existing ones in interpretation potential and in better distinguishing between different tracking behaviors.
We propose weighted boundary constraint to refine those segmentation predictions and incorporate it into a generative adversarial network (GAN)-based network for domain adaptation to achieve further significant improvement.
An auto-tuning neural network quantization framework for collaborative inference of DNNs.
We introduce stochastic training method for Neural Network with both binary weights and activations, which transfer well to a deterministic network at test time.
We introduce Learn2Perturb, an end-to-end feature perturbation learning approach for improving the adversarial robustness of deep neural networks.
We propose Generalized Trust Region Policy Optimization (GTRPO), a Reinforcement Learning algorithm for TRPO of Partially Observable Markov Decision Processes (POMDP).
A unified network based on JCS-Net for small-scale pedestrian detection, which integrates the classification task and the super-resolution task in a unified framework.
We consider the problem of discovering novel object categories in an image collection. We use such prior knowledge to reduce ambiguity of clustering, and improve the quality of newly discovered classes.
We present a supervised binary encoding scheme for image retrieval that learns relationship aware projections by minimizing the difference between inner products of binary codes and output embedding vectors.
We propose a probabilistic approach to learning task-specific and shared representations in CNNs for multi-task learning.
In this paper, we propose a novel building block for CNNs that represents multi-scale features at a granular level and increases the range of receptive fields for each network layer.
We propose a novel formulation to learn video summarization from unpaired data. We present an approach that learns to generate summary videos from such unpairedData.
We proposed a hybrid model for illumination invariant human activity recognition based on sub-image histogram equalization enhancement and k-key pose human silhouettes for low quality and night security operations.
We explore the potential of Constrained Dominant Sets for generating multi-labeled full mask predictions to train a fully convolutional network for semantic segmentation.
We provide a detailed description and analysis of different text generation models in addition to novel message ranking and selection methods for building a robust yet flexible open domain conversational agent.
We propose a novel temporal dynamic graph Long Short-Term Memory network (TD-Graph LSTM) for weakly-supervised object detection.
We propose an efficient method to generate white-box adversarial examples to trick a character-level neural classifier, based on the gradients of the one-hot input vectors.
We improve upon the cascade regression framework and propose the Constrained Joint Cascade Regression Framework for simultaneous facial action unit recognition and facial landmark detection.
The rapid development of deep learning techniques has created new challenges in identifying the origin of digital images because generative adversarial networks and variational autoencoders can create plausible digital images whose contents are not present in natural scenes. In this paper, we propose a novel method that uses a convolutional neural network and a local-to-global framework to reduce training complexity.
We train a fully convolutional neural network that can accurately recover facial normals from images including a challenging variety of expressions and facial poses.
We developed the Annotation, Mapping, Expression and Network (AMEN) software as a stand-alone, unified suite of tools that enables biological and medical researchers with basic bioinformatics training to manage and explore genome annotation, chromosomal mapping, protein-protein interaction, expression profiling and proteomics data.
In this paper, we present a method for fully automatic facial expression recognition in facial image sequences using feature extracted from tracking of facial landmarks.
We propose a new CF-based object tracking method that is robust to the background clutter and discriminative to the target scale variation and can effectively prevent tracking module degradation.
This paper proposes a novel framework for training deep convolutional neural networks from noisy labeled datasets that can be obtained cheaply.
We introduce the first federated implementation of a Collaborative Filter and demonstrate its applicability to a personalized recommendation system based on users' implicit feedback.
We introduce the Multi-Type Multi-Span Network (MTMSN), a neural reading comprehension model that combines a multi-type answer predictor designed to support various answer types (e.g., span, count, negation, and arithmetic expression) with amulti-span extraction method for dynamically producing one or multiple text spans.
We present XCMRC, the first public cross-lingual language understanding (XLU) benchmark which aims to test machines on their cross-Lingual reading comprehension ability.
Neuron Linear Transformation (NLT) method for cross-domain crowd counting .
We present a novel method for generating robust adversarial image examples building upon the recent `deep image prior' (DIP) that exploits convolutional network architectures to enforce plausible texture in image synthesis.
We propose an identity preserving generative adversarial network for cross-domain person re-identification task.
This paper proposes a novel algorithm which learns a formal regular grammar from real-world continuous data, such as videos or other streaming data.
We propose two different strategies that aim at constructing low-dimensional embedding feature extractors and hence reducing the number of model parameters for audio classification.
We propose a new, alternative approach to enable efficient execution of DNNs on embedded devices. It employs machine learning to develop a low-cost predictive model to quickly select a pre-trained DNN to use for a given input and the optimization constraint.
We propose a novel Semantic Transformation method to bridge the dense and sparse spaces, which can facilitate the NLP research to shift from dense space to sparse space or to jointly use both spaces.
In reinforcement learning, the discount factor $\gamma$ controls the agent's effective planning horizon. Reward tweaking learns a surrogate reward function $\tilde r$ for the discounted setting, which induces an optimal return in the original finite-horizon task.
A novel architecture that enables multiple low-compute NAO robots to perform real-time detection, recognition and localization of objects in its camera view and take programmable actions based on the detected objects.
This paper proposes an augmented parallel-pyramid net with attention partial module and differentiable auto-data augmentation for pose estimation.
We propose a second-order pooling convolution neural network to explore the correlation information between the facial features after deep network learning.
Decoders matter: we observe significant variance in results between different types of decoders on a variety of pixel-wise prediction tasks.
We propose a Factorized Bilinear (FB) layer to model the pairwise feature interactions by considering the quadratic terms in the transformations.
We present a novel spatial hashing based data structure to facilitate 3D shape analysis using convolutional neural networks.
This paper examines the effect that overfitting and influence have on the ability of an attacker to learn information about training data from machine learning models, either through training set membership inference or model inversion attacks.
We propose a directional regularization prior for tubular structures, suitable for use in a variational framework.
In this paper, we address the this weakness by introducing a generalized version of IoU as both a new loss and a new metric.
We provide new variants of Adam and AMSGrad, called AdaBound and AMSBound respectively, which employ dynamic bounds on learning rates to achieve a gradual and smooth transition from adaptive methods to SGD and give a theoretical proof of convergence.
In the task of factoid question answering over knowledge base, many questions have more than one plausible interpretation. In this paper, we introduce a simple and effective model which combines local knowledge subgraph with attention mechanism.
We propose a composite proximal framework for SVM optimization, which leverages the compositional nature of deep neural networks and can leverage powerful convex optimization algorithms by design.
We propose an indoor positioning system to locate users in large indoor scenes using smartphone cameras and computer vision.
This paper investigates the effects of utilising the background information as an extra input channel in the process of alpha calculation in image and video matting.
We present a deep-learning network that detects multiple small objects (hundreds to thousands) in a scene while simultaneously estimating their x,y pixel locations together with a characteristic feature set (for instance, target orientation and color).
We seek a balance between speed and accuracy by building an effective and efficient video classification system through systematic exploration of critical network design choices. We show that it is possible to replace many of the 3D convolutions by low-cost 2D convolution.
An auto-encoder based Boundary Equilibrium GAN to generate frontal faces using an interpolation of a side view face and its mirrored view.
This paper proposes a high-speed stereo matching algorithm (HSSM) for ultra-high resolution binocular images, which is highly efficient.
In this work we propose a simple and efficient framework for learning sentence representations from unlabelled data, and we show that the model learns high-quality sentence representations.
We introduce an online learning technique with max-margin to early event detection, which achieves satisfied performance in offline manner.
This paper presents a feature encoding method of complex 3D objects for high-level semantic features for Bayesian inference.
This paper tackles the task of estimating the topology of filamentary networks such as retinal vessels and road networks, inspired by a human delineating a complex network with the tip of their finger.
A dual CNN based model for unsupervised depth estimation with 6 losses (DNM6) with individual CNN for each view to generate the corresponding disparity map.
Fourier-like summation of several grid cell modules with different spatial frequencies in the medial entorhinal cortex (MEC) has long been proposed to form the contours of place firing fields. In this study, we derive the model from grid spatial frequencies represented by Gaussian profiles to a 1D place field by Bayesian inference.
We propose, to the best of our knowledge, the first rigorous face forensic localization dataset, which consists of genuine, generated, and manipulated face images.
Decoupling neural networks by using a model of the future computation of the network graph, followed by backpropagating error signal.
This paper introduces Sobolev Training for neural networks, which is a method for incorporating these target derivatives in addition the to target values while training, improving the data-efficiency and generalization capabilities of our learned function approximation.
We exploit hand-crafted motion boundary histogram features as well feature activations from deep networks such as VGG16, GoogLeNet, and C3D.
We proposed an adaptive model update strategy for calculating model update rate based on the response map, and it outperforms the state-of-the-art strategies.
This work tackles the problem of semi-supervised learning of image classifiers. Our main insight is that the field of Semi-Supervised learning can benefit from the quickly advancing field of self-super supervised visual representation learning.
In this paper, we propose a novel deep metric learning model based on the directional distribution that captures the global information about the embedding space.
This paper describes an approach to utilizing term weights for sentiment analysis tasks and shows how various term weighting schemes improve the performance of sentiment analysis systems.
This paper addresses the problem of similar image retrieval, especially in the setting of large-scale datasets with millions to billions of images, where scalability becomes crucial.
First-order factoid question answering assumes that the question can be answered by a single fact in a knowledge base .
We propose a symmetric optical flow method to address the well-known chicken-and-egg relation between optical flow and occlusions in both forward and backward direction.
We borrow the very idea of "contrast effects" from the field of psychology, cognition, and education to design and train a permutation-invariant model for Raven's Progressive Matrices.
This paper tackles the supervised evaluation of image segmentation and object proposal algorithms. It surveys, structures, and deduplicates the measures used to compare both segmentation results and object proposals with a ground truth database and proposes a new measure: the precision-recall for objects and parts.
We propose an approach to cross-domain semantic segmentation with auxiliary geometric information, which can also be easily obtained from virtual environments.
Real-time, person-independent 3D registration and reconstruction from 2D video using cascade regression.
Neural Egg Separation is an iterative method for extracting a signal from an unobserved distribution additively mixed with an observed distribution.
In this paper, we propose a novel dynamic BERT model (abbreviated as DynaBERT), which can run at adaptive width and depth.
We propose a new approach for dense stereo matching by detecting and rejecting mismatched points that occur in the commonly challenging ::: image regions such as textureless areas, occluded portions and discontinuities.
In the task of near similar image search, features from Deep Neural Network is often used to compare images and measure similarity. Our method, however, explore the vast data to compute k-nearest neighbors using both image and text.
We propose a novel multi-task learning system that combines appearance and motion cues for a better semantic reasoning of the environment.
We present models for encoding sentences into embedding vectors that specifically target transfer learning. The models are efficient and result in accurate performance on diverse transfer tasks.
A zoo of deep nets is available these days for almost any given task, and it is increasingly unclear which net to start with when addressing a new task. To address this issue, we develop knowledge flow which moves 'knowledge' from multiple deep nets, referred to as teachers, to a new deep net model, called the student.
We propose a novel strategy for solving this task, when pixel-level annotations are not available, performing it in an almost zero-shot manner by relying on conventional whole image neural net classifiers that were trained using large bounding boxes.
This paper proposes an improved multi-scale object detection network based on single shot multibox detector (SSD) which achieves state-of-the-art detection performance and improves the multi- scale object detection performance effectively.
We propose a novel approach for unsupervised person re-identification by leveraging virtual and real data for training deep re-ID.
We use a control unit that dynamically attends to the question at different reasoning hops to guide the model's multi-hop reasoning. After adversarial training, this 2-hop model not only achieves improvements over its counterpart trained on regular data, but also outperforms the adversarially-trained 1-hop baseline.
We introduce HAWCgen, a set of deep generative neural network models, which are designed to supplement, or in some cases replace, parts of the simulation pipeline for the High Altitude Water Cherenkov observatory.
We propose an efficient and accurate deep network for disparity estimation which achieves state-of-the-art prediction accuracy.
We propose a knowledge-enhanced pretraining model for commonsense story generation that captures causal and temporal dependencies between sentences in a reasonable story.
We introduce a deep two-stream ConvNet for key frame detection in videos based on human actions that learns to directly predict the location of key frames.
We address the problem of guided image-to-image translation where we translate an input image into another while respecting the constraints provided by an external, user-provided guidance image.
This paper reviews machine learning methods for the motion planning of autonomous vehicles (AVs), with exclusive focus on the longitudinal behaviors and their impact on traffic congestion. An extensive survey of training data, model input/output, and learning methods.
In this paper, we demonstrate how HDT - a compressed serialization format for RDF - can be extended to cater for supporting encryption.
We propose a novel and explicit high-order Cross Factorization Machine (HCFM), which captures the inherent correlations of real-word data and avoids the complex interaction computations.
We prove that pseudo-labels are related to network predictions by an exponential link function and propose a principled end-to-end framework named D2 for semi-supervised SSL.
We propose a deep learning approach that learns to predict a 180{\deg} panoramic image from a narrow-view image, and use it to generate expanded equirectangular images for viewing.
We evaluate the usefulness of different information sources for the DDI prediction. We adopt three representative methods: the neighbor recommender method, the random walk method and the matrix perturbation method to build prediction models based on different data.
We propose a novel method capable of retrieving clips from untrimmed videos based on natural language queries that combines video and language information at the word level.
We introduce the task of Embodied Visual Recognition (EVR) and develop a new model called Embodied Mask R-CNN, for agents to learn to move strategically to improve their visual recognition abilities.
In this letter, we propose an automated method to identify mistakes made by object detectors without ground truth labels .
Memory networks have been a popular choice among neural architectures for machine reading comprehension and question answering, but they are ineffective even in single-hop reading comprehension.
Neural networks for speech and music event detection over 77,937 10-second audio segments .
We compare engineered (hand-crafted) features (or descriptors) and learned features for content-based indexing of image or video documents.
We propose a novel supervised learning technique for summarizing videos by automatically selecting keyframes or key subshots by using Long Short-Term Memory.
Autonomous driving relies on deriving understanding of objects and scenes through images. For improved detection capabilities we propose the use of thermal sensors to augment the vision capabilities of an autonomous vehicle.
We introduce a novel conditional GAN model, called RoCGAN, which leverages structure in the target space of the model to address the issue. Our model augments the generator with an unsupervised pathway, which promotes the outputs of the generator to span the target manifold.
We combine different descriptors in an ensemble of deep SVMs where the product rule is used for combining probability estimates of the different classifiers.
This paper advocates a new approach that allows questions to be partially translated into relaxed queries, covering the essential but not necessarily all aspects of the user's input.
We construct a gradient boosting-based classifier that achieves robust DDI prediction even for drugs whose interaction profiles are completely unseen during training.
We propose a method to compose several primitive pruning saliencies, to exploit the cases where each saliency measure does well. Our experiments show that the composition of saliencies avoids many poor pruning choices identified by individual saliencies.
We propose TransA, an adaptive metric approach for embedding, utilizing the metric learning ideas to provide a more flexible embedding method.
We identify four key components of saliency models, i.e., input features, multi-level integration, readout architecture, and loss functions. We review the state of the art models on these four components and propose novel and simpler alternatives.
We propose to learn local descriptors for point clouds in a self-supervised manner, while being easier to train and not requiring labeled data.
We propose a super lightweight SR network with limited parameters and operations that achieves similar performance to other cumbersome DL-SR models on mobile devices.
Generative Adversarial Networks (GANs) using maximum mean discrepancy (MMD) as distance measure for generative models.
Unsupervised, iterative algorithm for detecting Green Fluorescent Protein labeled nuclei in mouse brain scans .
We propose a semi-parametric cascade that first aligns a parametric shape, then captures more fine-grained deformations of an explicit shape. The proposed framework achieves high accuracies on multiple challenging benchmarks, including small, medium and large pose experiments.
We propose a novel Multi-column Mutual Learning (McML) strategy to improve multi-column networks and improve their generalization ability.
We propose a novel inspire-and-create framework with a story-to-image retriever that selects relevant cinematic images for inspiration and a storyboard creator that further refines and renders images to improve the relevancy and visual consistency.
We propose a simple but effective method with BERT for multi-turn conversational machine comprehension.
Neural cache language models (LMs) extend the idea of regularcache language models by making the cache probability dependent on the similarity between the current context and the context of the words in the cache.
We propose Editable Training, a model-agnostic training technique that encourages fast editing of the trained model, without influencing the model behavior on other samples.
Graph-based RGB-D segmentation, primary saliency measure, background distribution measure, and combination for indoor robot vision system.
We developed CORNET (for CORrelation NETworks) as an access point to transcriptome, protein interactome, and localization data and functional information on Arabidopsis (Arabidopsis thaliana). It consists of two flexible and versatile tools, namely the coexpression tool and the protein-protein interaction tool.
We address the problem of finding a set of images containing a common, but unknown, object category from a collection of image proposals. We model the selection as an energy minimization problem with unary and pairwise potential functions. Inspired by recent few-shot learning algorithms, we propose a fast and simple greedy inference algorithm.
The problem of forged images has become a global phenomenon that is spreading mainly through social media. New technologies have provided both the means and the support for this phenomenon, but they are also enabling a targeted response to overcome it. Deep convolution learning algorithms are one such solution. These have been shown to be highly effective in dealing with image forgery derived from generative adversarial networks (GANs).
We analyze the state-of-the-art GC accuracy on three large datasets: MORPH, LFW and GROUPS. We discuss their respective difficulties and bias, concluding that the most challenging and wildest complexity is present in GROUps. We propose a solution based on local descriptors that beats any previously published results.
We propose an explainable selection method of $\mathbf{Q}$, under which the data tensor may have a more significant low tensor Q-rank structure than that of low tubal-rank structures.
In this work, we address the task of weakly-supervised human action segmentation in long, untrimmed videos. We propose a novel action modeling framework, which consists of a new temporal convolutional network, named Temporal Convolutional Feature Pyramid Network (TCFPN), for predicting frame-wise action labels, and a novel training strategy, named Iterative Soft Boundary Assignment (ISBA), to align action sequences.
In this paper, we study the problems of opinion expression extraction and expression-level polarity and intensity classification. We present two types of joint approaches that can account for such interactions during 1) both learning and inference.
We overcome the insufficiency of training sample size problem by fusing two kinds of virtual samples and original samples to perform small sample face recognition.
We present a novel approach for joint bilingual sentiment classification at the sentence level that augments available labeled data in each language with unlabeled parallel data.
We found many CNN units exhibit translation-invariant boundary curvature selectivity approaching that of exemplar neurons in the primate mid-level visual area V4, even though boundary information was not provided during training.
Policy gradient algorithms in reinforcement learning rely on efficiently sampling an environment. $\mathcal{V}^{ex}$ can be used to evaluate the impact each transition will have on the learning. This criterion refines sampling and improves the policy gradient algorithm.
In this paper, we address unsupervised pose-guided person image generation, which is known challenging due to non-rigid deformation learning.
We propose to use solely binary presence annotations to train a tool tracker for laparoscopic videos.
We present the signal processing framework and some results for the IEEE AASP challenge on acoustic source localization and tracking (LOCATA)
We explore LayerDrop, a form of structured dropout, which has a regularization effect during training and allows for efficient pruning at inference time.
We propose XLNet, a generalized autoregressive pretraining method that enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and overcomes the limitations of BERT thanks to its Autoregressive formulation.
We propose ManiFool as a simple yet scalable algorithm to measure the invariance of deep networks to geometric transformations.
In this paper, a structural local DCT sparse appearance model with occlusion detection for visual tracking in a particle filter framework.
In this paper, we propose a novel online hashing framework to update the binary codes efficiently without accumulating the whole database.
We propose to address the two tasks as a whole, i.e. to jointly understand per-pixel 3D geometry and motion, yielding significantly improved results for both tasks.
We propose an interpretability method to break down a DNN prediction score as sum of its hidden unit contributions, in the form of a metric called conductance. We identify distinguishable patterns of hidden unit activations for wrong and correct predictions.
Combining covariance matrices as local spatio-temporal descriptors and local ST features for action recognition .
In this paper, we propose Implicit ReasoNets (IRNs), which is designed to perform large-scale inference implicitly through a search controller and shared memory.
We propose a multi-scale context attention network with three main modules: atrous spatial pyramid pooling attention, richer convolutional features, and attention mechanism for stereo matching and disparity refinement.
We propose a phrase-based hierarchical Long Short-Term Memory (phi-LSTM) model to generate image description.
We have proposed an Inception module based Convolutional Neural Network Architecture for emotion recognition which can be used in real time based application such as human robot interaction.
We show how the spellings of known words can help us deal with unknown words in open-vocabulary NLP tasks. The method we propose can be used to extend any closedvocabulary generative model.
We propose a Recurrent Residual Convolutional Neural Network based on U-Net for medical image segmentation tasks.
We propose a convolutional sparse coding (CSC-SR) for super resolution algorithm with a joint Bayesian learning strategy.
We introduce a two-stream CNN with a flow-guided memory module, where each stream encodes visual and temporal features and leverage it for the task of depth prediction.
Tex-Ray helps to explore and quantify dynamics of (continual) knowledge transfer, to complement (costly) supervised probing task procurement and established statistics like perplexity, ROC or F scores.
We propose the use of unsupervised learning to train projection networks that project onto the latent space of an already trained generator, performing image super-resolution and clustering of images into semantically identifiable groups.
We propose a novel recurrent network based architecture to model long-range dependencies between intermediate features which is highly useful in tasks like keypoint localization and tracking.
We propose a deep Age-Invariant Model (AIM) for cross-age face recognition in the wild with three novelties.
We extend the recent success of an integrated neural method for hypernymy detection to recognize multiple relations, and analyze the contributions of each source.
We propose a flexible and efficient method to generate unrestricted adversarial examples using image translation techniques. The generated images are perceptually realistic and maintain personal identity while the perturbations are large enough to defeat certified defenses.
We propose a method to learn universal distributed representations of sentences by encoding the suffixes of word sequences in a sentence and training on the Stanford Natural Language Inference dataset.
We propose a dynamic region-growing approach for hand region detection in egocentric videos, which achieves superior performance compared with state-of-the-art methods in complicated scenarios.
We propose a new approach, named PolyMapper, to circumvent the conventional pixel-wise segmentation of (aerial) images and predict objects in a vector representation directly.
We tackle the problem of efficient keypoint-based object detection and introduce CornerNet-Lite, a combination of two efficient variants of CornerNet, which use an attention mechanism to eliminate the need for exhaustively processing all pixels of the image.
We present a new measure, CMetric, to classify driver behaviors using centrality functions. The measure combines concepts from computational graph theory and social traffic psychology to quantify and classify human drivers.
Alignment of objects is a predominant problem in visual object categorisation (VOC). State-of-the-art part-based VOC methods try to automatically learn object parts and their spatial variation, which is difficult for objects in arbitrary poses. A straightforward solution is to annotate images with a set of “object landmarks”, but due to laborious work required, less supervised methods are preferred.
We present a novel end-to-end network for robust point clouds processing, named PointASNL, which can deal with point clouds with noise effectively.
We present a method to explicitly separate diversification from generation using a general plug-and-play module (called SELECTOR) that wraps around and guides an existing encoder-decoder model.
An enhanced visual SLAM algorithm based on the sparse direct visual odometry (VO) for mobile ground equipment.
We propose the Zero-shot Manipulation Net (ZM-Net), a fully-differentiable architecture that jointly optimizes an image-transformation network (TNet) and a parameter network (PNet) for fast zero-shot image manipulation conditioned on any guiding signal.
We propose a new method, called time-frequency enhancement block (TFBlock), which temporal attention and frequency attention are employed to enhance the features from relevant frames and frequency bands for environmental sound classification.
We propose curriculum labeling, an approach that exploits pseudo-labeling for propagating labels to unlabeled samples in an iterative and self-paced fashion, achieving state-of-the-art results on image classification benchmarks.
Joint optimization of pedestrian detection, person re-identification and pedestrian segmentation enables to produce more discriminative features for pedestrian, and consequently leads to better person search performance.
The proposed TMFUF is first capable to predict both conventional binary DDIs and comprehensive DDIs such that it captures the pharmacological changes caused by DDIs, which change increasingly and decreasingly the pharmacologically behavior of interacting drugs respectively.
We introduce a large dataset to propel research on laser-based semantic segmentation for automotive LiDAR and propose three benchmark tasks based on this dataset.
A computational imaging approach for motion deblurring using dynamic phase-coding in the lens aperture during image acquisition.
This paper proposes a multi-scale edge fusion algorithm based on texture suppression, which can extract the edge information of aluminum foam structure more accurately and completely.
We propose a novel dense subpixel disparity estimation algorithm with high computational efficiency and robustness for road condition assessment.
We propose HAWQV2, a Hessian based framework for mixed-precision quantization, where more sensitive layers are kept at higher precision.
We quantify the impact of contextualized embeddings for ChemNER by using Bi-LSTM-CRF (bidirectional long short term memory networks) networks.
Non-rigid objects recognition is an important problem in video analysis and understanding. It relies, however, on the interpretation of the body movements and classifies them in different events.
We propose an ensemble SAN model that generates a diverse set of perturbed outputs for a given input face image that can confound an arbitrary gender classifier.
We propose a new downsampling layer based on local importance modeling for discriminative tasks, achieving state-of-the-art performance on image classification.
In this paper, we propose an effective yet efficient one-stage detector, which gained the second place in the Road Object Detection competition of CVPR2018 workshop - Workshop of Autonomous Driving(WAD) workshop.
We evaluate a number of different off-the-shelf image description systems and propose a series of binary forced-choice tasks that each focus on a different aspect of the captions.
This paper presents a method for learning such a feature space where the cosine similarity is effectively optimized through a simple re-parametrization of the conventional softmax classification regime. At test time, the final classification layer can be stripped from the network to facilitate nearest neighbor queries.
This paper proposes a person-centric and online approach to the challenging problem of localization and prediction of actions and interactions in videos in an online manner.
We present a principled approach to learning sets of general symmetric elements that adhere to certain symmetries.
We propose a memory-augmented network to learn and memorize the representative prototypes that cover diverse samples universally.
We propose a novel strategy to craft adversarial examples by solving a constrained optimization problem using an adversarial generator network. Unlike in many attack strategies, we show that the same trained generator is capable of attacking new images without explicitly optimizing on them.
This paper introduces a novel big feature data analytics scheme for integration toward data analytics with decision making.
We explore the use of binary gradient cameras that directly output binary gradient images to reduce the portion of the power consumption allocated to image sensing.
In this paper, we propose a method to enrich the representation power of feature maps using a new feature fusion method which makes use of the information from consecutive layer.
We aim to build a strong baseline system with three modules: human candidate detector, single-person pose estimator and human pose tracker for multi-target pose tracking.
This paper proposes a zero-shot learning approach for audio classification based on the textual information about class labels without any audio samples from target classes.
In this paper, we propose Hard Person Identity Mining (HPIM) that attempts to refine the hard example mining to improve the exploration efficacy in person re-identification.
We address the problem of disentanglement of factors that generate a given data into those that are correlated with the labeling and those that aren’t.
We propose a novel, lightweight, and efficient super-resolution method to maximize the usefulness of the recursive architecture, by introducing block state-based recursive network.
We describe a camera-based system to analyze hand-drawn mind maps written on a whiteboard. The goal of the presented system is to produce digital representations of such mind maps.
We use correlated MC rollouts for contextual generation of categorical sequences which reduce the high generation cost in large vocabulary scenarios, by decomposing each categorical action into a sequence of binary actions.
In this paper, we propose a new task of mining commonsense facts from the raw text that describes the physical world for knowledge base completion.
We present a large-scale dataset named as"COIN"for COmprehensive INstructional video analysis, which contains 11,827 videos of 180 tasks in 12 domains.
We introduce per-pixel 3D object motion into the learning framework, which provides holistic 3D scene flow understanding and helps single image geometry estimation.
ZeroQ enables mixed-precision quantization without any access to the training or validation data.
We propose a novel Multi-task Collaborative Network (MCN) to achieve a joint learning of REC and RES for the first time.
We take a closer look at SCAN and show that it does not always capture the kind of generalization that it was designed for. We propose a complementary dataset, which requires mapping actions back to the original commands, called NACS.
We propose an inductive method for automatic, data-driven evaluations of biological ontologies without formal class definitions in regards to the property-based consistency of instance assignment.
We propose a simple method- ::: ology to include a noise-based regularizer while training ::: the student from the teacher, which provides a healthy im-::: provement in the performance of the student network.
This work aims at enhancing intra-operative surgical visualization by exploiting the 3D information about the surgical site for improved dense 3D reconstruction of soft tissues.
We propose a novel TOF-stereo fusion method based on an efficient seed-growing algorithm which uses the TOF data projected onto the stereo image pair as an initial set of correspondences.
This article presents a hardware implementation for speeding up these methods. With hardware friendly approximation, we demonstrate the feasibility of implementing this expensive computational task on hardware to achieve real-time performance.
We show that it is possible to generate token-level explanations for NLI without the need for training data explicitly annotated for this purpose.
Large-scale training for semantic segmentation is challenging due to the expense of obtaining training data for this task relative to other vision tasks. We propose a novel training approach to address this difficulty.
We propose a novel Individual Aggregation Network (IAN) that can accurately localize persons by learning to minimize intra-person feature variations.
This paper presents Deep Retinal Image Understanding (DRIU), a unified framework of retinal image analysis that provides both retinal vessel and optic disc segmentation.
We provide the first unified framework using smoothing functional to certify the model robustness against general adversarial attacks, and propose an exact algorithm to smooth the training process.
Integrating PPI datasets with the PPI data from biomedical literature for protein complex detection.
We use a cascade of feed-forward networks to find the answer to a reading comprehension task that can scale to larger evidence documents.
We define and investigate the new problem of mining subjectively interesting trees connecting a set of query vertices in a graph, i.e., trees that are highly surprising to the specific user at hand.
In most state-of-the-art hashing-based visual search systems, local image descriptors of an image are first aggregated as a single feature vector and then subjected to a hashing function that produces a binary hash code. In this paper, we propose a novel framework where feature aggregating and hashing are designed simultaneously and optimized jointly.
We propose a simple yet effective method to learn to segment new indoor scenes from an RGB-D sequence without manual annotations by exploiting geometric constraints and readily available training data.
We present an automated system for vascular pattern ehnacement and segmentation for diabetic retinopathy.
We propose a state-of-the-art superpixel benchmark for fair comparison and propose an overall ranking of superpixel algorithms utilizing a benchmark focussing on fair comparison.
We formalize a Linear Span framework, and propose Linear Span Network (LSN) which introduces Linear Span Units (LSUs) to minimizes the reconstruction error. LSN can effectively suppress the cluttered backgrounds and reconstruct object skeletons.
In this paper, we introduce a novel deep neural network architecture specifically designed for the task of gaze estimation from single eye input.
We found convergent signature of positive selection at the gene level, particularly EPAS1 gene, which underwent positive selection in Tibetan domestic mammals.
We integrate two powerful ideas, geometry and deep visual representation learning, into recurrent network architectures for mobile visual scene understanding. We train the proposed architectures to detect and segment objects in 3D, using the latent 3D feature map as input.
We introduce the knowledge graph language model, a neural language model with mechanisms for selecting and copying facts from a knowledge graph that are relevant to the context, as well as generating out-of-vocabulary tokens.
An automatic skin lesions classification system with higher classification rate using transfer learning and the pre-trained deep neural network.
We propose an end-to-end deep learning based method for query-controllable video summarization to generate a query-dependent video summary.
We propose a deep architecture that maintains separated the information about the available source domains data while at the same time leveraging over generic perceptual information in an effective manner.
We first investigate how and why learning fails when strong L1 or L2 regularization is imposed on deep neural networks. We then propose a novel method, gradient-coherent strong regularization, which imposes regularization only when the gradients are kept coherent in the presence of strong Regularization.
The current Deep Learning (DL) landscape is fast-paced and is rife with non-uniform models, hardware/software (HW/SW) stacks, and frameworks, but lacks a DL benchmarking platform to facilitate evaluation and comparison of DL innovations.
We propose a novel framework dubbed as TKD: temporal knowledge distillation. This framework distills the temporal knowledge from a heavy neural networks based model over selected video frames (the perception of the moments) to a light-weight model.
We propose BERTScore, an automatic evaluation metric for text generation. We evaluate using the outputs of machine translation and image captioning systems.
In this work we introduce Deforming Autoencoders, a generative model for images that disentangles shape from appearance in an unsupervised manner, allowing us to manipulate face images.
In this paper, we present an appearance-based method for detecting fovea and OD from colour images.
We propose a graph correspondence transfer (GCT) approach for person re-identification.
Evaluating aesthetic value of digital photographs is a challenging task, mainly due to numerous factors that need to be taken into account and subjective manner of this process. In this paper, we propose to approach this problem using deep convolutional neural networks.
We propose Refine Network (RefNet), a method which tries to mimic the human process of generating questions by first creating an initial draft and then refining it.
The ability of intelligent agents to play games in human-like fashion is popularly considered a benchmark of progress in Artificial Intelligence. Similarly, performance on multi-disciplinary tasks such as Visual Question Answering (VQA) is considered a marker for gauging progress in Computer Vision.
Focal loss allows us to learn models that are already very well calibrated, whilst preserving accuracy and confidence.
This paper investigates a fundamental problem of scene understanding: how to parse a scene image into a structured configuration (i.e., a semantic object hierarchy with object interaction relations). We propose a deep architecture consisting of two networks: i) a convolutional neural network extracting the image representation and ii) a recursive neural network discovering the hierarchical object structure and the inter-object relations.
This paper categorizes these algorithms into singlemodal and multimodal face recognition.
This paper presents a novel method, utilizing subregion recognition rate to weight kernel function, for emotion recognition.
We propose a simple, yet effective approach for spatiotemporal feature learning using deep 3-dimensional convolutional networks (3D ConvNets) trained on a large scale supervised video dataset.
We introduce a model-based asynchronous multi-fidelity hyperparameter optimization method, combining strengths of asynchronous Hyperband and Gaussian process-based Bayesian optimization.
We propose a single-model method that combines learned high-level features computed from log-scaled mel-spectrograms and raw audio data to obtain better predictive performance.
We propose a novel parameter initialization strategy that avoids explosion/vanishment of information across layers for weight normalized networks with and without residual connections.
We demonstrate that the last weight layer of a neural network converges to a linear SVM trained on the output of the last hidden layer, for both binary case and the multi-class case with the commonly used cross-entropy loss.
We turn a coupled optimization of connection weights and neural architecture into a differentiable optimization by means of stochastic relaxation.
We applied FloatSD to recurrent neural networks (RNNs), specifically long short-term memory (LSTM), and we quantized the gradients and activations.
We address a learning-to-normalize problem by proposing Switchable Normalization (SN), which learns to select different normalizers for different normalization layers of a deep neural network.
We introduce a novel GAN conditioning scheme based on Action Units (AU) annotations, which describes in a continuous manifold the anatomical facial movements defining a human expression.
In this paper, we propose a novel deep learning architecture for multi-label zero-shot learning, which is able to predict multiple unseen class labels for each input instance.
We propose IterNet, a new model based on UNet, with the ability to find obscured details of the vessel from the segmented vessel image itself, rather than the raw input image.
We propose a margin based criterion for linear dimension reduction that addresses the above problem associated with LDA.
This article provides an overview of some of the datasets that are most used for visual tracking, but also of others that address specific tasks.
In this paper, we propose a two-layer structure for action recognition to automatically exploit a mid-level ``acton'' representation that is compact, informative, discriminative, and easy to scale.
We propose a policy gradient method to directly optimize a linear combination of SPICE and CIDEr, which results in image captioning methods that are semantically faithful and syntactically fluent.
We propose AutoScaler, a scale-attention network to explicitly optimize this trade-off in visual correspondence tasks.
In this paper we introduce the Bi-Directional Attention Flow (BIDAF) network, a multi-stage hierarchical process that represents the context at different levels of granularity and uses bi-directional attention flow mechanism to obtain a query-aware context representation without early summarization.
We propose another way to look at the problem that relies on the multi-task learning paradigm. In particular, we want to study whether the learning process of a given semantic relation can be improved by the concurrent learning of another semantic relation.
We introduce a Positive-Unlabeled Learning method for inferring potential drug-drug interactions.
We make the first endeavour to tackle the domain adaptation problem according to one shot learning and achieve competitive re-identification performance on the testing set of the target domain.
This paper presents a novel kind of rotation moment invariants based on the Slepian functions, which were originally introduced in the method of separation of variables for Helmholtz equations.
In this paper, we propose a novel multi-stage network architecture with two branches in each stage to estimate multi-person poses in images.
Textual distractors in current multi-choice VQA datasets are not challenging enough for state-of-the-art neural models. We introduce a novel task called DG-VQA, a reinforcement learning solution to generate the most confusing distractors, and use them for adversarial training.
In this paper, we introduce an innovative intervention strategy to be used in combination with a sampling approach that is widely used for hidden populations, Respondent-driven Sampling (RDS)
A novel hybrid method that merges recommendations provided by different collaborative filtering approaches based on a multi-class classification algorithm is proposed.
Social influence dynamics strongly depends on the nature of the initial cultural state, for the same level of propensity towards collective behavior.
A DPP-based method for extractive multi-document summarization with improved similarity measure inspired by capsule networks.
We present an auxiliary task to Mask R-CNN, an instance segmentation network, which leads to faster training of the mask head. The Edge Agreement Head encourages predicted masks to have similar image gradients to the ground-truth mask using edge detection filters.
SuperMix optimizes a mixing objective that considers: i) forcing the class of input images to appear in the mixed image, ii) preserving the local structure of images, and iii) reducing the risk of suppressing important features.
We propose a novel 3D convolutional layer that can be trained end-to-end for facial expression recognition on temporal image sequences without using facial landmarks.
We propose a novel approach to jointly infer the 3D rigid-body poses and shapes of vehicles from stereo images of road scenes through combined photometric and silhouette alignment.
A distributed word learning model that integrates linguistic and extra-linguistic information, handles referential uncertainty, and correctly learns to associate words with objects, even in cases of limited linguistic exposure.
We propose a novel model based on Adversarial Networks and inspirited by the Shared-Private model (ANSP), which aims at reducing common, irrelevant features from the extracted features for information credibility evaluation.
We propose three simple domain-independent strategies aimed to improve non-extractive machine reading comprehension (MRC) and fine-tune a pre-trained language model that incorporate them.
We present a method to extract speech style embed-dings from input speech queries and apply this embedding as conditional input to a TTS voice so that the TTS response matches the speaking style of the input query.
In this paper, we present a general methodology for photometric registration that can deal with multiple different cues in a natural and consistent way.
This study proposed a new probabilistic algorithm free of assumptions of latentfactors, while retaining the advantages of previous algorithms.
This paper aims at discovering meaningful subsets of related images from large image collections without annotations. While k-means is usually considered as the gold standard for this task, we evaluate and show the interest of diffusion methods such as the Markov Clustering algorithm.
In this paper, we propose an elegant linear model to untangle facial actions from expressive face videos which contain a mixture of linearly-representable attributes.
We investigate the effects of the number of grey levels on PCA, multiple exemplar discriminant analysis (MEDA) and the elastic bunch graph matching (EBGM) FR algorithms.
We introduce a new model SqueezeSetV2 for point cloud segmentation, which is more robust against dropout noises in LiDAR point cloud and achieves significant accuracy improvement.
We present an alternative, and show how ground truth labels for many vision tasks are easily extracted from video games in real time as we play them.
This paper presents a novel activity class representation using a single sequence for training, useful in new scenarios where capturing and labeling sequences is expensive or impractical.
We propose a novel framework for structured phase retrieval by modeling natural signals as being in the range of a deep generative neural network and enforcing the generative priors directly.
We propose Approximated Oracle Filter Pruning (AOFP), which keeps searching for the least important filters in a binary search manner, makes pruning attempts by masking out filters randomly, accumulates the resulting errors, and finetunes the model via a multi-path framework.
We apply a generative model of grounded semantics to a large set of real-world photographs that contain a much larger variety of object types and for which referring expressions are available.
This paper describes the Style and Content Disentangled GAN (SC-GAN), an unsupervised algorithm for training GANs that learns disentangled style and content representations of the data.
This paper presents a supervised multi-label classification framework based on deep convolutional neural networks (CNNs) for predicting the risk of 14 common thoracic diseases.
We introduce a novel Sequential Attention Generative Adversarial Network (SeqAttnGAN) framework for interactive image editing via conversational language, where users can guide an agent to edit images via multi-turn dialogue.
 DLHub addresses two significant shortcomings in current systems. First, its self-service model repository allows users to share, publish, verify, reproduce, and reuse models, and addresses concerns related to model reproducibility by packaging and distributing models and all constituent components. Second, it implements scalable and low-latency serving capabilities that can leverage parallel and distributed computing resources.
A simple and interpretable reasoning model to generate visual representation that captures key objects and semantic concepts of a scene.
We propose Centripetal SGD (C-SGD), a novel optimization method, which can train several filters to collapse into a single point in the parameter hyperspace for network slimming, thus no finetuning is needed.
We propose Iterative Normalization (IterNorm), which employs Newton’s iterations for much more efficient whitening, while simultaneously avoiding the eigen-decomposition.
In this paper, we propose a generalization of the discrete convolutional neural networks (CNN) able to deal with sparse input point cloud.
We investigate the transfer learning-based methods for cancer detection and identification from scarce and low-resolution histology images.
We propose an end-to-end learning approach for panoptic segmentation, a novel task unifying instance (things) and semantic (stuff) segmentation.
In this letter, we present a dense ground truth dataset of nonrigidly deforming real-world scenes. Our dataset contains both long and short video sequences, and enables quantitatively evaluation for RGB-based tracking and registration methods.
An RGB-infrared fusion tracking method based on the fully convolutional Siamese Networks, termed as SiamFT, is proposed.
We formulate a simple yet effective centralized coordinate learning (CCL) method, which enforces the features to be dispersedly spanned in the coordinate space while ensuring the classification vectors to lie on a hypersphere.
We propose to harness the potential of simulation for the semantic segmentation of real-world self-driving scenes in a domain generalization fashion.
In many real-time applications, the deployment of deep neural networks is constrained by high computational cost and efficient lightweight neural networks are widely concerned. In this paper, we propose that depthwise convolution (DWC) is used to expand the number of channels in a bottleneck block, which is more efficient than 1 x 1 convolution.
We propose a novel incremental PLS, named Covariance-free Incremental Partial Least Squares (CIPLS), which learns a low-dimensional representation of the data using a single sample at a time.
Automatic facial emotion recognition technique for adaptive AI agent behaviour.
We assume that a high-dimensional datum, like an image, is compositional expression of a set of properties, with a complicated non-linear relationship between the datum and its properties.
MOTSFusion exploits the 3D motion extracted from dynamic object reconstructions to track objects through long periods of complete occlusion and to recover missing detections.
An upper bound on the spectral norm of the jacobian of a standard 2D multi-channel convolution layer.
We extend anchor graph regularization (AGR) for semi-supervised learning to achieve dimensionality reduction.
We comprehensively study and compare four different temporal modeling methods (temporal pooling, temporal attention, RNN and 3D convnets) for video-based person reID.
We propose a novel method, Multi-Task Learning-Based Network Embedding, termed MLNE, for preserving the proximity of nodes in the whole network.
We propose a novel privacy-preserving multi-task learning approach that utilizes the differential private stochastic gradient descent algorithm to optimize the end-to-end multi-Task model and weighs the loss functions of multiple tasks to improve learning efficiency and prediction accuracy.
An end-to-end framework to learn attraction field maps for raw input images, followed by a squeeze module to detect line segments without loss of information.
Unsupervised image-to-image translation aims at learning the relationship between samples from two image domains without supervised pair information. A generative model with an XO-structure, called the XOGAN, is proposed to learn the cross domain relationship among the two domains and the ad- ditional variables.
A novel self-training scheme for unsupervised domain adaptive re-identification tasks.
We make a preliminary evaluation of the impact of syntactic structure in the tasks of evaluating the Semantic Textual Similarity and Semantic Relatedness and analyze the results from several experiments regarding to how syntactic Structure contributes to solving these tasks.
We propose the Competitive Pathway Network (CoPaNet), a multi-scale, competitive pathway network that combines multiple parallel residual-type subnetworks for feature competition.
We compare system performance using different lengths of the input signal, different types of acoustic features and different Types of emotion speech (improvised/scripted).
We propose a novel object-oriented semantic mapping approach aiming at overcoming such issues by introducing highly accurate object- oriented semantic scene reconstruction in real time.
This paper presents a new real-time stereo correspondence method using combined similarity measurement and guided filter.
HYENA exploits gazetteer features and accounts for the joint evidence for types at different levels. We present HYENA for multi-label hierarchical classification.
We demonstrate the first end-to-end attacks on autonomous driving in simulation, using simple physically realizable attacks: the painting of black lines on the road.
This paper proposes a network architecture to perform variable length semantic video generation using captions in an incremental manner.
We propose a semantic-enhanced image and sentence matching model, which can improve the image representation by learning semantic concepts and then organizing them in a correct semantic order.
We propose a novel deep learning based system for vessel segmentation using a unified CNN architecture to jointly exploit both local appearances and global vessel structures.
We propose a bottom-up clustering (BUC) approach to jointly optimize a convolutional neural network (CNN) and the relationship among the individual samples for person re-identification.
We present an automated method for quantifying the severity of motion impairment in patients with ataxia, using only video recordings.
The progress we are currently witnessing in many computer vision applications, including automatic face analysis, would not be made possible without tremendous efforts in collecting and annotating large scale visual databases. To this end, we propose 4DFAB, a new large scale database of dynamic high-resolution 3D faces (over 1,800,000 3D meshes).
Unifying the methods of generating adversarial examples by leveraging ADMM (Alternating Direction Method of Multipliers), an operator splitting optimization approach.
We propose a novel compressed deep Convolutional Neural Network (CNN) feature based Correlation Filter tracker for multi-object tracking.
In this paper, we propose a method called Hodge and Podge for sound event detection. This work explores how to extend deep semi-supervised learning to result in a new, state-of-the-art sound event Detection method.
We introduce a novel method called transitions forests, an ensemble of decision trees that both learn to discriminate static poses and transitions between pairs of two independent frames.
We propose a robust framework for fine-grained apparel classification, in-shop and cross-domain retrieval which eliminates the requirement of rich annotations like bounding boxes and human-joints or clothing landmarks.
In this paper, we propose a method for incorporating world knowledge (linked entities and fine-grained entity types) into a neural question generation model.
We present a method that is able to find the most informative video portions through information about individual local motion regions, as well as the interactions between these motion regions.
This paper proposes a simple yet effective Neurons Merging Layer (NMLayer) for deep supervised hashing.
We propose a novel spatiotemporal pyramid network to fuse the spatial and temporal features in a pyramid structure such that they can reinforce each other.
We introduce two novel descriptors which are invariant under monotonically increasing intensity rescalings, while containing a maximum possible amount of information.
We propose a predictive model to forecast the long-term scientific impact at the early stage, which simultaneously addresses a number of these open challenges, including the scholarly feature design, the non-linearity, the domain-heterogeneity and dynamics.
We propose a hierarchical approach to multi-action recognition that performs joint classification and segmentation that exploits the overlapping of the temporal windows.
We propose a novel multi-index hashing method called Bag of Indexes (BoI) for Approximate Nearest Neighbors (ANN) search.
We propose Asymmetric Pyramid Non-local Neural Network for semantic segmentation.
This paper proposes an end-to-end efficient point cloud generation network, which is composed of an encoder, a 2D–3D fusion module, and a decoder. The point cloud from the nearest shape effectively instructs the generation of finer point clouds.
We propose a novel Progressive Cross-camera Soft-label Learning (PCSL) framework for the semi-supervised person re-identification (Re-ID) case, which can generate cross-camera soft-labels and utilize them to optimize the network.
ADAM, a novel multimedia retrieval system that is tailored to large collections and that is able to support both Boolean retrieval for structured data and similarity-based retrieval for feature vectors.
The recently proposed Multilinear Compressive Learning (MCL) framework combines Compressive Sensing and Machine Learning into an end-to-end system that takes into account the multidimensional structure of the signals when designing the sensing and feature synthesis components.
We propose structural embedding of syntactic trees (SEST), an algorithm framework to utilize structured information and encode them into vector representations that can boost the performance of algorithms for the machine comprehension.
We introduce temporal regularization to SRDCF with single sample, which improves the tracking performance at the price of increasing complexity.
A learning based approach to predict camera motion parameters directly from optic flow, by marginalizing depthmap variations and outliers.
We propose a grid-based spherical convolutional neural network for detecting objects from spherical images.
We describe a novel weakly labeled Audio Event Classification approach based on a self-supervised attention model and propose a highly effective strongly supervised attention model.
Recommender systems are becoming a salient part of many e-commerce websites. Viewers' preference ratings are malleable and can be significantly influenced by the recommendation received.
We present a method for generating a video of a talking face that uses a joint embedding of the face and audio to generate synthesised talking face video frames.
We address the computational bottleneck of modern MOT systems by leveraging on an ensemble of detectors, each running every f frames.
We introduce a method called TrackIn that computes the influence of a training example on a prediction made by the model, by tracking how the loss on the test point changes during the training process whenever the training example of interest was utilized.
We introduce a novel unsupervised pose augmentation cross-view person Re-Id scheme called PAC-GAN that can combat the state-of-the-arts with recognition rate.
MorphNet iteratively shrinks and expands a network, shrinking via a resource-weighted sparsifying regularizer on activations and expanding via a uniform multiplicative factor on all layers.
A spectral analysis of a Boolean function is proposed for approximating the decision boundary of an ensemble of classifiers, and an intuitive explanation of computing Walsh coefficients for the functional approximation is provided.
We propose an unsupervised learning approach to adapt road scene segmenters across different cities without any user annotation or interaction.
We use recent advances in deep generative models, to outperform the state-of-the-art in achieving the highest classification accuracy using as few labels as possible.
We propose a recurrent graph neural network that captures long-term dependency across layers and achieves state-of-the-art results on three benchmarks.
This chapter presents a part-based face detection approach where the spatial relationship between the face parts is represented by a hidden 3D model with six parameters.
We propose a novel efficient tracking framework which combines DCF and SOSVM to obtain a novel formulation for training circular and structural learners which significantly reduces computational complexity and improves robustness.
The MIT Advanced Vehicle Technology (MIT-AVT) study collects large-scale naturalistic driving data collection that includes high-definition video to fuel the development of deep learning-based internal and external perception systems for autonomous vehicle development.
Scale-up neural architecture search by designing factorizable set of architectural parameters, so that the size of the search space goes up quadratically while the burden of optimization increases linearly.
We extend two related, model-free algorithms for continuous control to solve partially observed domains using recurrent neural networks trained with backpropagation through time.
For human pose estimation in still images, this paper proposes three semi- and weakly-supervised learning schemes.
This paper pushes the envelope on salient regions in a video to decompose them into semantically meaningful components, semantic salient instances.
We introduce an addition branch to generate a facial mask so as to focus on facial muscle moving regions. To guide the facial mask learning, we propose to incorporate prior domain knowledge by using the average differences between neutral faces and the corresponding expressive faces.
We investigate whether state-of-the-art object detection systems have equitable predictive performance on pedestrians with different skin tones. We investigate to what extent time of day, occlusion, and reweight the supervised loss during training affect this predictive bias.
In this paper, we propose a hierarchical deep neural network, with CNNs at multiple levels, and a corresponding training method for lifelong learning.
In this paper, we focus on studying the appearing time of different kinds of cars on the road. We propose a fully automatic method to carry out this study.
We introduce a deep open-world group-based person re-id model based on adversarial learning to alleviate the attack problem caused by similar non-target people.
In this paper, we propose a simple but efficient forward vehicle collision warning framework by aggregating monocular distance measurement and precise vehicle detection.
Auto-annotation by ensemble of models is an efficient method of learning on unlabeled data. We propose filtering the auto-labeled data using a trained model that predicts the quality of the annotation from the degree of consensus between ensemble models.
We propose a multi-task convolutional network that learns both personal attributes and identities in an end-to-end framework.
We propose a novel Progressive Object Transfer Detection (POTD) framework, which leverages various object supervision of different domains effectively into a progressive detection procedure.
We propose a model that estimates a dense 3D motion field, also known as scene flow, for Robotic Manipulation scenarios.
We address a fundamental challenge: Can we utilize the local processing capabilities of modern smartphones efficiently to provide desired features to approved analytics services, while protecting against undesired inference attacks and preserving privacy on the cloud? We propose a hybrid architecture for a distributed deep learning model between the smartphone and the cloud.
We introduce a general framework for visual forecasting, which directly imitates visual sequences from their raw pixel values without additional supervision.
We present an algorithm that automatically establishes dense correspondences between a large number of 3D faces. A deformable model is constructed from the dense corresponded faces and an algorithm is proposed for morphing the K3DM to fit unseen faces.
We propose a spherical kernel for efficient graph convolution of 3D point clouds without edge-dependent filter generation, making it computationally attractive for large point clouds.
In this paper we propose an affordable solution to self-localization, which utilizes visual odometry and road maps as the only inputs.
This paper aims to provide a comprehensive review of the social media RS on research articles published from 2011 to 2015 by exploiting a methodological decision analysis in six aspects.
Zero-shot Recognition: A Review of Zero-Shot Recognition Techniques and Applications .
We propose an effective structured pruning approach that jointly prunes filters as well as other structures in an end-to-end manner.
This paper proposes the Macro-Micro Adversarial Net (MMAN), a novel adversarial network that addresses the problem of local and semantic inconsistency in human parsing.
We propose a novel theoretical kernel-based framework for node classification that can bridge the gap between these two representation learning problems on graphs.
We explore an innovative strategy for image denoising by using convolutional neural networks (CNN) to learn similar pixel-distribution features from noisy images.
We propose a novel image representation, termed Attribute-Graph, to rank images by their semantic similarity to a given query image, which results in improved ranking performance over existing techniques.
We have combined the excitation source features and the well known Male-frequency cepstral coefficient features to develop emotion recognition system with improved performance.
The conditional entropy (CENT) H(Y |C,F) is shown in theory and experiments to be a highly compact and class-informative code, that can be computed from the filter outputs throughout an existing CNN and used to obtain higher classification results than the original CNN itself.
We address this issue by learning transferable features from weakly labeled data, which are collected from various parts of the body and are organized by non-medical experts.
We address the problem of semantic correspondence, that is, establishing a dense flow field between images depicting different instances of the same object or scene category. We propose to use binary foreground masks and subjected to synthetic geometric deformations to train a convolutional neural network (CNN) for this task.
Clustering internal Convnet representations with Dirichlet Process Gaussian Mixture Model, for visualization of learned representations in Convnets.
Neural language models (LMs) are typically trained using only lexical features, such as surface forms of words, but syntactic signals can be detected at high confidence using existing parsers.
This work explores the transferability of features learned by an object detection CNN (Faster R-CNN) to nucleus classification in histopathology images using class-agnostic models.
We use transfer learning to train the Faster R-CNN method for real-time deep object detection, by combining a large ground-based dataset for urban scene understanding with a smaller number of images from an aerial dataset.
In this paper, the authors proposed a gait recognition method for extremely low-quality videos, which have a frame-rate at one frame per second (1 fps) and resolution of 32 pixels.
We explore Interactiveness Prior which indicates whether human and object interact with each other or not. We found that interactiveness prior can be learned across HOI datasets, regardless of HOI category settings.
The training method of repetitively feeding all samples into a pre-defined network for image classification has been widely adopted by current state-of-the-art. In this work, we provide a new method, which can be leveraged to train classification networks in a more efficient way.
We study the problem of 3D object generation from a probabilistic space by leveraging recent advances in generative adversarial networks and generative Adversarial nets.
The goal of graph embedding is to learn a representation of graphs vertices in a latent low-dimensional space in order to encode the structural information that lies in graphs.
Multiview self-supervised learning using view invariant stochastic prototype embedding (VISPE)
We present a multi-purpose algorithm for simultaneousface detection, face alignment, pose estimation, genderrecognition, smile detection, age estimation and face recognitionusing a single deep convolutional neural network (CNN)
We propose a low cost method that can explain images with novel objects without retraining using the word embeddings of the objects.
We show that local handcrafted features and Convolutional Neural Networks share the same convolution-pooling network structure and propose a two-stream convolutional ISA (ConvISA) for efficient and powerful video feature learning.
In this paper, the edge caching problem in fog radio access networks (F-RAN) is investigated. Considering that users prefer to request the contents they are interested in, we propose to implement online content popularity prediction by leveraging the content features and user preferences, and offline user preference learning by using the FTRL-Proximal algorithm.
We propose to use Multi-Task Learning (MTL) and use gender and naturalness as auxiliary tasks in deep neural networks.
An efficient regression based method for people counting based on foreground density and number of people.
We introduce a functional feature map that embeds time span into high-dimensional spaces and propose several models to learn the functional time representation and the interactions with event representation.
We demonstrate state-of- the-art performance using the Wasserstein GAN gradient penalty (WGAN-GP) framework over CIFAR-10, STL10 and CelebA datasets and propose a novel discriminator gradient penalty function for GANs.
We propose a deep neural network model that synthesizes high-quality talking face video with natural head pose (making use of the visual information in V), expression and lip synchronization.
Using ensemble techniques to compose a neural network as an ensemble of smaller networks while keeping the same number of parameters.
We propose Asymmetric GAN to adapt the asymmetric domains by introducing an auxiliary variable (aux) to learn the extra information for transferring from the information-poor domain to the Information-rich domain, which improves the performance of state-of-the-art approaches in the following ways.
We propose a principled importance sampling scheme that focuses computation on"informative"examples, and reduces the variance of the stochastic gradients during training.
We show how to adjust for the variance introduced by dropout with corrections to weight initialization and Batch Normalization, yielding higher accuracy.
Attribute guided face image synthesis aims to manipulate attributes on a face image and generate synthetic face images conditioned on the attributes of interest.
We introduce a novel framework called Attention-Aware Compositional Network (AACN) for person ReID.
We consider the question: what can be learnt by looking at and listening to a large number of unlabelled videos? There is a valuable, but so far untapped, source of information contained in the video itself, and we introduce a novel "Audio-Visual Correspondence" learning task that makes use of this.
We introduce BlockDrop, an approach that learns to dynamically choose which layers of a deep network to execute during inference so as to best reduce total computation without degrading prediction accuracy.
In this paper we present an extension of Direct Sparse Odometry to a monocular visual SLAM system with loop closure detection and pose-graph optimization.
We show that cleaning up the training data can lead to substantial error rate reductions, and enhancement in training is advisable as long as enhancement in test is at least as strong as in training.
Spatial Aligned Temporal Pyramid Pooling (SATPP) network is proposed as a baseline algorithm to leverage the rich visual-temporal cues in LVreID for feature learning.
The classical likelihood ratio classifier easily collapses in many biometric applications especially with independent training-test subjects. The reason lies in the inaccurate estimation of the underlying user-specific feature density.
We assess the extent to which sequential scene category representations built by a CNN map onto those built in the human brain develop through a dynamic interplay between early activity over occipital electrodes as well as later activity over temporal and frontal electrodes.
Multi-modal information is essential to describe what has happened in a video. In this work, we represent videos by various appearance, motion and audio information guided with video topic.
In order to solve large matrix completion problems with practical computational cost, an approximate approach based on matrix factorization has been widely used. In this study, we propose a new algorithm based on the cavity method from statistical mechanics.
We report the "Recurrent Deterioration" (RD) phenomenon observed in online recommender systems. Motivated to tackle the problems causing the RD phenomenon, we propose the POMDP-Rec framework, which is a neural-optimized Partially Observable Markov Decision Process algorithm for recommender Systems.
This paper solves few-shot segmentation in a new perspective of "how to represent unseen classes by existing classes", and formulates few-Shot segmentation as the representation process that represents unseen classes (in terms of forming the foreground prior) byexisting classes precisely.
We propose a bottom-up domain adaptation method for stereo matching, in which two particular approaches are proposed, i.e. color transfer and cost regularization, that improve the generalization ability of existing disparity networks by a large margin.
We address the multi-label imbalance problem by introducing a novel mixed objective optimization network with a loss function that mixes multiple task objectives with domain adaptive re-weighting of propagated loss.
We proposed the Multi-modality Latent Interaction module (MLI), which learns the cross-modalities relationships between latent visual and language summarizations, which summarize visual regions and question into a small number of latent representations to avoid modeling uninformative individual region-word relations.
We propose a Visual-Spatial Network (VSN) that detects action-objects without using any first-person labels.
We propose a VAE-based generative model which is capable of extracting features correlated to binary labels in the data and structuring it in a latent subspace which is easy to interpret.
We propose a deep but compact convolutional network to directly reconstruct the high resolution image from the original low resolution image.
A hyper-parameter optimizer based on Tree-Structured Parzen Estimators (TPE) for finding optimal architecture depth of CNNs.
This paper presents a comprehensive survey of existing space-time representations of people based on 3D skeletal data, and provides an insightful categorization and analysis of the 3D skeleton-based representations.
This paper presents a new formulation of stereo as a maximum a posterior problem in which both a disparity map and MRF parameters are estimated from the stereo pair itself. We present an iterative algorithm for the MAP estimation that alternates between estimating the parameters while fixing the disparity map.
In this paper, a novel deep ReID CNN is designed, termed Omni-Scale Network, for omni-scale feature learning.
We propose and evaluate an approach based on antibody-guided annotation and deep learning to quantify immune cell-rich areas in hematoxylin and eosin stained samples.
The Computer Assisted Diagnosis systems could save workloads and give objective diagnostic to ophthalmologists. At first level of automated screening of systems feature extraction is the fundamental step. One of these retinal features is the fovea, a small fossa on the fundus.
We present an algorithm to defend against adversarial perturbations in the presence of such adversarial manipulations, without retraining or modifying the CNN.
In this paper, a ground-truth based measure of errors in estimated disparity maps is presented. The proposed measure is more suited than BMP to evaluate the depth accuracy of the estimated disparity map.
We investigate the referential games of Lazaridou et al. (2017) and find that the agents establish successful communication by inducing visual representations that almost perfectly align with each other, but, surprisingly, do not capture the conceptual properties of the input images.
This paper introduces a way to learn cross-modal convolutional neural network (X-CNN) architectures from a base CNN and the training data to reduce the design cost and enable applying cross-Modal networks in sparse data environments.
We propose a method for the delineation of blood vessels in retinal fundus images that is effective for vessels of different thickness.
We formulate object segmentation in video as a graph partitioning problem in both space and time, in which nodes are pixels and their relations form local neighbourhoods. We compute the main cluster using a fast 3D filtering technique that finds the spectral clustering solution, namely the principal eigenvector of the graph's adjacency matrix, without building the matrix explicitly.
We present MLPerf, a machine learning benchmark that overcomes these challenges and drives community progress on performance and scalability across multiple vendors.
We investigate an unsupervised domain adaptation technique that descends from another perspective, in order to avoid the complexity of adversarial training and cycle consistencies.
In this paper, we propose a novel pixel-wise visual object tracking framework that can track any anonymous object in a noisy background.
In this paper, we develop a novel system which can achieve a robust and accurate HR estimation under those challenging scenarios.
We address weakly supervised action alignment and segmentation in videos, where only the order of occurring actions is available during training, using discriminative modeling and end-to-end training.
In this work, we describe the design, development, and deployment of NEREA, an automatic Named Entity Recognizer and Disambiguation system, developed in collaboration with professional documentalists.
In this paper, we present the RNN Transformer network to tackle the Chinese MRC task.
Learning from human segmentations gives us a new insight into our problem. The human segmentation process would inevitably fulfill the human behavior's principles including the least effort principle.
We propose a simple yet effective building block for ResNeXt-style backbones, which allows discriminative local representation learning for multi-scale feature information across multi-parallel branches.
A scale-Aware Fast R-CNN framework for pedestrian detection in natural scenes.
We propose a probabilistic framework, learning from indirect observations, for learning from a wide range of weak supervision in real-world problems.
Attention-based Adversarial Autoencoder Network Embedding(AAANE) framework, which promotes the collaboration of different scales and lets them vote for robust representations.
We prioritized drug–drug-event associations derived from EHRs using four sources of information: (1) public databases, (2) sources of spontaneous reports, (3) literature, and (4) non-EHR prediction methods.
We propose a new geometry-based optimization approach to address this problem. We develop theory to guarantee that the mapping is bijective so that its inverse from feature space to data space results in expressive nonlinear contours.
A multi-resolution network can model the development of acuity and coarse-to-fine processing in mammalian visual cortex in an unsupervised manner.
We present a deep learning architecture for lipreading and audiovisual word recognition, which combines Residual Networks equipped with spatiotemporal input layers and Bidirectional LSTMs.
This paper proposes motionlet, a mid-level and spatiotemporal part, for human motion recognition, and proposes a data-driven approach to learn motion lets from training videos.
Improving subgraph selection through a novel ranking method and leveraging the subject--relation dependency for knowledge graph based simple question answering.
In this paper, we introduce a novel attentional similarity module for the problem of few-shot sound recognition, allowing the resulting model to especially match short sound events.
We present a novel method based on a 3D siamese neural network, for the re-identification of nodules in a pair of CT scans of the same patient without the need for image registration.
We consider the task of learning a classifier for semantic segmentation using weak supervision in the form of image labels specifying objects present in the image, and propose an Expectation-Maximization based approach.
The Open Archives Initiative Protocol for Metadata Harvesting (OAI-PMH) has found widespread adoption for exchanging bibliographic metadata. In parallel, the W3C's Linking Open Data Initiative exposes and interlinks structured data from a variety of data sources on the web as part of the Linked Data cloud.
In this paper, we present an efficient yet practical system, IMOD, to incrementally train an existing object detection model such that it can detect new object classes without losing its capability to detect old classes.
We introduce Multi-Expert Region-based Convolutional Neural Network (ME R-CNN) which is equipped with multiple experts (ME) where each expert is learned to process a certain type of regions of interest (RoIs).
We propose a novel method for robust subspace clustering with compressed data that recovers authentic row space that gives correct clustering results under certain conditions.
We present the results and the main findings of SemEval-2019 Task 6 on Identifying and Categorizing Offensive Language in Social Media.
We present a new deep learning-based approach for dense stereo matching. The resulting method is highly efficient at test time, while achieving good matching accuracy.
Our model learns a retrieval model based on user-item interactions, while generating an effective unigram language model for each item.
We propose a novel approach to learn node embedding for heterogeneous networks through a joint learning framework of both network links and text associated with nodes.
Vector models of language are based on the contextual aspects of language, the distributions of words and how they co-occur in text. We develop a dynamic vector semantics for language based on a form of dynamic interpretation inspired by Heim's context change potentials.
We propose a method to learn 3D deformable object categories from raw single-view images, without external supervision.
We propose a Pixel Adaptive Filtering Unit (PAFU) which introduces a differentiable kernel selection mechanism paired with a discrete, learnable and decorrelated group of kernels to allow for content-based spatial adaptation.
We propose a new architecture and training methodology for generative adversarial networks. We train each unit independently, instead of with end-to-end backpropagation on the entire chain.
We propose DC-BERT, a decoupled contextual encoding framework that has dual BERT models: an online BERT which encodes the question only once, and an offline BERTwhich pre-encodes all the documents and caches their encodings.
This paper addresses the importance of full-image supervision for monocular depth estimation. We propose a semi-supervised architecture, which combines both unsupervised framework of using image consistency and supervised framework of dense depth completion.
A training-free method to accelerate CNNs by transferring pre-trained CNN models into the MobileNet-like depthwise separable convolution structure, with promising speedup yet negligible accuracy loss.
Vessel enhancement using local line integrals and variational optimization produces accurate vesselness measures and vessel direction estimations that are less subject to local intensity abnormalities.
A looped deep pseudo-task optimization procedure for automatic category discovery of visually coherent and clinically semantic (concept) clusters on a large-scale radiology image database.
We introduce DropAll, a generalization of DropOut and DropConnect, for regularization of fully-connected layers within convolutional neural networks.
We propose a generative adversarial network (DR-GAN) to synthesize high-resolution fundus images which can be manipulated with arbitrary grading and lesion information and contribute to the DR grading task.
We show that adversarially-trained latent variational variable models are complementary, and propose a novel method for combining them to achieve realistic predictions.
In this paper, we introduce a novel image differential method for gaze estimation. We propose to directly train a differential convolutional neural network to predict the gaze differences between two eye input images of the same subject.
We apply feature labeling to researcher metadata extraction from homepages by combining a small set of expert-provided feature distributions with few fully-labeled examples for improved tagging performance.
We introduce a new attack called boundary projection that improves upon existing methods by a large margin. We investigate this speed-distortion trade-off in some depth.
We propose a new method for learning a pixel-wise representation that reflects segment relatedness, combined with an edge map to yield a new segmentation algorithm.
We propose an algorithm that performs depth completion of sparse LIDAR depth data using only basic image processing operations.
In this work we introduce novel image metrics that can be used with distance-based classifiers or directly to decide whether two input images belong to the same class.
We introduce a Boundary Neural Field (BNF), which is a global energy model integrating FCN predictions with boundary cues. The boundary information is used to enhance semantic segment coherence and to improve object localization.
We introduce Information Dropout, a generalization of dropout that is motivated by the Information Bottleneck principle and highlights the way in which injecting noise in the activations can help in learning optimal representations of the data.
We develop multi-label moves for graph cuts, which give each pixel a choice of more than two labels to switch to.
We propose a method to generate an image incrementally based on a sequence of graphs of scene-based text descriptions (scene-graphs) without needing any intermediate supervision during training.
A non-parametric way to control joint PMF complexity without relying on a priori structural assumptions regarding the underlying probability model.
Interlaced Derivative Patterns (IDP) is a derivative-based technique for gender classification.
We propose temporal flow maps for limbs (TML) and a multi-stride method for pose estimation in videos.
In this paper, we employ learnable optimizations to improve tracking robustness and speed up solver convergence.
SiamFC has a simple network structure and can be pretrained offline on a large data set, so it has attracted the attention of many researchers. Hence, there are no good solutions for complex tracking scenarios such as occlusion and large target deformation. We propose a method using the Kalman filter method and fusion multiresolution features and get multiple response scores.
We propose a novel, planned-ahead hybrid reinforcement learning model that combines model-free and model-based reinforcement learning to solve a real-world vision-language navigation task.
Adversarial training using the Fast Signed Gradient Method can be interpreted as regularization of the loss in the 2-norm.
We propose a novel stereo visual odometry approach, which is especially suited for poorly textured environments and is therefore well suited for various robotics and augmented reality applications.
We propose an alternative approach to learning spatiotemporal video representations that require no semantically labeled videos and instead leverages the years of effort in collecting and labeling large and clean still-image datasets.
Stereo matching is one of the most important and challenging subjects in the field of planetary rover with a stereo vision system. In this paper, we propose an efficient dense stereo matching method to generate disparity maps for a planetary rover.
We propose an end-to-end constrained clustering scheme to tackle the person re-identification (re-id) problem, which leverages contextual knowledge of a set of images corresponding to the given person-images.
In this paper, we propose a new interpretable emotion recognition approach with the activation mechanism by using machine learning and EEG signals.
We propose Long Short-Term Sample Distillation, a novel training policy that simultaneously leverages multiple phases of the previous training process to guide the later training updates to a neural network, while efficiently proceeding in just one single generation pass.
We propose a generative model based on Conditional Adversarial Autoencoder (CAAE) for face aging task without paired samples.
We present a comprehensive analysis of how and why face recognition accuracy differs between men and women. We show that the distribution of facial expressions may differ between male/female, but that the accuracy difference persists for image subsets rated confidently as neutral expression.
We propose an efficient temporal reasoning graph (TRG) to simultaneously capture the appearance features and temporal relation between video sequences at multiple time scales.
We introduce a deep autoencoder (AE) network with excellent reconstruction quality and generalization ability for 3D geometric data.
Deep generative models learn a mapping from a low dimensional latent space to a high-dimensional data space. Under certain regularity conditions, these models parameterize nonlinear manifolds in the data space, which are surprisingly close to zero curvature.
We present an approach for temporally consistent object segmentation in videos that combines frame-level object detection with concepts from object tracking and motion segmentation.
We propose a novel generative adversarial network (GAN) for the task of unsupervised learning of 3D representations from natural images. HoloGAN can be trained end-to-end from unlabelled 2D images only.
Enhanced discriminative locality alignment (EDLA) for robust feature extraction.
We present two information leakage attacks that outperform previous work on membership inference against generative models. The first attack allows membership inference without assumptions on the type of the generative model. The second attack specifically targets Variational Autoencoders, achieving high membership inference accuracy.
In this paper, we propose to incorporate convolutional neural networks with multi-context attention mechanism into an end-to-end framework for human pose estimation.
We propose label-noise robust GANs (rGANs), which can learn a clean label conditional generative distribution even when training labels are noisy.
A multiscale defect-detection network based on deep learning for aluminum profile surface defects detection.
This paper introduces a novel algorithm called fuzzy linear regression discriminant projection (FLRDP) for face recognition.
We propose an end-to-end weakly-supervised deep learning framework which is robust to the label noise in Web images and can effectively reduce the negative impact of noisy web image annotations.
We propose a heuristic data generation method that can alleviate data sparsity in order to use rating data more efficiently than the handcrafted features.
We introduce the back-matching propagation and propose an algorithm that turns to be the regular SGD with a layer-wise adaptive learning rate strategy and achieve favorable results over SGD.
Convolutional neural networks on large-scale annotated datasets can be effi- ciently transferred to other visual recognition tasks with limited amount of training data.
We present a simple and effective learning technique that significantly improves mAP of YOLO object detectors without compromising their speed.
A review of the state-of-the-art deep learning based methods for video anomaly detection.
We propose Batch Kalman Normalization for improving and accelerating the training of DNNs, particularly under the context of micro-batches.
We propose a novel method to directly learn a stochastic transition operator whose repeated application provides generated samples, enabling us to learn biologically plausible asymmetric neural networks.
We present a new method for retargeting video-captured motion between different human performers, without the need to explicitly reconstruct 3D poses and/or camera parameters.
To improve the training efficiency of hierarchical recurrent models without compromising their performance, we propose a strategy named as `the lower the simpler', which is to simplify the baseline models by making the lower layers simpler than the upper layers.
In this paper, we propose Variance Reduced Local SGD (VRL-SGD) to further reduce the communication complexity and achieve a linear iteration speedup.
We use 3D convolutions on video volume to extract spatial and temporal features simultaneously, and use a non-local block to tackle spatial-temporal long-range dependencies.
Generalization to new locations is poor, especially for classification systems. We present a dataset designed to measure recognition generalization to novel environments.
We study the benefits and limitations of current deep learning approaches to object recognition in robot vision scenarios, introducing a novel dataset used for our investigation, and identify the major bottlenecks affecting robotic scenarios.
We developed ResXplorer, a search interface that interactively visualizes linked data of research-related sources, revealing relationships between resources for researchers.
We present a novel efficient object detection and localization framework based on the probabilistic bisection algorithm based on a noisy oracle that provides answers to input query images.
A local stereo matching algorithm whose performance is insensitive to changes in radiometric conditions between the input images.
We make modifications to deep convolutional GANs to make them robust and efficient for classifying food images.
We present a novel single-shot text detector that directly outputs word-level bounding boxes in a natural image in a coarse-to-fine manner.
We exploit a novel Bregman distance for matrix factorization problems, which, at the same time, allows for simple/closed form update steps.
In this paper, an adversarial learning approach is proposed to colorize grayscale images in a realistic way, achieving top-tier performances relative to the state-of-the-art.
We propose to create a chimeric dataset from three modalities from two datasets: ECG, eye, and face, achieving impressive decidability of 7.20% ± 0.78 and an EER of 0.06.
We propose to achieve distractor-aware regression tracking with trajectory smoothing constraint and hard negative mining, which boosts the discriminability of convolutional regression trackers against background distractors.
We develop a set of new perturbation mechanisms for key-value data collection and analysis under the strong model of local differential privacy. The released statistics with conditions can further be used in learning tasks.
We study the problem of automatically building hypernym taxonomies from textual and visual data. We propose a probabilistic model for taxonomy induction by jointly leveraging text and images.
We present a novel deep neural network architecture for unsupervised subspace clustering, which achieves state-of-the-art performance.
We propose a new network architecture, Gated Attention Networks (GaAN), for learning on graphs, which achieves state-of-the-art results on the inductive node classification problem.
We propose a boundary-aware hierarchical language decoder for video captioning, which can discover hierarchical language information and distinguish the subject and the object in a sentence.
Training a robust classifier and an accurate box regressor are difficult for occluded pedestrian detection. To address such issue, a modification called visible IoU is proposed to explicitly incorporate the visible ratio in selecting samples.
In this paper, we propose a generalized pyramid matching kernel (GPMK) for recognizing human actions in realistic videos, based on a multi-channel “bag of words” representation constructed from local spatial-temporal features of video clips.
We propose a novel multimodal feature extraction and recognition approach based on subclass discriminant analysis (SDA), where a person's different bio-data are treated as different subclasses of one class in the input space.
We propose Cut-Based Graph Learning Networks (CB-GLNs) for learning video data by discovering these complex structures of the video.
We introduce a new approach which allows us to control the location of arbitrarily many objects within an image by adding an object pathway to both the generator and the discriminator.
Generating a photorealistic image of a person given a target pose while keeping fashion item consistent.
In this paper, we strive for solving the ambiguities arisen by the astoundingly high density of raw PseudoLiDAR for monocular 3D object detection for autonomous driving.
In this paper, we describe a mechanism for ontology alignment using instance based matching of types (or classes) using locality-sensitive hashing techniques to vastly improve the scalability of instance matching.
We propose a multi-branch discriminator for enhancing GANs on cross-species image-to-image translation tasks while reducing the number of parameters for computation.
We use the high-level and low-level features of ResNet as the source of context information and spatial information, respectively, and optimize them with attention fusion module and 2D position attention module, respectively.
We propose a generic deep pose estimation approach that generalizes to new types of 3D objects without any training.
We propose a novel approach to event extraction that supplies models with machine-readable natural language sentences that are based on annotation guidelines and that describe generic occurrences of events.
In this paper, we propose a new paradigm that estimates uncertainty in a model's internal hidden space instead of the model's output space for visual question answering and image captioning.
Real-time implementation of a stereo algorithm on field-programmable gate array (FPGA) that allows computation with sub-pixel accuracy.
The aim of this paper is to address recognition of natural human actions in diverse and realistic video settings. We present a new method for video classification that builds upon and extends several recent ideas including local space-Time features, space-time pyramids and multi-channel non-linear SVMs.
We propose to learn point cloud representation by bidirectional reasoning between local structures at different abstraction hierarchies and the global shape without human supervision.
We introduce the novel concept of Neural Architecture Disentanglement (NAD) in this paper, which sheds important light on the information flow of semantic concepts in DNNs, and provides a fundamental metric for interpretable network architectures.
We provide a meta-analysis of the literature, including an overview of approaches to pruning and consistent findings in the literature. We introduce ShrinkBench, an open-source framework to facilitate standardized evaluations of pruning methods.
We propose a novel adversarial defense method, the robust training (RT), by jointly minimizing two separated risks ($R_{stand} and R_{rob), which is with respect to the benign example and its neighborhoods respectively. The motivation is to explicitly and jointly enhance the accuracy and the adversarial robustness.
We find that fine-tuning only the last layer of existing detectors on rare classes is crucial to the few-shot object detection task.
Contextual embeddings, such as ELMo and BERT, move beyond global word representations like Word2Vec and achieve ground-breaking performance on a wide range of natural language processing tasks.
We introduce a new approach based on reshaping the search distribution for hyperparameter search, which leads to substantial gains over random search, both theoretically and empirically.
An unsupervised method for learning dictionaries of hierarchical compositional models for representing natural images.
We propose a novel Error Space Encoding (ESE) scheme for SVM evaluation which utilizes large number of classifiers already evaluated on the similar data set.
The objective learning formulation is essential for the success of convolutional neural networks. To address this problem, we develop two novel LR based objective functions that not only generalise the conventional LR but importantly turn out to be competitive alternatives to SR in single label classification.
In this paper, we propose a fast but effective way to extract motion features from videos utilizing residual frames as the input data in 3D ConvNets.
We propose an attention-based approach that leverages temporal context from the unlabeled frames of a novel camera to improve performance at that camera.
We present a novel visualization system for aligned biological networks in 3D space that naturally embeds existing 2D layouts. Our system provides an intuitive global understanding of aligned PPI networks and it allows the investigation of key biological questions.
We present a single view distortion correction method capable of undistorting images containing arbitrarily complex distortions by exploiting recent advancements in differentiable image sampling introduced by [9] and in the usage of semantic information.
We proposed an ensemble deep learning-based approach for automatic binary classification of breast histology images.
This paper tackles one such problem: establishing dense visual correspondence across different object instances. We use ground-truth synthetic-to-synthetic correspondences, provided by the rendering engine, to train a convolutional neural network to predict cross-instance correspondences between pairs of images of the same category.
We propose a generic confidence-based approximation that can be plugged in and simplify the auto-regressive generation process with a proved convergence.
In this paper, we propose symmetrical dilated residual convolution networks (FDSR) for image super-resolution problems.
We introduce a logo classification mechanism which combines a series of deep representations obtained by fine-tuning convolutional neural network (CNN) architectures and traditional pattern recognition algorithms.
We propose a weakly supervised deep learning framework equipped with squeeze-and-excitation blocks, multi-map transfer and max-min pooling for classifying common thoracic diseases as well as localizing suspicious lesion regions on chest X-rays.
In this paper, we propose a recurrent framework for Joint Unsupervised LEarning (JULE) of deep representations and image clusters.
In a given scene, humans can easily predict a set of immediate future events that might happen. In this paper, we focus on predicting the dense trajectory of pixels in a scene, where it will travel, and how it will deform over the course of one second.
We propose a creative algorithm for visual question generation which combines the advantages of variational autoencoders with long short-term memory networks. We demonstrate that our framework is able to generate a large set of varying questions given a single input image.
Ad affect is modulated by multiple information channels, including detected objects, coarse scene structure, object statistics and actively attended objects identified via eye-gaze.
De-expression Residue Learning for automatic facial expression recognition in the wild.
We present an alternative paradigm for image captioning, which factorizes the captioning procedure into two stages: (1) extracting an explicit semantic representation from the given image; (2) constructing the caption based on a recursive compositional procedure in a bottom-up manner.
In this paper, we introduce the contrastive loss function to encourage intra-class compactness and inter-class separability between learnable features.
We propose a cross-modal self-attention module that effectively captures the long-range dependencies between linguistic and visual features for referring image segmentation.
The tracking-by-detection framework requires a set of positive and negative training samples to learn robust tracking models for precise localization of target objects. We propose a novel structure-aware deep neural network to overcome such limitations.
In this paper, we develop novel, efficient 2D encodings for 3D geometry, which enable reconstructing full 3D shapes from a single image at high resolution.
We propose a novel Temporal Unit Regression Network (TURN) model for temporal action proposal generation, which outperforms state-of-the-art methods under average recall (AR) on THUMOS-14 and ActivityNet.
We aim to improve segmentation through the use of machine learning tools during region agglomeration, particularly in 3D electron microscopy images of neural tissue, and using variation of information to measure segmentation accuracy.
In Vision-and-Language Navigation (VLN), an embodied agent needs to reach a target destination with the only guidance of a natural language instruction. In this paper, we propose to exploit dynamic convolutional filters to encode the visual information and the lingual description in an efficient way.
We propose a novel visual tracking algorithm based on the representations from a discriminatively trained Convolutional Neural Network (CNN).
G-OpenMax extends OpenMax by employing generative adversarial networks for multi-class open set classification.
Unsupervised learning is of growing interest because it unlocks the potential held in vast amounts of unlabelled data to learn useful representations for inference. We introduce a novel analysis that shows how denoising may be incorporated into the training and sampling of adversarial autoencoders.
In this paper, we present a new unsupervised algorithm for retinal vessels segmentation using a modified Dolph-Chebyshev type II basis function and a new method to combine the matched filter bank's responses.
We propose an iterative search method for extractive QA and introduce a data-augmentation method to produce semantically valid examples.
We consider the problem of using a factor model we call {\em spike-and-slab sparse coding} (S3C) to learn features for a classification task. Since exact inference in this model is intractable, we derive a structured variational inference procedure and employ a variational EM training algorithm. We present an inference procedure appropriate for use with GPUs.
We introduce the Skip RNN model which extends existing RNN models by learning to skip state updates and shortens the effective size of the computational graph.
We propose End-to-End Module Networks (N2NMNs), which learn to reason by directly predicting instance-specific network layouts without the aid of a parser.
We propose a domain-adaptation-style crowd counting method, which can effectively adapt the model from synthetic data to the specific real-world scenes.
We propose a one-stage framework, SPRNet, which performs efficient instance segmentation by introducing a single pixel reconstruction (SPR) branch to off-the-shelf detectors.
We propose a deep neural network for visual tracking, namely the Motion-Appearance Dual (MADual) network, which employs a dual-branch architecture, by using deep two-dimensional and deep three-dimensional convolutions to integrate the local and global information of the target object’s motion and appearance synchronously.
We introduce a Hierarchical Kernel Sentence Embedding that approximates Kernel CCA for a special similarity kernel between words distributions.
We propose the first learning-based approach that jointly estimates albedo, normals, and lighting of an indoor scene from a single image. We finetune with real data.
We introduce a new dataset called ETRI-Activity3D, focusing on the daily activities of the elderly in robot-view. Additionally, we propose a novel network called four-stream adaptive CNN (FSA-CNN).
We propose an Illumination-Identity Disentanglement (IID) network to separate different scales of illuminations apart, while preserving individuals identity information.
We solve the problem of salient object detection by investigating how to expand the role of pooling in convolutional neural networks, aiming at providing layers at different feature levels the location information of potential salient objects.
We propose a real-time stereo matching method based on adaptive window, aiming at the trade-off between accuracy and efficiency in current local stereo matching.
We demonstrate that the traditional iris code is the solution of an optimization problem, which minimizes the distance between the feature values and the iris codes. We investigate two additional objective terms.
We release SciBERT, a pretrained contextualized embedding model based on BERT, to address the lack of high-quality, large-scale labeled scientific data.
We present a method for generating colored 3D shapes from natural language that captures the many-to-many relations between language and physical properties of 3D objects.
We propose LATTE, an open-sourced annotation tool for LiDAR point cloud data that accelerates annotation speed by 6.2x and significantly improves label quality.
We generalize the state-of-the-art image-to-image translation network (Cycle-Consistent Adversarial Networks) to the image-video/video- to-Image translation context by exploiting a image- video translation model and an identity preservation model.
We present a family of four novel methods for embedding knowledge graphs into real-valued tensors that capture the ordered relations found in RDF.
In spectral clustering, one defines a similarity matrix for a collection of data points, transforms the matrix to get the Laplacian matrix, finds the eigenvectors of the LaPLacian Matrix, and obtains a partition of the data using the leading eigenevectors. The last step is sometimes referred to as rounding. In this paper, we propose a novel method for rounding using latent tree models.
This paper formulates a new problem: weakly supervised dense event captioning, which does not require temporal segment annotations for training.
We propose to leverage already-available GAN models pretrained on large-scale datasets (like ImageNet) to introduce additional common knowledge (which may not exist within the limited data) following the transfer learning idea, which improves training efficiency and performance on limited-data generation.
We address the problem of semantic correspondence, that is, establishing a dense flow field between images depicting different instances of the same object or scene category. We propose to use binary foreground masks and subjected to synthetic geometric deformations to train a convolutional neural network for this task.
We propose two novel techniques, stochastic robust approximation and dynamic mixed training, to drastically improve the efficiency of verifiably robust training without sacrificing verified robustness.
We propose a method based on deep conditional generative adversarial network (DCGAN), which introduces additional data $( e.g.$, labels) towards determining specific representations of generated images.
We propose a novel multi-task learning scheme that utilizes multi-view attention learned from various perspectives to enable these tasks to interact with each other as well as learn more comprehensive sentence representations.
We propose a transfer learning method that learns to transfer optimal hyperparameter values for a small source dataset to hyperparameters with comparable performance on a dataset of interest.
We propose a novel semi-heterogeneous three-way joint embedding network (Semi3-Net), which integrates three branches (a sketch branch, a natural image branch, and an edgemap branch) to learn discriminative cross-domain feature representations for the SBIR task.
We propose a self-ensembling method for unsupervised domain adaptation for semantic segmentation.
We propose a hybrid end-to-mid approach predicting trajectories for neighbor vehicles and for the ego vehicle with a conditional navigation goal. We introduce a label augmentation mechanism.
We enable a BERT-based reading comprehension model to perform lightweight numerical reasoning by augmenting it with shallow programs.
Stereo videos for the dynamic scenes often show unpleasant blurred effects due to the camera motion and the multiple moving objects with large depth variations. In this paper, we propose to jointly solve these three tasks in a unified framework by exploiting their intrinsic connections.
Autoencoders are popular among neural-network-based matrix completion models due to their ability to retrieve latent factors from the partially observed matrices. Nevertheless, when training data is scarce their performance is significantly degraded due to overfitting. In this paper, we mit- igate overfitting with a data-dependent regularization technique that relies on the principles of multi-task learning.
We propose a novel Copula CNN deep learning approach for modeling multivariate ordinal variables and estimate complex feature representations simultaneously by combining conditional random field (CRF) encoded AU dependencies.
We propose softmax splatting to address this paradigm shift and show its effectiveness on the application of frame interpolation.
This paper studies the answer sentence selection task in the Bible domain and answer questions by selecting relevant verses from the Bible.
We propose a novel state alignment-based imitation learning method to train the imitator by following the state sequences in expert demonstrations as much as possible.
We propose an unsupervised method to determine whether to include perceptual input for a concept, and show that it significantly improves the ability of multi-modal models to learn and represent word meanings.
This paper aims to resolve these challenges induced by geometric variability and spatial displacements via a new Soft-Gated Warping Generative Adversarial Network (Warping-GAN), which is composed of two stages: 1) it first synthesizes a target part segmentation map given a target pose, which depicts the region-level spatial layouts for guiding image synthesis with higher-level structure constraints; 2) the Warping-GAN equipped with
We propose a new framework for predicting parametric shape primitives using deep learning and demonstrate efficacy on 2D and 3D tasks.
In this work, we exploit the full state observability in the simulator to train better policies which take as input only partial observations (RGBD images).
We propose a framework for learning audio representations guided by the visual modality in the context of audiovisual speech and achieve state of the art results for emotion recognition and speech recognition.
The kernel trick provides an easy way to kernelize linear machines. However, in many cases, formulating a kernel machine via the kernel trick could be difficult and even impossible.
We present a robust algorithm for complex human activity recognition for natural human-robot interaction that tracks the position of selected joints in human skeleton.
We propose a family of near-metrics based on local graph diffusion to capture similarity for a wide class of data sets, including structured data, continuous data, and vector representations of images and text.
We present a method to learn single-view reconstruction of the 3D shape, pose, and texture of objects from categorized natural images in a self-supervised manner.
We present a deep transformation model for probabilistic regression which estimates the whole conditional probability distribution, the most thorough way to capture uncertainty about the outcome.
We propose a simple and effective algorithm, named "DARTS+", to avoid the collapse and improve the original DARTS, by "early stopping" the search procedure when meeting a certain criterion.
We propose Continual Neural Architecture Search (CNAS), an autoML approach that takes advantage of the sequential nature of class-incremental learning to efficiently and adaptively identify strong architectures in a continual learning setting, thus saving a large amount of computational resources.
We describe the task of sentence expansion and enhancement, in which a sentence provided by a human is expanded in some creative way, and evaluate these expansions.
A shape-appearance-correlated AAM is proposed to tackle the generic problem of localizing feature points on unseen faces. A fast face-model initialization scheme is proposed, based on the idea that the local appearance of feature points can be accurately approximated with locality constraints.
A semi-supervised paragraph generative framework able to synthesize diverse and semantically coherent paragraph descriptions by reasoning over local semantic regions and exploiting linguistic knowledge.
We present RefineNet, a generic multi-path refinement network that explicitly exploits all the information available along the down-sampling process to enable high-resolution prediction using long-range residual connections.
In this paper, we address the question answering challenge with the SQuAD 2.0 dataset. We design a model architecture which leverages BERT's capability of context-aware word embeddings and BiDAF's context interactive exploration mechanism.
Retinal blood vessels have a significant role in the diagnosis and treatment of various retinal diseases. In this paper, a novel approach is developed to extract retinal blood vessel network.
We propose fixed-function neural network hardware that is designed to perform pixel-to-pixel image transformations in a highly efficient way within the power and silicon area limits.
We address this problem using the latent space of the $\beta$-Variational Autoencoder, which is sensitive to encode changes in the values of the generative factor and can be used for computationally inexpensive detection.
We introduce DoorGym, a simulation environment intended to be the first step to move RL from toy environments towards useful atomic skills in the real world.
We introduce a self-supervised method for learning visual correspondence from unlabeled video that uses cycle-consistency in time as free supervisory signal.
A novel high-resolution encoder-decoder network for fine-grained image segmentation that is highly accurate for small-scale targets.
The FiLM model achieves close-to-perfect performance on the diagnostic CLEVR dataset and is distinguished from other such models by having a comparatively simple and easily transferable architecture. We investigate in more detail the ability of FiLM to learn various linguistic constructions.
We propose a novel Contextual Generative Adversarial Nets (C-GANs) to specifically take it into consideration.
HashNet, a novel deep architecture for deep learning to hash by continuation method with convergence guarantees, which learns exactly binary hash codes from imbalanced similarity data.
We introduce the EPOpt algorithm, which uses an ensemble of simulated source domains and a form of adversarial training to learn policies that are robust and generalize to a broad range of possible target domains.
We propose a support vector machine-based processing pipeline to identify cognitive phenotypes associated with atypical emotional processing, based on canonical correlation analysis of EEG network features, and cognitive and behavioral evaluations.
In recent years, Convolutional Neural Networks (ConvNets) have become the quintessential component of several state-of-the-art Artificial Intelligence tasks. In this context, FPGAs can provide a potential platform that can be optimally configured based on different performance requirements.
In this paper, we target refining the boundaries in high resolution images given low resolution masks. We propose a framework with two prediction layers.
We introduce a partially supervised setting that significantly reduces the supervision level required for generic object counting. We propose two novel frameworks, named lower-count (LC) and reduced lower- count (RLC), to enable object counting under this setting.
Transfer learning is a solution to the problem of designing accurate and computationally-efficient CAD systems with limited data from real patients.
We benchmark well-established and recently developed methods for approximate posterior sampling combined with Thompson Sampling over a series of contextual bandit problems.
We propose an object detection method that improves the accuracy of the conventional SSD (Single Shot Multibox Detector), which is one of the top object detection algorithms in both aspects of accuracy and speed.
We propose TapNets, neural networks augmented with task-adaptive projection for improved few-shot learning.
This paper reviews different V-reID methods including sensor based methods, hybrid methods, and vision based methods which are further categorized into hand-craftedFeature based methods and deep feature based methods.
Neural networks for image recognition have evolved through extensive manual design from simple chain-like models to structures with multiple wiring paths. Encapsulation provides a unified view of randomly wired networks.
In this paper, we propose High-Order Paired-ASPP Network to exploit high-order statistics from various feature levels.
We explore the use of synthetic data generated by a game engine. Inspired by Generative Adversarial Networks (GANs), we generate a massive amount of syntheticdata and train a discriminative classifier to select a realistic subset, which we deem the Adversarie Imposters.
This paper proposes the decision tree latent controller generative adversarial network (DTLC-GAN), an extension of a GAN that can learn hierarchically interpretable representations without relying on detailed supervision.
We propose a novel filter pruning method that compresses CNN models by determining and pruning those filters with redundant information via Geometric Median (GM), rather than those with "relatively less" importance.
We develop a novel method, LEOPARD, which enables optimization-based meta-learning across tasks with different number of classes, and evaluate existing methods on generalization to diverse NLP classification tasks.
In this paper, we propose a set of visual-reasoning primitives which, when composed, manifest as a model capable of performing complex reasoning tasks in an explicitly-interpretable manner.
We propose an Attribute-Assisted Deep Con- volutional Neural Network (AADCNN) which leverages the facial attributes identification and face verification tasks in order to improve the sketch-photo recognition performance.
In this paper, we propose a novel hashing scheme, termed \emph{zero-shot hashing} (ZSH), which compresses images of "unseen" categories to binary codes with hash functions learned from limited training data of "seen" Categories.
We proposed a novel method to realize accurate multiclass underwater ATR using forward-looking sonar—Echoscope and deep convolutional neural networks (DCNNs).
We present the first proxyless hardware-aware search for latency-optimized DNN networks for dense semantic segmentation.
We propose a Dual Path Recurrent Neural Network (DP-RNN) which processes images and sentences symmetrically by recurrent neural networks (RNN).
We propose an end-to-end architecture for joint 2D and 3D human pose estimation in natural images. Key to our approach is the generation and scoring of a number of pose proposals per image.
Cancers are complex diseases that are regulated by multiple signaling pathways. Pharmacogenomics big data are being generated to uncover complex signaling mechanisms of cancers and correlate cancer-specific signaling with diverse drug responses.
We study domain-specific video streaming where the videos to be streamed from a server to a client are all in the same domain and they have to be compressed to a small size for low latency transmission.
We propose a new multi-class spatial semantic regularisation method based on affinity propagation clustering, which simultaneously optimises across all categories and all proposed locations in the image, to improve both the localisation and categorisation of selected detection proposals.
We investigate the generative performance of RevNets using an adversary on the latent space in the adversarial autoencoder framework, showing that they can generate coherent faces with similar quality as Variational Autoencoders.
We propose Group-Connected Multilayer Perceptron (GMLP) networks to enable deep representation learning in domains where the feature interactions are not given as a prior.
We propose a modified weight initialization strategy for recurrent neural networks with Rectified Linear Unit (ReLU) non linearity.
We investigate the compression of sentence embeddings using a neural encoder-decoder architecture, which uses latent representations in Hamming space produced by the encoder for similarity calculations.
This paper reduces the cost of DNNs training by decreasing the amount of data movement across heterogeneous architectures composed of several GPUs and multicore CPU devices.
We propose a fully connected temporal CRF model for reasoning over various aspects of activities that includes objects, actions, and intentions, where the potentials are predicted by a deep network.
We present a new, fast and flexible pipeline for indoor scene synthesis that is based on deep convolutional generative models.
We propose a novel training objective and learning network to perform a single image depth estimation in our convolutional neural network without the ground truth depth data.
We propose a hierarchical reinforcement learning framework which relies on a collection of subtask controllers trained to imitate simple, reusable mocap motions, and a meta controller trained to execute the subtasks properly to complete the main task.
We explore the impact of stale weights on the statistical efficiency and performance in a pipelined backpropagation scheme that maximizes accelerator utilization and keeps memory overhead modest.
We propose a new computational framework for robust and efficient fine-tuning for pre-trained language models that can prevent knowledge forgetting.
We propose Probabilistic Population-Based Training ($P2BT), an evolutionary algorithm that learns high-performing hyperparameter schedules on the fly in a single training run.
We propose a GOaL-Oriented Multi-task BERT-based dialogue state tracker (GOLOMB) inspired by architectures for reading comprehension question answering systems.
Deep Stereo Geometry Network for stereo-based 3D object detection in end-to-end learning.
We define and characterize three classes of errors - localization, scoring, and background - study how they are influenced by instance attributes and their impact on an algorithm's performance.
We propose a unified framework called Dynamic Curriculum Learning (DCL) to adaptively adjust the sampling strategy and loss learning in single batch, which resulting in better generalization and discrimination.
We propose a general-purpose compression framework for reducing the inference time and model size of the generator in conditional GANs.
We propose a cascaded implementation of Volterra Filter so as to significantly reduce the number of parameters required to carry out the same classification task as that of a conventional Neural Network.
We propose a novel face feature extraction method based on deep learning, based on the correlation between projections of a face point on images from different views.
We propose an Ensemble of Robust Constrained Local Models for alignment of faces in the presence of significant occlusions and of any unknown pose and expression.
We propose a vehicle detection framework that improves the performance of the conventional Single Shot MultiBox Detector (SSD), which effectively detects different types of vehicles in real-time.
The traditional bag-of-visual-words(BOV) model only uses one single feature to classify objects, which is difficult to achieve good results when dealing with many object categories.
This paper proposes a novel high-order local pattern descriptor, local derivative pattern (LDP), for face recognition.
We present an analysis of different techniques for selecting the connection be- tween layers of unsupervised deep neural networks.
We propose a semi-supervised training framework to improve the data efficiency of Tacotron. The idea is to utilize textual and acoustic knowledge contained in large, publicly-available text and speech corpora.
We propose a new approach for cross-modality 2D-3D face recognition (FR), which is called Multiview Smooth Discriminant Analysis (MSDA) based on Extreme Learning Machines.
Ladder networks can be used for emotion recognition in semi-supervised fashion, achieving superior performance than fully supervised single-task learning.
Do AU detectors transfer to new domains in which they have not been trained? To answer this question, we review literature on cross-domain transfer and conduct experiments to address limitations of prior research.
We propose an edge heuristic multi-scale generative adversarial network (GAN) for dynamic scene deblurring.
Neural architecture search (NAS) searches architectures automatically for given tasks, e.g., image classification and language modeling. However, few efforts have been devoted to understanding the generated architectures and particularly the commonality these architectures may share.
This paper provides a pair similarity optimization viewpoint on deep feature learning, aiming to maximize the within-class similarity $s_p$ and minimize the between- class similarity$s_n$ and propose a new loss function, the Circle loss, which is named due to its circular decision boundary.
We examine the effects of contaminating training data with anomalies for state-of-the-art GAN-based anomaly detection methods. As expected, detection performance is reduced.
This paper aims to improve privacy-preserving visual recognition, an increasingly demanded feature in smart camera applications, by formulating a unique adversarial training framework, in order to optimize the trade-off between target task performance and privacy budgets on the degraded video.
This paper proposes an efficient CNN called Multiply Spatial Fusion Network for fast and accurate semantic segmentation.
Proteogenomic studies of cancer samples have shown that copy number variation can be attenuated at the protein level, for a large fraction of 8,124 analyzed proteins.
We propose a novel method to refine both the geometry and the semantic labeling of a given mesh using a variational method that optimizes a composite energy made of a state-of-the-art pairwise photo-metric term and a single-view term that models the semantic consistency between labels of the 3D mesh and those of the segmented images.
This work proposes a transfer learning approach for multi-class classification of the seven prototypical expressions including the ‘neutral’ expression in children using a recently published child facial expression data set.
We propose a video captioning model with High-Order Cross-Modal Attention where the attention weights are calculated based on the high-order correlation tensor to capture the frame-level cross-modal interaction of different modalities sufficiently.
We propose a novel volumetric convolution operation based on Zernike polynomials that can effectively convolve arbitrary functions in $\mathbb{B}^3$.
In this paper, we introduce the SFA framework to the problem of human action recognition by incorporating the discriminative information with SFA learning.
We present an improved version of the MSL method of Sugaya and Kanatani for multibody motion segmentation. We replace their initial segmentation based on heuristic clustering by an analytical computation based on GPCA.
This paper develops a novel methodology for using symbolic knowledge in deep learning. From first principles, we derive a semantic loss function that bridges between neural output vectors and logical constraints.
We propose a novel framework with 3D convolutional networks for automated detection of pulmonary nodules from low-dose CT scans, which is a challenging yet crucial task for lung cancer early diagnosis and treatment.
We propose a novel method for joint frontal view reconstruction and landmark localization using a small set of frontal images only.
We propose a novel method, called Kernel Neighborhood Discriminant Analysis (KNDA), which can be regarded as a supervised kernel extension of Locality Preserving Projection (LPP)
News recommender systems provide users with access to news stories that they find interesting and relevant. NewsREEL represents a unique opportunity to evaluate recommendation algorithms and for students to experience realistic conditions and to enlarge their skill sets.
We solve the problem of centerline detection in terms of a regression problem, improving state-of-the-art techniques for 2D and 3D datasets.
We outline algorithmic components such as Attention-over-Attention, data augmentation and ensembling strategies that have shown to yield state-of-the-art results on benchmark datasets like SQuAD, even achieving super-human performance.
We show how we can exploit semantic information (Linked Data) at real-time for configuring (handily) a NEE system and we propose a generic model forconfiguring such services.
We propose a BLSTM-based model that reaches a level of performance comparable to the state of the art when using short input audio segments, while requiring a considerably less amount of memory.
This paper proposes a simple and novel method which employs disparity inheritance within above algorithm, further improving the accuracy and robustness of stereo correspondence.
We formulate the multi-class MKL in a bilinear form and propose a scheme for computationally efficient optimization.
In this paper, we extend the concept of attention model to measure the relevance of each observation (time step) of a sequence.
In this paper, we propose a natural class of completeness patterns, expressed by selections on database tables, to specify complete parts of database tables. We then show how to adapt the operators of relational algebra so that they manipulate these completeness Patterns to compute completeness pattern pertaining to query answers.
We propose a vector value function based multi-objective reinforcement learning (V2f-MORL) approach that seeks to quantify the inter-Objective relationship via reinforcement learning when the impact of one objective on others is unknown a prior.
A novel method for segmenting retinal blood vessels which involves pre-processing, segmentation and post-processing.
We explore the current state of compact architecture search for deep neural networks through both theoretical and empirical analysis of four different state-of-the-art Compact architecture search algorithms.
We propose a novel framework for clothing image recognition using multiple sources of features and ELM neural networks.
We introduce a new loss term, the cycle consistency loss, for frame interpolation, and propose two extensions: motion linearity loss and edge-guided training, which improve results.
The ability to edit materials of objects in images is desirable by many content creators. We propose an end-to-end network architecture that replicates the forward image formation process to accomplish this task.
We introduce a one-shot learning approach for video object tracking. The proposed algorithm requires seeing the object to be tracked only once, and employs an external memory to store and remember the evolving features of the foreground object as well as backgrounds.
We propose a fast face detection method based on discriminative complete features extracted by an elaborately designed convolutional neural network, where face detection is directly performed.
We design oversymmetric and overasymmetric relationships and apply these two constraints to triplet and impostors’ congeners to train our deep triplet-group network with original individual images rather than handcrafted features.
We propose a semi-supervised framework for kernel mean shift clustering (SKMS) that uses only pairwise constraints to guide the clustering procedure.
This paper solves the speed bottleneck of cascade version of deformable part model (DPM), while maintaining the accuracy in detection on challenging datasets.
We propose a marginalized average attentional network (MAAN) to suppress the dominant response of the most salient regions in a principled manner in an end-to-end fashion.
This work proposes an algorithm, called NetAdapt, that automatically adapts a pre-trained deep neural network to a mobile platform given a resource budget.
We explore the importance of spatial contextual information in human pose estimation. We present two conceptually simple and yet computational efficient modules, namely Cascade Prediction Fusion (CPF) and Pose Graph Neural Network (PGNN), to exploit underlying contextual information.
This paper presents a new video representation, called trajectory-pooled deep-convolutional descriptor (TDD), which shares the merits of both hand-crafted features [31] and deep-learned features.
We introduce a numerical integration perspective to broaden the applicability of the all-action estimator to general spaces and to any function class for the policy or critic components.
The rise of machine learning in image processing has created a gap between trainable data-driven and classical model-driven approaches: While learning-based models often show superior performance, classical ones are often more transparent.
A segmentation-based global optimization method for depth estimation.
We present an extension to the UR3D face recognition algorithm, which enables us to decrease the discrepancy in its performance for datasets from subjects with and without a neutral facial expression, from 15% to 3%.
We propose a novel approach to incorporate estimations of safety to guide exploration and policy search in deep reinforcement learning and extend control-theoretic results to approximate its derivative.
The capacity of meta-learning algorithms to quickly adapt to a variety of tasks, including ones they did not experience during meta-training, has been a key factor in the recent success of these methods on few-shot learning problems.
We address the problem of user-guided clustering in heterogeneous information networks with network motifs and propose the MoCHIN model based on joint non-negative tensor factorization.
The development of 3D face recognition algorithms that are robust to variations in expression has been a challenge for researchers over the past decade. One approach to this problem is to utilize the most stable parts on the face surface. The nasal region's relatively constant structure over various expressions makes it attractive for robust recognition.
In this paper, we tackle the challenge of action recognition by building robust models from Extreme Learning Machines from reduced preprocessed feature vectors on the Microsoft Research Cambridge-12 (MSRC-12) Kinect gesture dataset.
 ASIST is based on a unified formulation of semantic labeling and object replacement; both result from minimizing a single objective.
In this paper we present an autonomous system for acquiring close-range high-resolution images that maximize the quality of a later-on 3D reconstruction with respect to coverage, ground resolution and 3D uncertainty.
This paper proposes an approach to fuse semantic features and motion clues using CNNs, to address the problem of monocular semantic motion segmentation.
We present a compact representation for human action recognition in videos using line and optical flow histograms and apply feature selection to densify our feature representation.
We propose HG-RCNN, a simple and modular network that also leverages the benefits of the Hourglass architecture for multi-person 3D human pose estimation that does not require any multi- person 3D pose dataset.
We propose a principled method that automatically determines the sparsity of individual layers derived from the importance of each layer, without losing performance.
In this paper, we propose novel schemes to speed-up the processing of the CNN-based trackers.
We use an unsupervised decoding algorithm that exploits commonalities in representational similarity structure found within both image model and brain data sets to classify embodied visual representations with high accuracy and then extend it to exploit model combinations to robustly decode different brain regions in parallel.
An attribute-based approach for person re-identification, where the person of interest is described by a set of visual attributes, which are used to perform the search.
A depth post-processing framework based on the concept of the mutual structure for stereo images.
This paper aims to develop a new architecture that can make full use of the feature maps of convolutional networks for person re-identification.
We propose a novel end-to-end deep learning framework for joint AU detection and face alignment, which has not been explored before.
We propose an automatic trajectory annotation method exploiting an Iterative Plane Registration algorithm based on homographies and semantic segmentations.
We propose a multi-resolution neural network to leverage the whole hierarchy of representations for document retrieval.
We address the compatibility prediction problem using a graph neural network that learns to generate product embeddings conditioned on their context, and achieve state of the art results.
We propose an alternative GAN formulation based on random projections which, in its simplest form, results in a single objective rather than a saddle-point formulation.
We propose a systolic array architecture for real-time chip implementation of the various iterative image processing algorithms.
We propose a novel unsupervised feature selection algorithm named structure-preserving non-negative feature self-representation (SPNFSR).
We present a deep-learning framework for real-time multiple spatio-temporal (S/T) action localisation, classification and early prediction.
We propose a biologically-inpired model of visual saliency that can be extended to predict and understand distinct perceptual processes in which V1 cells are responsible.
In this paper, we propose to fully parametrize Convolutional Neural Networks (CNNs) with a single high-order, low-rank tensor.
We propose a method of weight re-initialization by repeated annealing and injection of noise in the training process that improves language modeling performance by up to 7.91 perplexity.
In this paper, we propose an SR method based on error compensation and fractal coding, which achieves competitive performance quantitatively and qualitatively.
We propose to learn an architecture of discriminative dictionaries for classification in a supervised framework using a patch-level approach using many layers of sparse coding and pooling in order to reduce the dimension of the problem.
We extend earlier work by using the concept of dynamic averages for calculating dynamic user averages and exploiting them in user-user collaborative filtering implementations.
We optimize maximum class separability in the binary space using Fisher's Linear Discriminant Analysis. We introduce a margin on distances between dissimilar image pairs.
We propose a novel approach towards adversarial attacks on neural networks (NN), focusing on tampering the data used for training instead of generating attacks on trained models.
We propose a novel Bidirectional Attentive Memory Network, called BAMnet, for knowledge base question answering.
We propose an end-to-end learned approach for stereo depth estimation in the anytime setting, using two orders of magnitude fewer parameters than the most competitive baseline.
We extend the standard Sobel kernels, which are used to compute the gradient of an image in order to find its edges in an image.
Robust network architectures that are resilient to adversarial attacks.
This paper proposes a novel approach to performing image-to-image translation between unpaired domains, in which multiple optional and diverse images are produced for a given image.
We collect a large-scale dataset of contemporary artwork from Behance, a website containing millions of portfolios from professional and commercial artists, and annotate it with rich attribute labels for content, emotions, and artistic media.
In this paper, we introduce a novel approach for early diagnosis of glaucoma in high-resolution FUNDUS images, only requiring a small number of training samples.
We propose Pixel-BERT to align image pixels with text by deep multi-modal transformers that jointly learn visual and language embedding in a unified end-to-end framework.
Cascaded Pyramid Mining Network (CPMN) for weakly supervised temporal action localization.
In this paper, a low-light sensor image enhancement algorithm based on HSI color model is proposed to improve the image quality.
We demonstrate with extensive experiments for object classification that the representation capability of features from deep networks can be complemented with information captured from local features.
We present an overview of some well-known face recognition techniques in each of the three categories, based on the face data processing methodology.
DBpedia project focus on creating semantically enriched structured information of Wikipedia. We test the project to get structured data as triples from some Wikipedia resources.
This paper investigates the impact of benchmark model selection, recency effect and synthetic weather station selection techniques on load forecast performance and presents a new weighted average based approach to generate a syntheticweather station.
In many scientific disciplines structures in high-dimensional data have to be found, e.g., in stellar spectra, in genome data, or in face recognition tasks. The problem of optimizing latent neighborhoods is difficult to solve, but the UNN formulation allows the design of efficient strategies that iteratively embed latent points to fixed neighborhood topologies.
We formulate this intuition as a non-parametric classification problem at the instance-level, and use noise-contrastive estimation to tackle the computational challenges imposed by the large number of instance classes.
A survey on adversarial attacks on deep learning in Computer Vision.
We tackle the tasks of: 1) predicting a Canonical Surface Mapping (CSM) that indicates the mapping from 2D pixels to corresponding points on a canonical template shape, and 2) inferring the articulation and pose of the template corresponding to the input image.
We present a novel and unified deep learning framework which is capable of learning domain-invariant representation from data across multiple domains.
We address this limitation by proposing a novel acceleration strategy to speed-up convolutional sparse coding filter learning for curvilinear structure segmentation.
In this paper, we introduce a new type of feature that captures dynamic properties of short tracklets that allow robust cross-view activity recognition, i.e. when actions are recognized using a classifier trained on data from a different viewpoint.
We develop unbiased stochastic gradients for spectral-sums, an important subclass of spectral functions, and exploit their utility for optimization problems.
We present a novel approach for learning to predict sets with unknown permutation and cardinality using deep feed-forward neural networks.
Unmanned aerial vehicles (UAVs) with mounted cameras have the advantage of capturing aerial (bird-view) images. The availability of aerial visual data and the recent advances in object detection algorithms led the computer vision community to focus on object detection tasks on aerial images.
In this paper we coupled fuzzy logic rules with the neural-based action recognition model to rate the intensity of a human action as intense or mild.
We develop a connection sensitive attention U-Net(CSAU) for accurate retinal vessel segmentation.
We introduce InverseFaceNet, a deep convolutional inverse rendering framework for faces that jointly estimates facial pose, shape, expression, reflectance and illumination from a single input image.
We propose Probabilistic Face Embeddings (PFEs), which represent each face image as a Gaussian distribution in the latent space in a probabilistic fashion.
We introduce deep hierarchical object grouping (DHOG) that computes a number of distinct discrete representations of images in a hierarchical order, eventually generating representations that better optimise the mutual information objective.
In conversation, we often ask one-word questions such as `Why?' or `Who?'. Such questions are typically easy for humans to answer, but can be hard for computers to answer.
We analyse modern MRC gold standards and present our findings: the absence of features that contribute towards lexical ambiguity, the varying factual correctness of the expected answers and the presence of lexical cues, all of which potentially lower the reading comprehension complexity and quality of the evaluation data.
We introduce an interactive learning framework for the development and testing of intelligent visual systems, called learning-by-asking (LBA), in context of the Visual Question Answering (VQA) task.
We address the problem of 3D reconstruction from a single image, generating a straight-forward form of output – point cloud coordinates. Driven by this unorthordox output form and the inherent ambiguity in groundtruth, we design architecture, loss function and learning paradigm that are novel and effective.
We analyze six different community detection algorithms on two important biological networks to find their communities and evaluate the results in terms of topological and functional features through Kyoto Encyclopedia of Genes and Genomes pathway and Gene Ontology term enrichment analysis.
We propose a novel framework for recovery of high-quality depth images and multi-view depth videos from simple acquisition systems using auto-regressive correlations.
We propose to use a hierarchical semantic representation of the objects, coming from a convolutional neural network, to solve the low-level correspondences problem.
In this work we propose an online multi person pose tracking approach which works on two consecutive frames $I_{t-1}$ and $I_t$ and achieve state-of-the-art results.
We propose to learn a 3D pose estimator by distilling knowledge from Non-Rigid Structure from Motion using solely 2D landmark annotations.
In this paper, we develop a real-time yet very accurate Ranking Attention Network (RANet) for VOS.
We propose a causal model for stochastic contextual bandits with a latent low-dimensional confounder that achieves regret guarantees for online recommendation and advertising systems.
We question the use of the LSTM models and propose the novel use of Transformer Networks for trajectory forecasting.
This paper presents PIC, Permutation Invariant Convolution, a novel neural layer to model the temporal structure of long-range activities.
In recent years, image manipulation is becoming increasingly more accessible, yielding more natural-looking images, owing to the modern tools in image processing and computer vision techniques. The task of the identification of forged images has become very challenging.
We propose a novel Asymmetric Distribution Measure (ADM) network for few-shot learning by calculating a joint local and global asymmetric measure between two multivariate local distributions of queries and classes.
We propose a way to learn visual features that are compatible with previously computed ones even when they have different dimensions and are learned via different neural network architectures and loss functions.
We propose a view-invariant Convolutional Neural Network (CNN) Model for scene understanding in disaster scenarios.
We propose an unsupervised method to learn pose features from videos that exploits a signal which is complementary to appearance and can be used as supervision: motion.
A meta-learning algorithm that learns a self-supervised representation on meta-training set, followed by training a linear classifier on top of this representation, outperforms state-of-the-art few-shot learning methods.
In this paper, a narrow structure of the convolutional neural network (CNN) has been proposed in order to obtain the tweets representations and classify the Arabic Dialect tweets into five, three and two polarities.
We propose a single deep neural network for panoptic segmentation, for which the goal is to provide each individual pixel of an input image with a class label and a unique identifier for specific objects in an image.
We propose a simple auto-encoder framework for molecule generation, in which a fully connected neural network uses the latent vector $z$ to produce a molecular formula, for example CO$_2$.
We propose sentence simplification from a non-parallel corpus with adversarial learning for open data en-Wikipedia and Simple-Wikipedia articles.
Learning fusion algorithms that are robust against noise added to a single source, while preserving the original performance on clean data.
This paper addresses this issue by proposing novel image captioning models which use facial expression features to generate image captions. We compare a comprehensive collection of image Captioning models with and without facial features using all standard evaluation metrics.
This paper presents an automatic emotion detector for affective classification of practical (or non-laboratory) data using facial expressions, where a lot of “real-world” challenges are present, including pose, illumination, and size variations etc.
In this article, we revisit two popular convolutional neural networks in person re-identification (re-ID) and propose a Siamese network that learns discriminative embedding and similarity measurement at the same time.
Vehicle re-identification is one of the core technologies of intelligent transportation systems, and it is crucial for the construction of smart cities. Therefore, making a comprehensive survey about the vehicle re-Identification methods based on deep learning is quite indispensable.
We propose a method, referred to as Active Learning (A$\mathbf{^2}$L), that actively adapts to the sequence tagging model being trained, to further eliminate such redundant examples chosen by an AL strategy.
We present a weakly supervised model that jointly performs both semantic- and instance-segmentation -- a particularly relevant problem given the substantial cost of obtaining pixel-perfect annotation for these tasks.
By leveraging a different output encoding, multi-way encoding, we decorrelate source and target models, making target models more secure.
In this work we introduce a novel, CNN-based architecture that can be trained end-to-end to deliver seamless scene segmentation results.
In this paper, we propose a k-reciprocal encoding method to re-rank the re-ID results.
We propose the Joint Voxel and Coordinate Regression (JVCR) method for 3D facial landmark localization, addressing it more effectively in an end-to-end fashion.
In this paper, we propose a novel coarse-to-fine pyramid model to relax the need of bounding boxes, which not only incorporates local and global information, but also integrates the gradual cues between them.
Evolvability ES is an evolutionary algorithm designed to explicitly and efficiently optimize for evolvability, i.e. the ability to further adapt, in the spirit of natural evolution.
We study some existing neural image captioning models that provide near state-of-the-art performances, and try to enhance one such model.
We introduce projection convolutional neural networks with a discrete back propagation via projection to improve the performance of binarized neural networks (BNNs) in resource-constrained environments.
In this paper, we propose a method that achieves competitive accuracy but only requires easily obtained bounding box annotations.
We propose a bilingual extension of the CBOW method which leverages sentence-aligned corpora to obtain robust cross-lingual word and sentence representations.
We propose to measure privacy through a black-box membership inference attack and compare the privacy-accuracy trade-off for different local and central differential privacy mechanisms. We experiment with several datasets and show that neither local differential privacy norcentral differential privacy yields a consistently better privacy-Accuracy tradeoff.
This paper offers a general description of cooperative optimization, addresses a number of design issues, and presents a case study to demonstrate its power.
We fuse information from multiple lidars, radars, a stereo camera and semantic camera information into one common evidential framework which improves scene reconstruction precision while retaining the real-time capability.
We propose a simple framework for cross-lingual transfer learning by reusing the encoder from a multilingual NMT system and stitching it with a task-specific classifier component for zero-shot classification.
 CSSD is built on top of SSD, with additional layers modeling multi-scale contexts. The experimental results show that the context modeling significantly improves the detection accuracy.
We propose a novel pooling strategy that learns how to adaptively rank deep convolutional features for selecting more informative representations.
We propose SSF-CNN which focuses on learning the "structure" and "strength" of filters which significantly reduces the number of parameters required for training while providing high accuracies on the test databases.
We propose a fast and accurate simulation framework to enable training and evaluation of large-scale DNNs on resistive crossbar based hardware fabrics.
This paper gives an overview of the eigenvalue problems encountered in areas of data mining that are related to dimension reduction and provides effective solution techniques.
We propose a simple but effective pattern mining-based method, called Object Mining (OM), which exploits the ad-vantages of data mining and feature representation of pre-trained convolutional neural networks (CNN) to discover dominant objects without using any annotations.
We identify simple NB and SVM variants which outperform most published results on sentiment analysis datasets, sometimes providing a new state-of-the-art performance level.
We propose a stagewise bidirectional latent embedding framework of two subsequent learning stages for zero-shot visual recognition, yielding state-of-the-art performance under inductive and transductive settings.
We introduce viewpoint-specific and temporally-evolving models for video understanding, defined over state-of-the-art motion and deep visual features. We analyze a novel dataset of micro-videos labeled with 58 thousand tags.
We propose a novel reconstruction algorithm that is robust to image noise and produces significantly fewer artifacts.
We present a conceptually simple yet effective algorithm to detect wireframes in a given image. We propose a new metric that penalizes overlapped line segments and incorrect line connectivities.
This paper provides an object recognition system that performs object detection and semantic segmentation tasks by using a deep learning model adapted to match the nature of equirectangular images.
This paper proposes a network named ResGroupNet that uses group symmetry theory to constrain the middle structure of ResNet-50.
We improve the stability of training GANs and improve the visual quality and diversity of state-of-the-art GAN.
 JPEG decompression can be seen as a reconstruction problem constrained by quantization. Our method allows to apply constrained Total Variation reconstruction in order to reduce JPEG artifacts (blocking, grainy effects and high frequency noise).
We design and architect A3, which accelerates attention mechanisms in neural networks with algorithmic approximation and hardware specialization.
We propose a CNN-based method to learn a discriminative metric with good robustness to the over-fitting problem in person re-identification.
We evaluate the use of superpixel pooling layers in deep network architectures for semantic segmentation.
We propose several geometrical features suited for autonomous driving and integrate them into state-of-the-art general proposal generation methods in a Bayesian framework in aBayesian framework.
We take the novel approach of considering race as a boundary for transfer learning in both the task (facial classification and image synthesis) and the domain (synthesis over distinct datasets).
Shape Signatures has been reformulated to automatically decompose compounds into fragments using ring systems as anchors, and to likewise partition the ray-trace in accordance with the fragment assignments.
We found three potent VEGFR-2 inhibitors (ZINC08254217, ZINC08254138, and ZINC03838680) from natural derivatives, with comparable binding affinity of axitinib.
We propose to exploit the semantic segmentation information for image inpainting task, aiming at recovering the missing area of an incomplete image given the context information.
 BMXNet is an open-source BNN library based on MXNet, which supports both XNOR-Networks and Quantized Neural Networks and work in GPU and CPU mode.
In this paper, we address key computational bottlenecks that current incremental techniques still suffer by introducing best-choice edge grafting, an incremental, structured method that activates edges as groups of features in a streaming setting.
We explored the extent of genomic robustness in budding yeast by genome wide dosage suppressor analysis of 53 conditional lethal mutations, revealing 660 suppressor interactions of which 642 are novel.
In this paper, we propose a novel approach for generating image captions with guiding objects (CGO). The CGO constrains the model to involve a human-concerned object when the object is in the image.
This paper introduces a novel generative encoder (GE) model for generative imaging and image processing with applications in compressed sensing and imaging.
We propose a new generative autoencoder that can achieve state-of-the-art performance with no adversarial losses.
In this paper, we focus on semantically multi-modal image synthesis (SMIS) task, namely, generating multi-Modal images at the semantic level.
This paper proposes the CirCNN architecture, a principled approach to represent weights and process neural networks using block-circulant matrices using Fast Fourier Transform.
We study how the hyperparameters of stochastic gradient descent used in the early phase of training affect the rest of the optimization trajectory, beyond which the curvature of the loss surface and noise in gradient are implicitly regularized by SGD.
In this paper, we propose an edge-aware scalerecurrent network (EASRN) to conduct camera motion deblurring.
We transfer knowledge from several lower-level language tasks (skills) including textual entailment, named entity recognition, paraphrase detection and question type classification into the reading comprehension model, which leads to significant improvements for the task.
We present a deep learning approach for high resolution face completion with multiple controllable attributes (male and smiling) under arbitrary masks.
We propose a novel approach that can exploit more effectively the rich video information, by accounting for the role that the changing pose/viewpoint factor plays in the sequences matching process.
P-bodies form in response to stress and act as sites of mRNA storage and degradation. The key P-body protein Lsm1 controls the abundance of HHT1, ACF4, ARL3, TMA16, RRS1 and YOX1 mRNA to prevent their toxic accumulation during replication stress.
Thinning is the removal of contour pixels/points of connected components in an image to produce their skeleton with retained connectivity and structural properties. The output requirements of a thinning procedure often vary with application.
We propose a novel yet simple framework called GaterNet, which involves a backbone and a gater network for dynamic filter selection in CNNs.
We propose a deep neural network, called Parts4Feature, to learn 3D global features from part-level information in multiple views.
Question answering (QA) using textual sources for purposes such as reading comprehension (RC) has attracted much attention. This study focuses on the task of explainable multi-hop QA.
This paper proposes a novel semi-supervised method on object recognition using Boost Picking, a universal algorithm.
We show how to perform quantization-aware training during the fine-tuning phase of BERT in order to compress BERT by $4\times$ with minimal accuracy loss.
We extend two recent proposals for selecting features using the Maximum Mean Discrepancy and Hilbert Schmidt Independence Criterion to condition on the minimal conditioning event, and demonstrate our proposal over a range of synthetic and real world experiments.
In this paper, we present HuggingFace's Transformers library, a library for state-of-the-art NLP, making these developments available to the community by gathering state of theart general-purpose pretrained models under a unified API together with an ecosystem of libraries, examples, tutorials and scripts.
We pose this problem as a non-convex optimization problem, where the goal is to decompose the corrupted data matrix as the sum of a clean and self-expressive dictionary plus a matrix of noise and/or gross errors.
We propose a novel differentiable NAS formulation, namely Single-Path NAS, that uses one single-path over-parameterized ConvNet to encode all architectural decisions based on shared convolutional kernel parameters.
In this paper, we propose a new method for sentiment classification using negative and intensive sentiment supplementary information, so as to exploit the linguistic feature ofnegative and intensive words in conjunction with the context information.
This paper introduces a new problem, called Visual Text Correction (VTC), i.e., finding and replacing an inaccurate word in the textual description of a video/sentence.
We provide a comprehensive study of the contribution of different components in M-BERT to its cross-lingual ability.
This paper proposes a two-stream flow-guided convolutional attention networks for action recognition in videos.
Domain Alignment Layers can automatically learn the degree of feature alignment required at different levels of the deep network, which can then be used to reduce the domain shift.
We propose a global Matrix Power Normalized COVariance (MPN-COV) Pooling, a robust covariance pooling method for deep CNNs.
The advancement of deep learning technology has been concentrating on deploying end-to-end solutions using high dimensional data, such as images. However, there has been very little work directed towards the generation of 3D point clouds from voxel grids.
We propose a novel, unsupervised domain adaptation approach for person re-identification for real-world, practical scenarios.
We generalize kernel machines from vectorial inputs to i.i.d. samples from an underlying feature distribution for a group of data points.
We introduce an independent scale filter for the estimation of the scale of an object and merge two complementary features to further boost the performance of the tracker.
In this work we introduce a novel hybrid architecture, Implicit Discriminator in Variational Autoencoder (IDVAE), that combines a VAE and a GAN, which does not need an explicit discriminator network.
We propose a new scale adaptive dictionary learning framework, which jointly estimates suitable scales and corresponding atoms in an adaptive fashion according to the training data, without the need of prior information.
A novel approach using the adversarially approximated autoencoder (AAAE) to investigate the latent codes with adversarial approximation.
We describe an iterative recursive attention model, which constructs incremental representations of input data through reusing results of previously computed queries.
In this paper, we develop a convolutional image captioning technique. We demonstrate its efficacy on the challenging MSCOCO dataset and demonstrate performance on par with the baseline, while having a faster training time.
We examined the contribution of lower-order subcortical representations to behavioral responses to threat in adult humans, revealing the characteristics of behaviors driven by a lower- order neural mechanism that is specialized for processing of ancestral threats.
Posterior collapse in Variational Autoencoders (VAEs) with uninformative priors arises when the variational posterior distribution closely matches the prior.
GPU-FV, a fast Fisher vector extraction method with the help of modern GPUs, for real-time video monitoring tasks.
Side-Aware Boundary Localization (SABL), where each side of the bounding box is respectively localized with a dedicated network branch, leads to significant improvements on Faster R-CNN.
Generative models for point clouds under the autoencoding framework must acknowledge the relationship between a continuous surface, a discretized mesh, and a set of points sampled from the surface.
This work proposes Recurrent Neural Network (RNN) models to predict structured ‘image situations’ – actions and noun entities fulfilling semantic roles related to the action.
An off-policy meta-reinforcement learning algorithm that uses probabilistic filtering of latent task variables to infer how to solve a new task from small amounts of experience.
We propose a novel 2D box association and object-centric stereo matching method that only estimates the disparities of the objects of interest to address these two issues.
The receptor-ligand interaction evaluation is one important step in rational drug design. One possible approach is to evaluate a set of molecular descriptors.
We generalize the non-local module and take the correlations between the positions of any two channels into account for fine-grained object recognition.
We propose Multi-Cluster Feature Selection (MCFS) for unsupervised feature selection.
In this paper, we present the details of our method on cascade regression framework, where a series of regressors are utilized to progressively refine the shape initialized by face detector, and then learn to rank or combine these hypotheses to get the final result.
We propose an approach called Active Dataset Subsampling (ADS), to identify favorable subsets within a dataset for training using ensemble based uncertainty estimation.
We extend previous work in two ways - we use as our starting point a very high quality data set of co-registered color and range values collected specifically for this purpose, and evaluate the statistics of perceptually relevant chromatic information in addition to luminance, range, and binocular disparity information.
We propose CoarseFine networks that learn highly discriminative features without loss of time granularity with two streams: the coarse and fine networks.
We develop a high-efficiency framework for face parsing annotation, which considerably simplifies and speeds up the parsing annotation by two consecutive modules. Benefit from the proposed framework, we construct a new Dense Landmark Guided Face Parsing benchmark.
A dataset is crucial for model learning and evaluation. Choosing the right dataset to use or making a new dataset requires knowledge of those that are available. In this work, we provide that knowledge, by reviewing twenty datasets that were published in the recent six years and that are directly related to object manipulation.
We propose a new preferential attachment-based network growth model in order to explain two properties of growing networks: (1) the power-law growth of node degrees and (2) the decay of node relevance.
We introduce a new computer aided detection and diagnosis system for lung cancer screening with low-dose CT scans that produces meaningful probability assessments for both nodule detection and malignancy diagnosis.
Aesthetic image captioning (AIC) refers to the multi-modal task of generating critical textual feedbacks for photographs. Towards this goal, we propose an automatic cleaning strategy to create a benchmarking AIC dataset, by exploiting the images and noisy comments easily available from photography websites.
In this paper, a novel approach to deep hashing is proposed, which incorporates local-level information, in the form of image semantic segmentation masks, during the hash code learning step.
We propose a hierarchical phrase-based captioning model trained with policy gradients, and enable a human teacher to give feedback to a learning agent in the form of natural language.
Adaptive morphological reconstruction (AMR) operation is proposed that adaptively filter useless seeds while preserving meaningful ones.
We develop a novel deep 3D convolutional neural network with an Encoder-Decoder structure for pulmonary nodule detection.
We propose the use of Monte Carlo planning in combination with two different UCT (upper confidence bound applied to trees) derivations to search for network architectures.
We propose a novel learned synthesis technique to better train classifier models than state-of-the-art offline graphical methods while using significantly less computational resources.
We present an approach to depth estimation that fuses information from a stereo pair with sparse range measurements derived from a LIDAR sensor or a range camera to exploit the complementary strengths of the two sensor modalities.
We propose a new state-of-the-art hyperparameter optimization method, which consistently outperforms both Bayesian optimization and Hyperband on a wide range of problem types, including high-dimensional toy functions, support vector machines, feed-forward neural networks.
We propose a novel hybrid publication recommendation approach using compound information which retrieves top-K most relevant papers from a publication depository for a set of user input keywords.
In this paper we present a deep learning method to estimate the illuminant of an image that is trained without ground truth illuminants.
We describe a computational methodology allowing to systematically and quantitatively characterize a Boolean mathematical model of a biological network in terms of genetic interactions between all loss and gain of function mutations with respect to all model phenotypes or outputs.
A proper semantic representation for encoding side information for zero-shot human action recognition. We investigate different encoding methods to generate semantic representations for human actions from such side information.
We consider the registration of temporal sequences of 3D face scans. We propose an automatic approach that can register large sets of dynamic face scans without the need for landmarks or highly specialized acquisition setups.
An evaluation criterion called overlap maximum matching ratio (OMMR) is proposed to analyze the similarity between the identified overlaps and the benchmark overlap modules. Comparison of essential proteins and gene ontology (GO) analysis are also used to assess the quality of overlaps.
We propose deep convolutional Gaussian processes, a principled Bayesian framework for detecting hierarchical combinations of local features for image classification.
We present a pixel-related Gaussian mixture model (GMM) to segment images into superpixels, resulting in segments of similar size and an algorithm of linear complexity.
In this paper, we propose a novel recurrent video encoding method and a novel visual spatial feature for the video captioning task.
We propose the use of a coupled 3D convolutional neural network (3D CNN) that can map both modalities into a representation space to evaluate the correspondence of audio–visual streams using the learned multimodal features.
This paper describes a novel approach to the semantic relation detection problem. Instead of relying only on the training instances for a new relation, we leverage the knowledge learned from previously trained relation detectors.
We propose an embarrassingly simple-yet-effective approach for training a deep neural network that maximises the exposure of the tail class samples to avoid the excessive dominance of head classes.
We proposed a multi-stage encoder based Seq2seq model for sentence simplification which outperforms state-of-the-art baseline simplification systems.
We investigate deep generative models that can exchange multiple modalities bi-directionally, e.g., generating images from corresponding texts and vice versa.
This paper studies unsupervised monocular depth prediction problem in the indoor environments and proposes two methods for improving the state-of-the-art design of architecture.
We address this limitation by formulating a multi-level architecture that is end-to-end trainable and fully leveraging 1k-resolution input images.
In this paper, we present the design of a BNN accelerator that is synthesized from C++ to FPGA-targeted Verilog. The accelerator outperforms existing FFPA-based CNN accelerators in GOPS as well as energy and resource efficiency.
We visualize the intra-class knowledge inside CNN to better understand how an object class is represented in the fully-connected layers.
Zero-Shot Action Recognition in Videos: A Survey of the Methods .
We propose a new elicitation method to generate a static preference questionnaire (SPQ) that poses relative preference questions to the user.
We propose a mixed gradient operator that combines a standard gradient in isotropic image regions, and a directional gradient in the regions where specific orientations are likely, and use it to construct image priors that take edge orientation, as well as intensity, into account.
This work explores the ability of collective matrix factorization models in recommender systems to make predictions about users and items for which there is side information available but no feedback or interactions data, and proposes a faster cold-start prediction formula that can be used in real-time systems.
An overview of recent advances in RGB-D-based motion recognition using convolutional neural networks and recurrent neural networks.
We propose a rich multi-scale feature representation, referred to as convolutional hypercube pyramid (HP-CNN), that is able to encode discriminative information from the Convolutional tensors at different levels of detail.
The main goal of this paper is to evaluate the potential of some combinations of watershed hierarchies and propose a new combination based on merging level sets of hierarchies.
We develop an edge-assisted object recognition system with the aim of studying the system-level trade-offs between end-to-end latency and object recognition accuracy and develop techniques that optimize the transmission delay.
This paper proposes a one-shot Siamese network for fast and efficient visual object tracking.
We present a novel multi-view denoising algorithm based on probabilistic formulation that marginalizes depth maps as hidden variables and therefore does not require perfect depth estimation.
This paper describes a baseline for the second iteration of the Fact Extraction and VERification shared task (FEVER2.0) which explores the resilience of systems through adversarial evaluation.
Cascade Gaussian process regression trees for face alignment using shape-indexed difference of Gaussian filter responses.
We review the task of Sentence Pair Scoring, popular in the literature in various forms - viewed as Answer Sentence Selection, Semantic Text Selection, Next Utterance Ranking, Recognizing Textual Entailment, Paraphrasing or e.g. a component of Memory Networks.
This paper is aimed at creating extremely small and fast convolutional neural networks (CNN) for the problem of facial expression recognition (FER) from frontal face images.
We propose a novel method with deep neural networks to detect vessels accurately in retinal fundus images.
We propose GRAM(GRAph propagation as Meta-knowledge) that adopts fine-grained (node-wise) search method and accumulates the knowledge learned in updates into a meta-graph.
We present a novel quicksort flavored algorithm for a large class of non-decomposable loss functions. We provide a complete characterization of the loss functions that are amenable to our algorithm, and show that it includes both AP and NDCG based loss function.
We propose PatchDrop a reinforcement learning approach to dynamically identify when and where to use/acquire high resolution data conditioned on the paired, cheap, low resolution images.
We propose PANet, a novel prototype alignment network to better utilize the information of the support set to perform few-shot segmentation.
We develop a procedure for constructing high-quality synthetic overlap datasets, necessary for most deep learning-based separation frameworks, and evaluate standard methods on this data.
We exploit the low mean curvature of the decision boundary and propose SparseFool, a geometry inspired sparse attack that controls the sparsity of the perturbations.
In this paper, we develop a model for detection of objects in drone images using the VisDrone2019 DET dataset using the RetinaNet model and build a custom Deep Association network for the algorithm.
In this paper, we propose to track different objects in an object-independent approach with a novel two-flow convolutional neural network.
In this paper we introduce a new indexable ::: ::: symbolic data representation that allows us to efficiently index and retrieve from a large amount of data that :::::: may appear in multiple dimensions.
We propose an efficient multibranch residual network for single image super-resolution.
This paper proposes a novel approach to eye contact detection during adult-child social interactions in which the adult wears a point-of-view camera which captures an egocentric view of the child’s behavior.
In this study we propose a new set of muscle activity based features for facial expression recognition.
This paper presents the deep reinforcement learning (DRL) framework to estimate the optimal Dynamic Treatment Regimes from observational medical data, with the goal of providing data-driven personalized decision recommendations.
Autonomous explorative robots frequently encounter scenarios where multiple future trajectories can be pursued. In this work, we propose a 2 stage Convolutional Neural Network architecture which mimics such an ability to map the perceived surroundings to multiple trajectories.
We introduce the View Parsing Network (VPN) for cross-view semantic segmentation.
BlockSwap: a fast algorithm for choosing networks with interleaved block types by passing a single minibatch of training data through randomly initialised networks and gauging their Fisher potential.
We introduce UniDual, a novel architecture that enables joint training of a unified model on mixed collections of image and video examples spanning different tasks.
In this paper, adopting a fine-to-coarse attention mechanism on multi-scale spans via binary partitioning (BP), we propose BP-Transformer (BPT for short).
Generating semantically meaningful adversarial examples in the low dimensional manifold of the data using variational autoencoders.
We propose a taxonomy that classifies pruning signals based on four mostly-orthogonal components of the signal. We find that some of our newly constructed signals outperform the best existing pruning signal.
Silence is a part of human-to-human communication, which can be a clue for human emotion perception. This paper presents an investigation of the effect of using silence feature in dimensional emotion recognition.
We propose a Siamese network based tracker that improves upon tracking performance as follows. The GOT-10k dataset is applied to train our tracker.
We propose a lattice-based framework and algorithms for building recommender systems and apply them to generate quality recommendations in real-time.
SLAMBench 3.0 includes the first publicly available implementation of DynamicFusion, along with datasets and evaluation infrastructure for dynamic SLAM.
In this paper, a discriminative learning method for emotion recognition using both articulatory and acoustic information is proposed. The proposed method is extended to include additional constraints that enforce the model to reconstruct articulatory data.
We propose a novel diffusion technique that performs 10∼ times faster in terms of online search speed on large datasets.
We propose novel Stacked Spatio-Temporal Graph Convolutional Networks (Stacked-STGCN) for action segmentation, i.e., predicting and localizing a sequence of actions over long videos.
In this paper, we propose an unsupervised learning model for sequence data, called the Integrated Sequence Autoencoder (ISA), to learn a fixed-length vectorial representation by minimizing the reconstruction error.
This paper addresses the above issues by 1) interpreting that the conventional training methods with regularization by noise injection optimize the lower bound of the true objective and 2) proposing a technique to achieve a tighter lower bound using multiple noise samples per training example in a stochastic gradient descent iteration.
In this article we explore the problem of constructing person-specific models for the detection of facial Action Units (AUs), addressing the problem from the point of view of Transfer Learning and Multi-Task Learning.
We propose an end-to-end deep learning framework to localize and match query persons from the scene images without relying on the annotations of candidate boxes.
We introduce a simple yet effective fusion method of LiDAR and RGB data to segment LiDar point clouds.
We apply state-of-the-art visual reasoning model and demonstrate that it is feasible to ask a smart fridge about its contents and various properties of the food with close-to-natural conversation experience.
We propose a learning system which first clusters visually similar classes and then learns deep convolutional neural network features specific to each subset.
We propose a method to address this issue in large MDPs with sparse rewards, in which exploration and routing across remote states are both extremely challenging.
We evaluate the performance of various post-processing calibration methods on state-of-the-art neural networks, unlike those from a decade ago, are poorly calibrated.
Convolutional Neural Network (CNN) has become the state-of-the-art for object detection task.
COEGAN is a model that uses neuroevolution and coevolution in the GAN training algorithm to provide a more stable training method and the automatic design of neural network architectures.
We propose a multi-region two-stream R-CNN model for frame-level action detection in realistic videos, which improves state of the art with a significant margin.
We address the data association problem optimally while reusing computation, resulting in faster inference than standard solvers.
We introduce an explicit, constrained pairwise word interaction mechanism to pretrained language models that improves their effectiveness on semantic similarity tasks.
We propose Blank Language Model (BLM), a model that generates sequences by dynamically creating and filling in blanks, and achieves perplexity comparable to traditional left-to-right language models.
We introduce a novel compact motion representation for video action recognition, named Optical Flow guided Feature (OFF), which enables the network to distill temporal information through a fast and robust approach.
In this paper, we propose a low-cost modification to alpha matting networks to also predict the foreground and background colours.
A relative speaker modeling method is proposed to address the problem where speaker annotations are inconsistent among different dialogs.
In this paper, we propose a novel method called Network-aided Bi-Clustering (NetBC) to discover bi-clusters of relevant samples that exhibit similar gene expression profiles over a subset of genes.
We propose a new 3D representation method that extracts planarity from the depth-assisted image segmentation and then projects these depth planes into the 3D world.
We propose an iterative matrix square root normalization method for end-to-end training of covariance pooling networks.
We first propose the epsilon-neighborhood attack, which can fool the defensively distilled networks with 100% success rate in the white-box setting, and it is fast to generate adversarial examples with good visual quality. On the basis of this attack, we further propose the region-based attack against defensively distilled DNNs in the black- box setting.
We propose a boosting approach which directly takes advantage of hierarchical CNN features for detecting regions of interest fast.
We propose a novel unsupervised deep learning approach for predicting stereo depth maps and show that the depth estimation task can be effectively tackled within an adversarial learning framework.
We present the MSP-IMPROV corpus, a multimodal emotional database, where the goal is to have control over lexical content and emotion while also promoting naturalness in the recordings.
We propose a knowledge distillation framework that accelerates the speed of state-of-the-art deep correlation filters to real-time on a single-core CPU while maintaining almost the same tracking accuracy.
This work addresses the unsupervised adaptation of an existing object detector to a new target domain by using high-confidence detections from the existing detector, augmented with hard (misclassified) examples acquired by exploiting temporal cues using a tracker.
We propose ways to improve the performance of fully connected networks. We show how both approaches can be related to improving gradient flow and reducing sparsity.
We develop a theoretical framework on stability and reversibility of deep neural networks, and derive three reversible neural network architectures that can go arbitrarily deep in theory.
To combat adversarial spelling mistakes, we propose placing a word recognition model in front of the downstream classifier, achieving 32% relative (and 3.3% absolute) error reduction over vanilla semi-character models.
We employ a large and rich set of feature descriptors for face identification using partial least squares to perform multichannel feature weighting and extend the method to a tree-based discriminative structure to reduce the time required to evaluate probe samples.
In this paper, we present an off-line cursive word handwriting recognition methodology based on an additive fusion resulted after a novel combination of two different modes of word image normalization and robust hybrid feature extraction.
In interactive object segmentation a user collaborates with a computer vision model to segment an object. Recent works rely on convolutional neural networks to predict the segmentation, taking the image and the corrections made by the user as input.
Multialgorithmic face recognition system combining holistic and texture methods for human authentication in unconstrained environment.
We present an online framework for video anomaly detection using a compact set of highly descriptive features, which is extracted from a novel cell structure that helps to define support regions in a coarse-to-fine fashion.
We aim to explore a Hybrid Geometric Spatial Image Representation that is based on the combination of histograms computed over the rectangular, triangular and circular regions of the image.
The recent research of facial expression recognition has made a lot of progress due to the development of deep learning technologies, but some typical challenging problems such as the variety of rich facial expressions and poses are still not resolved. To solve these problems, we develop a new Facial Expression Recognition framework by involving the facial poses into our image synthesizing and classification process.
We propose a simple yet effective solution for automatic facial attribute extraction by training a deep convolutional neural network for each facial attribute separately, without using any pre-training or dataset augmentation, and obtain new state-of-the-art facial attribute classification results on the CelebA benchmark.
We propose a weakly supervised approach to predict point-level results using weak labels on 3D point clouds and train a point cloud semantic segmentation network.
MobileNetV2 improves the state of the art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes.
This paper accelerates the two-stream architecture by replacing optical flow with motion vector which can be obtained directly from compressed videos without extra calculation.
MINE is an agglomerative clustering algorithm able to identify highly modular sets of gene products within highly interconnected molecular interaction networks. The algorithm allows a high degree of flexibility and user-customisation.
This paper presents a novel feature learning and extraction framework for video-based person re-identification, namely, the extended global-local representation learning network (E-GLRN)
We build upon Besag's auto-normal parameterization and pseudo-likelihood, which not only enables computationally efficient learning, but also connects the areas of MRFs and sparse inverse covariance estimation with autoencoders.
We introduce diversity and discrimination simultaneously when generating proposals, and in doing so propose Diversified and Discriminative Proposal Networks model (DDPN)
We posit that a person’s gaze behavior while freely viewing a scene contains an abundance of information, not only about their intent and what they consider to be important in the scene, but also about the scene's content.
We address the problem of generating images across two drastically different views, namely ground (street) and aerial (overhead) views. For this, we resort to homography as a guide to map the images between the views based on the common field of view to preserve the details in the input image.
StuffNet uses convolutional features learnt from stuff segmentation for improving object detection performance on Pascal VOC 2010 and 2012 datasets.
We develop an intelligent surveillance system on the basis of spatio-temporal information in comprehensive flow of human ::: traffic in public spaces and thoroughfares.
In order to resist the adverse effect of viewpoint variations, we design quadruple directional deep learning features (QD-DLF) for improving vehicle re-identification performance.
We propose the new training algorithm, binary direct feedback alignment (BDFA) to minimize the computational cost while maintaining the training accuracy compared with DFA.
This paper introduces a new definition of multiscale neighborhoods in 3D point clouds. With an appropriate learning strategy, the proposed features can be used in a random forest to classify 3D points.
Neural network compression has recently received much attention due to the computational requirements of modern deep models. In this work, we propose an adversarial network compression approach to transfer knowledge from a deep and accurate model to a smaller one.
We present Fully Convolutional Adaptation Networks (FCAN), a novel deep architecture for semantic segmentation which combines Appearance-level and representation-level domain adaptation and achieves superior results when comparing to state-of-the-art unsupervised adaptation techniques.
We propose a novel formulation to learn video summarization from unpaired data, where there exists no correspondence between raw videos and summary videos.
In this paper we present the generalization of the automatic face recognition system, presented in [2], making it able to deal with different expressions and the presence of spectacles.
We find that the degree of delay interacts with the learning rate, to change the set of minima accessible by an asynchronous stochastic gradient descent algorithm.
We present a novel approach to weakly supervised object detection. The key idea is to train the object detector to produce physically plausible object motion when applied to the first video and to not detect anything in the second video.
We introduce a new task of identifying a well-formed natural language question, which can improve the performance of neural sequence-to-sequence models for reading comprehension.
This paper presents a novel method of augmented local binary patterns (A-LBP) for face recognition in uncontrolled environment.
We propose a novel approach based on deep Convolutional Neural Networks (CNN) to recognize human actions in static images by predicting the future motion, and detecting the shape and location of the salient parts of the image.
A fully automated vessel segmentation system based on 4-D tensor field for retinal diseases.
We introduced ViPeD - Virtual Pedestrian Dataset, a new synthetically generated set of images collected from a realistic 3D video game where the labels can be automatically generated exploiting 2D pedestrian positions extracted from the graphics engine.
This paper addresses a novel contextual method based on the geometry of the primary visual cortex (V1) to study the geometrical structure of multi-orientation cortical connectivity.
We introduce a novel self-supervised learning method based on adversarial training. Our objective is to train a discriminator network to distinguish real images from images with synthetic artifacts, and then to extract features from its intermediate layers.
We consider the problem of providing dense segmentation masks for object discovery in videos, where the goal is to cluster foreground pixels in videos into different objects.
We propose a novel method, aggregation cross-entropy (ACE), for sequence recognition from a brand new perspective, with competitive performance to CTC and attention mechanism.
Supervision-by-registration augments the training loss function with a registration loss, thus training the detector to have output that is not only close to the annotations in labeled images, but also consistent with registration on large amounts of unlabeled videos.
We propose a refined Adversarial Inverse Reinforcement Learning (rAIRL) method to handle the reward ambiguity problem by disentangling reward for each word in a sentence, as well as achieve stable adversarial training by refining the loss function.
We propose the Adaptive Quantile Sparse Image (AQuaSI) prior, based on a quantile filter, which can be used as a joint filter on guidance data, and be readily plugged into numerical optimization algorithms.
We propose HaS (Hide a Share), a novel landmark-based similarity mechanism for decentralized KNN computation, which allows users to estimate how close they lay to one another without disclosing their individual profiles.
We introduce a new method for learning the shared space between multiple domains based on the prediction of the domain label for each example.
We propose adversarial margin maximization (AMM), a learning-based regularization which exploits an adversarial perturbation as a proxy to improve DNNs generalization ability.
We propose a new MRC model in which the TriviaQA dataset is validated and trained using a high-quality dataset, and the answer extraction model learns with the validated training data.
We evaluate the impact of docker container on the performance of deep learning applications. It turns out that the docker container will not cause noticeable drawbacks.
A small, few-layer artificial neural network that employs feedback will reach top level performance on a benchmark task, otherwise only obtained by large feed-forward structures.
Unsupervised method to learn to transfer visual attribute without any corresponding images.
A robust Local Binary Pattern (LBP) Guiding Pooling (G-RLBP) mechanism is proposed in this paper to down sample the input feature maps and lower the noise impact simultaneously.
In this paper we propose a novel approach to model compression termed Architecture Compression. Instead of operating on the weight or filter space of the network like classical model compression methods, our approach operates on the architecture space.
We explore to ease the annotation of ReID by replacing the accurate annotation with inaccurate annotation, i.e., we group the images into bags in terms of time and assign a bag-level label for each bag.
We hypothesize that adversarial weakness is composed of three sources of bias: architecture, dataset, and random initialization. We show that one can decompose adversarial examples into an architecture- dependent component, data-dependent component, and noise-dependent components and that these components behave intuitively.
A three-stage support vector machine (SVM) for facial expression recognition is proposed.
We propose a computationally efficient system called DeepCount to automatically identify and count the number of wheat spikes in digital images taken under natural field conditions.
We develop an algorithm for analysis of pointwise robustness of neural networks that operate on 3D data. We then use our algorithm to evaluate an array of state-of-the-art models.
We present a novel aggregation method inspired by the anisotropic diffusion technique used in image filtering that produces results similar to adaptive-weight solutions while reducing the computational requirements.
This paper addresses the human action recognition in video by proposing a method based on three main processing steps. We achieve this by reducing an input video to a set of key-sequences that represent atomic meaningful acts of each action class. We then join these representations still preserving information about temporal relationships.
We propose a two-stage depth ranking based method (DRPose3D) to tackle the problem of 3D human pose estimation.
A key challenge in generic object detection is being to handle large variations in object scale, poses, viewpoints, especially part deformations when determining the location for specified object categories. Recent advances in deep neural networks have achieved promising results for object detection.
We took part in the YouTube-8M Video Understanding Challenge hosted on Kaggle, and achieved the 10th place within less than one month's time.
We explore adversarial behaviors in practical scenarios by manipulating the shape and texture of a given 3D mesh representation of an object.
In this paper we propose a new approach, Hardware Aware Knowledge Distillation (HAKD) which uses empirical observations of hardware behaviour to design efficient student networks which are then trained with knowledge distillation.
We propose a new method to generate adversarial images which can trick the algorithms as much as possible.
We propose a novel algorithm for softmax computation in just two passes that avoids both numerical overflow and the extra normalization pass by employing an exotic representation for intermediate values.
This paper proposes a novel region-based active contour model for image segmentation in the presence of intensity inhomogeneity.
MorphNet uses a sequence-to-sequence recurrent neural network to combine morphological analysis and disambiguation.
In most real-world scenarios, labeled training datasets are highly class-imbalanced, where deep neural networks suffer from generalizing to a balanced testing criterion. In this paper, we explore a novel yet simple way to alleviate this issue by augmenting less-frequent classes via translating samples (e.g., images) from more frequent classes, by transferring and leveraging the diversity of the majority information.
We propose a novel time-weighted and detection-guided self-paced learning strategy for easy-to-hard sample selection for robust visual tracking.
In this paper, we propose a novel systematic method to understand natural language questions by using a large number of binary templates rather than semantic parsers.
We propose a novel Kronecker Product Matching module to match feature maps of different persons in an end-to-end trainable deep neural network.
This paper presents a mobile application for real-time facial expression recognition running on a smart phone with a camera.
We propose an end-to-end deep hashing framework with category mask for fast video retrieval.
Local SGD improves the generalization performance compared to large-batch training and converges to flatter minima.
We propose a multi-task end-to-end Joint Classification-Regression Recurrent Neural Network to better explore the action type and temporal localization information.
We propose a probabilistic method based on recursive Latent Dirichlet Allocation for image layer representations.
We consider the problem of designing models to leverage a recently introduced approximate model averaging technique called dropout. We define a simple new model called maxout (so named because its output is the max of a set of inputs, and because it is a natural companion to dropout) designed to both facilitate optimization by dropout and improve the accuracy of dropout's fast approximatemodel averaging technique.
We formalize such a diversification process then propose two methods to improve the universality of CNN representations that limit the need for additive annotation data.
In this paper, we introduce the position information to machine reading comprehension and investigate the performance of position information.
We propose a generative adversarial network (GAN)-based framework called category-level adversarial adaptation networks for domain adaptation in the context of semantic segmentation.
Likelihood-based generative models are a promising resource to detect out-of-distribution inputs which could compromise the robustness or reliability of a machine learning system. However, likelihoods derived from such models are problematic for detecting certain types of inputs that significantly differ from training data.
The non-receptor tyrosine kinase proline-rich tyrosinate kinase 2 (Pyk2) is a critical mediator of signaling from cell surface growth factor and adhesion receptors to hematopoietic cell response, bone density, neuronal degeneration, angiogenesis, and cancer.
We propose a mobile application for faceted search and exploration of a large, multi-dimensional data set of open social media on a touchscreen mobile phone.
We study the problem of attacking video recognition models in the black-box setting where the model information is unknown and the adversary can only make queries to detect the predicted top-1 class and its probability.
An FCN-based approach to detect building corners in aerial images .
In this paper, we propose an evolutionary strategy to find better topologies for deep CNNs.
Scale-wise convolution is proposed to convolve across multiple scales for scale-invariance for image restoration.
This study investigates two aspects of image-caption embedding-and-retrieval systems. On the basis of the concept that `Bayesian deep learning knows what it does not know,' the uncertainty of DNN outputs has been investigated as a reliability measure for classification and regression tasks.
Multi-modal semantics has relied on feature norms or raw image data for perceptual input. In this paper we examine grounding semantic representations in raw auditory data.
A referring expression (RE) is a description that identifies a set of instances unambiguously. Mining REs from data finds applications in natural language generation, algorithmic journalism, and data maintenance.
We propose a generic sensor-agnostic multi-modality MOT framework, where each modality (i.e., sensors) is capable of performing its role independently to preserve reliability, and could further improving its accuracy through a novel multi-Modality fusion module.
We present a novel robust and real-time long-term tracking framework based on the proposed skimming and perusal modules.
We propose a Kernel Structured Sparsity method that can handle both the temporal alignment problem and the structured sparse reconstruction within a common framework, and it can rely on simple features.
We fuse false-negative detection with uncertainty based false-positive meta classification for semantic segmentation. We thereby achieve improved trade-offs between false-Negatives and false-Positions.
Determining effective control strategies and solutions for high-degree-of-freedom humanoid characters has been a difficult, ongoing problem. Our first contribution is to show how DOA expansion can be performed for a high-dimensional simulated character.
We propose a novel distance-based camera network topology inference method for efficient person re-identification.
This paper thoroughly analyses the effect of different input representations on polyphonic multi-instrument music transcription. We use our own GPU based spectrogram extraction tool, nnAudio, to investigate the influence of using a linear-frequency Spectrogram, log-frequency spectrogram, Mel spectrogram.
In this paper, we propose a new multi-index fusion scheme for image retrieval, based on multilinear optimization problem.
Object retrieval plays an increasingly important role in video surveillance, digital marketing, e-commerce, etc. It is facing challenges such as large-scale datasets, imbalanced data, viewpoint, cluster background, and fine-grained details (attributes). This paper has proposed a model to integrate object ontology, a local multitask deep neural network (local MDNN), and an Imbalanced data solver to take advantages and overcome the shortcomings of
We introduce a cooperative embedding to integrate multiple instance, attribute and category similarity notions while preserving their specific level of semantic representation.
We propose a novel reinforcement learning framework for automatic architecture designing, where the action is to grow the network depth or layer width based on the current network architecture with function preserved.
We present 3DDE, a robust and efficient face alignment algorithm based on a coarse-to-fine cascade of ensembles of regression trees.
We propose a real-time method to estimate spatially-varying indoor lighting from a single RGB image in less than 20ms.
We propose an end-to-end system for live reconstruction of large-scale outdoor dynamic environments. We leverage recent advances in 6-DoF object pose estimation to segment the scene into objects and stationary background.
In this paper, we evaluate three common decisions that need to be made by a CNN designer, namely the performance of transfer learning, the effect of object/image size and the relation between training set size.
We show that texture loss alone allows the generation of perceptually high quality images. We develop a novel semantically guided texture constraining method for further improvement.
We propose an efficient spectral clustering algorithm to identify natural communities, which are relatively densely connected sub-graphs, in the network, and develop a novel method to measure the agreement between the gene communities and the modular structures in other reference networks.
We propose a deeply-recursive network based on ResNet blocks for crowd counting in images.
We propose a novel learning architecture capable of navigating an agent, e.g. a mobile robot, to a target given by an image.
We propose the use of synthetic labels obtained through clustering to disentangle and stabilize GAN training, and demonstrate latent space exploration techniques to ease the logo design task in an interactive manner.
SING (Subgraph search In Non-homogeneous Graphs), a novel indexing system able to cope with large graphs, is presented.
By extracting features temporally as well as utilizing an accumulation to bound decision making model, an object recognition model accounting for both recognition time and accuracy.
We propose a transformer-based conditional language model with a shallow encoder "condition" stack, and a deep "language model" stack of multi-headed attention blocks.
This paper evaluates different Restricted Boltzmann Machines models in unsupervised, semi-supervised and supervised frameworks using information from human actions.
We present an approach to recover absolute 3D human poses from multi-view images by incorporating multi-View geometric priors in our model.
This paper presents a new model of scale, rotation, and translations invariant interest point descriptor for human actions recognition.
This paper presents KeypointNet, an end-to-end geometric reasoning framework to learn an optimal set of category-specific 3D keypoints, along with their detectors.
We propose a controllable face aging method via attribute disentanglement generative adversarial network.
We introduce Deep500: the first customizable benchmarking infrastructure that enables fair comparison of the plethora of deep learning frameworks, algorithms, libraries, and techniques.
We propose a video story question-answering (QA) architecture, Multimodal Dual Attention Memory (MDAM), which uses a dual attention mechanism with late fusion.
We aim at improving on the WGAN by generalizing its discriminator loss to a margin-based one, which leads to a better discriminator, and in turn a better generator, and then carrying out a progressive training paradigm involving multiple GANs to contribute to the maximum margin ranking loss so that the GAN at later stages will improve upon early stages.
Algebraic Subspace Clustering is limited to equi-dimensional subspaces because the estimation of the subspace dimension via algebraic methods is sensitive to noise.
We extend the traditional binary dropout to continuous dropout, which is closer to the activation patterns of neurons in the human brain than traditional binarydropout.
This paper proposes multi-process training GAN, or MP-GAN for short, which significantly improves the disentangled representation, diversity, and quality of identity-preserving faces.
A probabilistic neural network for uncertainty and confidence estimation of dense stereo matching .
We propose a novel learning algorithm with a Viterbi-based loss that allows for online and incremental learning of weakly annotated video data.
We propose a technique for event recognition in crowded videos that reliably identifies human actions in the presence of partial occlusion and background clutter, with few false positives.
We combine temporal propagation and re-identification functionalities into a single framework that can be trained end-to-end, outperforming the winning solution.
This is an official pytorch implementation of Deep High-Resolution Representation Learning for Human Pose Estimation with a focus on learning reliable high-resolution representations.
We propose a novel algorithm to perform filter pruning by using Multi-Objective Evolution Strategy (ES) algorithm, called DeepPruningES, which can significantly reduce a DNN model's computational complexity.
We show that state-of-the-art domain transfer algorithms still struggle with this task. We propose a dataset that will make it easier to study the detail-invariance problem concretely.
We comprehensively compare the classification/clustering of various redoxins from all domains of life based on their similarity in amino acid sequence, tertiary structure, and their electrostatic properties.
We propose novel end-to-end multimodal ASR systems and compare them to the adaptive approach by using a range of visual representations obtained from state-of-the-art neural networks.
Image Captioning is a task that requires models to acquire a multi-modal understanding of the world and to express this understanding in natural language text. In this work, we address this limitation and train a model that generates more diverse and specific captions through an unsupervised training approach that incorporates a learning signal from an Image Retrieval model.
We show that label noise in the training and/or validation data can lead to various degrees of performance variations in neural architecture search.
We introduce a large-scale synthetic dataset, which is freely and publicly available, and use it to answer several fundamental questions regarding invariance and selectivity properties of convolutional neural networks.
We present W-TALC, a Weakly-supervised Temporal Activity Localization and Classification framework using only video-level labels, which can be utilized to temporally localize the activities.
In this work, we incorporate a human decision-making model in reinforcement learning to control AVs for safe and efficient operations.
We propose a graph-based framework that explicitly models relationships between all seen and novel classes in the joint label space in generalized few-shot learning, enabling fast adaptation and global discrimination.
We identified 172 CVID candidate genes that have similar biological functions to known CVID genes, and eight genes were recently reported as CVID-related genes.
We consider the recent challenges of 3D shape analysis based on a volumetric CNN that requires a huge computational power. In this context, we propose a multiorientation Volumetric deep neural network (MV-DNN) for 3D object classification with octree-based auxiliary learning approach.
We use the recent advances in representation learning to propose a neural architecture for the problem of natural language inference. The model uses variants of Long Short Term Memory (LSTM), attention mechanism and composable neural networks.
A data caching scheme for F-RAN from the social point of view.
We propose a multi-channel neural network structure that adopts a two-stream network structure and use it as a spatiotemporal video feature extractor for solving video question and answering task.
We propose a deep-wide neural network, called ShufflePointNet, to exploit fine-grained local features and reduce redundancy in parallel using group convolution and channel shuffle operation.
We proposed a face recognition algorithm based on both the multilinear principal component analysis (MPCA) and linear discriminant analysis (LDA) based on multidimensional tensor.
We propose Relational Collaborative Filtering (RCF) to exploit multiple item relations in recommender systems.
Exploring the potential of GANs for unsupervised disentanglement learning, we propose a novel framework called OOGAN.
We present a novel global representation of 3D shapes as multi-layered height-maps, suitable for the application of 2D CNNs.
We give a comprehensive overview and key insights into the state of the art of higher dimensional features from deep learning and also traditional approaches.
We develop an accurate deep transfer learning and fine-tuning method for tumor sub-type classification, where predicted class is indicative of the primary site of origin. We achieve state-of-the-art tumor type classification accuracy of 78.3% for 29 tumor classes relying on DNA point mutations only.
We propose the first direct end-to-end multi-person pose estimation framework, which directly predicts instance-aware keypoints for all the instances from a raw input image, eliminating the need for heuristic grouping in bottom-up methods or bounding-box detection and RoI operations.
We propose a novel non-parametric method for cross-modal retrieval which is applied on top of precomputed image and text embeddings which outperforms most existing methods on a challenging image-to-recipe task.
In this paper, we propose a new Independent and Task-Identically Distributed (ITID) assumption, to consider the task properties into the data generating process, to improve practical generalization performance.
 Wikipedia is a free, open and worldwide accessible source of knowledge. It contains more than 150,000 articles of medical content in the form of texts (non-structured information) that can be used in a research context.
We propose the UnBounded output network (UBnet) which is characterized by three features: (1) unbounded output units; (2) the target value of correct classification is set to a value much greater than one; and (3) the models are trained by a modified mean-squared error objective.
We evaluate the robustness of Adversarial Logit Pairing, a recently proposed defense against adversarial examples, and find that the defense achieves 0.6% accuracy.
We propose a novel generative adversarial network based approach, named the Conditional Multi-Adversarial AutoEncoder with Ordinal Regression (CMAAE-OR) for facial aging and rejuvenation.
Unsupervised learning of 3D shapes and pose from single images in a completely unsupervised fashion.
We develop a Mixed-curvature Variational Autoencoder, an efficient way to train a VAE whose latent space is a product of constant curvature Riemannian manifolds, where the per-component curvature can be learned.
We propose an interpretable 3-module system called Explore-Propose-Assemble reader (EPAr) for multi-hop reading comprehension.
From neuroscience findings, a hierarchical four-level dorsal architecture has been designed and implemented for understanding depth cues.
We present a unified and complete view of these algorithms and classify them with respect to three main characteristics.
In this paper, we propose the first deep learning-based colorfulness estimation metric which simultaneously learns to extracts the pertinent characteristic color features and the mapping from feature space to the ideal colorfulness scores.
We propose a novel point tracking algorithm to accurately and efficiently track CoMaL points at the object boundaries that separate multiple objects.
We propose a new framework based on Conditional Generative Adversarial Networks (CGAN), which jointly learns a generator to produce descriptions conditioned on images and an evaluator to assess how well a description fits the visual content.
We propose FCLT - a fully-correlational long-term tracker which localizes the target in each frame and re-detects the target when it is lost.
We propose an alternative formulation of the super-resolution problem based on creating realistic SR images that downscale correctly. PULSE thereby generates high-resolution, realistic images at resolutions previously unseen in the literature.
We present several computational hardness results for consensus maximisation, underlining the fundamental intractability of the problem, and resolve several ambiguities existing in the literature.
In this paper we propose a novel approach named Hierarchical Attention Network (HAN), which enables to incorporate static spatial information, short-term motion information and long-term video temporal structures for complex human action understanding.
We connect existing class-balanced methods for long-tailed classification to target shift, a well-studied scenario in domain adaptation. The connection reveals that these methods implicitly assume that the training data and test data share the same class-conditioned distribution.
This paper devises a new means of filter diversification, dubbed multi-fold filter convolution ( $\mathcal {M}$ -FFC), for face recognition.
We introduce a defensive mechanism called DeepCloak, which limits the capacity an attacker can use generating adversarial samples and therefore increase the robustness against such inputs.
We propose DCCR, a deep collaborative conjunctive recommender, a hybrid architecture that consists of two different kinds of neural network models for rating prediction tasks that are solely based on the raw ratings.
This article proposes U-Det, a resource-efficient model architecture, which is an end to end deep learning approach to solve the task of lung nodule segmentation in computed tomography images.
In this work, we propose a novel salient region detection method that captures, in an unsupervised manner, patterns that are both discriminative and common in the dataset.
We consider the problem of reconstructing a low-rank matrix from a small subset of its entries, using singular value decomposition followed by local manifold optimization.
We investigate the under-studied but practically critical pose model efficiency problem. We present a new Fast Pose Distillation (FPD) model learning strategy capable of executing rapidly with low computational cost.
In this paper, we introduce two coordinated reasoning methods, i.e., the Easy-to-Hard decoding strategy and joint entity alignment algorithm, which address the many- to-one problem and significantly improve existing baselines.
The aim of this paper is to mitigate the shortcomings of automatic evaluation of open-domain dialog systems through multi-reference evaluation, which improves correlation between several automatic metrics and human judgement for both the quality and diversity of system output.
Experience replay (ER) is crucial for attaining high data-efficiency in off-policy reinforcement learning (RL) and we propose a method that relies on systematically Remembering and Forgetting past behaviors (ReF-ER) to improve the effectiveness of ER.
This paper presents a geodesic voting method for tubular tree structure segmentation, using minimal interaction.
We describe a method to train spiking deep networks that can be run using leaky integrate-and-fire (LIF) neurons, achieving state-of-the-art results on five datasets, including the large ImageNet ILSVRC-2012 benchmark.
We propose LogSparse Transformer with only O(L(log L)^2) memory cost, improving forecasting accuracy for time series with fine granularity and strong long-term dependencies.
We propose metrics for measuring the robustness of a neural net and devise a novel algorithm for approximating these metrics based on an encoding of robustness as a linear program.
We address the challenge of localizing certain object classes within an image, using different publicly available virtual-world data, and propose an alternative for collecting such annotations automatically.
A feature-based algorithm for the recognition of textured 3D faces which is robust to shape variation.
We introduce collaborative learning in which multiple classifier heads of the same network are simultaneously trained on the same training data to improve generalization and robustness to label noise with no extra inference cost.
We present a novel Dynamic Differentiable Reasoning (DDR) framework for jointly learning branching programs and the functions composing them in two highly compact and data efficient architectures.
We use the gradient norm to evaluate the impact of a filter on error, and re-initialize filters that have little impact on the prediction.
We address the essential problem of scale inconsistency for self-supervised joint depth-pose learning and achieve state-of-the-art results on KITTI Odometry and NYUv2 dataset.
This paper tackles the task of online video object segmentation with weak supervision, i.e., labeling the target object and background with pixel-level accuracy in unconstrained videos, given only one bounding box information.
A new area-based stereo matching algorithm that computes dense disparity maps for a real-time vision system.
We combine a visual processing approach inspired by colour-opponent theory in humans with recent advancements in one-stage deep learning networks to accurately, rapidly and robustly detect ripe soft fruits (strawberries) in real industrial settings and using standard (RGB) camera input.
We propose a learning model for the task of visual storytelling. The main idea is to predict anchor word embeddings from the images and use them and the image features jointly to generate narrative sentences.
Scale variation is one of the key challenges in object detection. We propose a novel Trident Network (TridentNet) aiming to generate scale-specific feature maps with a uniform representational power.
We propose Residual Attribute Generative Adversarial Network (RAG), a novel model to achieve unpaired editing for multiple facial attributes.
We present a new person re-identification model that combines effective embeddings built on multiple convolutional network layers, trained with deep-supervision, and propose two new formulations of the person reID problem under resource-constraints.
We propose a deep two-branch neural network model for matrix completion. The proposed model not only inherits the predictive power of neural net- works, but is also capable of extending to partially observed samples outside the training set, without the need of retraining or fine-tuning.
We propose a generative framework that tackles video frame interpolation. The framework, which we call deep locally temporal embedding (DeepLTE), is powered by a deep CNN and can be used instantly like conventional models.
In this paper, we propose a novel deep 3D face reconstruction approach that leverages a robust, hybrid loss function for weakly-supervised learning which takes into account both low-level and perception-level information for supervision.
In this paper, we propose to"look into object"(explicitly yet intrinsically model the object structure) through incorporating self-supervisions into the traditional framework for more robust representation learning.
We propose Continuous Growth and Pruning (CGaP), where we start the training from a small network seed, then literally execute continuous growth by adding important learning units and finally prune secondary ones for efficient inference. The inference model generated from CGaP is sparse in the structure.
We study the relationship between the role of deformable parts and the mixture model components within this detector, and understand their relative importance.
A proposed stereo matching algorithm to obtain depth map, enhance and measure.
We propose a novel long-term temporal feature learning architecture for recognizing human action in video, named Pseudo Recurrent Residual Neural Networks.
This paper proposes a novel two-stage defense (NNoculation) against backdoored neural networks (BadNets) that, unlike existing defenses, makes minimal assumptions on the shape, size and location of backdoor triggers and BadNet's functioning.
We utilize an instance segmentation neural network to obtain a class mask for separately filtering the background and foreground of an image.
We propose the TPRU, a recurrent unit that, at each time step, explicitly executes structural-role binding and unbinding operations to incorporate structural information into learning.
We adopt a feature-engineering based approach to tackle the task of speech emotion recognition.
We propose a deep autoencoder with graph topology inference and filtering to achieve compact representations of unorganized 3D point clouds in an unsupervised manner.
We present a 3D Convolutional Neural Networks (CNNs) based single shot detector for spatial-temporal action detection tasks.
This paper proposes RV-SSDH, a deep image hash algorithm that incorporates the classical VLAD (vector of locally aggregated descriptors) architecture into neural networks.
We propose a novel framework that generates segmentation labels of images given their image-level class labels and uses them to learn semantic affinities.
We treat the image generation task using an autoencoder by directly estimating the latent distribution and propose an incremental learning strategy of latent variables.
Multi-task learning of face detection and head pose estimation helps to extract more representative features. We propose a multi-task CNN cascade framework that integrates these two tasks.
A theoretical analysis of batch normalization, where we perform a thorough theoretical analysis on BN applied to a simplified model: ordinary least squares (OLS), where we discover that gradient descent with BN has interesting properties.
We propose a simpler optimization objective based on local matching that combines the content structure and style textures in a single layer of a pretrained convolutional neural network.
In this paper, a range of open-source tools, datasets, and software that have been developed for quantitative and in-depth evaluation of eye gaze data quality, comparing performance of multiple trackers, or studying the impact of various operating conditions on a tracker's accuracy.
Neural network-based systems can now learn to locate the referents of words and phrases in images, answer questions about visual scenes, and even execute symbolic instructions as first-person actors in partially-observable worlds. How do they do it?
We generalize 2D convolution to use a channel-wise sparse connection structure and show that this leads to significantly better results than the baseline approach for large networks including VGG.
We use the Lipschitz Continuity Condition (LCC) to regularize the GAN. The GAN is optimized together with the encoding network in an attempt to make the generator converge to a more ideal and disentangled mapping that can generate samples that look real.
We propose a generative adversarial network method for image inpainting that captures both local continuity of image texture and pervasive global features.
We propose a multisource domain adaptation method that selects and weights the sources based on inter-domain distances.
We propose methods for learning multilingual embeddings using weakly-supervised image-text data, by enforcing similarity between the representations of the image and the text.
We propose the use of parallel convolutional layers in the feature extraction block that are jointly trained with the LSTM based classification network for emotion recognition task.
We address the challenging problem of learning motion representations using deep models for video recognition. To this end, we make use of attention modules that learn to highlight regions in the video and aggregate features for recognition.
Pairwise Alignment Bilinear Network for Few-Shot Fine-Grained Recognition using Meta-Learning .
We cast black box model interpretation as a hypothesis testing problem, and derive a multiple hypothesis testing framework for finding important features that enables control over the false discovery rate.
The stringent requirements for low-latency and privacy of the emerging high-stake applications with intelligent devices such as drones and smart vehicles make the cloud computing inapplicable in these scenarios. Instead, edge machine learning becomes increasingly attractive for training a machine learning model on computation, storage, energy and bandwidth limited mobile devices in a distributed manner.
We propose Consistent Normalization (CN) that retains the advantages of the existing normalization methods, but achieves state-of-the-art performance on various tasks including image classification, segmentation, and machine translation.
In this paper, we propose visibility and disparity magnitude constraints for initialization, propagation, and refinement of stereo images. The proposed constraints increase the probability of estimating correct plane parameters, and lead to improved 3D reconstruction of the scene.
We propose a collaborative adversarial learning approach to face completion, which allows better semantic understanding of a target object through collaborative learning of multiple tasks.
We introduce a regularized continual learning framework that allows an artificial agent initialized with a generic language model to more accurately and efficiently communicate with a partner over time.
The goal of the FRGC is to improve the performance of face recognition algorithms by an order of magnitude over the best results in Face Recognition Vendor Test (FRVT) 2002.
We proposed a generalized approach that can handle Internet of Multimedia Things events as a native event type in event processing engines with high efficiency.
We propose a methodology to aid clinicians in performing lumbar spinal stenosis detection through semantic segmentation and delineation of magnetic resonance imaging (MRI) scans of theLumbar spine using deep learning.
This paper proves that pruning a given layer of the neural network is equivalent to adding a certain amount of differentially private noise to its hidden-layer activations.
In this paper, we enforce an end-to-end 3D Aggregated Faster R-CNN solution by stacking an "aggregated classifier branch" on the backbone of RPN.
We propose a novel multi-task Convolutional Neural Network for large-scale 3D reconstruction from consecutive monocular images.
We propose a state-of-the-art sequential LSTM-based model for inference in natural language, which achieves state of the art results.
An augmented neural network learns to attend to lower-level feature activations without requiring part annotations and uses those activations to update and rectify the output likelihood distribution.
We propose an Information-Distillation Generative Adversarial Network (ID-GAN), a simple yet generic framework that easily incorporates the existing state-of-the-art models for both disentanglement learning and high-fidelity synthesis.
We present a method based on regression forests which can handle head rotations even if they are not included in the training data.
In this paper, we proposed an integrated model of semantic-aware and contrast-aware saliency combining both bottom-up and top-down cues for effective saliency estimation and eye fixation prediction.
We propose a framework for weakly-supervised temporal action localization, which only requires video-level supervision in the form of action category labels and the corresponding count.
Joint Gaussian regularization of latent embeddings of multiple modalities for cross-modal retrieval and phrase localization.
We propose a real-time end-to-end CNN architecture for MOD utilizing spatio-temporal context to improve robustness.
We propose a Two-Round Training approach, aiming to achieve higher generalization accuracy. We locate unfavorable samples after the first round of training, and then retrain the model from scratch.
We study the problem of learning probabilistic first-order logical rules for knowledge base reasoning. We propose a framework, Neural Logic Programming, that combines the parameter and structure learning of first- order logical rules in an end-to-end differentiable model.
We propose a hierarchical approach to address the problem of weakly supervised learning from ordered action labels by structuring recognition in a coarse-to-fine manner by combining a framewise RNN model with a coarse probabilistic inference.
A deep network based on Tucker tensor decomposition, and analyze its expressive power.
We use the Recursive Autoencoder architecture to develop a Cross Lingual Sentiment Analysis (CLSA) tool using sentence aligned corpora between a pair of resource rich (English) and resource poor (Hindi) language.
We present a realtime algorithm that can detect the eyes and the nose tip in 3D face images in about 210 msecs.
In this paper, we present a new perspective towards image-based shape generation. We design new differentiable guidance including the front constraint, the diversity constraint, and the consistency loss.
We introduce a Hetero-Homogeneous Learning (HHL) method to improve the generalization ability of re-ID models on the target testing set.
We propose a novel Riemannian extension of the Euclidean stochastic variance reduced gradient algorithm (R-SVRG) to a compact manifold search space.
We represent natural language semantics by combining logical and distributional information in probabilistic logic. The system is evaluated on the SICK dataset.
We propose improvements to 3D coordinate prediction which avoid the aforementioned undesirable traits by predicting 2D marginal heatmaps under an augmented soft-argmax scheme. Our resulting model produces visually coherent heatmaps whilst maintaining differentiability.
The properties of fragrance molecules in the public databases SuperScent and Flavornet were analyzed to define a “fragrance-like” (FL) property range (Heavy Atom Count ≤ 21, only C, H, O, S, (O + S) ≤ 3) and the corresponding chemical space including FL molecules from PubChem (NIH repository of molecules), ChEMBL (bioactive molecules), ZINC (
In this paper, we explore neural network models that learn to associate segments of spoken audio captions with semantically relevant portions of natural images that they refer to.
This paper proposes a deep regression neural network integrating adaptive multi-attribute fusion method (DRNN-AMAF), which can make the person re-identification process end-to-end.
We describe a model for multi-target tracking based on associating collections of candidate detections across frames of a video. The resulting model with learned parameters outperforms existing methods across several categories on the KITTI tracking benchmark.
We show how a simple convolutional neural network can be trained to accurately and robustly regress 6 degrees of freedom (6DoF) 3D head pose, directly from image intensities.
We study the intrinsic robustness of two common image benchmarks under $\ell_2$ perturbations, and show the existence of a large gap between the robustness limits implied by our theory and the adversarial robustness achieved by current state-of-the-art robust models.
We unify the current dominant approaches for semi-supervised learning to produce a new algorithm, MixMatch, that works by guessing low-entropy labels for data-augmented unlabeled examples and mixing labeled and unl labeled data using MixUp.
This paper is the first systematic study with the main objective of assessing the true effectiveness of embedding models for link prediction when the unrealistic triples are removed.
Iterative clustering with Game-Theoretic Matching for robust multi-consistency image feature matching .
We show that using only the error sign is sufficient to maintain feedback alignment and to provide learning in the hidden layers. We propose the direct random target projection (DRTP) algorithm and demonstrate that, despite the absence of an explicit error feedback, DRTP performance can still lie close to the one of BP, FA and DFA.
In this paper, we present a specific use of the Particle-based Belief Propagation (PBP) algorithm as an approximation scheme for the joint distribution over many random variables with very large or continuous domains.
We propose a technique to accelerate architecture selection by learning an auxiliary HyperNet that generates the weights of a main model conditioned on that model's architecture, allowing us to effectively search over a wide range of architectures at the cost of a single training run.
We propose a two-level merging strategy to construct deep CNNs, referred to as a joint Grouped Merging Net (GM-Net), which can produce joint grouped and reused deep features while maintaining the feature discriminability for classification tasks.
In this paper, we propose a novel way to analyze and measure the robustness of the state of the art models w.r.t semantic visual variations as well as propose ways to make models more robust against spurious correlations.
In this paper, a deep learning network framework based on the low-order residual network is proposed to detect low-contrast defects.
We improve the state-of-the-art tracker MDNet based on channel attention, which can distinguish among similar objects by suppressing the background and highlighting the object.
We contrive a stereo matching algorithm with careful handling of disparity, discontinuity and occlusion.
Statistical Schema Induction can be applied on an RDF dataset to induce domain and range restrictions. We provide results from an experiment on the DBpedia graph.
In this paper, we aim to understand the generalization properties of generative adversarial networks (GANs) from a new perspective of privacy protection.
We develop a multi-channel deep network for block-based image CS with performance significantly exceeding the current state-of-the-art methods.
An end-to-end question answering system that integrates BERT with the open-source Anserini information retrieval toolkit.
In modern computer vision tasks, convolutional neural networks (CNNs) are indispensable for image classification tasks due to their efficiency and effectiveness. Part of their superiority compared to other architectures, comes from the fact that a single, local filter is shared across the entire image.
We propose a simple and effective network, which is named PyramNet, suites for point cloud object classification and semantic segmentation in 3D scene.
This paper proposes a series of lightweight and memory efficient neural architectures for a potpourri of natural language processing (NLP) tasks.
 ATTEND-GAN can generate correlated captions as well as more human-like variability of stylistic patterns.
This study determined the features of line, curve, and ridge structures in images using complex ripplet-I and enabled extraction of blood vessel networks from retinal images through a complex valued articial neural network using those features.
We propose a novel cross-domain point cloud labeling method that leverages the existing massive 2D semantic labeled datasets from decade-long community efforts, such as Image Net and Label Me, and a novel ``cross-domain''.
This paper proposes an object detection network combined with an attention mechanism to accurately locate targets in complex scenarios and achieve real-time detection.
We propose a new supervised method for joint codebook creation and class learning, which learns the cluster centers of the codebook in a goal-directed way.
In this paper, a quaternion principal component analysis network (QPCANet), which extends PCANet by using quaternian theory, is proposed for color image classification.
We propose novel stochastic gradient algorithms for Riemannian matrix manifolds by adapting the row and column subspaces of gradients.
We propose a real-time method for odometry and mapping using range measurements from a 2-axis lidar moving in 6-DOF, achieving state of the art performance.
We present an architecture that computes continuous global 6-DoF poses throughout joint 2D landmark estimation and 3D pose reconstruction. The architecture, which does not rely on intrinsic camera parameters, can be applied to all surveillance cameras.
We propose a novel EBM trained with multi-scale denoising score matching, which achieves data generation performance comparable to state-of-the-art techniques.
Facial expressions are one of the most powerful, natural and immediate means for human being to communicate their emotions and intensions. Recognition of facial expression has many applications including human-computer interaction, cognitive science, human emotion analysis, personality development etc.
We propose Cross-Dataset Data Augmentation and demonstrate its feasibility over a concrete case study.
This paper presents cost-efficient remedies: a selection mechanism increases the precision of document retrieval and a fused approach to transfer learning improves the performance of answer extraction.
This paper demonstrates that a mesh representation (i.e. vertices and faces to form polygonal surfaces) is able to capture fine-grained geometry for 3D reconstruction tasks. We address this problem by proposing a learning framework to infer the parameters of a compact mesh representation rather than learning the mesh itself.
We present an approach with a novel differentiable flow-to-depth layer for video depth estimation, which improves state-of-the-art depth estimation methods.
Is it possible to "remove" data from a machine-learning model, which implicitly stores information about its training data, should be affected by such a removal request?
We propose to use the temporal redundancy in natural video to avoid unnecessary computation on most frames. We use an adaptive key frame rate to control the trade-off between efficiency and vision quality.
This paper introduces the problem of organizing the attributes by expressing the compositional structure of their names as a rule-based grammar. The paper describes an unsupervised learning method to generate such a grammar automatically from a large set of attribute names.
We propose a method of incorporating high-level semantic concepts into the CNN-RNN approach, and show that it achieves a significant improvement on the state-of-the-art performance in both image captioning and visual question answering.
In this paper, we demonstrate how deep binary networks can be accelerated in modified von Neumann machines by enabling binary convolutions within the static random access memory (SRAM) arrays.
We present consistent optimization for single stage object detection. Consistent optimization focuses on matching the training hypotheses and the inference quality by utilizing of refined anchors during training.
Data augmentations are an important ingredient in the recipe for training robust neural networks, especially in computer vision. We introduce a systematic approach to investigate which layers of neural networks are the most predictive of augmentation transformations.
We present the first application-oriented image matching benchmark to facilitate the analysis of matching algorithms in application level, on which state-of-the-art matchers (local features with correspondence selection methods) are exhaustively evaluated and analyzed.
How can we understand classification decisions made by deep neural nets? We propose answering this question by using ideas from causal inference to measure the causal effect that the presence or absence of a concept has on the prediction of a given neural net.
This work presents an approach to incrementally build volumetric object-centric maps during online scanning with a localized RGB-D camera using instance-aware semantic predictions.
A novel joint Spatial and Temporal Attention Pooling Network for video-based person re-identification, which enables the feature extractor to be aware of the current input video sequences, in a way that interdependency from the matching items can directly influence the computation of each other's representation.
Subspace-based holistic registration is introduced as an alternative to landmark-based face registration, which has poor performance on low-resolution images.
We introduce the contrastive variational autoencoder (cVAE), which combines the benefits of contrastive learning with the power of deep generative models. The cVAE is designed to identify and enhance salient latent features.
In this work, we introduce Video Question Answering in temporal domain to infer the past, describe the present and predict the future.
We present a method for weakly-supervised action localization based on graph convolutions that uses similarity graphs to explicitly model similarity between video moments.
We propose a unified, systematic framework of structured weight pruning for DNNs without loss of accuracy, along with fast convergence rate.
A mathematical model to capture and distinguish the latent structure in the articulation of questions is presented. We extend this model to iteratively refine clusters of questions based on latent articulation.
A lidar odometry method, integrating into the computation the knowledge about the physics of the sensor, is proposed.
We propose a novel approach to tackle the two tasks by a joint ASR and SD system using a recurrent neural network transducer. Our approach utilizes both linguistic and acoustic cues to infer speaker roles.
This paper builds upon prior research by proposing a modified ResNet architecture with calibrations that permit us to train networks that are deeper than previously published approaches. Interpretation suggests that this deeper architectures allows the network to take more contextual information into consideration, which helps to improve classification accuracy and generalizability.
In recent years, convolutional neural networks (CNN) have played an important role in the field of deep learning. However, there are two big drawbacks to CNN's: their failure to take into account of important spatial hierarchies between features, and their lack of rotational invariance. To address this concern, Hinton et al propose a novel type of neural network using the concept of capsules in a recent paper.
In order to achieve crowd counting by edge computing (in embedded terminals), we propose a tiny model based on convolutional neural networks.
We introduce Interactive Differentiable Simulation (IDS), a differentiable physics engine that allows for efficient, accurate inference of physical properties of rigid-body systems. Integrated into deep learning architectures, our model is able to accomplish system identification using visual input, leading to an interpretable model of the world whose parameters have physical meaning.
We propose a novel architecture that learns an end-to-end mapping function to improve the spatial resolution of the input natural images, achieving comparable or better PSNR than them.
We propose to learn the coexistence discriminative features for multi-class object detection.
We develop Personalized Attention Network (PANet), a convolutional network that predicts saliency in images with personal preference.
We propose a new Self-reflective Risk-aware Artificial Cognitive (SRAC) model that allows co-robots to consider action risks and identify new situations so that better decisions can be made in response to human activities.
A novel multi-scale re-identification model that learns discriminative feature representations at different scales and automatically determines the most suitable scales for matching.
We present a method to learn object detectors incrementally, when neither the original training data nor annotations for the original classes in the new training set are available.
We show that humans often miss targets when their size is inconsistent with the rest of the scene, even when the targets were made larger and more salient.
We present the MAC network, a novel fully differentiable neural network architecture, designed to facilitate explicit and expressive reasoning.
Adaptive gradient methods, which adopt historical gradient information to automatically adjust the learning rate, despite the nice property of fast convergence, have been observed to generalize worse than stochastic gradient descent (SGD) with momentum in training deep neural networks.
We have developed a protocol to predict protein-protein interactions using sequence homology data and a reference Human interactome. Then, using Neo4j as our database manager, we developed PlanNET, a web application to explore the multiplicity of networks and the associated sequence annotations.
We propose a graph-based approach to extract evidence from both structured and unstructured knowledge sources, and answer questions based on the extracted evidence.
We propose two approaches to dependency parsing especially for languages with restricted amount of training data. Our first approach combines a state-of-the-art deep learning-based parser with a rule-based approach and the second one incorporates morphological information into the parser.
We present a generative model for multitask conditional language generation. We instantiate this latent variable in a latent variable sequence-to-sequence model in a task embedding space.
We adapted the join-training scheme of Faster RCNN framework from Caffe to TensorFlow as a baseline implementation for object detection.
ComQA is a three-phase KBQA framework by which end-users can ask complex questions and get answers in a natural way.
We propose a novel deep learning network architecture called Structural Inference Embedded Adversarial Networks for pixel-wise scene labeling.
We propose a novel conditional GAN (cGAN) model for continuous fine-grained human action segmentation, that utilises multi-modal data and learned scene context information.
We derive a categorization of eight semantic image-text classes (e.g., "illustration" or "anchorage") and show how they can systematically be characterized by a set of three metrics: cross-modal mutual information, semantic correlation, and the status relation.
An assessment of the suitability of a recently invented spatially adaptive contrast enhancement technique for enhancing retinal fundus images for blood vessel segmentation.
We propose a method for learning discriminative category-level features in a principled probabilistic manner and demonstrate state-of-the-art results on large-scale action recognition in video.
This paper proposes a framework incorporating deep-learned features with the conventional machine learning models within which the objective function is optimized by using quadratic programming or quasi-Newton methods instead of an end-to-end deep learning approach.
We propose Poseidon, a scalable system architecture for distributed inter-machine communication in existing DL frameworks that accelerates DNN training on commodity GPU clusters.
In this paper, we propose an algorithm that recovers binocular disparities in accordance with the surface properties of the scene under consideration.
We investigate training Generative Adversarial Networks, GANs, with less data and measure the additive value of generator ensembles.
In this paper, we propose Double Supervised Network with Attention Mechanism (DSAN), an end-to-end trainable framework for scene text recognition.
In this article, we propose a new method for principal component analysis (PCA), whose main objective is to capture natural “blocking” structures in the variables.
We propose a novel framework for semantic bilinear pooling for fine-grained recognition with hierarchical multi-label learning.
We derive a correspondence between parameter inference and free energy minimisation in statistical physics, where wide but shallow minima can be optimal if the system is undersampled.
We address the problem of fine-grained classification and image retrieval by leveraging textual information along with visual cues to comprehend the existing intrinsic relation between the two modalities.
A transfer learning based approach for semantic person identification and semantic person search.
We study the task of image inpainting, which is to fill in the missing region of an incomplete image with plausible contents.
We propose a framework for adversarial training that relies on a sample rather than a single sample point as the fundamental unit of discrimination.
We introduce a design strategy for neural network macro-architecture based on self-similarity. Repeated application of a simple expansion rule generates deep networks whose structural layouts are precisely truncated fractals.
A recurrent neural network-based system learns end-to-end learning of motion policies suited for active category recognition, by simultaneously learning to forecast the effects of the agent's motions on its internal representation.
We address the problem in its entirety and propose a complete system for real-time aerial cinematography that combines: (1) vision-based target estimation; (2) 3D signed-distance mapping for occlusion estimation;(3) efficient trajectory optimization for long time-horizon camera motion; and (4) learning-based artistic shot selection.
We compared and contrasted a variety of state-of-the-art visual representations using synthetic recognition tasks designed to systematically probe invari-ance.
We propose a method to mine the cross-modal rules to help the model infer these informative concepts given certain visual input.
We propose a new architecture search method that adapts and attunes to the computation resources (budget) available by varying the exploration vs. exploitation trade-off. We reduce the expert bias by searching over an augmented search space induced by Superkernels.
We address the problem of novel view synthesis: given an input image, synthesizing new images of the same object or scene observed from arbitrary viewpoints, we learn to copy them from the input image.
In this paper, we propose a novel network structure, Interaction-and-Aggregation (IA), to enhance the feature representation capability of CNNs.
We propose a computationally feasible discriminative ternary census transform histogram (DTCTH) for image representation which uses dynamic thresholds to perceive the key properties of a feature descriptor.
In this paper, targeted fooling of high performance image classifiers is achieved by developing novel attack methods.
We use Generative Adversarial Networks (GANs) for synthesizing high quality retinal images, along with the corresponding semantic label-maps, to be used instead of real images during the training process.
In this paper, we tackle the challenging one-shot semantic segmentation problem by taking advantage of objectness. In order to capture prior knowledge of object and background, we first train an objectness segmentation module which generalizes well to unseen categories.
In this paper, we propose Dense Steerable Filter CNNs (DSF-CNNs) that use group convolutions with multiple rotated copies of each filter in a densely connected framework for histology image analysis.
We extend the sequence-to-sequence model augmented with pointer generator network for neural abstractive summarization of (arbitrarily) long texts.
In recent saliency detection research, many graph-based algorithms have applied boundary priors as background queries, which may generate completely "reversed" saliency maps if the salient objects are on the image boundaries. Moreover, these algorithms usually depend heavily on pre-processed superpixel segmentation, which leads to notable degradation in image detail features.
We propose an improved Variantial Autoencoder model to extract the features with a high connection to the coming scenarios, also known as Predictive Learning.
We propose a robust point cloud registration method for ground vehicles using iterative closest point (ICP) algorithm.
Data-to-text generation models face challenges in ensuring data fidelity by referring to the correct input source. We introduce a purified and larger-scale dataset, RotoWire-FG (Fact-Grounding), with 50% more data from the year 2017-19 and enriched input tables.
In this paper, we propose an image representation based on the detection images from a large number of windowed object detectors where an image is represented by different statistics derived from these detections.
In this paper we present a technique for efficiently producing disparity maps using a novel optimization framework in which inference is performed in “bilateral-space”.
In this paper, we formulate a novel graph-based learning problem, multi-graph classification (MGC), which aims to learn a classifier from a set of labeled bags each containing a number of graphs inside the bag.
This paper presents the first certified defense that both scales to large networks and datasets (such as Google's Inception network for ImageNet) and applies broadly to arbitrary model types.
We introduce a new 2D convolutional temporal stream that is trained end-to-end with a neural network. The flexibility to freeze some network layers from training in this temporal stream brings the possibility of ensemble learning.
We propose a novel nested sparse network, which exploits an n-in-1-type nested structure in a neural network. The proposed framework realizes a resource-aware versatile architecture as the same network can meet diverse resource requirements.
In this paper, we present a novel methodology based on a reinforcement learning formulation to accelerate instructional videos to produce shorter versions that convey the same information without creating gaps in the final video.
This paper proposes a new cost-aggregation module to compute the matching responses for all the image pixels at a set of sampling points generated by a hierarchical clustering algorithm.
We propose a novel going-back-to-the-basic solution which straightforwardly models the MRC relationship as attention mechanism inside network, which is capable of generally promoting pre-trained Language Models.
In this paper, new subspace learning techniques are presented that use symmetry constraints in their objective functions.
We investigate the cause and provide experiments to shows that the skip-layer connections in FCN can promote flat optimization landscape, which is well known to generalize better.
In this paper, we propose a novel approach to depth map prediction from monocular images that learns in a semi-supervised way. We also enforce our deep network to produce photoconsistent dense depth maps in a stereo setup using a direct image alignment loss.
In this paper, we explore the overthinking problem, and, as a remedy, we propose a generic modification to off-the-shelf DNNs---the Shallow-Deep Network (SDN). With this modification, a DNN can efficiently produce predictions from either shallow or deep layers, as appropriate for the given input.
This work investigates group-level expression recognition on crowd videos where information is not only aggregated across a variable length sequence of frames but also over the set of faces within each frame to produce aggregated recognition results.
This paper proposes an Agile Aggregating Multi-Level feaTure framework (Agile Amulet) for salient object detection, which improves training and testing speed while also increase prediction accuracy.
The entorhinal-hippocampal circuit as a variant locality-sensitive hashing algorithm is capable of generating sparse encoding for easily distinguishing different locations in the environment.
We propose CROSS, Controllable Sentence Simplification model, which allows to control both the level of simplicity and the type of the simplification, offering flexible generation output.
We propose a new model involving a non-local fitting term, in the Chan-Vese framework, for tubular object segmentation.
CrossE, a novel knowledge graph embedding which explicitly simulates crossover interactions, achieves state-of-the-art results.
We present a solution for the goal of extracting a video from a single motion blurred image to sequentially reconstruct the clear views of a scene as beheld by the camera during the time of exposure.
This paper leverages recent advances in stochastic gradient Markov Chain Monte Carlo (also appropriate for large training sets) to learn weight uncertainty in RNNs.
We propose a joint model that learns to identify object states and to localize state-modifying actions, and introduce new optimization techniques to learn model parameters without additional supervision.
A novel deep learning-based model with multiple strategies is proposed for the precise diagnosis of the malignant nodules in lung cancer diagnosis.
We propose a two-part network consisting of a DNN-based architecture followed by a Conditional Random Field (CRF) module for facial expression recognition in videos.
Generating diverse yet specific data is the goal of the generative adversarial network (GAN), but it suffers from mode collapse. We introduce the concept of normalized diversity which force the model to preserve the normalized pairwise distance between the sparse samples from a latent parametric distribution and their corresponding high-dimensional outputs.
We propose Single-Path NAS, a novel differentiable NAS method for designing hardware-efficient ConvNets in less than 4 hours.
We use three dimensional deep convolutional neural networks with shortcut connections and an ensemble method to capture 3D features of nodules.
We propose a novel and efficient way to obtain discriminative appearance-based tracklet affinity models in a complex scene captured by a single camera.
We propose an effective transforming paradigm and a customized gradient transformer module to transform existing perturbations into regionally homogeneous ones.
In this paper, we propose a novel approach to learn domain adaptive features between largely-gapped source and target domains with unlabeled domain bridges.
We define the new task of 3D controllable image synthesis and propose an approach for solving it by reasoning both in 3D space and in the 2D image domain.
We proposed an unsupervised monocular vision stereo matching method. The output results of this method outperforms the current mainstream monocular depth estimation method in the challenging KITTI dataset in the test phase.
A perspective-aware convolutional neural network for efficient crowd counting, which integrates the perspective information into density regression to provide additional knowledge of the person scale change in an image.
We propose a completely unsupervised deep learning procedure based solely on video sequences, which starts from scratch without requiring pre-trained networks, predefined body models, or keypoints.
In this paper we present seven techniques that everybody should know to improve example-based single image super resolution (SR): augmentation of data, 2) use of large dictionaries with efficient search structures, 3) cascading, 4) image self-similarities, 5) back projection refinement, 6) enhanced prediction by consistency check, and 7) context reasoning.
Observation learning is the process of learning a task by observing an expert demonstrator. We present a robust observation learning method for robotic systems.
In this paper, we propose a fast and effective multi-view nearest-subspace classifier (MV-NSC) by taking advantage of both the two relationships simultaneously.
In this paper we propose a generic framework to incorporate unobserved auxiliary information for classifying objects and actions.
We develop a rigorous theory based on the neuron activation subspace match model and propose efficient algorithms to find the maximum match and simple matches.
In this paper, we propose a computationally efficient approach to fuse several hand-crafted and deep features, based on the probabilistic distribution of a given membership score of a constrained cluster in an unsupervised manner, for image retrieval.
We propose an end-to-end framework for automatic attributes tagging and analysis of sport videos by segmenting the points played, tracking and recognizing the players in each point and annotating the strokes.
The survey introduced in this paper tries to cover the lack of a complete description of the most important public datasets for video-based human activity and action recognition.
Color provides useful and important information for object detection, tracking and recognition, image (or video) segmentation, indexing and retrieval, etc.
We treat counting as a sequential decision process and force our model to make discrete choices of what to count.
We propose OSH: an Online Supervised Hashing technique that learns and adapts its hashing functions in a discriminative manner.
We propose a unified eyeglass removal model called Eyeglasses Removal Generative Adversarial Network (ERGAN), which could handle different types of glasses in the wild.
We focus on the task of Visual Question Answering (VQA) and propose a system that uses Visual Question Generation to produce questions, asks them to social media users, and collects their responses as data.
Open Science is an umbrella term encompassing a multitude of assumptions about the future of knowledge creation and dissemination. Based on a literature review, this chapter proposes five Open Science schools of thought.
We generalize the notion of gauge frames on images to gauge frames in differential invariants and crossing preserving PDE-flows acting on extended data representations in the roto-translation group.
A general autoencoder-based architecture for lossy geometry point cloud compression.
We investigated whether perceptually-relevant internal noise arises in early visual areas or later decision making areas, and how Birdsall's linearisation can resolve it.
We propose a fast neural network adaptation method FNA, which can adapt the manually designed network on ImageNet to the new seg/det tasks efficiently.
A dual-graph attention network that learns to use primary and subsidiary relations to improve inference: encouraging the right interpretations and discouraging incorrect ones.
A recently introduced latent feature learning technique for time-varying dynamic phenomena analysis is the so-called slow feature analysis (SFA) and we propose a number of extensions in both the deterministic and probabilistic SFA optimization frameworks.
We investigate the effect of utilizing information not only from the final layer but also from intermediate layers ofa pre-trained language representation model to detect grammatical errors.
In this paper, we present a novel approach for contour detection with Convolutional Neural Networks. We show the proposed CNN is able to to detect large-scale contours in an image efficienly.
We consider whether appearance similarities can also be learnt in a distributional mode. As grounds for such a mode we advance the Appearance Hypothesis that ‘words of similar meaning tend to occur in similar contexts’.
The retinal image diagnosis is an important methodology for diabetic retinopathy detection and analysis. in this paper, the morphological operations and svm classifier are used to detect and segment the blood vessels from the Retinal image.
A novel GAN-based network based on Retinex theory for low-light image enhancement.
We introduce the first RC system for languages without RC training data that leverages existing RC resources in the pivot language by combining a competitive RC model with an attentive Neural Machine Translation (NMT) model.
In this paper, we propose an efficient method to use Gaussian RBM for learning motion-difference features from actions in videos.
In this paper we address three different aspects of semantic segmentation from remote sensor data using deep neural networks. Firstly, we explore the relationship of the classification accuracy to the reconstruction accuracy and propose ICT-Net.
We present a new approach to rigid-body motion segmentation from two views. We use a previously developed nonlinear embedding of two-view point correspondences into a 9-dimensional space and identify the different motions by segmenting lower-dimensional subspaces.
We propose a separable spatio-temporal attention mechanism for video-based action recognition, which leads to state-of-the-art performance.
This paper proposes a novel transition system, arc-swift, that enables direct attachments between tokens farther apart with a single transition.
We investigate a new perspective of facial landmark detection that leverages style and shape space of each individual to augment existing structures via style translation.
We develop a new perspective on the equivariance approach by noting that dense landmark detectors can be interpreted as local image descriptors equipped with invariance to intra-category variations. We then propose a direct method to enforce such an invariance in the standard equivariant loss.
We tackle a novel few-shot learning challenge, which we call few- shot semantic edge detection, aiming to localize crisp boundaries of novel categories using only a few labeled samples. We also propose a new regularization method based on multi-split matching.
We propose a new local descriptor, local directional-structural pattern (LDSP), for facial expression recognition with explicit representation of expression-affiliated features along with the exclusion of random futile textures.
The incorporation of pseudo data in the training of grammatical error correction models has been one of the main factors in improving the performance of such models. However, consensus is lacking on experimental configurations, namely, choosing how the pseudo data should be generated or used.
We propose a convolutional block which extracts spatial information by performing a 2D convolution and extracts temporal information by exploiting temporal differences, using simple operations of shift, subtract and add without utilizing any trainable parameters.
We propose a transfer learning method that uses model-based rewards transferred from tasks that directly compare the similarity of sentence pairs to improve on semantical evaluation measures.
Automatic abnormality detection in video surveillance by using multiple features and cascade classifiers, yet achieve above real-time processing speed.
The aim of the proposed study is to assess the uncertainties introduced in the vessel width measurements when choosing a specific distribution as an intensity profile model.
This paper proposes a new methodology for computing Hausdorff distances between sets of points in a robust way.
Funding: This work is supported by the French regional council of Grand-Est and the European regional development fund-FEDER. Acknowledgments:
A large-scale dataset for human tracking, activity recognition and anticipation of multiple persons in captured 3D environments.
We present a novel method for 3D surface reconstruction from an input cloud of 3D points augmented with visibility information. We observe that it is possible to reconstruct surfaces that do not contain input points.
We propose ResNet-50, a CNN model that combines several techniques to improve the accuracy and robustness of a basic CNN model while minimizing the loss of throughput.
We propose the first deep learning solution to video frame inpainting, a more challenging but less ambiguous task than related problems such as general video inPainting, frame interpolation, and video prediction.
We present a detailed study of the part of the Web related to media content, i.e., the Media Web, and propose a new class of models for the appearance of new media content on the Web where different \textit{attractiveness} functions of nodes are possible including ones taken from preferential attachment and fitness models.
We propose a 2D convolutional network for sequential recommendation that captures pairwise relationships and achieves state-of-the-art performance on various evaluation metrics.
We propose a new neural network module suitable for CNN-based high-level tasks on point clouds, including classification and segmentation. It incorporates local neighborhood information.
A novel Non-negative Sparse and Collaborative Representation (NSCR) based classifier for pattern classification.
Inspired by the success of compositional models and DCNNs at classifying partially occluded objects, we propose a unified deep model with innate robustness to partial occlusion.
In this article, the graph convolutional networks are integrated into the object detection framework to exploit the benefit of category relationship among objects, which is able to provide extra confidence for any pre-trained object detection model in our framework.
We propose Spatial-Aware Non-Local (SANL) block, an attentive module in deep neural network which can utilize spatial information while capturing global dependency.
We describe the implementation of reranking models for fine-grained opinion analysis, allowing us to model complex relations between multiple opinions in a sentence.
We present Context Forest (ConF), a technique for predicting properties of the objects in an image based on its global appearance.
We propose a new feature learning algorithm, Multi-Task Autoencoder (MTAE), that provides good generalization performance for cross-domain object recognition.
We propose Curve-GCN, a graph convolutional network for polygon-RNN, and it outperforms all existing approaches in automatic and interactive mode.
We introduce completion moment detection for actions - the problem of locating the moment of completion, when the action's goal is confidently considered achieved.
We propose Lattice-LSTM (L2STM), an end-to-end system that extends LSTM by learning independent hidden state transitions of memory cells for individual spatial locations for long-term motion dynamics.
We propose a method that learns a 3D human pose from 2D joint locations in a single image in an unsupervised manner.
We propose a method, called Label Embedding Network, which can learn label representation (label embedding) during the training process of deep networks.
An increasing number of software applications incorporate runtime Deep Neural Network inference for its great accuracy in many problem domains. To address this need, we propose ALERT, a co-designed combination of runtime system and DNN nesting technique, and use dynamic feedback to predict the best DNN-model and system power-limit setting.
A comparison of cross-modal retrieval methods for multimodal data.
We propose a novel method for image inpainting based on a Deep Convolutional Generative Adversarial Network (DCGAN).
We propose to encode relational knowledge in a separate word embedding, which can be used even when no external knowledge base is available.
We propose a Context-aware Scale Aggregation CNN-based Crowd Counting method (CASA-Crowd) to obtain the deep, varying scale and perspective varying features.
Evolutionary-based optimization approaches have recently shown promising results in domains such as Atari and robot locomotion but less so in solving 3D tasks directly from pixels. This paper presents a method called Deep Innovation Protection that allows training complex world models end-to-end.
A stereo approach to resolve the occlusion problem in stereo video sequence using a temporal propagation procedure.
We propose a method for pointwise semantic classification of 3D LiDAR data into three classes: non-movable, movable and dynamic.
We address the problem of segmenting an object given a natural language expression that describes it. We propose a novel method that integrates these two insights in order to fully exploit the recursive nature of language.
An empirical study on the impact of negative sampling on knowledge graph embeddings, assessed through the task of link prediction. We compare well known methods for negative sampling and propose embedding based sampling methods.
This study presents methods to 2-D registration of retinal image sequences and 3-D shape inference from fluorescein images.
A new dataset REPresentAtion bIas Removal (REPAIR) procedure is proposed to reduce the representation biases of datasets.
We propose SAST, a novel segmentation-based text detector, which employs a context attended multi-task learning framework based on a Fully Convolutional Network to learn various geometric properties for the reconstruction of polygonal representation of text regions.
We combine ideas from shock graph theory with more recent appearance-based methods for medial axis extraction from complex natural scenes, improving upon the present state-of-the-art, excelling particularly in the high-precision regime.
We study the influence of a set of blind pre-processing methods on the face detection rate using the Viola-Jones algorithm. We propose three simple and fast blind photometric normalization methods as a pre-training step in order to improve the accuracy of the pre-trained Viola Jones face detector.
We propose a method for semi-supervised semantic segmentation that leverages the information present in the unlabeled images and uses it as a supervision signal.
We propose a novel pruning in-training method that prunes a network real-time during training, reducing the overall training time to achieve an optimal compressed network.
We propose Deep Back-Projection Networks (DBPN), the winner of two image super-resolution challenges (NTIRE2018 and PIRM2018), that exploit iterative up- and down-sampling layers.
As the use of technology increases and data analysis becomes integral in many businesses, the ability to quickly access and interpret data has become more important than ever. To reduce some of the burden on already overstretched data teams, many organizations are looking for tools that allow non-developers to query their databases.
We propose a novel architecture capable to quickly infer an accurate depth map on a CPU, even of an embedded system, using a pyramid of features extracted from a single input image.
We review research works that address this difference and generatetextual adversarial examples on DNNs.
We make a systematic study on using artificial attention and human attention in neural network design in computer vision tasks.
In this paper, we introduce a new convolutional layer named the Temporal Gaussian Mixture (TGM) layer and present how it can be used to efficiently capture temporal structure in continuous activity videos.
We present a convolutional neural network for semantic segmentation and object recognition with 3D point clouds.
We present a GAN-based framework for learning from complex, high-dimensional incomplete data.
We evaluate S3DCNN on a large-scale 3D Shape benchmark, and measure how it is impacted by voxel resolution of input shape.
We introduce an unsupervised domain adaptation method, which is especially suitable for unlabelled small target dataset and use the GAN generated samples to fine-tune the model pretrained on source dataset.
In this paper, we propose a novel efficient network pruning method that is suitable for both non-structured and structured channel-level pruning.
Convolutional neural nets can focus the attention on a specific region of the image while still extracting contextual cues from the background.
We analyze this question in the context of eBird, a large fine-grained classification dataset, and a state-of-the-art deep network classification algorithm. We find that peak classification performance on well-represented categories is excellent.
We propose a novel unsupervised image denoising model with a pixel-wise uncertainty loss, which can be applied to any image dataset.
Deep Learning Library (DLL) is a library for machine learning with neural networks that focuses on speed.
We propose to incorporate generative processes into the cross-modal feature embedding, through which we are able to learn not only the global abstract features but also the local grounded features.
This paper introduces a method for scene categorization by modeling ambiguity in the popular codebook approach, where the frequency distributions of these words are used for image categorization.
We present NOLBO, a variational observation model estimation for 3D multi-object from 2D single shot and propose a method to approximate the Bayesian observation model of scene-level 3D Multi-object understanding.
We propose a novel normalization method that normalizes exclusively across channels, which allows us to capture structural information of the input image in the first and second moments, which improves the performance of deep neural networks.
Higher quality training data for End-to-End cascade network training, which give computers more space to automatic adjust weight parameter and accelerate convergence.
We propose a new optical-flow based training paradigm which reduces the difficulty of unsupervised learning by providing a clearer training target and handles the non-texture regions.
We propose a novel regression-based approach that first learns a number of experts describing relationships in ratings between pairs of items and uses statistical methods to predict the user’s preferences for the remaining items.
We propose Voxel-FPN, a novel one-stage 3D object detector that utilizes raw data from LIDAR sensors only, obtaining good performance on both speed and accuracy in real-world scenarios.
X-View leverages semantic graph descriptor matching for global localization of multi-view robot data, enabling localization under drastically different view-points.
A convolutional neural network model for unsupervised learning of depth and ego-motion from cylindrical panoramic video.
We propose a novel Cross-layer Feature Pyramid Network (CFPN), in which direct cross-layer communication is enabled to improve the progressive fusion in salient object detection.
This paper proposes RIU-Net (for Range-Image U-Net), the adaptation of a popular Semantic Segmentation network for the semantic segmentation of a 3D LiDAR point cloud.
Generative modelling is often cast as minimizing a similarity measure between a data distribution and a model distribution. Recently, a popular choice for the similarity measure has been the Wasserstein metric, which can be expressed in the Kantorovich duality formulation as the optimum difference of the expected values of a potential function under the real distribution and the model hypothesis.
We present MVDepthNet, a convolutional network to solve the depth estimation problem given several image-pose pairs from a localized monocular camera in neighbor viewpoints.
We propose S2E to distill structural information and combine it with semantic information for different KGs as a neural architecture search (NAS) problem and propose a recurrent network-based search space.
We investigate the non-identifiability issues associated with bidirectional adversarial training for joint distribution matching and propose both adversarial and non-adversarial approaches to learn desirable matched joint distributions.
AutoRemover is a video inpainting algorithm for generating street-view videos without any moving objects.
We propose an effective complementary tracker based on structural patch response fusion under correlation filter and color histogram models for part-based visual tracking.
In this paper we introduce two measures based on image classification---GAN-train and GAN-test, which approximate the recall (diversity) and precision (quality of the image) of GANs respectively.
A bio-inspired method to calculate binocular disparity based on energy model for depth perception of real world images is described and implemented.
In this work, we propose a 2D-PCA based face recognizer as a semi-automatic tool for helping indexing people in historical photographs.
We propose BatchChannel Normalization (BCN), which uses batch knowledge to avoid the elimination singularities in the training of channel-normalized models.
We present a new visual forecasting task called crowd density forecasting, which enables forecasting over a sequence of crowd density maps describing how crowded each location is in each video frame.
Image warping is a necessary step in many multimedia applications such as texture mapping, image-based rendering, panorama stitching, image resizing and optical flow computation etc.
We propose the EmoRL model that triggers an emotion classification as soon as it gains enough confidence while listening to a person speaking.
We propose a two-stage Fully Separable Block (FSB) to significantly compress the model sizes of 3D ConvNets. Then a feature enhancement approach named Temporal Residual Gradient (TRG) is developed to improve the performance of compressed model on video tasks, which provides higher accuracy, faster convergency and better robustness.
We propose to improve the estimation of tail ratings by extending traditional single latent representations (e.g., an item is represented by a single latent vector) with multi-latent representations for better modeling these tail ratings.
We propose SimVODIS, a neural architecture that simultaneously performs both geometric and semantic tasks in a single thread.
We propose a novel idea of leveraging attribute semantic space to capture different granularity of similarity, and then integrate this information into deep metric learning.
We present a computer vision tool that analyses video from a CCTV system installed on fishing trawlers to monitor discarded fish catch and verify numbers, species and sizes of discarded fish.
We propose a direct perception approach which maps video input to intermediate representations suitable for autonomous navigation in complex urban environments given high-level directional inputs.
We propose a fast bottom-up multi-face alignment approach, which can simultaneously localize multi-person facial landmarks with high this http URL more detail.
We propose a principled Topic-Aware Mixture of Experts (TAMoE) model for zero-shot video captioning, which learns to compose different experts based on different topic embeddings, implicitly transferring the knowledge learned from seen activities to unseen ones.
We propose discriminative adversarial networks (DAN) for semi-supervised learning and loss function learning.
We propose a novel unified robust tracking framework which explicitly encodes both generic features and category-based features for tracking.
This paper proposes an object detection framework based on Faster R-CNN that introduces a feature fusion network and an adversary occlusion network into the structure. The two compete with and learn from each other to further improve the performance of the algorithm.
An automatic method for data collection of structured visual facts from images with captions.
This paper proposes a dynamic fusion framework to utilize the potential advantages of the complementary spectrogram-based statistical features and the auditory-based empirical features for speech emotion recognition.
We present a new approach to extraction of hypernyms based on projection learning and word embeddings and show that explicit negative examples used for regularization of the model significantly improve performance.
An image is a very effective tool for conveying emotions. In this paper, we focus on two high level features, object and the background, and assume that the semantic information of images is a good cue for predicting emotion.
This paper targets at learning to score the figure skating sports videos. To address this task, we propose a deep architecture that includes two complementary components, i.e., Self-Attentive LSTM and Multi-scale Convolutional Skip LSTMs.
In this paper, we propose a new active contour model that uses hybrid region information of the image to approach this problem.
We present a 3D car tracking method that combines more data from different sensors (cameras, Lidar, GPS/IMU) to track static and dynamic cars in a3D bounding box.
We propose a CNN-based approach that takes MIP images of different slab thicknesses (5 mm, 10 mm, 15 mm) and 1 mm axial section slices as input.
We propose a simple approach to generate a synthetic dataset with minimum human effort for object instance detection in cluttered indoor environment.
Fuzzy gradient-based feature extractors can better represent the fuzziness of spatio-temporal visual information.
We applied several computational tools to analyze the bibliographic information of published articles in systems biology to answer the question: Did the research topics of systems biology become more biology-oriented or more systems-oriented from 1992 to 2013?
In an era when the performance of a single compute device plateaus, software must be designed to scale on a massively parallel system for better runtime performance. We restructure BP into a scan operation which is scaled by our modified version of the Blelloch scan algorithm.
We propose an end-to-end dual-path convolutional network to discriminatively embed the image and text to a shared visual-textual space.
MFD-SOM is an improved self-organization map (SOM) algorithm for color feature extraction.
A real time face recognition based on face descriptor and its application for door locking.
In this paper we analyze the error modes of the state-of-the-art Selective Search object proposal algorithm and suggest extensions to broaden its feature diversity in order to mitigate its error modes.
This paper introduces a novel approach to sentiment analysis that integrates lexicon embeddings and an attention mechanism into Convolutional Neural Networks.
Fast training of adversarially robust models improves the state-of-the-art results.
We propose a novel Unsupervised Domain Adaptation (UDA) strategy to address the domain shift issue between real world and synthetic representations for semantic segmentation.
In this paper, we propose a novel end-to-end trainable Video Question Answering (VideoQA) framework with three major components: 1) a new heterogeneous memory which can effectively learn global context information from appearance and motion features; 2) a redesigned question memory which helps understand the complex semantics of question and highlights queried subjects; and 3) a multimodal fusion layer which performs multi-step reasoning.
We introduce the Caltech Pedestrian Dataset, which is two orders of magnitude larger than existing datasets. We propose improved evaluation metrics, demonstrating that commonly used per-window measures are flawed and can fail to predict performance on full images.
We propose a method to increase robustness and reduce computational complexity in a Convolutional Neural Network (CNN) based anomaly detector that utilizes the optical flow information of video data.
We propose a meta-learning-based recommender system to alleviate the cold-start problem that can estimate user preferences based on only a small number of items.
This paper describes an attention-based fusion method for outfit recommendation which fuses the information in the product image and description to capture the most important, fine-grained product features into the item representation.
We present an audio-visual multimodal approach for zeroshot learning (ZSL) for classification and retrieval of videos.
In this paper, a new method for generating object and action proposals in images and videos is proposed. It builds on activations of different convolutional layers of a pretrained CNN, combining the localization accuracy of early layers with the high informative-ness of the later layers.
We proposed an iterative method which applied MAX-VAR generalized canonical correlation analysis (GCCA) on users latent factors learned from matrix factorization on each domain, which provides better recommendations in cold-start scenarios.
We introduce a novel crowd dataset, the DLR Aerial Crowd Dataset (DLR-ACD), which is composed of 33 large aerial images acquired from 16 flight campaigns over mass events with 226,291 persons annotated. To tackle the problem of accurate crowd counting and density map estimation in aerial images of crowds, we propose a new encoder-decoder convolutional neural network.
In this work, we address the problem of obtaining better part templates which are able to handle a very high variation in body pose and appearances.
We propose a novel region-based multiscale spatiotemporal saliency detection method for videos, where static features and dynamic features computed from the low and middle levels are combined together.
Attentive Pooling enables the pooling layer to be aware of the current input pair, in a way that information from the two input items can directly influence the computation of each other's representations.
We revisit the importance of the individual units in Convolutional Neural Networks (CNNs) for visual recognition. We compute the correlation between the accuracy drop under unit ablation and various attributes of an individual unit such as class selectivity and L1 norm.
We introduce a novel multi-scale proposal regression network (MPRN) for temporal action proposal generation.
In this paper, we propose a transformation of the standard BoW model into a neural network, enabling discriminative training of the visual vocabulary on large action recognition datasets.
We propose a novel crowd counting model that maps a given crowd scene to its density. We provide interpretable representations of the multichotomy of space of crowd scene patches inferred from the switch.
We propose layer-wise conditioning analysis, which explores the optimization landscape with respect to each layer independently, in order to investigate their learning dynamics.
We propose a novel top-down approach that tackles the problem of multi-person human pose estimation and tracking in videos.
In this paper, we aim at tackling a general issue in NLP tasks where some of the negative examples are highly similar to the positive examples, i.e., hard-negative examples. We propose the distant supervision as a regularizer approach to tackle this issue.
We provide an up to date survey on AutoML and propose a general AutoML framework and a detailed analysis of AutoML approaches.
We propose a wide-baseline video stitching algorithm for linear camera arrays that is temporally stable and tolerant to strong parallax.
Binarization can greatly compress and accelerate deep convolutional neural networks (CNNs) for real-time industrial applications. Addressing the limitation, an improved BCNN named BitFlow-Net is proposed.
We propose the first convolutional neural network (CNN)-based ego-motion classification algorithm designed for the compound eye structure which fully utilizes one of the unique features of compound images.
We compare the performance and behavior of models based on a deep neural network and low-rank approximation to examine the reasons for the low effectiveness of traditional deep neural networks.
We propose a novel pruning method that optimizes the final accuracy of the pruned network and distills knowledge from the over-parameterized parent network's inner layers.
We propose the Graph HyperNetwork to amortize the search cost: given an architecture, it directly generates the weights by running inference on a graph neural network.
In this paper, we propose a spatial-channel parallelism network (SCPNet) in which each channel in the ReID feature pays attention to a given spatial part of the body.
We show that the assignment of weights to the component classifiers of a boosted ensemble can be thought of as a game of Tug of War between the classes in the margin space. We then demonstrate how this insight can be used to attain a good compromise between the rare and abundant classes.
We present Tigris, an algorithm-architecture co-designed system specialized for point cloud registration, which achieves 77.7% registration performance improvements and 3.4× power reduction in KD-tree search over an RTX 2080 Ti GPU.
We introduce GQA, a new dataset for real-world visual reasoning and compositional question answering, seeking to address key shortcomings of previous VQA datasets. We use the programs to gain tight control over the answer distribution and present a tunable smoothing technique to mitigate question biases.
We define and address the problem of unsupervised learning of disentangled representations on data generated from independent factors of variation and propose FactorVAE, a method that disentangles by encouraging the distribution of representations to be factorial and hence independent across the dimensions.
In this paper, we propose a novel iterative delexicalization algorithm, which can accurately de lexicalize the input, even with out-of-vocabulary slot values, and improve parsing performance for RNN based models.
This paper presents the first use of graph neural networks for higher-order proof search and demonstrates that GNNs can improve upon state-of-the-art results in this domain.
We present a system to recover the 3D shape and motion of a wide variety of quadrupeds from video.
We present an improved three-step pipeline for the stereo matching problem and introduce multiple novelties at each stage. We propose a new highway network architecture for computing the matching cost at each possible disparity.
Pyramid Residual Module (PRMs) to enhance the invariance in scales of DCNNs.
The most successful 2D object detection methods require a large number of images annotated with object bounding boxes to be collected for training. We present an alternative approach that trains on virtual data rendered from 3D models, avoiding the need for manual labeling.
We explore an approach for injecting prior domain structure into neural network training by supervising hidden layers of a CNN with intermediate concepts that normally are not observed in practice.
We propose a novel method for training a robust convolutional neural network with extremely noisy labels, which is called group-teaching.
We propose an open-domain VQA system that learns a set of base weights for a given question with the information required at test time. The resulting method dynamically utilizes data from an external source, such as a large set of questions/answers/captions.
We present an approach for detecting human-object interactions (HOIs) in images, based on the idea that humans interact with functionally similar objects in a similar manner.
We propose an approach to localization from images that is designed to explicitly handle the strong variations in appearance happening between daytime and nighttime, improving on the state-of-the-art VLAD-based methods on nighttime localization.
We present a differential topic model that models both topic differences and similarities. We use hierarchical Bayesian nonparametric models for this application.
We propose input space distance regularization as a stabilizer for pre-image estimation and apply it to the USPS digit modeling problem.
We propose a real-time mapping procedure for data matching to deal with hybrid time-of-flight (ToF) multi-camera rig data fusion.
In this paper, we propose a novel Orthogonal Center Learning method with Subspace Masking for person re-identification.
In this paper, we propose IoU-Uniform R-CNN, a simple but effective method that directly generates training samples with uniform IoU distribution for the regression branch as well as the IoU prediction branch.
We propose a neural network reconstruction method that unifies all these properties within a single powerful framework for data fusion and scene completion.
Pose Machines provide a sequential prediction framework for learning rich implicit spatial models. Our approach addresses the characteristic difficulty of vanishing gradients during training by providing a natural learning objective function that enforces intermediate supervision.
We propose a novel type of cross-modal multimedia retrieval, which aims to find a set of geo-multimedia objects according to geographical distance proximity and semantic concept similarity, which can be used to bridge the gap between different modalities.
Conditional Neural Processes combine the flexibility of stochastic and Bayesian neural networks for efficient function approximation.
We investigate whether artificial neural networks encode grammatical distinctions necessary for inferring the idiosyncratic frame-selectional properties of verbs.
We propose a capsule-based approach for semi-supervised video object segmentation which can segment several frames at once conditioned on a reference frame and segmentation mask.
In this paper, for the first time, we systematically investigate the impact of different layer assignments to the network performance by building an architecture dataset of layer assignment on CIFAR-100.
We present a deep neural network to automatically abstract low-level representation of service description to high-level features without feature engineering and then predict service classification on 50 service categories.
Data Mining and Knowledge Discovery in Databases using Semantic Web and Linked Open Data .
We aim at transforming an image with a fine-grained category to synthesize new images that preserve the identity of the input image, which can thereby benefit the subsequent fine- grained image recognition and few-shot learning.
 LP-SparseMAP uses the flexible and powerful domain specific language of factor graphs for defining and backpropagating through arbitrary hidden structure, supporting coarse decompositions, hard logic constraints, and higher-order correlations.
This paper proposes a novel Non-Local Attention Optimized Deep Image Compression (NLAIC) framework, which is built on top of the popular variational auto-encoder (VAE) structure.
We employ the Augmented Random Search method (ARS) to improve the performance of AutoAugment.
A new framework for person re-identification with a triplet-based deep similarity learning using convolutional neural networks.
We propose a computer-aided diagnosis system for glaucoma, which provides a reliable estimation of the height of the optic disk and the cup in terms of the relative height error and provides a good agreement with manual annotations.
We propose GALD, an end-to-end trainable global aggregation module for semantic segmentation, where long-range dependencies are more confidently used inside large pattern regions and vice versa.
In machine learning, training sample set management has an important impact on the performance of visual detection and tracking algorithms, as corrupted training samples degrade the tracking performance.
We present an unsupervised representation learning approach that compactly encodes the motion dependencies in videos and learn a robust video representation that captures long-term motion dependencies and spatial-temporal relations.
Cross-modal tasks occur naturally for multimedia content that can be described along two or more modalities like visual content and text. Methods like kernelized canonical correlation analysis (KCCA) attempt to solve such tasks by finding aligned subspaces in the description spaces of different modalities. However, a direct use of the subspace alignment obtained by KCCA only leads to coarse translation abilities.
Domain Adaptive Semantic Segmentation using Fully Convolutional Domain Adversarial Learning .
We combine the Multi-set canonical correlation analysis and Kernel method and propose one novel color image recognition approach: color image kernel canonicalrelation analysis.
We develop a novel network structure named MixPred based on this idea to address this issue. We divide the prediction problem into two parts and build two subnets to solve these two parts separately.
We present Bag of Negatives (BoN), an efficient and loss-independent method for accelerated and improved training of Siamese networks that scales well on datasets with a large number of identities.
We propose a novel objective function that exploits abundant stereo imagery to learn a model to hypothesize 3-dimensional structure of a scene from a single image.
Federated Learning enables visual models to be trained on-device, bringing advantages for user privacy (data need never leave the device), but challenges in terms of data diversity and quality.
The exploration of retinal vessel structure is colossally important on account of numerous diseases including stroke, Diabetic Retinopathy (DR) and coronary heart diseases, which can damage the retinal vascular network. The proposed technique consists of unique parallel processes for denoising and extraction of blood vessels in retinal images.
We show that a set of real-valued word vectors formed by right singular vectors of a transformed co-occurrence matrix are meaningful for determining different types of dependency relations.
We propose a cascaded framework consisting of a denoiser subnetwork and a deblurring subnetwork. Joint learning reduces the effect of the residual noise after denoising ondeblurring, hence improves the robustness of deblring to heavy noise.
A suitable similarity index for comparing learnt neural networks plays an important role in understanding the behaviour of the highly-nonlinear functions, and can provide insights on further theoretical analysis and empirical studies.
In this paper, we propose a new edge detection technique based on the regional recursive hierarchical decomposition using quadtree and post-filtration of edges using a finite difference operator that is efficient and accurate.
We formulate shadow removal as an optimization problem that minimizes dissimilarities between a shadow area and its non-shadow counterpart.
We introduce a novel concept-wise temporal convolution layer for training deeper action localization networks, which improves state-of-the-art action localization performance.
In this paper, we propose the Dynamic Memory Generative Adversarial Network (DM-GAN) to generate realistic images from text descriptions.
We explore the problem of real-time stereo matching on high-res imagery. To address this issue, we propose an end-to-end framework that searches for correspondences incrementally over a coarse to fine hierarchy.
We use linear discriminant analysis to select features in the self-similarity features according to their generalized Rayleigh quotient, leading to a small number but most discriminative features.
We propose a new video captioning approach based on object-aware aggregation with bidirectional temporal graph (OA-BTG), which captures detailed temporal dynamics for salient objects in video, and learns discriminative spatio-temporal representations by performingobject-aware local feature aggregation on detected object regions.
We introduce a data-driven approach to aid the repairing and conservation of archaeological objects: ORGAN, an object reconstruction generative adversarial network.
By borrowing the wisdom of human in gaze following, we propose a two-stage solution for gaze point prediction of the target persons in a scene without considering the scene contents.
In this paper, we aim to exploit accurate AU labels from a well-constrained source domain for training an AU detector for the target domain of unconstrained in the wild images.
We propose two Siamese architectures for learning from unlabeled videos, and their corresponding novel loss functions, to exploit the local temporal coherence between contiguous frames, and a global discriminative margin used to separate representations of different videos.
In this paper, we pose the novel problem of universal semi-supervised semantic segmentation and propose a solution framework, to meet the dual needs of lower annotation and deployment costs.
We address the issue of speeding up the training of convolutional networks. Here we study a distributed method adapted to stochastic gradient descent (SGD).
A probabilistic, maximum aposteriori approach to finding landmarks in a face image, based on a likelihood ratio detector, is proposed.
Meta-learning-based meta-learning improves state-of-the-art visual object trackers that use online adaptation.
BiCANet: A Bi-directional Contextual Aggregating Network for Semantic Segmentation .
This paper introduces the visually informed embedding of word (VIEW), a continuous vector representation for a word extracted from a deep neural model trained using the Microsoft COCO data set to forecast the spatial arrangements between visual objects, given a textual description.
Speaker-Aware Speech-Transformer for speaker aware training of E2E models.
We introduce a spherical exponential mapping on $n$-spheres at the regression output, which leads to stable training and stable gradients.
We propose an end-to-end network that learns discriminative representations by implicitly learning a geometric transformation from multi-view images for fine-grained rigid object retrieval.
We propose a new method for human action recognition from video sequences using latent topic models, and show improvement over previous methods.
This paper focuses on the problem of predicting future trajectories of people in unseen scenarios and camera views. We propose a method to efficiently utilize multi-view 3D simulation data for training.
We propose Reconfigurable Voxels, a new approach to constructing representations from 3D point clouds that improve the detection performance for small and distant objects, without incurring noticeable overhead costs.
We propose a novel deep neural network architecture for fast video inpainting and achieve competitive video results.
We explore multiple methods for the combination of cues from multiple modalities into one common classifier for Emotion Recognition in the Wild.
Image inpainting techniques have shown promising improvement with the assistance of generative adversarial networks (GANs) recently. However, most of them often suffered from completed results with unreasonable structure or blurriness. To mitigate this problem, we present a one-stage model that utilizes dense combinations of dilated convolutions to obtain larger and effective receptive fields.
We present a novel co-attention model for Visual Question Answering that jointly reasons about image and question attention, improving the state-of-the-art on VQA.
This paper alleviates this issue by proposing a novel framework to replace the classification task in one-stage detectors with a ranking task, and adopting the Average-Precision loss (AP-loss) for the ranking problem.
We solve this problem by developing a novel network trained in a weakly supervised manner. The training is end-to-end and does not require any saliency ground truth.
We propose a first spike-based Siamese network for object tracking, which achieves short latency and low precision loss.
This paper proposes a Supervised Descent Method (SDM) for minimizing a Non-linear Least Squares (NLS) function.
We adopt a dual adversarial discriminator with $2K$-dimensional output to perform both domain-level and class-level alignments simultaneously in a single discriminator and use semi-supervised learning regularization to make it discriminative.
We have used the existing structural information of M. tuberculosis GlgB for high throughput virtual screening and molecular docking. We also used three-dimensional shape as well as two-dimensional similarity matrix methods to identify diverse molecular scaffolds that inhibit M tuberculosis GlGB activity.
We analyze the feature aggregation patterns of ResNets and DenseNets under a uniform aggregation view framework. We compare the strengths and drawbacks of these two aggregation methods and analyze their potential effects on the networks' performance.
This paper presents a new MRC model that is capable of three key comprehension skills: 1) handling rich variations in question types; 2) understanding potential answer choices; and 3) drawing inference through multiple sentences.
We propose a highly efficient multi-segment activation, which can significantly improve the expressiveness ability with very little cost, in the compact student model.
This paper shows that Hidden Markov models can be effectively applied to 3D face data.
A variety of machine learning tasks---e.g., matrix factorization, topic modelling, and feature allocation---can be viewed as learning the parameters of a probability distribution over bipartite graphs. Recently, a new class of models for networks, the sparse exchangeable graphs, have been introduced to resolve some important pathologies of traditional approaches to statistical network modelling; most notably, the inability to model sparsity in the asymptotic sense.
This paper proposes to encode equivalent temporal characteristics in video representations for action recognition and achieve state-of-the-art results on four benchmark datasets.
The material attributes of foreign object debris (FOD) are the most crucial factors to understand the level of damage sustained by an aircraft. However, the prevalent FOD detection systems lack an effective method for automatic material recognition.
The objective of this paper is a neural network model that controls the pose and expression of a given face, using another face or modality (e.g. audio), for lightweight, sophisticated video and image editing.
Automated retinal screening relies on vasculature segmentation before the identification of other anatomical structures of the retina, where multi-ethnicity and brightness variations are parts of the problem.
This paper describes a novel approach of packing sparse convolutional neural networks into a denser format for efficient implementations using systolic arrays using efficient bit-serial implementations of multiplier accumulators.
In this paper, we propose a hybrid framework, Super-Recognition of Pedestrian Re-Identification (SRPRID), in order to strengthen pedestrian re-identification based on multi–resolutions images captured by disparate cameras.
We propose a novel multi-scale deep re-identification network that learns discriminative feature representations at different scales, and uses the information from multiple scales to lead and determine the optimal weightings for each scale.
We introduce Repetition-Reduction network for resource-constrained depth estimation, offering significantly improved efficiency in terms of computation, memory and energy consumption.
The surgical workflow challenge at M2CAI 2016 consists of identifying 8 surgical phases in cholecystectomy procedures. Here, we propose to use deep architectures that are based on our previous work where we presented several architectures to perform multiple recognition tasks on laparoscopic videos.
We study the phenomenon of bias amplification in classifiers, wherein a machine learning model learns to predict classes with a greater disparity than the underlying ground truth.
We review the current state-of-the-art deep learning architectures for 3D sensed data understanding, including RGB-D, multi-view, volumetric and fully end-to-end architecture designs.
We present a novel methodology based on Deep Learning to build a combined image- andtext based personality trait model, trained with images posted together with words found highly correlated to specific personality traits.
In this paper, we propose a novel action recognition method by processing the video data using convolutional neural network (CNN) and deep bidirectional LSTM (DB-LSTM) network.
We solve the problem of visual sentiment analysis using the high-level abstraction in the recognition process, thereby significantly reducing the annotation burden.
A new texture representation framework called statistical binary patterns (SBPs) extends LBP self-similarity operator from the local grey level to the local distribution level.
We propose an end-to-end learning framework for segmenting generic objects in videos. We formulate this task as a structured prediction problem and design a two stream fully convolutional neural network which fuses together motion and appearance in a unified framework.
In this paper, we study the smoothness of perturbations and propose SmoothFool, a general and computationally efficient framework for computing smooth adversarial perturbation.
We propose a new algorithm, whose parameter updates rely on two forces: a regular gradient step, and a corrective direction dictated by the currently best-performing worker (leader), and extend it to the multi-leader setting.
We propose Adi-Red, an adaptive approach to discriminative region discovery for scene recognition using a CNN classifier, which was pre-trained using only image-level scene labels, to discover discriminATIVE image regions directly.
In this paper, we propose a new occlusion-aware R-CNN (OR-CNN) to improve the detection accuracy in the crowd.
We propose a structured robust correlation filter (SRCF), which employs the L2,1 norm as the regularization to improve the robustness of the feature.
We propose a low-complexity and model-free procedure, which operates in a lifted space by representing distinct label values in orthogonal directions, and which attempts to optimize quadratic functions over hypercubes. We prove that the algorithm makes no error.
We construct a general unified framework for learning representation of structured data, i.e. data which cannot be represented as the fixed-length vectors (e.g. sets, graphs, texts or images).
Adversarial perturbations are noise-like patterns that can subtly change the data, while failing an otherwise accurate classifier. In this paper, we propose to use them for improving the robustness of video representations.
We propose a learned updater based on recurrent neural networks and demonstrate its application in a template-based Tracker and a correlation filter-based tracker.
We propose a deep metric learning model to create embedded sub-spaces with a well defined structure. We also propose a new semi-supervised method to create sub-classes.
In neural architecture search, the structure of the neural network to best model a given dataset is determined by an automated search process. In this work, we evaluate the learning progress of the controller which generates the architectures in ENAS.
This paper discusses the effect of hubness in zero-shot learning, when ridge regression is used to find a mapping between the example space to the label space.
We propose a CNN architecture that combines disparity estimation with the help of semantic segmentation and achieve state-of-the-art results.
We explore the capabilities of Multi-modal Auto-Encoders to fuse the information available from cameras and depth sensors, and to reconstruct missing data, for scene understanding tasks.
In many previous works, a single-pixel imaging system is constructed as an optical image encryption system. In this work, we propose a known-plaintext attack scheme and a ciphertext-only attack scheme to an encrypted SPI system for the first time.
We propose a Hierarchical Memory Network (HMN) architecture, which is able to successfully detect faked faces by utilising knowledge stored in neural memories as well as visual cues.
ATTCONV extends the context scope of the convolution operation, deriving higher-level features for a word not only from local context, but also information extracted from nonlocal context by the attention mechanism commonly used in RNNs.
We propose a novel long-term tracking framework based on deep regression and verification networks. The offline-trained regression model is designed using the object-aware feature fusion and region proposal networks to generate a series of candidates and estimate their similarity scores effectively.
A method for self-adaptive recognition of human action in image and video data using restricted Boltzmann machine.
Our goal is to learn a neural semantic parser when only prior knowledge about a limited number of simple rules is available, without access to either annotated programs or execution results.
This paper explores the problem of matching entities across different knowledge graphs. We formalize this problem and present two large-scale datasets for this task.
In this paper, we propose an imitation learning approach to unsupervised parsing, where we transfer the syntactic knowledge induced by the PRPN to a Tree-LSTM model with discrete parsing actions.
We propose a local classification-based model (LCM), which considers the topology of DDI network and has the relaxation of the degree-induced bias. Furthermore, we design a novel supervised fusion rule based on the Dempster-Shafer theory of evidence ( LCM-DS), which aggregates the results from multiple LCMs.
We present assertion based question answering (ABQA), an open domain question answering task that takes a question and a passage as inputs, and outputs a semi-structured assertion consisting of a subject, a predicate and a list of arguments.
We propose a novel deep learning architecture for color (multichannel) image denoising and report on thousands of images from ImageNet dataset as well as commonly used imagery.
We propose the concept of a multi-frame GAN and demonstrate its potential as an image sequence enhancement for stereo visual odometry in low light conditions.
We propose the task of free-form and open-ended Visual Question Answering (VQA). Given an image and a natural language question about the image, the task is to provide an accurate natural language answer.
We propose a new singing voice separation algorithm called Low-rank, Sparse ::: Representation with pre-learned dictionaries and side Information (LSRi)
We propose a new SOD system which aims at designing a more efficient and effective way to pass back global information for object detection.
We propose a novel deep supervised hashing based on stable distribution to eliminate the discrepancy between quantization error minimization and discriminability maximization.
We propose a novel 3D human pose detector using two panoramic cameras, capable of accurately estimating human poses over a large field of view.
We propose to extend the input representations with an abstract view of the relation between the hypothesis and the premise, i.e., how well the individual words, or word n-grams, of the hypothesis are covered by the premise.
This paper focuses on scale transformation and proposes a network architecture called the weight-shared multi-stage network (WSMS-Net), which consists of multiple stages of CNNs.
We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems without the need for parameter tweaking.
We propose a method for converting a single RGB-D input image into a 3D photo - a multi-layer representation for novel view synthesis that contains hallucinated color and depth structures in regions occluded in the original view.
We propose a boosting algorithm that directly optimizes the cost function of linear asymmetric classifier for cascade object detection.
In this paper the framework is analysed and a new intent-aware objective is derived that considers the minimum variance criterion, connecting the framework directly to portfolio diversification from finance.
We introduce a generic framework that reduces the computational cost of object detection while retaining accuracy for scenarios where objects with varied sizes appear in high resolution images.
We propose a new architecture, named Gated Fully Fusion(GFF), to selectively fuse features from multiple levels using gates in a fully connected way for semantic segmentation tasks.
In this paper we study how different ways of combining character and word-level representations affect the quality of both final word and sentence representations.
In this paper, we propose Two-Stream AMTnet, which leverages recent advances in video-based action representation[1] and incremental action tube generation[2]
We present an approach to joint classification, detection and semantic segmentation using a unified architecture where the encoder is shared amongst the three tasks.
We aim to investigate the effect of computer-aided triage system, which is implemented for the health checkup of lung lesions involving tens of thousands of chest X-rays (CXRs) that are required for diagnosis.
A novel combination representation called global Gist feature and local patch coding for human action recognition.
In this paper, we propose three novel curriculum learning strategies for training GANs. All strategies are first based on ranking the training images by their difficulty scores, which are estimated by a state-of-the-art image difficulty predictor.
We argue that flow-based density models based on continuous bijections are limited in their ability to learn target distributions with complicated topologies, and propose Localised Generative Flows (LGFs) to address this problem.
We propose a shrinking Deep Learning with recall (sDLr) approach to speed up deep learning computation.
We propose a novel FCN able to work with omnidirectional images that outputs accurate probability maps representing the main structure of indoor scenes, which generalize on different data.
We propose a novel part-based method for tracking an arbitrary object in challenging video sequences, focusing on robustly tracking under the effects of camera motion and object motion change.
We propose a new protocol to collect long-term video memorability data and build a computational model to better understand the effects of response time, duration of memory retention and repetition of visualization on video memorablity.
We propose a set of prosodic modifications that highlight potentially important parts of the answer using various acoustic cues for voice-only question answering.
We propose a new method for age invariant face recognition that captures the intuition above through a probabilistic model with two latent factors: an identity factor that is age-invariant and an age factor affected by the aging process.
We propose a novel approach to obtain generative probabilistic models that sample from given densities using denoising density estimators.
This work explores the use of spatial context as a source of free and plentiful supervisory signal for training a rich visual representation that captures visual similarity across images.
We present a deep learning method for end-to-end monocular 3D object detection and metric shape retrieval using 10D lifting of sparse 2D Regions of Interests.
We present an approach for joint inference of 3D scene structure and semantic labeling for monocular video. We make use of class specific semantic cues that constrain the 3D structure in areas where multiview constraints are weak.
A novel curriculum learning algorithm pertaining to clustering is proposed to address this issue in this paper.
We present a novel disentanglement method which uses latent optimization of an architecture borrowed from style-transfer, to enforce separation of pose and content.
We proposed a novel CNN-based method for skeleton-based action recognition that captures long-term dependencies and improves the state of the art.
In this paper, we propose the Broadcasting Convolutional Network (BCN) that extracts key object features from the global field of an entire input image and recognizes their relationship with local features.
We propose novel Gradient Estimation black-box attacks for adversaries with query access to the target model’s class probabilities, achieving adversarial success rates similar to well known, state-of-the-art white- box attacks.
Automatic replacement of the sky region in a video with a different sky, providing nonprofessional users with a simple yet efficient tool to seamlessly replace the sky.
In recent years, convolutional neural network (CNN) has attracted considerable attention since its impressive performance, such as Arabic sentence classification. However, building a powerful CNN for Arabic sentiment classification can be highly complicated and time consuming. In this paper, we address this problem by combining differential evolution (DE) algorithm and CNN, where DE algorithm is used to automatically search the optimal configuration including CNN architecture and network parameters.
This paper exploits a transfer learning technique to improve the performance of speech emotion recognition systems that is novel in cross-language and cross-corpus scenarios.
We improve the state-of-the-art single-shot detector, RetinaNet, in three ways: integrating instance mask prediction for the first time, making the loss function adaptive and stable, and including additional hard examples in training.
In this work we revisit gradient regularization for adversarial robustness with new ingredients.
GLO discovers loss functions de novo, builds them hierarchically from a set of operators and leaf nodes, and optimizes them for a target task.
The potential of the nasal region for expression robust 3D face recognition is thoroughly investigated by a novel five-step algorithm that provides the highest reported nasal region-based recognition ranks on FRGC, Bosphorus and BU-3DFE datasets.
We propose a new sentence embedding method by dissecting BERT-based word models through geometric analysis of the space spanned by the word representation. It is called SBERT-WK.
We propose PoWER-BERT, a novel method for improving the inference time for BERT without significant loss in the accuracy.
We developed a framework for tampering detection which derives features from authentic content and utilises them to localise key frames and tampered regions in three publicly available tampered video datasets.
We propose a remedy for this problem by modifying the original approach for introducing the LVs, which we call SPN augmentation. We discuss conditional independencies in augmented SPNs.
We explore weight pruning for BERT and ask: how does compression during pre-training affect transfer learning? We find that pruning affects transfer learning.
Domain Adaptative Neighborhood Clustering via Entropy Optimization for Unsupervised Domain Adaptation .
We propose a general framework of Language-Conditioned Graph Networks (LCGN), where each node represents an object, and is described by a context-aware representation from related objects through iterative message passing conditioned on the textual input.
We propose a U-Net variant for improved vessel segmentation in retinal fundus images using a cascading technique.
Attentive encoder-decoder networks for Video Summarization .
We present an end-to-end trainable, deep neural network with a visual attention mechanism for memorability estimation in still images.
In this paper, we present a framework to control a self-driving car by fusing raw information from RGB images and depth maps for redundancy and fault tolerance in the presence of sensor failures.
We present PointFusion, a generic 3D object detection method that leverages both image and 3D point cloud information for application-agnostic results.
We analyse the main issues and potential divergences in the application of Information Retrieval methodologies to recommender system evaluation, and provide a systematic characterisation of experimental design alternatives for this adaptation. We propose two experimental design approaches that effectively neutralise such biases to a large extent.
We introduce the use of ghosting cues that exploit asymmetry between the layers, thereby helping to reduce the ill-posedness of the problem that has both aesthetic and practical applications.
We propose methods to construct similarities from the probabilistic viewpoint, whilst the similarities have so far been formulated in a heuristic manner such as by k-NN.
A survey of geometric deep learning and related methods for graph data.
We propose a unified NRL framework by introducing community information of vertices, named as Community-enhanced Network Representation Learning (CNRL), which learns embeddings of both vertices and communities.
In this paper, we propose a novel global spatio-temporal self-similarity measure to score saliency using the ideas of dictionary learning and sparse coding.
We propose Libra R-CNN, a simple but effective framework towards balanced learning for object detection, which improves the detection performance.
A first-person camera, placed at a person's head, captures, which objects are important to the camera wearer. Most prior methods for this task learn to detect such important objects from the manually labeled first- person data in a supervised fashion. We formulate an important detection problem as an interplay between 1) segmentation and 2) recognition agents.
We propose an axiomatic framework to capture desired properties for dataset granularity measure and provide examples of measures that satisfy these properties.
Black Box Recursive Translation (BBRT), a new inference method for molecular property optimization, where the goal is to map an input compound to a target compound with improved biochemical properties.
In this work we ask whether it is possible to create a"universal"detector for telling apart real images from these generated by a CNN, regardless of architecture or dataset used.
We analysed the recent scientific developments in semantic segmentation, specifically on deep learning-based methods using 2D images.
We describe methods used to add 35K new concepts mined from Wikipedia to collections in ResearchCyc entirely automatically.
Boltzmann machines can perform image denoising as well as, or in certain cases of high level of noise, better than Denoising autoencoders.
A large-scale full driving scene segmentation dataset, densely annotated for every pixel and every one of 5,000 video frames.
This paper proposes key instance selection based on video saliency covering objectness and dynamics for unsupervised video object segmentation.
We present a feature descriptor targeting line drawings learned from a 3D shape data set. The goal is to embed semantically similar anchor points close to one another, and to pull the embeddings of different points far apart.
We use pose estimation from key body points detection to extend pedestrian skeleton when whole body not in image (occluded by obstacles or partially outside of frame), which achieves better location estimation performance compared to fitting a bounding box over pedestrian and scaling.
We propose a 2-view depth network to infer the scene depth from consecutive frames, thereby learning inter-pixel relationships. To ensure better correspondences, thereby better geometric understanding.
The paper describes the preparation and development of the text collections within the framework of MorphoRuEval-2017 shared task, an evaluation campaign designed to stimulateDevelopment of the automatic morphological processing technologies.
We present an agent that can continuously learn by posing natural language questions to humans, expanding its knowledge.
This work presents a neural network that consists of nodes with heterogeneous sensitivity. The network is trained by a constrained optimization that minimizes the sparsity of sensitivity variables while ensuring the network's performance.
We propose the TrPATE framework which extends Private Aggregation of Teacher Ensembles (PATE), a generic framework for transfer learning.
We propose a new method for high-quality speech source separation ::: by synthesizing the source from a speech mixture corrupted by various environmental noise.
In this paper, we propose a novel domain adaptation approach based on 3D geometry and image synthesis based on a generalized appearance flow to preserve identity across pose transformations, while using an attribute-conditioned CycleGAN to translate a single source into multiple target images that differ.
This paper presents a method of building an embedding representation via deep metric learning, which works well in both classification and verification problems. The loss explores the tradeoff, balancing the discriminativeness and invariance.
We investigate an approach that uses lipophilicity, affinity, and similarity to known aggregators to advise on the likelihood that a candidate compound is an aggregator.
We propose several MAMAB-based algorithms for learning-based caching in small-cell networks when user preference is unknown.
We identify two types of units that emerge when the network's width is increased and show that DNNs consistently increase either the number of removable units, repeated units, or both at greater widths for a comprehensive set of hyperparameters.
A graph-to-sequence neural encoder-decoder model that maps an input graph to a sequence of vectors and uses an attention-based LSTM method to decode the target sequence from these vectors.
We investigate the use of a method recently introduced in statistics, the so-called Joint and Individual Variance Explained (JIVE) method, for the robust recovery of joint and individual components in visual facial data consisting of an arbitrary number of views in the presence of sparse non-Gaussian errors.
Scale-invariant Convolutional Neural Network for Resilient to Scale Variance .
We propose natural action structures, i.e., multi-size, multi-scale, spatial-temporal concatenations of local features, as the basic features for representing natural actions.
This paper proposes a set of criteria to evaluate the objectiveness of explanation methods of neural networks, which is crucial for the development of explainable AI.
We propose robust co-training for adversarial learning with unlabeled data. We believe that the quality of pseudo labels is the bottleneck.
Class-incremental learning of deep networks sequentially increases the number of classes to be classified. During training, the network has only access to data of one task at a time, where each task contains several classes. In this setting, networks suffer from catastrophic forgetting which refers to the drastic drop in performance on previous tasks.
We propose a new model that explicitly reasons about different temporal segments in a video, and shows that temporal context is important for localizing phrases which include temporal language.
This paper proposes a generic formulation that significantly expedites the training and deployment of image classification models, particularly under the scenarios of many image categories and high feature dimensions.
We address the problem of joint detection and recounting of abnormal events in videos by integrating a generic CNN model and environment-dependent anomaly detectors.
We propose using supervised feature learning as a way to learn spatio-temporal features for human action analysis.
We introduce a new form of latent optimisation inspired by the CS-GAN and show that it improves GAN training, obtaining state-of-the-art performance for the ImageNet dataset.
This paper proposes deep convolutional networks that utilize local and global context to make human activity label predictions in still images, achieving state-of-the-art performance on two recent datasets with hundreds of labels each.
In this paper, we address the problem of scene parsing with deep learning and focus on the context aggregation strategy for robust segmentation.
We propose Graph2Gauss - an approach that can efficiently learn versatile node embeddings on large scale (attributed) graphs that show strong performance on tasks such as link prediction and node classification.
This paper introduces a new learning paradigm called eXtreme Regression (XR) whose objective is to accurately predict the numerical degrees of relevance of an extremely large number of labels to a data point. XR can provide elegant solutions to many large-scale ranking and recommendation applications including Dynamic Search Advertising.
We tackle the problem of semantic boundary prediction, which aims to identify pixels that belong to object(class) boundaries by explicitly reasoning about annotation noise.
In this paper, we propose two ways of improving image classification based on bag-of-words representation, that go further in the analogy with textual data.
This paper addresses the problem of generating recommendations for completing the outfit given that a user is interested in a particular apparel item. The proposed method is based on a siamese network used for feature extraction followed by a fully-connected network for learning fashion compatibility metric.
This paper gives an effective solution for a hard problem of LIDAR based recognition problems, namely the far-object detection in case of mobile LIDars of limited or poor vertical resolution.
In this paper, we propose a novel model of graph-regularized discriminative analysis-synthesis dictionary pair learning (GDASDL), in which a graph regularized term and a discrimInative term are incorporated into Dictionary pair learning.
We propose a new robust score function that combines the classification model with local structural information for protein complex detection.
FAN-Large is a large scale database of images and captions, designed for supporting research on how to use captioned images from the Web for training visual classifiers.
We explore two paths to boost the performance of the face PAD system against challenging attacks, by using multichannel (RGB, Depth and NIR) data, which is still easily accessible in a number of mass production devices.
We propose a novel approach towards face deidentification, called k-Same-Net, which combines recent Generative Neural Networks (GNNs) with the well-known k-Anonymitymechanism and provides formal guarantees regarding privacy protection on a closed set of identities.
We propose a method for aggregation of features in temporal domain for vehicle and person re-identification tasks and introduce a novel dataset CarsReId74k.
We propose a novel RNN-based model that learns a shared feature embedding over the space of many quantised time series, even when there is little to no training data available.
We propose a novel implicit representation for capturing the visual appearance of an object in terms of its surface light field in a continuous fashion and independent of the geometry.
We propose a new random forest (RF)-based online action detection framework that addresses these challenges. Our algorithm uses computationally efficient skeletal joint features.
We show that injecting implicit pairs into unpaired sets strengthens the mapping between the two domains, improves the compatibility of their distributions, and leads to performance boosting of unsupervised techniques by over 14% across several measurements.
We propose an end-to-end recurrent neural network architecture with an attention mechanism to model a human-like counting process, and produce detailed instance segmentations.
Data augmentation is a popular technique largely used to enhance the training of convolutional neural networks. In this paper, we systematically analyze these techniques through ablation studies of different network architectures trained with different amounts of training data.
We present a new method to translate videos to commands for robotic manipulation using Deep Recurrent Neural Networks using Deep Convolutional Neural Networks.
We provide a comprehensive survey of the recent developments in the field of depth reconstruction research, and summarize the most commonly used pipelines.
We propose the incorporation of sexual evolutionary synthesis, a method for generating more diverse and generalizable offspring networks in subsequent generations via the combination of two parent networks.
We propose the Open Deep Network for the open-set action recognition task, which can effectively detect and recognize new categories with little human intervention.
We present a novel neural network architecture that automatically detects word- and character-level features using a hybrid bidirectional LSTM and CNN architecture, eliminating the need for most feature engineering.
This paper formulates the Triplet Permutation method to generate multiple training sets, from a certain re-id dataset, which reduces the overfitting of the Single-Shot Re-Id model.
We show that prior methods designed for few-shot learning do not work out of the box in these challenging conditions, based on a new "meta-iNat" benchmark. We introduce three parameter-free improvements: (a) better training procedures based on adapting cross-validation to meta-learning.
In this paper, we propose an end-to-end 3D CNN for action detection and segmentation in videos.
We introduce knowledge distillation for end-to-end person search. This procedure not only helps fixing the sub-optimal detector training in the joint optimization and simultaneously improving the person search, but also closes the performance gap between the teacher and the student.
Weighted Center Regression Adaptive Feature Mapping (W-CR-AFM) is mainly proposed to transform the feature distribution of testing samples into that of trained samples.
We present model-based value expansion, which enables wider use of learned dynamics models within a model-free reinforcement learning algorithm, which, in turn, reduces the sample complexity of learning.
We propose a computational model for the role of lateral connections in a given block, in which the weights of the block vary dynamically as a function of its activations, and the input from the upstream blocks is iteratively reintroduced.
We present the results of a visual recognition neuro-imaging fusion experiment and compare them within and across experimental settings.
We extend a neural generator to become a pragmatic speaker reasoning about uncertain object categories, and show that this conversational strategy for dealing with novel objects often improves communicative success.
We present a method that tackles the challenge of predicting color and depth behind the visible content of an image from a single RGB input, including originally occluded regions.
A fully automated image watermarking system based on deep neural networks that achieves high capacity and high robustness without any prior knowledge of possible attacks.
We propose a novel multi-label transfer learning approach to jointly learn the information provided by the multiple annotations, rather than treating them as separate tasks.
We propose a novel weakly-supervised semantic segmentation method for motion removal, leveraging the power of deep Semantic Segmentation CNN.
This study explores a neural transfer learning approach to developing accurate and robust models for identifying infants that have suffered from perinatal asphyxia.
An unsupervised learning framework that uses the perceptual loss for depth estimation from monocular videos.
We propose a novel feature named pair normalized channel feature that combines and normalizes two channel features in image channels, achieving a highly discriminative power and computa- tional efficiency.
In this paper we propose an effective approach that incorporates both the fine and coarse pose information of the person to learn a discriminative embedding.
We investigate the IoU computation for two rotated Bboxes first and then implement a unified framework, IoU loss layer for both 2D and 3D object detection tasks.
A sequence-aware view aggregation module based on bi-directional Long Short-Term Memory network for 3D shape recognition.
Hidden-Task Learning and Semi-Hidden Task Learning improve the generalization ability of AU classifiers by training them with additional facial expression data.
We introduce a deep convolutional architecture that yields patch-level descriptors, an alternative to the popular SIFT descriptor for image retrieval.
We present an approach to non-factoid answer selection with a separate component based on BiLSTM to determine the importance of segments in the input, while assuming independence of questions and answers.
We exploit the natural connection between CSC and Convolutional Neural Networks to address CSC based image Super-Resolution problem.
We present JRMOT, a novel 3D MOT system that integrates information from 2D RGB images and 3D point clouds into a real-time performing framework.
This paper proposes an innovative framework to learn a nonlinear 3DMM model from a large set of unconstrained face images, without collecting 3D face scans.
Policy gradient methods are an appealing approach in reinforcement learning because they directly optimize the cumulative reward and can straightforwardly be used with nonlinear function approximators such as neural networks.
We show that convolutional neural networks are not appropriate for the coordinate transform problem, and propose a new solution, CoordConv, which works by giving convolution access to its own input coordinates through the use of extra coordinate channels.
We describe a class of systems theory based neural networks called "Network Of Recurrent neural networks" (NOR), which introduces a new structure level to RNN related models.
This work addresses the task of instance-aware semantic segmentation. Our approach, we term InstanceCut, represents the problem by two output modalities: (i) an instance-agnostic Semantic Segmentation and (ii) all instance-boundaries.
We propose DRAGON, a novel modular architecture for long-tail learning designed to address these biases and fuse multi-modal information in face of unbalanced data.
Unsupervised kinematic structure learning of complex articulated objects from a single-view 2D image sequence using iterative merging strategy.
We propose a novel visual-assisted diagnosis hybrid model mixing the support vector machine (SVM) and deep neural networks (DNNs) for ophthalmology.
We propose a novel measure based on normalized local structure attributes, called normalized local centrality, which considers the topology of the local network around a node as well as the influence feedback of the node’s nearest neighbor nodes.
We present a method for simultaneously learning, in an unsupervised manner, (i) a conditional image generator, (ii) foreground extraction and segmentation, (iii) clustering into two-level class hierarchy, and (iv) object removal and background completion, all done without any use of annotation.
We propose an algorithm for inexpensive gradient-based hyperparameter optimization that combines the implicit function theorem (IFT) with efficient inverse Hessian approximations.
In formal logic-based approaches to Recognizing Textual Entailment (RTE), a Combinatory Categorial Grammar parser is used to parse input premises and hypotheses to obtain their logical formulas.
We propose a cross-modality attention operation, which can obtain information from other modality in a more effective way than two-stream.
We first present a neural network based relation extractor to retrieve candidate answers from Freebase, and then infer over Wikipedia to validate these answers.
We leverage web images and corresponding tags, along with fully annotated datasets, in training for learning the visual-semantic joint embedding.
In this paper, we introduce the Face Magnifier Network (Face-MageNet), a face detector based on the Faster-RCNN framework which enables the flow of discriminative information of small scale faces to the classifier without any skip or residual connections.
We generalize the setting of online clustering of bandits by allowing non-uniform distribution over user frequencies. A new algorithm is proposed with simple set structures to represent clusters.
We propose a method to incorporate actionness data to explicitly regulate a learning algorithm that is trained for summary generation and demonstrate an advantage compared to state-of-the-art summarization methods.
We propose an alternative approach using second order optimization method that shows similar generalization capability to first order methods, but converges faster and can handle larger mini-batches.
The objective of this paper is the effective transfer of the Convolutional Neural Network (CNN) feature in image search and classification.
We propose VoteNet, an end-to-end 3D object detection network based on a synergy of deep point set networks and Hough voting for point cloud data.
We propose a method to regularize GAN training by adding an additional regularization term referred to as manifold regularizer, which forces the generator to respect the unique geometry of the real data manifold and generate high quality data.
We propose a novel method dubbed deep likelihood network (DL-Net), aiming at generalizing off-the-shelf image restoration networks to succeed over a spectrum of degradation settings while keeping their original learning objectives and core architectures.
In this paper, a novel approach to facial expression recognition based on the discrete separable shearlet transform and normalized mutual information feature selection is proposed.
We introduce a new diagnostic tool to analyze the performance of temporal action detectors in videos and compare different methods beyond a single scalar metric.
We propose a learned augmentation network composed of physically-based augmentation functions that reduces the domain gap between synthetic and real datasets for object detection.
In this paper, we propose a principled network to jointly learn spatiotemporal correspondence for stereo matching and flow estimation, with a newly designed geometric connection as the unsupervised signal.
We propose a comprehensive framework, named CAPTAIN (Composition Assistance for Photo Taking), containing integrated deep-learned semantic detectors, sub-genre categorization, artistic pose clustering, personalized aesthetics-based image retrieval, and style set matching.
In this paper, we propose a novel attributed network embedding framework, Similarity Enhancing Attributed Network Embedding (SEANE), which jointly preserves structural and attributed information, and adopts similarity measure to enhance the node embedding.
We propose a deep learning based person re-identification method by transferring knowledge of mid-level attribute features and high-level classification features and improve its accuracy.
In this paper, we propose to seamlessly enforce structural layout relationships among landmarks on the intermediate representations via multiple stacked layout-graph reasoning layers.
We provide a comprehensive survey on various current approaches for DIBR-synthesized views and provide a summary and analysis of the representative state-of-the-art objective metrics.
We propose an end-to-end visual relation detection network that uses vector translation to localize and predict visual relations in a convolutional fashion.
We show that neural network policies can be decomposed into "task-specific and "robot-specific" modules, where the task-specific modules are shared across robots, and the robot-specificmodules are shared within robots, enabling zero-shot generalization.
We propose Efficient Neural Architecture Search (ENAS), a fast and inexpensive approach for automatic model design that achieves state-of-the-art performance.
We propose to capture the deep learning communication (DLC) trace to achieve the measurement. We intend to analyze the network behavior and then carry out some research.
Generative adversarial networks (GANs) methods from the perspectives of algorithms, theory, and applications.
We address the task of detecting interaction triplets in challenging everyday photos. We propose a novel model that is driven by a human-centric approach.
We propose Relational LSTM to address the challenge for relation reasoning across space and time between objects in videos in a principled way.
We introduce a novel way of parametrizing embedding layers based on the Tensor Train decomposition, which allows compressing the model significantly at the cost of a negligible drop or even a slight gain in performance.
In this paper, a simple, fast, and efficient hybrid segmentation method is presented for extracting vessel structures in retinal fundus images.
We introduce syntactic dependency of interest (SDOI) design into the SAN to form an SDOI-SAN with syntax-guided self-attention. Syntax-guided network (SG-Net)
We propose an efficient transfer learning method for adapting ImageNet pre-trained Convolutional Neural Network (CNN) to fine-grained image classification task.
Super-resolution methods that exploit temporal correlation between low-resolution and high-resolution frames can cause temporal inconsistency, which can be observed as flickering.
Knowledge distillation refers to the process of training a compact student network to achieve better accuracy by learning from a high capacity teacher network. In this work, we propose a novel way to achieve this goal: by distilling the knowledge through a quantized space.
In this work, we perform a wide variety of experiments with different Deep Learning architectures in small data conditions. Differently from the literature, we improve the state of the art using low complexity models.
We improve automatic correction of grammatical, orthographic, and collocation errors in text using a multilayer convolutional encoder-decoder neural network using a character N-gram information to better suit this task.
We present LemmaTag, a featureless neural network architecture that jointly generates part-of-speech tags and lemmas for sentences by using bidirectional RNNs with character-level and word-level embeddings.
We consider the problem of grounding the meaning of words in the physical world and focus on the visual modality which we represent by visual attributes.
We propose a dynamic selection mechanism in CNNs that allows each neuron to adaptively adjust its receptive field size based on multiple scales of input information.
Autonomous vehicles need safe development and testing environments. Many traffic scenarios are such that they cannot be tested in the real world.
We interpret graph convolutions as integral transforms of embedding functions under probability measures, which leads to a batched training scheme for semi-supervised learning.
We analyze failure cases of state-of-the-art detectors and observe that most hard false positives result from classification instead of localization and they have a large negative impact on the performance of object detectors.
In this study, we examine the issue of evaluating accuracy of predictive models from deep learning features in digital pathology, as an hallmark of reproducibility. We introduce the DAPPER framework for validation based on a rigorous Data Analysis Plan derived from the FDA’s MAQC project, designed to analyse causes of variability in predictive biomarkers.
In this paper, we propose a framework to learn coordinated tasks in cluttered environments based on DiGrad - A multi-task reinforcement learning algorithm for continuous action-spaces.
We present an unsupervised representation learning framework to encode scene dynamics in videos captured from multiple viewpoints.
We present a fully automatic face recognition algorithm and demonstrate its performance on the FRGC v2.0 data.
We train a character-level 4096-dimension multiplicative LSTM for unsupervised text reconstruction over 3 epochs of the 40 GB Amazon Reviews dataset in four hours.
A review of 2-D fundus imaging and image analysis methods and their clinical implications.
A novel perception-inspired partial similarity measure is introduced, which can help capture the prominent partial similarities that are dominant in human perception. Two methods, based on the general golden section rule and the maximum margin criterion, are proposed to automatically set the similarity threshold.
We study the combination of structured sparse low-rank kernels, using a loose complementary condition, to generate a dense convolutional kernel.
In this paper we introduce PeerNets, a novel family of convolutional networks alternating classical Euclidean convolutions with graph convolutions to harness information from a graph of peer samples for robustness to adversarial attacks.
We present a framework for learning an efficient holistic representation for handwritten word images. The proposed method uses a deep convolutional neural network with traditional classification loss.
We propose a new sampling scheme and an unbiased estimator that estimates the partition function accurately in sub-linear time in near-constant time using locality sensitive hashing.
We propose a new method for multi-dimensional data classification which relies on two premises: 1) tensors are usually represented by tensors, due to benefits from multilinear algebra and the established tensor factorization methods; and 2) this kind of data can be described by a subspace lying within a vector space.
We introduce Combinatory Categorial Autoencoders to learn high dimensional embeddings for sentences and evaluate them in a range of tasks, demonstrating that syntax allows a concise model to learn representations that are both effective and general.
In reinforcement learning (RL), temporal abstraction still remains as an important and unsolved problem. In this paper, we propose a Hellinger distance regularizer for disentangling options.
We propose a principled way to generate object labelling in 3D space by combining information from multiple sources: geometric properties (from the 3D mesh), and appearance properties from images.
This paper proposes a new multi-task learning method with implicit inter-event relevance estimation, and applies it to complex Internet video event detection, which is a challenging and important problem in practice, yet seldom has been addressed.
Understanding the visual discrepancy and heterogeneity of different places is of great interest to architectural design, urban design and tourism planning.
We propose a Multi-Perspective Context Matching (MPCM) model that directly predicts the answer beginning and ending points in a passage in SQuAD.
A remarkable feature of human beings is their capacity for creative behaviour, referring to their ability to react to problems in ways that are novel, surprising, and useful.
We propose a new universal human parsing agent, named "Graphonomy", which incorporates hierarchical graph transfer learning upon the conventional parsing network to encode the underlying label semantic structures and propagate relevant semantic information and achieve state-of-the-art results.
We improved the FNC-1 best performing model adding BERT sentence embedding of input sequences as a model feature, (2) we fine-tuned BERT, XLNet, and RoBERTa transformers and obtained state-of-the-art results.
We focus on the problem of predicting future states of entities in complex, real-world driving scenarios. We propose different ways of modelling the future as a distribution over future states using standard supervised learning.
In this paper, we develop a hybrid method for sentiment analysis for Arabic tweets for a specific Arabic dialect which is the Saudi Dialect.
Our goal is to design architectures that retain the groundbreaking performance of CNNs for landmark localization and at the same time are lightweight, compact and suitable for applications with limited computational resources. To this end, we make the following contributions:
In this paper we compare learning-based methods and classical methods for navigation in virtual environments, as well as how characteristics of the virtual environment impact navigation performance.
We present a novel spatio-temporal fusion network that integrates temporal dynamics of appearance and motion information from entire videos and achieve state-of-the-art results with the best network.
We propose a novel data augmentation method named Semantic Constraint Generative Adversarial Network (SCGAN) for person re-identification (Re-ID) in camera sensor networks.
In this work, we propose a technique to convert CNN models for semantic segmentation of static images into CNNs for video data with little extra computational cost.
In this paper, we propose a LogDet divergence-based metric learning with triplet constraints (LDMLT) approach, which can learn Mahalanobis distance metric accurately and efficiently.
We propose a model that predicts future images by learning to represent the present state and its transformation given only a sequence of images.
This paper presents a unified Vision-Language Pre-training (VLP) model that achieves state-of-the-art results on both vision-language generation and understanding, across three challenging benchmark datasets.
This work presents a 3-step technique to fine-tune a pre-trained ResNet-50 architecture to improve model performance and reduce training time.
In this paper, we propose to exploit the rich hierarchical features of deep convolutional neural networks to improve the accuracy and robustness of visual tracking and exploit these multiple levels of abstraction to represent target objects.
In this paper, we exploit another approach which uses lateral interconnections in feature learning networks. However, we introduce an inhibitory layer placed right after normal encoding layer.
We propose a method for converting geometric shapes into hierarchically segmented parts with part labels, obtaining finer scale details than existing alternatives.
In this paper, we introduce a task-dependent neuron/filter level pruning framework based on Fisher's LDA. The approach can be applied to convolutional, fully-connected, and module-based deep structures.
We propose a novel Graph Reasoning Network (GRNet) on a Similarity Pyramid, which learns similarities between a query and a gallery cloth by using both global and local representations in multiple scales, enabling to improve clothing retrieval.
We propose a novel deep architecture, SegNet, for semantic pixel wise image labelling. It learns to map encoder outputs to image pixel labels.
We present WiBi, an approach to the automatic creation of a bitaxonomy for Wikipedia, that is, an integrated taxonomy of Wikipage pages and categories.
We present a method for training a neural network to perform image denoising without access to clean training examples or access to paired noisy training examples.
We propose an attention-based fine-tuning algorithm that automatically selects relevant contextualized features from the pre-trained language model and uses those features on downstream text classification tasks.
Segmentation is one of the most important low-level tasks in image processing as it enables many higher level computer vision tasks like object recognition and tracking. Segmentation can also be exploited for image compression using graph-based algorithms.
FCCP_LGNP: A novel descriptor for face description based on fuzzy convex-concave partition and local gradient number pattern.
We propose a weakly supervised person re-id setting where we only know that the identity appears in the video without the requirement of annotating the video during the training procedure.
We develop Point Attention Transformers (PATs), using a parameter-efficient Group Shuffle Attention (GSA) to replace the costly Multi-Head Attention, and propose an end-to-end learnable and task-agnostic sampling operation, named Gumbel Subset Sampling (GSS), to select a representative subset of input points.
We present a novel non-parametric clustering technique based on the notion that each latent cluster is comprised of layers that surround its core, where the external layers, or border points, implicitly separate the clusters.
We propose a Distilled Camera-Aware Self Training framework for semi-supervised person re-identification with limited labelled data.
We propose Virtual Pooling, a model-level approach to improve speed and energy consumption of CNN-based image classification and object detection tasks, with provable error bound.
 Cluster-Based Active Learning, a novel framework that employs clustering to boost active learning by reducing the number of human interactions required to train deep neural networks.
We study how to learn a semantic parser of state-of-the-art accuracy with less supervised training data.
We propose an adversarial discriminative loss to advocate representation coherence between standard and web data, which performs favorably against state-of-the-art methods.
Deep learning architectures are showing great promise in various computer vision domains including image classification, object detection, event detection and action recognition.
This article discusses a useful tool in dimensionality reduction and low-rank matrix approximation called the CUR decomposition. Various viewpoints of this method in the literature are synergized and are compared and contrasted.
We propose a novel locally-consistent deformable convolution, which utilizes the change in receptive fields and enforces a local coherency constraint to capture motion information effectively.
We introduce a principled semi-supervised framework that only uses a small set of fully supervised images (having semantic segmentation labels and box labels) and a set of images with only object bounding box labels (we call it the weak set).
In this paper we introduce a scalable training technique for 3D generative models from 2D data which utilizes an off-the-shelf non-differentiable renderer.
In this paper, we propose the CREST algorithm to reformulate DCFs as a one-layer convolutional neural network for end-to-end training.
We present an up-to-date critical review of the existing literatures on face alignment, focusing on those methods addressing overall difficulties and challenges of this topic under uncontrolled conditions.
We provide an up-to date list of available annotated datasets and an in-depth analysis of geometric, hand-crafted, and learned facial representations that are used for facial aging and kinship characterization.
We propose a face detection algorithm based on multi task learning and multilayer feature fusion, which integrates three tasks, namely, face classification, facial feature location, and bounding box regression.
We propose Continuous Sparsification, a new algorithm to search for winning tickets which continuously removes parameters from a network during training, and learns the sub-network's structure with gradient-based methods instead of relying on pruning strategies.
This paper addresses an important and challenging task, namely detecting the temporal intervals of actions in untrimmed videos in an end-to-end manner using structured segment network.
We propose RefineDetLite, a fast and accurate real-time object detector on a single-thread CPU device.
Model selection when designing deep learning systems for specific use-cases can be a challenging task as many options exist and it can be difficult to know the trade-off between model complexity, accuracy and speed.
Learning transform-based domain adaptation classifiers in a scalable manner.
In this paper, we propose two simple yet effective mechanisms, namely angle estimation and spatial masking, for Siamese network based trackers, to address these issues.
We propose a novel, stochastic training scheme for deep neural networks that better classifies the faint, ambiguous regions of the image.
We investigate how suitable DNNs are for accurate and automatic annotation of landmarks in video datasets representative of those collected by scientists studying animal behavior and kinematics.
We present an algorithm for computing class-specific universal adversarial perturbations for deep neural networks. The method does not require any training data.
We propose multi-label-based similarity learning for vehicle re-identification obtaining an efficient deep-learning-based model that derives robust vehicle representations.
Transfer learning-based approaches perform better than task-specific models trained on 3 times as much data on Japanese text classification datasets.
Pulmonary nodule analysis using convolutional neural network using medical images .
We propose a semantically aligned paired cycle-consistent generative (SEM-PCYC) model for zero-shot sketch-based image retrieval.
We propose to efficiently learn higher-order interactions between arbitrary subgroups of objects for fine-grained video understanding, while saving more than 3-times the computation over traditional pairwise relationships.
Capsule networks (CapsNet) are recently proposed neural network models containing newly introduced processing layer, which are specialized in entity representation and discovery in images. The CapsNet architecture is plausible and has been proven to be effective in some image data processing tasks.
We propose a novel tensor-based tensor convolutional network for graph embeddings of dynamic graphs.
We extend a recently proposed Deep Alignment Network (DAN) with a term related to facial features to solve emotion recognition task.
We propose a semi-supervised learning approach for video classification, VideoSSL, using convolutional neural networks (CNN) and exploit two regulatory signals from unlabeled data.
We introduce and compare three different approaches to identify writers on Wikipedia using data from DBpedia, a community project with the goal of extracting and providing structured information from Wikipedia.
We present a novel Spatio-Temporal Hybrid Convolution Network (denoted as"STH") which simultaneously encodes spatial and temporal video information with a small parameter cost.
We propose an accelerated ADMM optimisation method obtained by adding a momentum to the optimisation sequence iterates, and by relaxing the impact of the error between DCF parameters and their norm.
We propose a novel deep neural architecture to extract the informative feature representations from the heterogeneous acoustic feature groups which may contain redundant and unrelated information leading to low emotion recognition performance in this work.
We propose logistic LDA, a novel discriminative variant of latent Dirichlet allocation which is easy to apply to arbitrary inputs which exploits the group structure present in the data.
Object proposals have quickly become the de-facto pre-processing step in a number of vision pipelines (for object detection, object discovery, and other tasks). Their performance is usually evaluated on partially annotated datasets. In this paper, we introduce a nearly-fully annotated version of PASCAL dataset, which serves as a test-bed to check if object proposal techniques are overfitting to a particular list of categories.
We propose a novel Recurrent Neural Network (RNN) that takes a continuous (possibly previously unseen) stereo video as input, and directly predicts a depth-map at each frame without a pre-training process, and without the need of ground-truth depth-maps.
A generative recurrent neural network is quickly trained in an unsupervised manner to model popular reinforcement learning environments through compressed spatio-temporal representations, achieving state of the art results in various environments.
We use a suite of in-house and public tools to identify Functional Determinants (FDs), i.e. residue sites, responsible for conferring different phenotypes between different classes, different types and different variants of beta-lactamases.
This work proposes a novel efficient variant of the CF employed over a multidimensional content-addressable space. The proposed approach heuristically decreases the computational effort required by the CF algorithm by limiting the search process only to potentially similar users.
We perform automatic paraphrase detection on subtitle data from the Opusparcus corpus comprising six European languages: German, English, Finnish, French, Russian, and Swedish.
We propose an attention model learning fashion compatibility given a specific theme, and build a real-world theme-aware fashion dataset.
This research was funded by the National Natural Science Foundation of China under Grant 61772400, ::: Grant 61801351, Grant 61501353, grant 61772399, and grant 61573267. Zhou was supported by UK EPSRC under Grant EP/N011074/1.
We explore the power and limitation of persistence diagrams for graph data and shape data, and propose a permutation test for persistence diagrams, which improves on both summaries and pairings of critical values.
We learn a shape prior, consisting of vehicle geometry and appearance features, and we fit a vehicle model to initially detected vehicles.
We propose a novel Temporal Trilinear Pooling module for mobile video action recognition, where only the computational capabilities of mobile devices are accessible.
We develop a set of methods to improve on the results of self-supervised learning using context. We start with a baseline of patch based arrangement context learning.
We address this problem by observing that setting targets for hard-threshold hidden units in order to minimize loss is a discrete optimization problem that can be solved as such.
A 3D object detection Depth Neural Network based on multi-modality data of USVs in complicated marine environment.
We explore the multi-task learning setting for the recent BERT model on GLUE benchmark, and how to best add task-specific parameters to a pre-trained BERT network, with a high degree of parameter sharing between tasks.
Generative dialogue models currently suffer from a number of problems which standard maximum likelihood training does not address. In this work we show how all of these problems can be addressed by extending the recently introduced unlikelihood loss to these cases.
We propose an approach to learn spatio-temporal features in videos from intermediate visual representations we call "percepts" using Gated-Recurrent-Unit Recurrent Networks.
We propose a framework that makes use of semantic knowledge and estimates the relevance of object pairs during both training and test phases. Using this approach, we observe a significant improvement on all classes of Visual Genome, a challenging visual relationship dataset.
In this paper, we leverage existing single-task datasets for human action classification and captioning data for efficient human behavior learning.
We propose a semi-supervised self-growing generative adversarial network (SGGAN) based on the generative framework to exploit the power of unlabeled data.
We study the unsupervised learning of CNNs for optical flow estimation using proxy ground truth data.
We investigate a self-supervised learning setup in which stereo vision depth estimates serve as targets for a convolutional neural network (CNN) that transforms a single still image to a dense depth map.
We propose a new multimodal pattern mining approach that leverages the descriptive captions often accompanying news images to learn semantically meaningful image patch patterns from a large corpus of weakly supervised image-caption pairs.
In this paper, we propose a novel scene graph generation model for predicting object instances and its corresponding relationships in an image.
We propose a novel training objective that enables our convolutional neural network to learn to perform single image depth estimation, despite the absence of ground truth depth data.
We propose a supervised learning framework to generate compact and bit-scalable hashing codes from raw images in an end-to-end fashion.
We demonstrate that it is possible to learn features for network-flow-based data association via backpropagation, by expressing the optimum of smoothed network flow problem as a differentiable function of the pairwise association costs.
We present the first attacks and defenses against membership inference attacks on complex, state of the art models for semantic segmentation, and evaluate their effectiveness.
This paper constructs a data analysis model based on deep learning for medical images and transcripts, and is used for intelligent identification and diagnosis of diseases.
The ability of a dialog system to express prespecified language style during conversations has a direct impact on its usability and on user satisfaction.
We propose a novel approach for effectively encoding the user input from extreme points and corrective clicks, in a novel and scalable manner that allows the network to work with a variable number of clicks, including corrective clicks for output refinement.
We present a deep analysis of the effectiveness of SPADE and observe that its advantages actually come mainly from its semantic-awareness rather than the spatial-adaptiveness. Inspired by this point, we propose class-adaptive normalization, a lightweight variant that is not adaptive to spatial positions or layouts.
We can predict the number of views a photograph will receive even before it is uploaded using both image content and social cues.
We propose the prototype based Open Deep Network (P-ODN) for open set recognition tasks.
We address the shape-from-shading problem by training deep networks with synthetic images, achieving state-of-the-art performance.
In this paper we propose an approach which can dynamically adapt the weights of the tasks according to the difficulty for training the task.
We give a method to compute sparse features for arbitrary kernels, re-deriving as a special case a popular map for the intersection kernel and extending it to arbitrary additive kernels.
In this paper, in order to build an ensemble detector for large scale object detection, we present a conceptually simple but very effective class-wise ensemble detection.
We adapted the time-lagged Ordered Lasso, a regularized regression method with temporal monotonicity constraints, for de novo reconstruction, and developed a semi-supervised method that embeds prior network information into the Orderer Lasso to discover novel regulatory dependencies.
We propose a relational metric learning algorithm that uses relational information to improve the quality of the learned metric.
We explore different architectures and training configurations with the use of ReLUs, Nesterov's accelerated gradient, dropout and maxout networks for image classification tasks.
This paper proposes an object recognition model, named Statistic Experience-based Adaptive One-shot Detector (EAO), based on convolutional neural network, for improving the detection precision and the processing speed.
Instrumented vehicles can produce huge volumes of video data per vehicle per day that must be analysed automatically, often in real time. An important element in achieving this is the annotation of training data for machine learning algorithms.
We propose to replace existing normalization methods with a simple, secondary objective loss that we term a standardization loss that accelerates training on the primary training objective.
We propose a unified framework for face image analysis through end-to-end semantic face segmentation through Conditional Random Fields based model.
This paper presents a supervised method for blood vessel detection in digital retinal images where the vascular structure has been precisely marked by experts.
In this paper, we introduce DYAN, a novel network with very few parameters and easy to train, which produces accurate, high quality frame predictions, significantly faster than previous approaches.
We identify two issues with the family of algorithms based on the Adversarial Imitation Learning framework that require a prohibitively large number of interactions with the environment in order to imitate the expert for many real-world applications.
In this paper we target at generating generic action proposals in unconstrained videos. Each action proposal corresponds to a temporal series of spatial bounding boxes, which has a good potential to locate one human action.
Question answering has emerged as an intuitive way of querying structured data sources, and has attracted significant advancements over the years. In this article, we provide an overview over these recent advancements, focusing on neural network based question answering systems over knowledge graphs.
We propose a novel coupled 2D-3D Kalman filter, combined with a conceptually clean and extendable hypothesize-and-select framework, for 3D tracking.
We propose a new architecture for difficult image processing operations, such as natural edge detection or thin object segmentation.
We propose a fully-coupled two-stream spatiotemporal architecture for reliable human action recognition on extremely low resolution (e.g., 12x16 pixel) videos.
The recent tremendous success of unsupervised word embeddings in a multitude of applications raises the obvious question if similar methods could be derived to improve word sequences as well.
In this survey, we systematically summarize methods of path prediction that take video as input and extract features from the video in addition to predicting paths.
We introduce an unsupervised deep learning-based interest point detector and descriptor that is end-to-end trainable and runs in real-time.
We show that Batch Normalization can be beneficial in the final layer of the generator network for faster training of Generator networks.
We present an approach to predicting velocity and direction changes from visual information (”visual odometry”) using an end-to-end, deep learning-based architecture.
In this paper, we propose a novel GAN, namely IntersectGAN, to learn multiple attributes from different image domains through an intersecting architecture.
We propose an end-to-end, data-driven method of solving inverse problems inspired by the Neumann series, which we call a Neumann network, which outperforms state-of-the-art unrolled iterative methods on standard datasets.
In this paper, a face emotion is considered as the result of the composition of multiple concurrent signals, each corresponding to the movements of a specific facial muscle. This paper proposes to use the dynamics regulating each appearance feature time series to recognize among different face emotions.
Unsupervised Data Augmentation improves state-of-the-art data augmentation in semi-supervised learning setting.
We propose a lightweight and memory-friendly architecture for action recognition that performs on par with or better than current architectures by using only a fraction of resources.
We formulate the grouping of body part detections into people as a minimum-weight set packing (MWSP) problem where the set of potential people is the power set of the detections. We exploit the problem structure utilizing a nested Bender's decomposition (NBD) exact inference strategy.
Inverse Problems in medical imaging and computer vision are traditionally solved using purely model-based methods. We propose a data-driven approach that uses a neural network as a regularization functional.
We utilize AND-OR Grammar (AOG) as network generator in this paper and call the resulting networks AOGNets.
We propose top-down modulations as a way to incorporate fine details into the detection framework, connected using lateral connections.
Person re-identification (re-ID) has become increasingly popular in the community due to its application and research significance. Considering different tasks, we classify most current re-ID methods into two classes, i.e., image-based and video-based.
We introduce selective kernel network into optical flow estimation, which can adaptively select different scale features and adjust their receptive field according to the global information.
In this work, we propose a new method for multi-person pose estimation which combines the traditional bottom-up and the top-down methods.
We propose a multimodal MAML framework, which is able to modulate its meta-learned prior parameters according to the identified mode, allowing more efficient fast adaptation.
In this paper, we propose a novel method to incorporate partial evidence in the inference of deep convolutional neural networks, which drastically reduces the computational cost of training and inference.
This paper introduces KG-Story, a three-stage framework that allows the story generation model to take advantage of external Knowledge Graphs to produce interesting stories.
In this paper, we propose Contextual Recurrent Units (CRU) for enhancing local contextual representations in neural networks.
We address the problem of learning to look around: if a visual agent has the ability to voluntarily acquire new views to observe its environment, how can it learn efficient exploratory behaviors that reduce its uncertainty about the unobserved portions of its environment?
We propose a novel multi-source domain adaptation method, Mutual Learning Network for Multiple Source Domain Adaptation.
We propose leveraging deep convolutional activation features to perform classification, segmentation and visualization in large-scale tissue histopathology images.
We present three tasks, including datasets and baseline systems, and analyze the challenge entries for each.
We exploit social networks to make sentiment analysis more robust to social language variation, improving the accuracies of sentiment analysis on Twitter and review data.
This work approaches the instance segmentation problem as an annotation problem and presents a novel technique to encode and decode ground truth annotations using distance to center of mass encoding.
We present a texture network called Deep Encoding Pooling Network (DEP) for the task of ground terrain recognition.
We propose a scientific evaluation methodology aimed at assessing the quality, efficacy, robustness and efficiency of randomized defenses to protect DNNs against adversarial examples. Using this methodology, we evaluate a variety of defense mechanisms.
A novel neural architecture for understanding human communication called the Multi-attention Recurrent Network (MARN).
We address the problem of self-supervised estimation of a large number of parameters by introducing controlled graduation in estimation of the free parameters. A new tracker is proposed which exhibits the qualities of part-based as well as holistic models.
This paper presents a novel adaptation of fuzzy clustering and feature encoding for image classification, using fuzzy logic to model the ambiguity and combine it with clustering to discover fuzzy visual words.
The VoxCeleb Speaker Recognition Challenge 2019 aimed to assess how well current speaker recognition technology is able to identify speakers in unconstrained or `in the wild' data.
We propose AugMix, a data processing technique that improves the robustness and uncertainty estimates of image classifiers.
We show that the Transformer can be interpreted as a numerical Ordinary Differential Equation solver for a convection-diffusion equation in a multi-particle dynamic system.
Surprise is a property of recommender systems that has been receiving increasing attention owing to its links to serendipity. Most of the metrics for surprise poorly agree with definitions employed in research areas that conceptualise surprise as a human factor, and because of this, their use in the task of evaluating recommendations may not produce the desired effect.
We propose a novel end-to-end approach for scalable visual search infrastructure. We harness the availability of large image collection of eBay listings and state-of-the-art deep learning techniques to perform visual search at scale.
We propose quantized densely connected U-Nets for efficient visual landmark localization. The idea is that features of the same semantic meanings are globally reused across the stacked U-Net.
In this paper, we aim to discover visual attributes in a weakly supervised setting that is commonly encountered with contemporary image search engines.
In automatic facial expression detection, very accurate registration is desired which can be achieved via a deformable model approach where just a couple of key features (such as face and eyes) are tracked using a Viola-Jones type approach.
In this paper, we present a method to calibrate and enhance depth information captured by an infrared-based time-of-flight video-plus-depth camera called “Kinect camera”.
We propose a real-time multi object detection and tracking technique for road smart mobility.
A new method for robust estimation, MAGSAC++, is proposed. We also propose a new sampler, Progressive NAPSAC, for RANSAC-like robust estimators.
Video skimming, also known as dynamic video summarization, generates a temporally abridged version of a given video. Skimming can be achieved by identifying significant components either in uni- modal or multi-modal features extracted from the video.
We present the first multi-modal framework for evaluating English word representations based on cognitive lexical semantics.
We propose a novel adversarial training procedure to leverage unpaired data in the target domain and propose a critic-based planning method to select high-quality sentences.
In this paper, we propose to weight spatial locations based on their discriminative abilities in sparse coding for robust face recognition.
In this paper, we propose ARCH (Animatable Reconstruction of Clothed Humans), a novel end-to-end framework for accurate reconstruction of animation-ready 3D clothed humans from a monocular image.
 SenseNet was created for the purpose of researching and training Artificial Intelligences to interact with the environment via sensorimotor neural systems and tactile feedback.
This paper describes an approach that combines generative adversarial networks (GANs) with interactive evolutionary computation (IEC) for controllable and high-quality image generation.
We examine several aspects, such as how to define and diagnose overfitting in MDPs, and how to reduce risks by injecting sufficient training diversity.
We use the power of deep learning to capture 3D shape information from training data and provide high-quality initialization, while allowing both image evidence and shape priors to influence iterative refinement at inference time.
We study questions that have multiple targets in them, such as "Is the dresser in the bedroom bigger than the oven in the kitchen?", where the agent has to navigate to multiple locations ("dresser in bedroom", "oven in kitchen") and perform comparative reasoning before it can answer.
We apply Bayesian variational inference to DNNs for multimodal audiovisual activity recognition and quantify model uncertainty along with principled confidence.
We propose an approach to generating sentences, conditioned on an input sentence and a logical inference label, that approximates the conditional latent space over a logical antecedent.
We propose a new visual structure constraint on class centers for transductive ZSL, to improve generality of the projection function and alleviate the above domain shift problem.
We propose Word2VisualVec, a deep neural network architecture that learns to predict a deep visual encoding of textual input based on sentence vectorization and a multi-layer perceptron.
We propose DeepErase, a neural-based preprocessor to erase ink artifacts from text images, and use them to train an artifact segmentation network.
We propose an acquisition method that learns the cases when a given collective classification algorithm makes mistakes, and suggests acquisitions to correct those mistakes.
In this paper, we design a teacher-student learning framework to learn an occlusion-robust model from the full-body person domain to the occluded person domain.
In this paper we incorporate residual learning into NDF and the resulting model achieves state-of-the-art level accuracy on three public age estimation benchmarks while requiring less memory and computation.
An emerging problem in computer vision is the reconstruction of 3D shape and pose of an object from a single image. Hitherto, the problem has been addressed through the application of canonical deep learning methods to regress from the image directly to the 3D shapes and pose labels. These approaches, however, are problematic from two perspectives.
We investigate the use of a scanning visible-beam LIDAR to simultaneously provide enhanced texture within the scene and to provide additional opportunities for data fusion in unmatched regions.
We aim to obtain an interpretable, expressive, and disentangled scene representation that contains comprehensive structural and textural information for each object, enabling 3D-aware scene manipulation.
We introduce Budget-Aware Adapters that select the most relevant feature channels to better handle data from a novel domain and propose a novel strategy to adjust the computational complexity of the network.
We propose a method for detecting paraphrases via natural deduction proofs of semantic relations between sentence pairs.
In this paper, we propose a new approach to learn the regression model for visual tracking with single convolutional layer.
We compare different combinations of three spatial and two semantic affinity measures with four clustering methods for MC Dropout with a Single Shot Multi-Box Detector, where detection sample bounding boxes must be accurately associated and merged.
We introduce LUCSS, a language-based system for interactive col- orization of scene sketches, based on their semantic understanding.
The face recognition system based on the only single classifier considering restricted information can not guarantee the generality and superiority of performances in a real situation. To challenge such problems, we propose the hybrid Fourier features extracted from different frequency bands and multiple face models.
This paper presents and compares ear recognition models built with handcrafted and CNN features. The experimental results show the superior performance of the CNN based models by 22%.
In this paper, we employ fast nonparametric Bayesian inference techniques to more accurately model sensor uncertainty in dynamic environments.
We propose a novel consequentialism method for updating the weights of multi-layer neural networks with the mean squared error loss.
In this paper, we present a novel algorithm for precise eye detection that uses Histograms of Oriented Gradients descriptors.
We introduce a new neural architecture for sorting unordered sequences where the correct sequence order is not easily defined but must rather be inferred from training data.
Bayesian Convolutional Neural Network (BayesCNN) using Variational Inference is proposed.
We present an approach to learn an object-centric forward model, and show that this allows us to plan for sequences of actions to achieve distant desired goals. We present experiments both in simulation and the real world.
This companion paper supports the replication of scene recognition experiments using Adaptive Discriminative Region Discovery (Adi-Red), an approach presented at ACM Multimedia 2018.
We propose a framework, called SPLIT, which allows us to disentangle local and global information into two separate sets of latent variables within the variational autoencoder framework.
We employ convolutional feed-forward networks for solving the reconstruction problem efficiently while maintaining good reconstruction quality. We examine the performance of our method on a variety of synthetic and experimental datasets.
We introduce a novel and generalized version of the influence maximization problem that considers simultaneously the following three practical aspects: (i) Often cross-sell among products is possible, (ii) Product specific costs (and benefits) for promoting the products have to be considered, and (iii) Since a company often has budget constraints, the initial seeds have been chosen within a given budget.
We propose a novel attention-guided Generative Adversarial Network (AGGAN), which can detect the most discriminative semantic object and minimize changes of unwanted part for semantic manipulation problems without using extra data and models.
We formulate a compact and efficient network for seamless attenuation of different compression artifacts, achieving superior performance than state-of-the-art methods.
Depth captured by consumer RGB-D cameras is often noisy and misses values at some pixels, especially around object boundaries. In this paper, we present a depth map enhancement algorithm that performs depth map completion and de-noising simultaneously.
We propose an action recognition framework using Gen- erative Adversarial Networks using only appearance infor- mation using an unsupervised pre-training step.
This paper studies the accuracy of nearest-neighbor baselines without meta-learning. Surprisingly, we find simple feature transformations suffice to obtain competitive few-shot learning accuracies.
We present a method for creating video summaries in real-time on commodity hardware. Our method on average is able to generate a video summary in time that is shorter than the duration of the video.
We present a new algorithm to train a robust neural network against adversarial attacks, leading to an adversarial-trained Bayesian neural net.
We present an approach based on inferred models of influence that underlie recommender systems to guide the generation of dataset modifications to assess a recommender’s stability.
We propose a simple yet efficient deep-network-based multi-index hashing method for simultaneously learning the powerful image representation and the efficient searching.
A CNN cascaded architecture specifically designed for learning part relationships and spatial context, and robustly inferring pose even for the case of severe part occlusions.
We provide a method for predicting rare words on the fly from small amounts of auxiliary data with a network trained end-to-end for the downstream task.
We incorporate psychophysical measurements of visual perception into the loss function of a deep neural network being trained for a recognition task, under the assumption that such information can enforce consistency with human behavior.
In this paper, we propose a new GAN, trained on RGB-D face datasets, effective for a face-to-face translation from depth to RGB.
We propose a tube proposal network for object detection in video and propose two CNN architectures for generating and classifying tubes, respectively.
In this paper, we propose a fine-grained spatial-temporal attention model (FSTA) for video captioning tasks.
We propose a multidimensional evaluation criterion for GANs, specifically the Boundary Equilibrium Generative Adversarial Network (BEGAN), based on methods from the image quality assessment literature.
We present FasterSeg, an automatically designed semantic segmentation network with not only state-of-the-art performance but also faster speed than current methods.
We propose a novel solution for semi-supervised video object segmentation by leveraging memory networks and learn to read relevant information from all available sources.
We present a novel pseudo agent-based multiobjective hyperparameter optimization (PABO) for maximizing the DNN performance while obtaining low hardware cost.
In this paper, we propose to mitigate noise incurred by imperfect label assignment such that the contributions of anchors are dynamically determined by a carefully constructed cleanliness score associated with each anchor, allowing for improved localization and classification accuracy.
We augment the standard cross-entropy loss for action classification with an adversarial loss for scene types and a human mask confusion loss for videos where the human actors are masked out.
We propose to use a 3D Delaunay triangulation of Edge-Points to exploit the sharp edges of urban landscape, which are the 3D points corresponding to image edges.
We propose a method to extract a discrete reasoning chain over the text, which consists of a series of sentences leading to the answer, and achieve state-of-art performance on WikiHop and HotpotQA.
We propose to use the stereo matching network as a proxy to learn depth from synthetic data and use predicted stereo disparity maps for supervising the monocular depth estimation network.
An artificial neural network architecture that learns the acoustic and prosodic features that are relevant for the perception of emotional states in speech.
We introduce a novel end-to-end-trainable neural network that is capable of generating a Social Relationship Graph - a structured, unified representation of social relationships and attributes from a given input image.
We investigate time-continuous predictions of emotion (Arousal and Valence) in music and speech, and the Transfer Learning between these domains.
In the last decades several cost aggregation methods aimed at improving the robustness of stereo correspondence within local and global algorithms have been proposed.
We propose HyperLearner, a CNN-based pedestrian detection framework that learns pedestrian detection as well as the given extra feature without extra inputs.
In this paper we propose two saliency models for salient object segmentation based on hierarchical image segmentation, a tree-like structure that represents regions at different scales from the details to the whole image.
Improving pixel-wise semantic segmentation by manipulating dilated convolution-related operations that are of both theoretical and practical value.
We improve each step of the boundary delineation workflow, including image segmentation, boundary classification and interactive delineation, and apply it to UAV and aerial imagery.
We propose active learning with partial feedback, a novel annotation method for large-scale multiclass datasets.
We introduce a stochastic optimization algorithm, with convergence guarantees, to efficiently train group DRO models, while maintaining high average accuracies.
We introduce "Let's Dance", a 1000 video dataset (and growing) comprised of 10 visually overlapping dance categories that require motion for their classification. We compare our datasets' performance using imaging techniques with UCF-101.
Gradient-based search using Differentiable Architecture Sampler for efficient neural architecture search on CIFAR-10.
We perform a comprehensive error resilience analysis of DNNs subjected to hardware faults (e.g., permanent faults) in the weight memory. We propose a novel error mitigation technique which squashes the high-intensity faulty activation values to alleviate their impact.
This paper presents a novel approach for real-time egocentric activity recognition in which component atomic events are characterised in terms of binary relationships between parts of the body and manipulated objects.
We formulate a conditional random field over a four-connected graph as end-to-end trainable convolutional and recurrent networks, estimate them via an adversarial process, and use them for semantic face segmentation.
We propose a novel Bayesian model-agnostic meta-learning method that combines scalable gradient-based meta- learning with nonparametric variational inference in a principled probabilistic framework.
The existing compressive sensing (CS) reconstruction algorithms require enormous computation and reconstruction quality that is not satisfying. In this paper, we propose a novel Dual-Channel Reconstruction Network (DC-Net) module to build two CS reconstruction networks that outperform state-of-the-art CS reconstruction methods in PSNR and have excellent visual reconstruction effects.
In this paper, we propose a novel segmentation approach that uses a rectangle as a soft constraint by transforming it into an Euclidean distance map. Our approach gets accurate segmentation results given sloppy rectangles.
We propose a new spatial memory module and a spatial reasoner for the Visual Grounding task.
We extend the popular BERT architecture to a multi-modal two-stream model, processing both visual and textual inputs in separate streams that interact through co-attentional transformer layers.
We propose Multi-Task Label Embedding to convert labels in text classification into semantic vectors, thereby turning the original tasks into vector matching tasks.
We propose an approach that can reliably extract spatio-temporal object proposals for both known and unknown object categories from stereo video, which generalizes well to real-world scenarios.
We propose a multi-view deep network architecture coupled with n-pair loss (JNPL) to eliminate the complex view discrepancy and learn nonlinear mapping functions that are view-invariant.
We investigate the presence of transfer, from which task the transfer is sourced, and the application of fine tuning (i.e., retraining of the deep learning model after transfer).
We introduce a novel unified spatio-temporal 3D-CNN architecture (DynamoNet) that jointly optimizes the video classification and learning motion representation by predicting future frames as a multi-task learning problem.
We propose a multitask framework for jointly 2D and 3D pose estimation from still images and human action recognition from video sequences that achieves state of the art results.
This paper presents a probabilistic generative model for image segmentation, i.e. the task of partitioning an image into homogeneous regions.
We propose a parallel very largescale integration VLSI architecture for stereomatching with beliefpropagation, which can be used for real-time applications.
Protein interactions play a vital part in the function of a cell. As experimental techniques for detection and validation of protein interactions are time consuming, there is a need for computational methods for this task. Protein interactions appear to form a network with a relatively high degree of local clustering.
We propose Video Noise Contrastive Estimation, a method for using unlabeled video to learn strong, transferable single image representations. We demonstrate improvements over recent unsupervised single image techniques.
We propose an open set GAN architecture that is conditioned per-input sample with a feature embedding drawn from a metric space, allowing the generative model to produce samples that are semantically similar to a given source image.
We propose a novel parallel tracking and verifying (PTAV) framework, which achieves the best tracking accuracy among all real-time trackers, and in fact even outperforms many deep learning based algorithms.
We propose a numerical implementation of the linear optimal transport transform, which uses Brenier's theorem to characterize the solution of the Monge functional as the derivative of a convex potential function, and show that it is able to match images with lower error that existing methods.
We propose an Asymmetric GAN model with both translation and reconstruction generators of unequal sizes and different parameter-sharing strategy to adapt to the asymmetric need in both unsupervised and supervised image-to-image translation tasks, achieving superior model capacity and better generation performance compared with existing GAN models.
We propose a relation module for machine reading comprehension, which improves a MRC model's ability to determine whether a question has an answer in a given context.
We introduce a learnable module, cylindrical convolutional networks (CCNs), that exploit cylindherical representation of a Convolutional kernel defined in the 3D space. CCNs extract a view-specific feature through a convolutionsal kernel to predict object category scores at each viewpoint.
This paper presents a simple yet effective supervised deep hash approach that constructs binary hash codes from labeled data for large-scale image search, while the classification performance is not sacrificed.
We introduce the vine copula autoencoder (VCAE), a flexible generative model for high-dimensional distributions built in a straightforward three-step procedure.
This paper proposes a Residual Convolutional Neural Network (ResNet) based on speech features and trained under Focal Loss to recognize emotion in speech.
We studied and implemented a few illumination correction and contrast enhancement techniques on color retinal images to find the best technique for optimum image enhancement.
We propose and evaluate a novel text-based question answering task: Question Answering with Interactive Text (QAit) for machine reading systems.
We propose a fully-differentiable module based on monotonic rational-quadratic splines, which enhances the flexibility of both coupling and autoregressive transforms while retaining analytic invertibility.
We view label correction procedure as a meta-process and propose a new meta-learning based framework termed MLC for learning with weak supervision.
We propose a novel and probabilistically principled framework for pluralistic image completion that generates multiple and diverse plausible solutions.
Generative Adversarial Networks (GANs) can successfully approximate a probability distribution and produce realistic samples. We formalize this problem within the full-information adversarial bandit framework.
This work presents a real-time system producing reliable disparity estimation results on the new embedded energy-efficient GPU devices for stereo-camera systems.
We propose an effective lightweight model for facial landmark detection using a simple backbone MobileNetV2, three deconvolutional layers and feature-aligned distillation.
We exploit class peak responses to enable weakly supervised instance segmentation with image-level labels, instead of expensive pixel-level masks.
We propose an effective image denoising method by learning two image priors from the perspective of domain alignment.
We put forward the idea of performing self-supervised learning of visual features by mining a large scale corpus of multi-modal content.
We propose Information Dropout, a generalization of dropout rooted in information theoretic principles that automatically adapts to the data and can better exploit architectures of limited capacity.
We propose a Deep Texture Encoding Network with a novel Encoding Layer integrated on top of convolutional layers, which ports the entire dictionary learning and encoding pipeline into a single model.
A real-time 3D object detector based on LiDAR based Simultaneous Localization and Mapping (LiDAR-SLAM).
We propose Texture Fields, a novel texture representation which is based on regressing a continuous 3D function parameterized with a neural network and enable learning probabilistic generative models for texturing unseen 3D models.
We leverage VerbNet to build a rulebase (called the Semantic Lexicon) of the preconditions and effects of actions, and use it along with commonsense knowledge of persistence to answer questions about change.
We propose BodyNet, a neural network for direct inference of volumetric body shape from a single image, achieving state-of-the-art results on SURREAL and Unite the People datasets.
A novel end-to-end deep auto-encoder for unsupervised point cloud learning .
This paper presents a novel approach to learn and detect distinctive regions on 3D shapes. Unlike previous works, which require labeled data, our method is unsupervised.
In this paper we evaluate and report the performance of normal Softmax Vs Hierarchical Softmax on LSHTC datasets on large scale data sets.
We propose a novel and useful method to segment an original vehicle image into several discriminative foreground parts, and these parts consist of some fine grained regions that are named discrimInative patches.
Extraneous variables are variables that are irrelevant for a certain task, but heavily affect the distribution of the available data. In batch normalization, the statistics used to normalize features are learned from the training set and fixed at test time, which produces a mismatch in the presence of varying extraneous variables.
We propose a general framework, called hierarchical surface prediction (HSP), which facilitates prediction of high resolution voxel grids around predicted surfaces.
We propose a novel feed-forward encoder-decoder network architecture that enables fully automatic video modification at high frame rates.
We present an approach that uses a multi-camera system to train fine-grained detectors for keypoints that are prone to occlusion, such as the joints of a hand, enabling 3D markerless hand motion capture.
This paper proposes an approach to 3-D building model retrieval based on a topology structure and view feature using two filter steps to finish the buildingModel retrieval.
We identify the state-of-the art face emotion recognition methods that are potentially suitable for embedded environment and the most frequently used datasets for this task. We use it for evaluation of detection accuracy, power consumption and inference time on three frequently used embedded devices with different computational capabilities.
We propose an adaptive SLAM method that reduces the number of processed frame with minimum impact error, and make available a synthetic flexible stereo dataset with absolute ground truth, which allows to run new benchmarks for visual odometry challenges.
SMART Protocols ontology, an ontology for representing experimental protocols. We build upon previous experiences and bringing together the view of researchers managing protocols in their laboratory work.
We propose a novel deep learning framework, named Cascaded Context Pyramid Network (CCPNet), to jointly infer the occupancy and semantic labels of a volumetric 3D scene from a single depth image.
Generative Adversarial Networks can generate high-fidelity and locally-coherent audio waveforms faster than WaveNet models.
FEELVOS uses a semantic pixel-wise embedding together with a global and a local matching mechanism to transfer information from the first frame and from the previous frame of the video to the current frame.
In this paper, we propose the 3DFeat-Net which learns both 3D feature detector and descriptor for point cloud matching using weak supervision.
We present a simple yet highly efficient method to eliminate spurious trails of dynamic objects for 3-D point cloud map updating using RGB-D data input.
We investigate one recently proposed approach, AFLite, which adversarially filters such dataset biases, as a means to mitigate the prevalent overestimation of machine performance.
We propose an end-to-end learning framework for generating foreground object segmentations. We formulate the task as a structured prediction problem of assigning foreground/background labels, implemented using a deep fully convolutional network.
This paper defines a positive and unlabeled classification problem for standard GANs, which then leads to a novel technique to stabilize the training of the discriminator in GGANs.
We propose an experience ranking CNN method for sparse and binary rewards, which can speed up learning.
We propose a method for mining the collective knowledge contained in recent deep learning research to discover underlying principles for designing neural network architectures.
We propose an algorithm for low rank matrix completion which obtains explicit binary factors which represent a decomposition of the matrix into tiles.
We propose a component based method for age invariant face recognition, which is more robust to large time lapses.
We first propose a novel transformer distillation method that is a specially designed knowledge distillation (KD) method for transformer-based models. By leveraging this new KD method, the plenty of knowledge encoded in large teacher BERT can be well transferred to a small student TinyBERT.
We propose a novel Split DQN algorithm aiming at singulating the target object from its surrounding clutter, by means of lateral pushing movements of both the neighboring objects and thetarget object until sufficient 'grasping room' has been achieved.
Matrix factorization is one of the best approaches ::: for collaborative filtering because of its high accuracy in presenting ::: users and items latent factors.
We propose a layer-wise conditioning analysis that explores the optimization landscape with respect to each layer independently of its curvature matrix.
We propose to use self-supervised learning to achieve domain generalization and adaptation, and cast the problem within an auxiliary learning principled framework.
We propose an iterative inference algorithm based on gradient search, which is the first inference algorithm that can be broadly applied to any neural sequence generative models for text infilling tasks.
We propose a novel threein-one framework where three tasks domain adaptation, disentangled representation, and style transfer are considered simultaneously.
We first develop a novel weakly-supervised TAL framework called AutoLoc to directly predict the temporal boundary of each action instance. We propose a novel Outer-Inner-Contrastive (OIC) loss for training such a boundary predictor.
This study proposes a directional multi-scale line detector technique for the segmentation of retinal vessels with the prime focus on tiny vessels that are most difficult to segment out.
We derive exact analytic expressions for the first and second moments (mean and variance) of a small piecewise linear (PL) network (Affine, ReLU, Affine) subject to general Gaussian input.
We proposed FSSD (Feature Fusion Single Shot Multibox Detector), an enhanced SSD with a novel and lightweight feature fusion module which improves the performance significantly over SSD with just a little speed drop.
In this paper, we introduce a motion boundary based dense sampling strategy, which greatly reduces the number of valid trajectories while preserves the discriminative power.
Image translation, where the input image is mapped to its synthetic counterpart, is attractive in terms of wide applications in fields of computer graphics and computer vision. Despite significant progress on this problem, largely due to a surge of interest in conditional generative adversarial networks (cGANs), most of the cGAN-based approaches require supervised data, which are rarely available and expensive to provide.
Generative adversarial networks conditioned on simple textual image descriptions are capable of generating realistic-looking images. However, current methods still struggle to generate images based on complex image captions from a heterogeneous domain.
We introduce Exponential Machines (ExM), a predictor that models all interactions of every order and achieves state-of-the-art performance.
In this paper, we propose a novel clustering framework, named deep comprehensive correlation mining(DCCM), for exploring and taking full advantage of various kinds of correlations behind the unlabeled data from three aspects.
Deep Archetypal Analysis (DeepAA) generates latent representations of high-dimensional datasets in terms of intuitively understandable basic entities called archetypes.
A domain adaptation system that uses light-weight input adapters to pre-processes input images, irrespective of their appearance, in a way that makes them compatible with off-the-shelf computer vision tasks that are trained only on inputs with ideal conditions.
This paper introduces a revertive connection into the pedestrian re-recognition detector, making it more similar to the human cognitive process by converting a single image into an image sequence pattern, allowing them to reidentify pedestrians in images.
A novel semi-supervised learning technique based on a simple iterative learning cycle together with learned thresholding techniques and an ensemble decision support system.
We propose a low-rank shape deformation model to represent 3D structures of degenerate deformations. Based on this model, we formulate the NRSfM problem as two coherent optimization problems.
We propose a novel neural network architecture that integrates attention into a CNN with an emotion polarity constraint for fine-grained visual emotion regression.
We propose a Hierarchical Back Projection Network (HBPN), that cascades multiple HourGlass (HG) modules to bottom-up and top-down process features across all scales to capture various spatial correlations and then consolidates the best representation for reconstruction.
We first define a variety of situations and train a specialized object boundary detector for each of them using [10]. Then given a test image, we classify it into these situations using its context, which we model by global image appearance.
Proposed structural features improve the accuracy of answer extraction when combined with the basic features and designed using dependency principles.
We use diagnostic classifiers to probe agreement and transitivity information in vectors learned by a transition-based neural parser in four typologically different languages.
We propose an approach for exploiting contextual information in semantic image segmentation, and particularly investigate the use of patch-patch context and patch-background context in deep CNNs.
This paper uses quantitative evaluation on a challenging, novel dataset to demonstrate that (a) for any warping method, one can choose target models automatically to improve results, and (b) learning multiple coordinated specialized warpers offers further improvements on results.
This paper proposes a late fusing scheme that combines three systems that focus on extracting features and provide supervised learning on different abstraction levels for person re-identification.
In this work we aim to develop a universal sketch grouper that can be applied to sketches of any category in any domain to group constituent strokes/segments into semantically meaningful object parts.
We propose a feature-based sparse representation for image similarity assessment in terms of sparse representation.
We propose Dynamic Temporal Pyramid Network (DTPN), a new activity detection framework with a multi-scale pyramidal architecture featuring three novel designs.
We present a deep generative model for learning to predict classes not seen at training time using a latent-space distribution conditioned on class attributes.
A novel feature extraction approach using latent topic models (LTMs), based on restricted Boltzmann machines and distributed representations, is proposed to learn naturally discriminative topics.
In this paper, we propose a new technique called split annotations (SAs) that enables key data movement optimizations over unmodified library functions.
In this paper, a novel matched filter based on a new kernel function with Cauchy distribution is introduced to improve the accuracy ofthe automatic retinal vessel detection compared with other available matched filterâ€‘based methods, most notably, the methods builton Gaussian distribution function.
We propose a transfer learning setting specialized for semantic similarity, which can lead to state-of-the-art performance, and compare several approaches to transfer sentence encoders.
We present a survey of the role of visual analytics in deep learning research, which highlights its short yet impactful history and thoroughly summarizes the state-of-the-art using a human-centered interrogative framework.
CMM-Net explicitly exploits facial landmarks for generating smile sequences. Our experimental results demonstrate the effectiveness of our CMM-net in generating realistic videos of multiple smile expressions.
We propose an effective face completion algorithm using a deep generative model that can deal with a large area of missing pixels in arbitrary shapes and generate realistic face completion results.
ACK-MSCKF is proposed to fuse Ackermann error state measurements and the Stereo Multi-State Constraint Kalman Filter with a tightly-coupled filter-based mechanism for improved pose estimation accuracy.
We propose a deformable model based 3D face matching scheme to match 2.5D facial scans in the presence of both nonrigid deformations and pose changes (multiview) to a stored 3D model with neutral expression.
We propose a generative adversarial network for image compression, which is able to produce images with more photorealistic details than MSE or SSIM based networks.
We propose a frame-work for reformulating existing single-prediction models as multiple hypothesis prediction (MHP) models and an associated meta loss and optimization procedure to train them.
In this paper, we propose a semi-coupled mapping based set-to-set distance learning (SMDL) approach for person re-identification between low-resolution and high-resolution video pedestrian videos.
This paper proposes a novel support aggregation strategy which includes information obtained from a segmentation process.
We propose robust retinal blood vessel segmentation method based on reinforcement local descriptions, which is robust to intensity variety.
A meta-learner that explicitly relates tasks on a graph describing the relations of their output dimensions (e.g., classes) can significantly improve few shot learning.
A hierarchical co-occurrence model is proposed to enhance the semantic representation of a pedestrian with partial occlusions.
We present a context-aware unsupervised dual encoding framework for graph representation learning, combining real-time neighborhoods with neighbor-attentioned representation.
In this paper, we attempt to translate the speech signals into image signals without the transcription stage.
We extend object proposal methods with context proposals, which allow to incorporate the immediate context in the saliency computation, which improves salient object detection.
In order for machines interacting with the real world to have conversations with users about the objects and events around them, they need to understand dynamic audiovisual scenes. In this paper, we introduce a new data set of dialogs about videos of human behaviors, as well as an end-to-end Audio Visual Scene-Aware Dialog (AVSD) model that generates responses in a dialog about a video.
In this paper, we propose a novel convolution layer, called the conditional convolutionlayer, which directly generates different feature maps by employing the weights which are adjusted depending on the conditions.
We propose a novel attention mechanism, called \textit{text-conditional attention}, which allows the caption generator to focus on certain image features given previously generated text.
We address QA with respect to the OpenBookQA dataset and combine state of the art language models with abductive information retrieval (IR), information gain based re-ranking, passage selection and weighted scoring to achieve 72.0% accuracy.
This paper presents an occupancy based generative model of stereo and multi-view stereo images. In this model, the space is divided into empty and occupied regions.
This paper proposes a novel approach for the classification of 3D shapes exploiting deep learning techniques.
In this paper, we propose Entity Descriptions-Guided Embedding (EDGE), a novel method for learning the knowledge graph representations with semantic guidance from entity descriptions.
This paper provides a survey of state-of-the-art pruning techniques that are suitable for compressing deep Siamese networks applied to person re-identification.
Class incremental learning (CIL) problem, in which a learning agent continuously learns new classes from incrementally arriving training data batches, has gained much attention recently in AI and computer vision community due to both fundamental and practical perspectives of the problem. In this paper, we propose two simple modifications for vanilla FT, separated softmax (SS) layer and ratio-preserving mini-batches for SGD updates.
We propose the deep frame potential: a measure of coherence that is approximately related to representation stability but has minimizers that depend only on network structure. We validate its use as a criterion for model selection.
The ability to look multiple times through a series of pose-adjusted glimpses is fundamental to human vision. Short term memory plays an integral role in aggregating information obtained from these glimpses and informing our interpretation of the scene.
We introduce a new multi-dimensional nonlinear embedding—Piecewise Flat Embedding for image segmentation.
A novel adaptive copying recurrent neural network model to tackle the problem of question generation from sentences and paragraphs.
Randomized smoothing is a recently proposed defense against adversarial attacks that has achieved state-of-the-art provable robustness against $\ell_2$ perturbations. This begs the question: can we find a general theory for randomized smoothing, and validate its effectiveness in practice.
3D reconstruction from 2D images is a central problem in computer vision. Recent works have been focusing on reconstruction directly from a single image. We introduce an approach to compactly represent a 3D mesh.
We propose a novel representation of the first person actions derived from feature trajectories. We train a bag of words classifier with the proposed features.
We introduce a novel semi-supervised video segmentation approach based on an efficient video representation, called as super-trajectory, which handles occlusions and drifts in a robust and natural way.
We propose a novel fully convolutional network, that can take advantage of the structural information explicitly by incorporating the inverse depth features.
We define the problem of active learning as core-set selection, ie. choosing set of points such that a model learned over the selected subset is competitive for the remaining data points.
In this paper, we propose a novel invertible nxn convolution approach that overcomes the limitations of the Invertible 1x1 convolution.
We propose a novel probabilistic model which introduces a latent variable, i.e. the 'real' ground-truth which is semantically consistent, to optimize.
We propose a cross-connected CNN, an architecture that connects singletask CNNs through convolutional layers that transfer useful information to their counterparts.
We propose a two-stage convolutional neural network (CNN) architecture for robust recognition of hand gestures, called HGR-Net.
A simple way to utilize stereo camera data to improve feature descriptors.
Laughter is a highly spontaneous behavior that frequently occurs during social interactions. It serves as an expressive-communicative social signal which conveys a large spectrum of affect display.
We replace the expensive maximization over all actions with a small subset of possible actions sampled from a learned proposal distribution. The resulting approach, which we dub Amortized Q-learning (AQL), is able to handle discrete, continuous, or hybrid action spaces while maintaining the benefits of Q- learning.
Context-aware method that analyses the workflow of an intervention online and automatically predicts the remaining duration of procedures beforehand.
We propose to use a semantically regularised embedding layer as the interface between the CNN and RNN, allowing them to jointly train.
Attribute based knowledge transfer has proven very successful in visual object analysis and learning previously unseen classes. However, the common approach learns and transfers attributes without taking into consideration the embedded structure between categories in the source set.
We propose a new Deep Triplet Classification Siamese Network for instance-level Sketch-Based Image Retrieval.
We propose a general framework for transfer learning for paraphrase identification and natural language inference, which can effectively and efficiently adapt the shared knowledge learned from a resource-rich source domain to aresource-poor target domain.
We integrate prototypes, partial matching and top-down attention regulation into deep neural networks to realize robust object classification under occlusion.
Macquarie University's participation applies query-based multi-document extractive summarisation techniques to generate a multi-sentence answer given the question and the set of relevant snippets.
In this paper, we propose an effective framework that bridges the gap between the given question and the answer entities, by reconstructing the intermediate natural sequences on the basis of the entities and relations in knowledge bases.
In this paper, we study how we can solve difficult control problems in the real world by decomposing them into a part that is solved efficiently by conventional feedback control methods, and the residual which is solved with RL. The final control policy is a superposition of both control signals.
CANet, a class-agnostic segmentation network that performs few-shot segmentation on new classes with only a few annotated images available.
In this paper, we proposed a novel model that measured consistency between captioning predicted attentions and intrinsic visual attentions for genealogy research.
We address the problem of learning to suggest the single best frame across the video for user annotation---this is, in fact, never the first frame of video.
We present a neural compatibility modeling scheme with attentive knowledge distillation based on the teacher-student network scheme.
Deep Neural Networks (DNNs) are now increasingly adopted in a variety of Artificial Intelligence (AI) applications. Therefore, the DNN models can be deployed in the cloud, on the mobile devices, or even mobile-cloud coordinate processing.
This paper proposes a 3D Convolutional Neural Network method for Facial Expression Recognition in videos.
We propose a novel attention mechanism in which the attention between elements from input sequence(s) is directional and multi-dimensional (i.e., feature-wise), based solely on the proposed attention without any RNN/CNN structure.
We present an end-to-end framework for nodule detection, integrating nodule candidate screening and false positive reduction into one model, trained jointly.
We address the problem of reconstructing an object's surface from a single image using generative networks. We propose an encoder-decoder network that generates such kind of multiple view-dependent point clouds.
In this paper, we introduce TextBrewer, an open-source knowledge distillation toolkit for natural language processing.
This paper introduces a rank-based real-time annotation tool, we name AffectRank, and compares it against the popular rating-based Real-time FeelTrace tool through a proof-of-concept video annotation experiment.
The main goal of this paper is to illustrate a geometric analysis of 3D facial shapes in presence of varying facial expressions using the nose region. The experimental results demonstrate the success of the proposed framework in recognizing people under different facial expressions.
This paper presents a novel idea of video-based attack, which appends a few dummy frames (e.g., containing the texts of `thanks for watching') to a video clip and then adds adversarial perturbations only on these new frames.
We propose a novel spatial-temporal attention mechanism for DCF tracking, which improves the tracking performance during challenges like partial occlusion and deformation.
We attempt to exploit the effectiveness of Neural networks to perform multimodal Emotion recognition on IEMOCAP dataset using data from Speech, Text, and Motion capture data from face expressions, rotation and hand movements.
We propose a structured Robust Adaptive Dic-tionary Pair Learning (RA-DPL) framework for the discrim-inative sparse representation learning.
In this paper we present a novel lemmatization method based on a sequence-to-sequence neural network architecture and morphosyntactic context representation.
We propose spatial VAEs that use feature maps of larger size as latent variables to explicitly capture spatial information in a variational auto-encoder model.
We propose a novel face SR method that generates photo-realistic 8x super-resolved face images with fully retained facial details.
Name ethnicity of computer science scholars is investigated by population size, publication contribution and collaboration strength. We use name ethnicity classification as an indicator of ethnicity.
Long Short-Term Memory with Attributes (LSTM-A) - a novel architecture that integrates attributes into the successful Convolutional Neural Network (CNN) plus Recurrent Neural Networks (RNNs) image captioning framework, by training them in an end-to-end manner.
We introduce a contrasting GAN (contrast-GAN) with a novel adversarial contrasting objective. Equipped with the new contrasting objective, a novel mask-conditional contrast-GAN architecture is proposed.
SYnthetic BAsis (SYBA) feature descriptor for matching feature points to generate a sparse motion field for analysis.
We show that Variational Autoencoders consistently fail to learn marginal distributions in latent and visible space. We explore alternatives provided by marginal distribution matching and implicit distributions through the use of GANs.
We propose an end-to-end generative adversarial network that infers a face-specific disentangled representation of intrinsic face properties, including shape (i.e. normals), albedo, and lighting, and an alpha matte.
We find that applying orthogonal regularization to the generator renders it amenable to a simple "truncation trick," allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input.
This paper presents a neural network model for a knowledge base (KB)-based single-relation question answering (SR-QA) with attention-based question representation.
Superpixel algorithms are a common pre-processing step for computer vision algorithms such as segmentation, object tracking and localization. Many superpixel methods only rely on colors features for segmentation.
We propose a novel method to automatically generate low-level spatio-temporal descriptors showing good performance, for high-level human-action recognition tasks.
Support estimation (SE) of a sparse signal refers to finding the location indices of the non-zero elements in a sparse representation. This study proposes a novel approach for learning such a mapping from a training set.
In this paper, an unsupervised feature learning approach called convolutional denoising sparse autoencoder is proposed.
We propose a decentralized stochastic gradient tracking (DSGT) algorithm over peer-to-peer networks for empirical risk minimization problems, and explicitly evaluate its convergence rate in terms of key parameters of the problem.
This survey presents a deep analysis of the learning and inference capabilities of Siamese neural networks for visual tracking.
MLI is an Application Programming Interface designed to address the challenges of building Machine Learning algorithms in a distributed setting based on data-centric computing, with minimal complexity and competitive performance and scalability.
We propose a flow-based autoregressive model for molecular graph generation that achieves state-of-the-art performance on both chemical property optimization and constrained property optimization.
This paper presents a novel depth quality assessment scheme that is completely different from conventional approaches. In particular, this scheme focuses on depth edge misalignment errors in texture-plus-depth ( $\text{T}+\,\text{D}$) images and develops a robust method to detect them.
We address the task of evaluating image description generation systems. We propose a novel image-aware metric that estimates the faithfulness of a generated caption with respect to the content of the actual image.
This paper proposes a novel deep architecture to address multi-label image recognition, a fundamental and practical task towards general visual understanding.
To improve the robustness to rain, we present a physically-based rain rendering pipeline for realistically inserting rain into clear weather images.
We apply low-rank matrix factorization to LSTM recurrences, and explore the effectiveness on different NLP tasks and model components.
This paper proposes a Fast Region-based Convolutional Network method for object detection.
In this paper, we propose a zoom-out-and-in network for generating object proposals. We utilize different resolutions of feature maps in the network to detect object instances of various sizes.
We address the challenging problem of training object detectors with noisy annotations, where the noise contains a mixture of label noise and bounding box noise. We propose a learning framework which jointly optimizes object labels, bounding boxes, and model parameters by performing alternating noise correction and model training.
A stress-induced evolutionary synthesis framework for efficient feature extraction of deep neural networks.
We proposed a deep bias probabilistic matrix factorization (DBPMF) model by utilizing the convolutional neural network to extract latentuser/item features from user/item side information to address these problems.
In this paper, we introduce a novel convolutional neural network dubbed SCA-CNN that incorporates Spatial and Channel-wise Attentions in a CNN that incorporates contextual fixations over time.
In this work, we propose an effective scheme (called DP-Net) for compressing the deep neural networks (DNNs) while preserving accuracy.
We propose a novel robust nuclear norm regularized regression (RNR) method for face recognition with occlusion.
We propose a model encoder approach to learn a fixed length representation of deep learning architectures along with its hyperparameters, in an unsupervised fashion.
We revisit the problem of image aesthetic assessment from a self-supervised feature learning perspective and achieve comparable performance to supervised methods.
A biologically-inspired candidate weighting framework for detecting contours in complex scenes.
We present a regularized SVD (RSVD), present an efficient computational algorithm and provide several theoretical analysis.
We propose a new generative model-based approach, which trains a shared network twice with different targets and utilizes a single network during the testing phase, so that we can effectively save inference time.
This paper presents a generic context-mining RoI operator seamlessly integrated in R-CNNs, and the resulting object detection system is termed \textbf{Auto-Context R- CNN} which is trained end-to-end.
We present a novel image dataset construction framework that can be generalized well to unseen target domains and build an image dataset with 20 categories.
In this paper, we propose a robust object tracking algorithm based on a branch selection mechanism to choose the most efficient object representations from multi-branch siamese networks.
CUPCF is a combination of two similarity measures in collaborative filtering to solve the data sparsity problem and poor prediction problems for better recommendation.
We propose an efficient and effective architecture with a good trade-off between speed and accuracy, termed Bilateral Segmentation Network (BiSeNet V2) for realtime semantic segmentation.
The proposed BoW approach takes into account the manifold geometry of SPD matrices during the generation of the codebook and histograms, improving discrimination accuracy.
In this paper, we propose a novel approach to improve the structure of the predicted segmentation masks by enforcing sharp boundaries and avoiding discontinuities inside objects.
In this paper, we present a simple yet effective instance-aware image-to-image translation approach (INIT), which employs the fine-grained local (instance) and global styles to the target image spatially.
We compare LSTMs and Bi-LSTMs on six different benchmarks, which belong to different domains and have different levels of granularity.
We introduce a dual-step strategy that first extracts the task-specific knowledge from the heterogeneous teachers sharing the same sub-task, and then amalgamates the extracted knowledge to build the student network that tackles a set of selective tasks.
We propose a meta-learning framework for zero-shot forecasting of time-series data and demonstrate its applicability to new TS datasets.
We first propose a supervised multi-person 3D pose estimation and animation framework for a given input RGB video sequence.
We propose distributed layer-partitioned training with step-wise activation functions for privacy-preserving deep learning.
We develop the first multimodal shape completion method that completes the partial shape via conditional generative modeling, without requiring paired training data.
In this paper, we describe our submissions to the WMT17 Multimodal Translation Task. We also present negative results, based on ideas that we believe have potential of making improvements, but did not prove to be useful.
A simple yet effective convolutional prototype learning (CPL) framework for zero-shot recognition.
We propose a systematic learning-based approach to the generation of massive quantities of synthetic 3D scenes and arbitrary numbers of photorealistic 2D images thereof, with associated ground truth information, for the purposes of training, benchmarking, and diagnosing Learning-based computer vision and robotics algorithms.
We define a feed-forward deep neural network algorithm that can reconstruct 3D shapes from 2D landmark points almost perfectly (i.e., with extremely small reconstruction errors), even when these 2D landmarks are from a single image.
We train a deep network, using fully automatic supervision, to predict relative scene depth from single images, using classic depth from motion techniques, and no human provided labels.
The computational demands of computer vision tasks based on state-of-the-art Convolutional Neural Network (CNN) image classification far exceed the energy budgets of mobile devices. This paper proposes FixyNN, which consists of a fixed-weight feature extractor that generates ubiquitous CNN features, and a conventional programmable CNN accelerator which processes a dataset-specific CNN.
A good conversation requires balance -- between simplicity and detail; staying on topic and changing it; repetition, specificity, response-relatedness and question-asking. By controlling combinations of these variables our models obtain clear improvements in human quality judgments.
We propose a method for multi-person detection and 2-D pose estimation that achieves state-of-art results on the challenging COCO keypoints task.
Unsupervised image-to-image translation aims at learning a mapping between two visual domains. However, learning a translation across large geometry variations always ends up with failure.
We propose an adversarial training procedure for learning a causal implicit generative model for a given causal graph, and propose two new conditional GAN architectures for the problem.
This paper presents a fast algorithm for high-accuracy large-scale outdoor dense stereo reconstruction of man-made environments by enhancing the discontinuities along building facades.
This paper presents our metric (UoWLSTM) submitted in the WMT-15 metrics task, which uses dense vector spaces and Long Short Term Memory networks, which are types of Recurrent Neural Networks.
T(6;9)-DEK/CAN directly activates signaling pathways that are driven by the ABL1, AKT/mTOR, and SRC family kinases. The interplay of these signaling pathways creates a network with nodes that are credible candidates for combinatorial therapeutic interventions.
We propose a new model that can predict people trajectories at the desired time horizons and propose a novel method of long term odometry prediction.
A method for training a car detection system with annotated data from a source domain (day images) without requiring the image annotations of the target domain (night images) is presented.
We propose a novel single-step training strategy that allows convolutional encoder-decoder networks that use skip connections, to complete partially observed data by means of hallucination.
To learn how cognition is implemented in the brain, we must build computational models that can perform cognitive tasks, and test such models with brain and behavioral experiments.
We propose to adapt the Generative Adversarial model to perform low-dimensional network embedding, in which the generator is trying to generate vertex pairs, while the discriminator tries to distinguish the generated vertex pairs from real connections (edges) in the network.
We propose a new spatial attention fusion (SAF) method for obstacle detection using mmWave radar and vision sensor, where the sparsity of radar points are considered in the proposed SAF.
We propose a novel CL framework, named Balance Loss Curriculum Learning(BLCL), to reveal the comprehensive difficulty level of an example and improve the curriculum process based on the deep architectures.
This paper proposes a novel graph-based method for representing a human's shape during the performance of an action.
We present a method for automated segmentation of the vasculature in retinal images, based on the pixel's feature vector and Gabor wavelet transform responses.
We propose a neural network architecture able to set state-of-the-art results on drug-drug interactions, using the type of the side-effect and the molecular structure of the drugs alone.
In this paper, we present an in-depth investigation of the convolutional autoencoder (CAE) bottleneck, showing that increased height and width of the bottleneck drastically improves generalization, which in turn leads to better performance of the latent codes in downstream transfer learning tasks.
We propose a novel end-to-end deep neural network architecture for word level VSR called MobiVSR with a design parameter that aids in balancing the model's accuracy and parameter count.
We develop a tractable and stable caption-based image generation model using attention-based encoder to learn word-to-pixel dependencies.
We make a thorough investigation of the mainstream deep convolutional neural network architectures for multi-label image classification and present a strong baseline.
One-versus-all multiclass classification by providing algorithms with the complexity of a single binary classifier.
Automatically generating natural language descriptions from an image is a challenging problem in artificial intelligence that requires a good understanding of the correlations between visual and textual cues. In this paper we propose two novel approaches to address this issue - (i) a two-stream attention mechanism that can automatically discover latent categories and relate them to image regions based on the previously generated words, (ii) a regularization technique that captures the syntactic and semantic structure of captions
In this paper, we propose a novel feature-space local pooling method for the commonly adopted architecture of image classification that learns more accurate space partitioning that takes semantics into account.
We present an end-to-end lightweight network architecture to learn the convolutional features and perform the correlation tracking process simultaneously, while being more compact and much faster.
We use off-the-shelf CNNs trained for face recognition tasks to do facial attribute prediction from face images in the wild.
We introduce the Genetic-Gated Networks (G2Ns), simple neural networks that combine a gate vector composed of binary genetic genes in the hidden layer(s) of networks to improve sample efficiency and performance.
This paper proposes an attention pooling based representation learning method for speech emotion recognition (SER).
Using the scene context information obtained from moving and stationary pixels in the key frames, in conjunction with motion features, to solve the action recognition problem on a large (50 actions) dataset with videos from the web.
This paper presents an effective yet simple video representation for RGB-D-based action recognition. It proposes to represent a depth map sequence into three pairs of structured dynamic images (DIs) at body, part, and joint levels.
This paper proposes combining spatio-temporal appearance descriptors with optical flow for human action recognition.
We propose a new neuron model along with a novel activation function enabling learning of non-linear decision boundaries using a single neuron.
We introduce Cooperative Generator-Discriminator Networks (Co-opNet), a general framework for abstractive summarization with distinct modeling of the narrative flow in the output summary.
In this paper we propose Scene Completeness-Aware Depth Completion (SADC) to complete raw lidar scans into dense depth maps with fine whole scene structures.
We propose a broad attribute prediction model with enhanced attribute and feature (EAF-BAP) based on broad learning and elastic net constraint to improve the zero-shot image classification efficiently.
We propose an efficient self-organization strategy for convolutional networks so as to improve their efficiency and performance.
We benchmark several SVM objective functions for large-scale image classification. A comparison of online and batch methods for optimizing the objectives shows that online methods perform as well as batch methods in terms of classification accuracy but with a significant gain in training speed.
We propose ACE, a novel network embedding method, to preserve the features of hierarchical clustering structures in graphs.
We propose a novel GAN framework called evolutionary GANs for stable GAN training and improved generative performance.
We consider the problem of generating pairwise-aligned or pose-normalised depth maps from noisy 3D point clouds in a relatively unrestricted poses in a 3D face alignment application.
We propose a zero-shot sketch-image hashing work suitable for SBIR and cross-modal search.
Automatic affect analysis has attracted great interest in various contexts including the recognition of action units and basic or non-basic emotions. In spite of major efforts, there are several open questions on what the important cues to interpret facial expressions are and how to encode them. We analyse the state-of-the-art solutions by decomposing their pipelines into fundamental components, namely face registration, representation, dimensionality reduction and recognition.
We propose to train a single network for end-to-end nodule detection instead, without transfer learning or further post-processing.
We present an update to UDPipe 1.0 (Straka et al., 2016), a trainable pipeline which performs sentence segmentation, ::: tokenization, POS tagging, lemmatization and dependency parsing.
In a local and perceptual organization framework, a novel stereo correspondence algorithm is proposed to provide dense and accurate disparity maps under point ambiguity.
We learn view-invariant subspace for person re-identification, and its corresponding similarity metric using an adversarial view adaptation approach.
We present PointFusion and VoxelFusion: two simple yet effective early-fusion approaches to combine the RGB and point cloud modalities, by leveraging the recently introduced VoxelNet architecture.
We propose the novel spatio-temporal GAN-architecture $G^3AN$, which seeks to capture the distribution of high dimensional video data and to model appearance and motion in disentangled manner.
We propose an efficient Siamese CNN architecture that combines the low resolution disparity estimation and the depth discontinuity aware super-resolution for efficient stereo matching.
In particle filtering, dimensionality of the state space can be reduced by tracking control (or feature) points as independent objects, which are traditionally named as partitions. Two critical decisions have to be made in implementation of reduced state-space dimensionality.
A novel approach for detecting expert users just based on their ratings (unlike previous systems which consider the separate profile and extra information for each user)
In this paper we propose a novel algorithm for estimating the drivable collision-free space for autonomous navigation of on-road and on-water vehicles.
We propose a simple modification of stochastic gradient descent that stabilizes adversarial networks, enabling faster training with larger learning rates.
This paper considers recognizing products from daily photos, which is an important problem in real-world applications but also challenging due to background clutters, category diversities, noisy labels, etc. We address this problem by two contributions. First, we introduce a novel large-scale product image dataset, termed as Product-90, and develop a simple yet efficient guidance learning method for training convolutional neural networks (CNNs) with noisy supervision.
The employment of convolutional neural networks has led to significant performance improvement on the task of object detection. However, when applying existing detectors to continuous frames in a video, we often encounter momentary miss-detection of objects.
We study the ringing effects using a common Gabor filter for linear structure detection, and suggest a method for generating non-ring filters in 2D and 3D.
We propose a learning-based method to compose a video-story from a group of video clips that describe an activity or experience.
We use pairwise kernels to predict novel links, along with multiple kernel learning to integrate distinct sources of data into a decision function. Combined with cautious classification and data cleaning, we can achieve predictive accuracies of 99.6%.
MetaL-TDVS aims to excavate latent mechanism for summarizing video by reformulating video summarization as a meta learning problem and promote generalization ability of the trained model.
Optimal feature selection based on the orthogonality index minimizes the degree of uncertainty in estimating essential, fundamental, or homography matrix.
We propose an adaptive training-less system capable of detecting anomaly on-the-fly while dynamically estimating and adjusting response based on certain parameters.
We explore recently introduced definition modeling technique that provided the tool for evaluation of different distributed vector representations of words through modeling dictionary definitions of words and propose a possible solution by employing latent variable modeling and soft attention mechanisms.
In this paper, we build a general summarization framework for both of edited and raw video summarization.
We introduce the CoLlision Events for Video REpresentation and Reasoning (CLEVRER) dataset, a diagnostic video dataset for systematic evaluation of computational models on a wide range of reasoning tasks. We study the complementary problem, exploring the temporal and causal structures behind videos.
Using synthetic data to create an end-to-end deep learning pipeline, beginning with real-world objects and culminating in a trained model.
Attention mechanisms are ubiquitous components in neural architectures applied to natural language processing. In addition to yielding gains in predictive accuracy, attention weights are often claimed to confer interpretability, purportedly useful both for providing insights to practitioners and for explaining why a model makes its decisions.
We propose a novel citation recommendation model, called TopicCite, which mines such fine-grained correlations between topics and citations, which improves the state-of-the-art methods.
We propose the Edge-Embedded Multi-Dropout (EEMD) framework for real-time face alignment and explore multiple dropout architecture for locating facial landmarks.
In this paper, a new edge detection method is proposed where multi-scale anisotropic Gaussian kernels are used to obtain an edge map from an input image.
We propose an end-to-end convolutional neural network for variable-length multi-frame video interpolation, where motion interpretation and occlusion reasoning are jointly modeled.
We propose to aggregate deep convolutional features into an SPD matrix representation through the SPD generation and the SPD transformation under an end-to-end deep network.
In this paper, we propose a bottom-up gated hierarchical attention (GHA) mechanism for image captioning.
In this paper, we propose a novel attention-driven multi-branch network that learns robust and discriminative human representation from global whole-body images and local body-part images simultaneously.
We improve object detectors using a highly efficient and fine-grain mechanism called Inverted Attention (IA).
A robust VQA model is one, whose performance is not changed much when related basic questions as also made available to it as input.
We propose distortion robust DCT-Net, a Discrete Cosine Transform based module integrated into a deep network which is built on top of VGG16 and it generalizes well to unseen distortions.
We present Machine learning Assisted Image Annotation (MAIA), a new image annotation method for environmental monitoring and exploration that overcomes the obstacle of missing training data. The MAIA approach represents a substantial improvement on the path to greater efficiency in the annotation of large benthic image collections.
We present a novel method of compression of deep Convolutional Neural Networks by weight sharing through a new representation of convolutional filters. We further propose Differentiable FSNet where the way filters share weights is learned in a differentiable and end-to-end manner.
We introduce a new convolutional layer named the Temporal Gaussian Mixture (TGM) layer and present how it can be used to efficiently capture longer-term temporal information in continuous activity videos.
We apply two unsupervised learning algorithms, PCA and ICA, to the outputs of a deep Convolutional Neural Network trained on the ImageNet of 1000 classes, to reveal the hidden structure in them.
We introduce a novel sentence complexity model for Seq2Seq-based sentence simplification, and use it to promote fluency, adequacy, and simplicity.
We present a method for single image three-dimensional object detection and multiview object simultaneous localization and mapping in both static and dynamic environments, and demonstrate that the two parts can improve each other.
We propose a new Convolutional Neural Network CNN-based food image recognition algorithm to address this problem. We applied our proposed approach to two real-world food image data sets and achieved impressive results.
We propose to use uncertainty maps in the form of 2D soft localization heatmap images over five facial key-points to regress the head pose while using deep learning architectures.
The ability to semantically interpret hand-drawn line sketches, although very challenging, can pave way for novel applications in multimedia. We propose SketchParse, a novel architecture for fully automatic parsing of freehand object sketches.
Generating adversarial examples is an intriguing problem and an important way of understanding the working mechanism of deep neural networks. Most existing approaches generated perturbations in image space, i.e., each pixel can be modified independently. By interpreting them in physical space, most of these adversaries are authentic.
In this paper, we introduce the Taxonomy Enhanced Adversarial Learning (TEAL) for hypernymy prediction. It is implemented based on a word embedding projection network distantly trained over a taxonomy.
This paper presents Multi-view Labelling Object Detector (MLOD). The detector takes an RGB image and a LIDAR point cloud as input and follows the two-stage object detection framework [1] [2].
The goal of this paper is to classify objects mapped by LiDAR sensor into different classes such as vehicles, pedestrians and bikers.
In this paper we present a combined solution to reduce the required computational resources and time to apply a convolutional neural network (CNN) to extract events from e-sport gameplay videos.
This work proposes a general-purpose, fully-convolutional network architecture for efficiently processing large-scale 3D data.
In this paper, a novel integrated deep architecture is developed to effectively encode the detailed semantics of informative cross-modal data with semantic-rich cues for quality textual-visual search.
We present a method for simultaneously estimating 3D human pose and body shape from a sparse set of wide-baseline camera views, whilst recovering a 3D estimate of joint positions with equal or greater accuracy than the state of the art.
We present an instance segmentation algorithm trained and applied to a CCTV recording of beef cattle during a winter finishing period for early detection of animal welfare-related problems.
A well-trained model should classify objects with a unanimous score for every category. For each category, it is assumed that there are two feature sets: one with reliable information and the other with less reliable source.
We propose a joint neural network for action recognition that captures long-term temporal dependence of an action.
A dual-probabilistic model by sufficiently combining the content-based and collaborative filtering for personalized search.
We explore to "eliminate" the parameter of the number of topics, which is a key parameter of most topic models.
We introduce a novel metric that allows us to assess whether the generated captions meet our requirements (i.e., subject, predicate, object, and product name) and address annotator disagreements for the image ratings with an approach called soft targets.
This study tackles unsupervised domain adaptation of reading comprehension (UDARC).
An overview of state-of-the-art researches in pairwise trust prediction using machine learning techniques, especially in the context of social networking.
We propose Covariance-Preserving Adversarial Augmentation Networks to overcome existing limits of low-shot learning.
We propose SfM-Net, a geometry-aware neural network for motion estimation in videos that decomposes frame-to-frame pixel motion in terms of scene and object depth, camera motion and 3D object rotations and translations.
We propose a model-free multi-object tracking approach that uses a category-agnostic image segmentation method to track objects in rich human-made environments.
We propose a temporal action detection by spatial segmentation framework, which simultaneously categorize actions and temporally localize action instances in untrimmed videos.
DeOccNet is the first deep learning-based LF-DeOcc method that can effectively remove foreground occlusions and achieves superior performance.
We propose to apply semi-supervised learning and self-training to the problem of cursive, handwritten word recognition.
We provide a comprehensive survey of deep SOD algorithms from different perspectives including network architecture, level of supervision, learning paradigm and object/instance level detection, and provide detailed analysis of the comparison results.
We propose a deep hashing framework for sketch retrieval that, for the first time, works on a multi-million scale human sketch dataset.
We describe PullNet, an integrated framework for learning what to retrieve (from the KB and/or corpus) and reasoning with this heterogeneous information to find the best answer to open-domain queston answering.
Fashion Inpainting Networks (FiNet), a two-stage image-to-image generation framework that is able to perform compatible and diverse inpainting.
We propose a neural module network architecture for visual dialog that performs explicit, grounded, coreference resolution at a finer word level, achieving near perfect accuracy.
We propose a neural question generation model with two concrete modules: sentence-level semantic matching and answer position inferring.
This paper studies the problem of recovering the authentic samples that lie on a union of multiple subspaces from their corrupted observations.
The proposed AutoFCL model attempts to learn the structure of FC layers of a CNN automatically using Bayesian optimization. Fine-tuning the newly learned FC layers leads to state-of-the-art performance.
This paper introduces adversarial dropout, which is a minimal set of dropouts that maximize the divergence between the outputs from the network with the dropouts and the training supervisions.
In this paper, to the best of our knowledge, we for the first time integrate weakly supervised object proposal into convolutional neural networks (CNN) in an end-to-end learning manner.
We address the problem of detecting deep network generated (DNG) images by analyzing the disparities in color components between real scene images and DNG images. We propose a feature set to capture color image statistics for detecting the DNN images.
We propose a self-supervised learning method to jointly reason about spatial and temporal context for video recognition without any heavy preprocessing.
We propose a new convolution called Dynamic Region-Aware Convolution (DRConv), which can automatically assign multiple filters to corresponding spatial regions where features have similar representation, which significantly improves representation ability of convolution.
We present Tempest, a suite of novel attacks based on (1) client mobility, (2) usage patterns, and (3) changes in the underlying network routing that degrade user privacy across a wide range of anonymity networks.
We propose an effective feature representation called Local Maximal Occurrence (LOMO), and a subspace and metric learning method called Cross-view Quadratic Discriminant Analysis (XQDA)
We present a novel method for constructing Variational Autoencoder (VAE). Instead of using pixel-by-pixel loss, we enforce deep feature consistency between input and the output of a VAE, which ensures the VAE's output to preserve the spatial correlation characteristics of the input, thus leading the output to have a more natural visual appearance and better perceptual quality.
Transformation Equivariant Representations (TERs) aim to capture the intrinsic visual structures that equivary to various transformations by expanding the notion of {\em translation} equivariance underlying the success of Convolutional Neural Networks.
We propose a new BNN architecture BinaryDenseNet, which significantly surpasses all existing 1-bit CNNs on ImageNet without tricks.
Recognition of objects using Deep Neural Networks is an active area of research and many breakthroughs have been made in the last few years.
We extend the YouTube-8M video classification challenge by including text information in the classification, making this a truly multi-modal approach with vision, audio and text.
We propose a novel Octave Convolution operation to store and process feature maps that vary spatially "slower" at a lower spatial resolution reducing both memory and computation cost.
We view open set recognition as a retrieval task and propose a new approach, Opposite-Direction Feature Attack (ODFA), to generate adversarial examples / queries.
We propose an improved binary training method, by introducing a new regularization function that encourages training weights around binary values. We also introduce an improved approximation of the derivative of the $sign$ activation function in backward computation.
A novel CNN architecture that implicitly captures motion information between adjacent frames and directly predicts action classes without explicitly computing optical flow.
We propose a novel UDA framework based on an iterative self-training procedure, where the problem is formulated as latent variable loss minimization, and can be solved by alternatively generating pseudo labels on target data and re-training the model with these labels.
We combine hand-crafted features, SIFT, LBP and geometric feature, with deep learning feature as the representation of the expressions.
We propose UPSA, a novel approach that accomplishes Unsupervised Paraphrasing by Simulated Annealing.
We present a learnable attention map module for learning feature renormalization and mask-updating in an end-to-end manner, which is effective in adapting to irregular holes and propagation of convolution layers.
We build upon recent research that suggests that explicit regularization is not as important as widely believed and carry out an ablation study that concludes that weight decay and dropout may not be necessary for object recognition if enough data augmentation is introduced.
We present a novel approach to fully automated delineation of tree structures in noisy 2D images and 3D image stacks using global objective function.
We propose a global optimal rank selection method based on Bayesian optimization (BayesOpt), which is a machine learning based global optimization technique.
In this paper, we propose a novel Image-embodied Knowledge Representation Learning model (IKRL), where knowledge representations are learned with both triple facts and images.
Transfer learning enhances learning across tasks, by leveraging previously learned representations -- if they are properly chosen. We describe an efficient method to estimate the appropriateness of a previously trained model for use in a new learning task.
In this paper, we address the uncertainty modelling for predicting long-term future activities without compromising the accuracy.
We propose a novel entailment dataset and analyse the ability of recently proposed NLP models to perform inference on temporal predications that depend on tense and aspect.
We propose a differential gating scheme for the LSTM neural network, which emphasizes on the change in information gain caused by the salient motions between the successive frames, when they gate the information that ought to be memorized through time.
The goal of this work is the computation of very compact binary hashes for image instance retrieval. Our approach has two novel contributions.
We propose a new approach to train the Generative Adversarial Nets (GANs) with a mixture of generators to overcome the mode collapsing problem.
We propose a new pose-aware human instance segmentation method that integrates both top-down and bottom-up cues for an instance: it adopts detection results as human proposals and jointly estimates human pose andinstance segmentation for each proposal.
A systematic evaluation of recent CNN-based texture descriptors for recognition and attempts to understand the nature of invariances captured by these representations, providing a means for understanding categorical properties.
We compare two implementations of k Nearest Neighbors algorithm, i.e. Mahout and LensKit, as well as six similarity measures.
Semantic Scene Completion from RGB-D data using edge detection and flipped truncated signed distance .
A novel mechanism to preserve differential privacy in adversarial learning for deep neural networks, with provable robustness to adversarial examples.
The field of functional recognition or affordance estimation from images has seen a revival in recent years. In a tribute to Gibson, this paper explores his theory of affordances as originally proposed.
We propose a new label adaptation technique that first extracts internal states of vehicles from the underlying driving simulator, and then refines labels by predicting future paths of vehicles based on a well-studied motion model.
This paper addresses the problem of event recognition by proposing a convolutional neural network that exploits knowledge of objects and scenes for event classification (OS2E-CNN)
We present a new approach to analyzing drug-drug interaction networks, based on clustering and topological community detection techniques that are specific to complex network science.
We analyse the problem of Semantic Segmentation and find that the data distribution does not exhibit low density regions separating classes and offer this as an explanation for why semi-supervised segmentation is a challenging problem.
We present a statistical and computational technique for identifying AEs caused by two-drug combinations using the Likelihood Ratio Test.
We first build many inclusive thin sub-networks (of the same depth) under a minor modification of existing multi-branch DNNs, and found that they can significantly outperform the state-of-art dense architecture for anytime prediction.
We introduce a novel generative autoencoder network model that learns to encode and reconstruct images with high quality and resolution, and supports smooth random sampling from the latent space of the encoder.
We propose an automatic, efficient and unsupervised method based on gradient matrix, the normalized cut criterion and tracking strategy for retinal vessel segmentation.
We propose a stable GAN training procedure with low computational cost that yields reliable building blocks for deep learning.
This paper proposes a sequential coupling of a hidden Markov model (HMM) recognizer for offline handwritten English sentences with a probabilistic bottom-up chart parser using stochastic context-free grammars extracted from a text corpus.
Dilated InceptionV3 achieved better overall and per-class accuracy than any known methods on skin lesions classification to the best of our knowledge while experimenting with a complex open-source dataset with class imbalances.
This paper proposes novel framework for facial expressions analysis using dynamic and static information in video sequences.
We reformulate the facial pose estimation as a label distribution learning problem, considering each face image as an example associated with a Gaussian label distribution rather than a single label, and construct a convolutional neural network which is trained with a multi-loss function on AFLW dataset and 300W-LP dataset.
We propose a Semantic-Specific Graph Representation Learning (SSGRL) framework that incorporates category semantics to guide learning semantic-specific representations and explores their interactions via a graph propagation mechanism.
This paper formulates object detection as a problem of graph structure inference, where given an image the objects are treated as nodes in a graph and relationships between them are modeled as edges in such graph.
We propose a novel graph neural network (GNN) based model for conversational machine reading comprehension, which captures conversational flow in the dialog.
In this paper, we propose a novel pixel-wise contextual attention network, i.e., the PiCANet, to learn to selectively attend to informative context locations.
This paper presents a novel approach for depth video enhancement based on a weighted mode filtering method for temporally consistent enhancement of depth video.
We propose an efficient framework for training contextual representation models by bypassing the softmax layer and performing language modeling without truncating the vocabulary.
We look into robustness of deep learning based MRI reconstruction when tested on unseen contrasts and organs. We propose to generalise the network by training with large publicly-available natural image datasets with synthesised phase information.
We propose a method that uses deep motion features as well as deep still-image features, following the success of two-stream convolutional networks, each of which are trained separately for spatial and temporal streams.
We present two new datasets and a novel attention mechanism for Natural Language Inference and propose a modification to the "word-to-word" attention function which has been uniformly reused across several popular NLI architectures.
This paper examines how emotion feedback influences emotion awareness and gaze behavior in a videoconference setup.
We use shingling and chord trajectory matrices to create signature for each music piece and perform spectral clustering to find the clusters.
We use Preferential based Reinforcement Learning to solve inspiration learning tasks in different action spaces.
This paper revisits the problem of point cloud representation and recognition from the viewpoint of data augmentation without incorporating additional data or more annotations.
We propose a novel pose descriptor which can represent and recognize human actions in videos in a simple and compact way.
We propose an effective, efficient and end-to-end proposal generation method, named Boundary-Matching Network (BMN), which generates proposals with precise temporal boundaries as well as reliable confidence scores simultaneously.
In this paper, we propose the gated multiple feedback network (GMFN) for accurate image SR, in which the representation of low-level features are efficiently enriched by rerouting multiple high- level features.
We expose and tackle some of the basic weaknesses of a GCNN model with a capsule idea and propose our Graph Capsule Network (GCAPS-CNN) model to solve especially graph classification problem which current GCNN models find challenging.
This paper proposes to associate a bivariate label distribution (BLD) to each landmark of an image, alleviating the problem of inaccurate landmarks.
Convolutional neural networks can solve multiple image restoration tasks.
We present a method for 3D object detection and pose estimation from a single image using a novel hybrid discrete-continuous loss, which significantly outperforms current techniques.
We show that geo-tagged content can vary significantly based on whether they are captured by a local versus a tourist to the location.
We improve and propose a SincNet-based classifier for EEG signals classification, which consists of three convolutional layers, and three deep neural network (DNN) layers.
The proposed self-similarity hypercubes (SSH) model, which observes the concurrent occurrences of visual words in an image, is able to describe the structural information of the BOF, and thus improves classification performance.
We propose a novel generative adversarial network that synthesizes CNN features conditioned on class-level semantic information, offering a shortcut directly from a semantic descriptor of a class to a class-conditional feature distribution.
Learning over multi-view data is a challenging problem with strong practical applications. Most related studies focus on the classification point of view and assume that all the views are available at any time.
This paper proposes a novel method for understanding daily hand-object manipulation by developing computer vision-based techniques by exploring their contextual relationships.
Unsupervised meta-reinforcement learning that transfers to downstream tasks specified by hand-crafted reward functions and serves as pre-training.
We propose the MACRo-mIcro Disentangled Variational Auto-Encoder for learning disentangled representations from user behavior.
We construct CNNs capable of solving the optical flow estimation problem as a supervised learning task, achieving competitive accuracy at frame rates of 5 to 10 fps.
We address the over-confidence issue and over-sensitivity issue existing in current RC models simultaneously with the help of external linguistic knowledge. We first incorporate external knowledge to impose different linguistic constraints (entity constraint, lexical constraint, and predicate constraint), and then regularize RC models through posterior regularization.
In this paper, a novel approach is proposed which divides the training process into two consecutive phases to obtain better generalization performance.
We propose a neural network model, named as histogram of oriented gradient improved CNN (HCNN), that combines local and global features towards human-like classification based on CNN and HOG.
This paper presents an efficient method for detection and localization of anomalies in videos. Using fully convolutional neural networks and temporal data.
We propose a bias-free representation learning method for person re-identification that can efficiently correct the feature bias during the representation learning step.
A review of AI-based research for GPCR bioactive ligand discovery with a particular focus on the most recent achievements and research trends.
We propose a geometrically-consistent, geometry-aware image generation method that leverages various types of scene information, including geometry and segmentation, to create realistic looking natural images that match the desired scene structure.
A Semantic Compositional Network (SCN) is developed for image captioning, in which semantic concepts (i.e., tags) are detected from the image, and the probability of each tag is used to compose the parameters in a long short-term memory network.
Adapting domain-adapted vision and language representations to relevant in-domain tasks for Vision-and-Language Navigation tasks improves competitive agents in R2R.
We introduce multilayer gradient fusion for training a densityaware global count regressor. We show that a CNN regressing a global count trained with density map supervision can make more accurate prediction.
We propose an active learning method to train a LiDAR 3D object detector with the least amount of labeled training data necessary.
 LO-Net is a novel pipeline for lidar odometry estimation from 3D lidar scanning data using deep convolutional networks.
Protein complexes are fundamental for understanding principles of cellular organizations. As the sizes of protein–protein interaction (PPI) networks are increasing, accurate protein complex prediction from these PPI networks can serve as a guide for biological experiments to discover novel protein complexes.
We extend RL-based architecture search methods to support parallel training on multiple tasks and then transfer the search strategy to new tasks.
Regulatory mechanisms shared by prognostic GSs from individual cancer types and across cancer types, which shed light on the discovery of new prognosticGSs in cancers and the understanding of the regulatory mechanisms.
We propose a no-example approach to stream retrieval, which can accommodate arbitrary search queries, and propose means for evaluating them.
In this paper, we propose Attentive CutMix, a naturally enhanced augmentation strategy based on CutMix.
We propose to analyze deep networks using known operators, by adopting a divide-and-conquer strategy to replace network components, whilst retaining its performance.
We propose a content-aware Variational multi-view stereo method, which preserves fine-scale details and sharp features while suppressing noise, and obtains cleaner and more accurate reconstructions than state-of-the-art methods.
Generative Adversarial Networks (GANs) can efficiently generate new, physically realistic realizations of the cosmic web in a fraction of a second.
We propose a mutimodal semantic segmentation framework that dynamically adapts the fusion of modality-specific features while being sensitive to the object category, spatial location and scene context in a self-supervised manner in an efficient and robust manner.
The goal of this paper is to perform 3D object detection in the context of autonomous driving. We formulate the problem as minimizing an energy function that encodes object size priors, placement of objects on the ground plane as well as several depth informed features that reason about free space, point cloud density and distance to the ground.
We propose the Conditional Domain Normalization (CDN) to bridge the domain gap and address the domain shifts of different level's representation.
We model information diffusion in heterogeneous information networks, and use interactions of different meta-paths to predict the diffusion process.
The paper proposes an approach that considers individual and crowd metrics to determine anomaly, and uses emotional state of individuals.
In this paper, we introduce the first methodology for 3D facial motion synthesis from speech captured in arbitrary recording conditions ("in the wild") and independent of the speaker.
High-order covariates interaction is considered into Lasso-type variable selection. We propose a new regularization term in Lasso regression model to impose high order interactions between covariates and responses.
We show how to adapt existing 3D object detection methods to images from fisheye cameras, including in the case that no labeled training data is available for training.
An end-to-end trainable gated fusion method for two-stream ConvNets based on the MoE theory for action recognition.
We propose the use of a proportional-derivative (PD) control based policy learned via reinforcement learning (RL) to estimate and forecast 3D human pose from egocentric videos.
We present our submitted systems for Semantic Textual Similarity (STS Track 4 at SemEval-2017.
We introduce a cross modal image retrieval system that allows both text and sketch as input modalities for the query, allowing multiple objects in the query.
We introduce novel variants of white-box and black-box adversarial training, dubbed gray-box Adversarial Training, based on which we propose novel evaluation method to assess the robustness of the learned models.
We propose an approach for learning category-level semantic segmentation purely from image-level classification tags indicating presence of categories.
We propose a novel dataflow-based joint quantization approach with the hypothesis that fewer number of quantization operations would incur less information loss and thus improve the final performance.
We propose an approach for semi-automatic annotation of object instances in Cityscapes, mimicking how most current datasets have been annotated.
We investigate whether existing detectors will continue to improve as data grows, or saturate in performance due to limited model complexity and the Bayes risk associated with the feature spaces in which they operate.
Automated iris segmentation of iris region pixels from visible face images using visible imaging .
We propose an end-to-end online 3D video object detector that operates on point cloud sequences, which enhances the conventional ConvGRU with an attentive memory gating mechanism.
We propose the S3-GAN Generative Adversarial Network for style separation and synthesis on object photographs.
We present a novel iterative refinement process to apply to any stereo matching algorithm. The quality of its disparity map output is increased using rigorously defined refinement modules, which can be iterated multiple times.
We propose a novel graph mining algorithm (PEWCC) to identify protein complexes from protein-protein interaction data.
In this paper, two deep transfer learning methods are proposed to address the training data sparsity problem for person re-identification.
The vertebrate visual system is hierarchically organized to process visual information in successive stages. Neural representations can emerge as a direct consequence of different neural resource constraints on the retinal and cortical networks, and for the first time we find a single model from which both geometries spontaneously emerge at the appropriate stages of visual processing.
This paper describes the Imperial College London team's submission to the 2019' VATEX video captioning challenge, where we first explore two sequence-to-sequence models, namely a recurrent (GRU) model and a transformer model, which generate captions from the I3D action features.
A 1281-fragment library was screened by nuclear magnetic resonance (NMR) against AmpC β-lactamase, and hits were confirmed by surface plasmon resonance (SPR) and computationally docked 290,000 purchasable fragments with chemotype holes.
We train an autonomous agent using a single video demonstration and use human feedback (using numerical similarity rating) to construct a mapping between the standard representation of the agent and the visual representations of the demonstration.
In this paper, we develop an evolutionary optimization technique for the automated design of hardware-optimized DNN architectures with respect to their hardware efficiency and error resilience.
We introduce an end-to-end differentiable model for interpreting questions about a knowledge graph (KG), which generalizes well to longer questions than seen in its training data.
The paper presents the result on cross-representation mediation of user models in the context of movie recommendation using community-based ratings.
We propose Unified Visual-Semantic Embeddings (UniVSE) for learning a joint space of visual and textual concepts. A contrastive learning approach is proposed for the fine-grained alignment from only image-caption pairs.
We evaluate a computational approach to predict genetic interactions in Homo sapiens , Drosophila melanogaster , and Saccharomyces cerevisiae .
We propose and evaluate methods that can be employed to transfer a repository of subjectivity resources across languages and generate resources for subjectivity analysis in a new language.
We present Quadtree Generating Networks (QGNs), a novel approach able to drastically reduce the memory footprint of modern semantic segmentation networks.
We introduce a labeling tool and dataset aimed to facilitate computer vision research in agriculture, and introduce novel methods for labeling with a variety of manual, semi-automatic, and fully-automatic tools.
We introduce a non-linear morphable face model, capable of producing multifarious face geometry of pore-level resolution, coupled with material attributes for use in physically-based rendering.
This paper proposes a knowledge transfer method to support learning using cross-domain datasets, from generic to specific domain.
Text-to-speech acoustic models map linguistic features into an acoustic representation out of which an audible waveform is generated. This way, possible signal naturalness losses are avoided as intermediate acoustic representations are discarded.
The availability of large annotated datasets and affordable computation power have led to impressive improvements in the performance of CNNs on several benchmark datasets. These, along with a better understanding of deep learning methods, have also led to improved capabilities of machine understanding of faces.
The paper proposes a stacked Wasserstein autoencoder with a new regularization as an optimal transport to learn a deep latent variable model.
We propose Show-and-Fool, a novel algorithm for crafting adversarial examples in neural image captioning. The proposed algorithm can successfully craft visually-similar adversarialExamples with randomly targeted captions or keywords.
A new family of trust region based adversarial attacks, with the goal of computing adversarial perturbations efficiently. We propose several attacks based on variants of the trust region optimization method.
We use convolutional variational auto-encoders for end-to-end learning of semantic-metric occupancy grids from monocular data.
We present two techniques to improve landmark localization in images from partially annotated datasets, where only a small fraction of the dataset has landmark labels.
PixelDCL can be used to replace any deconvolutional layer in a plug-and-play manner without compromising the fully trainable capabilities of original models.
We propose a flexible Bayesian nonparametric hierarchical clustering prior based on the time-marginalized coalescent and develop a new inducing-point approximation and inference algorithm for large datasets.
In this paper, we propose a novel temporal spiking recurrent neural network (TSRNN) for robust action recognition.
We use a novel four-layer CNN architecture that is as good as much larger networks on the task of evaluating objectness while being much faster.
This paper addresses the generation of referring expressions that not only refer to objects correctly but also let humans find them quickly.
We learn audio representations by solving a novel self-supervised learning task, which consists of predicting the phase of the short-time Fourier transform from its magnitude, leading to generalization across downstream audio tasks.
Deep residual refining based pseudo-multi-frame network for efficient Single Image Super-resolution .
This paper studies deep network architectures to address the problem of video classification. A multi-stream framework is proposed to fully utilize the rich multimodal information in videos, where the optimal fusion weights are learned adaptively for each class.
We propose a robust monocular visual odometry framework using category-aware semantic edges and a semantic nearest neighbor field that facilitates a robust data association of edges across frames using semantics.
In this paper, we investigate the effect of erasing ReLUs of certain layers and apply it to various representative architectures following deterministic rules.
We propose a framework that combines recent advances in knowledge distillation (teacher-student framework), relational reasoning and probabilistic logical languages to incorporate such knowledge in existing neural networks for the task of Visual Question Answering.
We propose a tree-guided visual tracking model based on the multimodality correlation filter which could estimate the target state according to the most reliable information in previous frames.
We provide empirical counterexamples to the view of GAN training as divergence minimization and show that GANs are able to learn distributions in situations where the divergence maximization point of view predicts they would fail.
We propose a novel extractive approach that predicts the start and end frames by leveraging cross-modal interactions between the text and video - this removes the need to retrieve and re-rank multiple proposal segments.
We have converted various well-known resource efficient 2D CNNs to 3D kernels and evaluated their performance on three major benchmarks in terms of classification accuracy for different complexity levels.
In this paper a simple and efficient framework for single human action recognition is proposed by introducing a frame-by-frame learning approach.
We aim at benefiting from several datasets with different categories without additional labelling, not only to increase the number of categories detected, but also to take advantage from transfer learning and to enhance domain independence.
We propose a method for compressing large, complex trained ensembles into a single network, where knowledge from a variety of trained deep neural networks (DNNs) is distilled and transferred to a single DNN.
This paper introduces a new framework for data efficient and versatile meta-learning employing a flexible and versatile amortization network that takes few-shot learning datasets as inputs, with arbitrary numbers of shots, and outputs a distribution over task-specific parameters in a single forward pass.
We propose a novel video saliency model, called ACLNet, that augments the CNN-LSTM network with a supervised attention mechanism to enable fast end-to-end learning.
We propose a cascaded backbone-branches fully convolutional neural network for rapidly and accurately localizing facial landmarks in unconstrained and cluttered settings.
Handwritten text recognition is challenging because of the virtually infinite ways a human can write the same message. Our fully convolutional handwriting model uses both local and global context and mitigates the need for heavy preprocessing steps such as connectionist temporal classification, dictionary matching or language models.
This paper addresses two challenging tasks: improving the quality of real-world low resolution face images via super-resolution and accurately locating the facial landmarks on such poor resolution images.
We propose Cognitive Databases, an approach for transparently enabling Artificial Intelligence (AI) capabilities in relational databases, and use it to enable a new class of SQL-based analytics queries called cognitive intelligence (CI) queries.
We propose a simple yet effective framework, named GARP-Face, that balances utility preservation and privacy protection in face de-identification.
We propose a novel Multi-scale Conditional Generative Adversarial network for synthesizing high-resolution person images with arbitrary poses.
We introduce SkewScout, a system-level approach that adapts the communication frequency of decentralized learning algorithms to the (skew-induced) accuracy loss between data partitions between devices/locations.
We propose a novel and efficient way to obtain discriminative appearance-based tracklet affinity models in a complex scene captured by a single camera.
We propose a novel learning framework which incorporates an analysis-by-synthesis paradigm to reconstruct images in a viewpoint aware manner with a generative network, along with symmetry and adversarial constraints to successfully supervise our viewpoint estimation network.
We propose to explicitly model pairwise word interactions and present a novel similarity focus mechanism to identify important correspondences for better similarity measurement.
We propose Neural Error Correcting and Source Trimming (\modelname) codes to jointly learn the encoding and decoding processes in an end-to-end fashion.
We explore an efficient convolutional deep neural network design for spatiotemporal encoding of time windowed video frame sub-sequences and study the respective balance between speed and accuracy.
A first theoretical and experimental contribution of the paper is to establish that even in the large sample limit with arbitrarily powerful neural architectures and latent space, the VAE failsif the sharpness of the distribution class does not match the scale of the data.
We developed a real-time, high-quality video object segmentation algorithm for semi-supervised video segmentation using a novel global context module that reliably summarizes and propagates information through the entire video.
Unsupervised feature extraction from incomplete tensors using low-rank tensor decompositions and feature variance maximization .
We propose a novel refinement architecture to address the challenging problem of learning a crisp edge detector using ConvNet.
We introduce a generic CV model that creates the basis for the hazard analysis and—for the first time—apply an extensive HAZOP to the CV domain.
In this study, we have considered all 9 Nipah proteins as potential therapeutic targets and computationally identified 4 putative peptide inhibitors (against G, F and M proteins) and 146 small molecule inhibitors (Against F, G, M, N, and P proteins).
We present a neural rendering framework that maps a voxelized scene into a high quality image and allows controllable rendering.
We present Dual Channel-wise Alignment Networks, a simple yet effective approach to reduce domain shift at both pixel-level and feature-level.
We present a new approach for pretraining a bi-directional transformer model that provides significant performance gains across a variety of language understanding problems.
We propose a new protein complex identification method based on an edge weight method and core-attachment structure (EWCA) which consists of a complex core and some sparse attachment proteins.
We developed a convolutional neural network (CNN) to automatically classify images of vascular anomalies and other pediatric skin conditions to aid physicians with diagnosis.
We propose a framework for depth estimation from a set of calibrated images, captured under general camera motion and parameter variation.
In this paper, we address a challenging image segmentation problem called multiple foreground cosegmentation, which concerns a realistic scenario in general Webuser photo sets where a finite number of K foregrounds of interest repeatedly occur cross the entire photo set, but only an unknown subset of them is presented in each image.
Generating adversarial examples by increasing false positive rate on large-scale image datasets.
We propose a novel architecture to conduct the equivalent of the deconvolution operation globally and acquire dense predictions, improving state-of-the-art semantic segmentation models.
This paper presents an approach to the categorisation of spatio-temporal activity in video, which is based solely on the relative distribution of features alone (without explicit appearance information), and demonstrate performance consistent with state-of-the-art.
We propose an approach to semantic (image) segmentation that reduces the computational costs by a factor of 25 with limited impact on the quality of results.
In this work we present an in-depth analysis of the user behaviors on different Social Sharing systems. We characterize the tagging behavior as well as the tendency to create friendship relationships of these platforms.
ImageNet is a large-scale hierarchical database of object classes with millions of images. We propose to automatically populate it with pixelwise object-background segmentations, leveraging existing manual annotations in the form of class labels and bounding-boxes.
We propose a novel multi-class multiple kernel learning framework which improves the state-of-the-art by enhancing the local separation of the classes in the feature space in the kernel space.
We propose a novel surrogate task to learn visual characteristics shared across classes with a separate encoder for class information.
We propose a novel approach based on pre-processed DWT representation of audio signals and SVM to secure audio systems against adversarial attacks.
We propose an Online High-quality Anchor Mining Strategy (HAMBox), which explicitly helps outer faces compensate with high-quality anchors. We will release the codes with PaddlePaddle.
This paper presents a method of learning Spatial Pyramid Attentive Pooling (SPAP) which is a novel architectural unit and can be easily integrated into both generators and discriminators in GANs and CycleGANs.
We propose Task-Aware Feature Embedding Networks (TAFE-Nets) to learn how to adapt the image representation to a new task in a meta-learning fashion.
Hexagonal grids use a hierarchical subdivision tessellation to cover the entire plane or sphere, which makes them suitable for geospatial information processing and intelligent decision-making.
Pretraining with language modeling and related unsupervised tasks has recently been shown to be a very effective enabling technology for the development of neural network models for language understanding tasks. However, language model-style pretraining is not an ideal starting point for efficient transfer learning.
This study explores various speech data augmentation methods for the task of noise-robust fundamental frequency (F0) estimation with neural networks.
Multi-hop reading comprehension focuses on one type of factoid question, where a system needs to properly integrate multiple pieces of evidence to correctly answer a question.
We propose Adversarial Model Cascades (AMC), a cascade of models sequentially where each model is optimized to be robust towards multiple attacks.
The detection and localization of anomalous behaviors in crowded scenes is considered, and a joint detector of temporal and spatial anomalies is proposed that achieves state-of-the-art results.
We propose a novel methodology for learning to detect image transformations visible to human observers through approximating perceptual thresholds through equivariant representation learning.
In this paper we address the problem of representing 3D visual data with parameterized volumetric shape primitives. Specifically, we present a (two-stage) approach built around convolutional neural networks capable of segmenting complex depth scenes into the simpler geometric structures that can be represented with superquadric models.
We design a cascaded network architecture that unrolls the proximal gradient iterations by permeating benefits from generative residual networks (ResNet) to modeling the proximate operator.
We introduce a Group Convolutional Neural Network with linear equivariance to translations and right angle rotations in three dimensions, achieving state-of-the-art performance on a variety of 3D inference problems.
We propose a framework for constructing and analyzing multiclass and multioutput classification metrics, i.e., involving multiple, possibly correlated multiclass labels.
We propose a simple yet robust approach for irregular text recognition that achieves state-of-the-art performance on the evaluated regular and irregular text benchmark datasets.
We aim to prune networks at initialization, thereby saving resources at training and test time as well.
In this paper, we propose a unified formulation for learning a deformable convolution filter that improves the baseline method, leading to state-of-the-art performance.
In this paper, we explore the knowledge distillation approach under the multi-task learning setting. We distill BERT into bidirectional LSTM with attention mechanism.
We propose joint analysis for simultaneous motion part segmentation and motion attribute estimation, taking a single 3D model as input, which achieves state-of-the-art performance.
We train a neural network for answering simple questions in an end-to-end manner, leaving all decisions to the model.
A multi-features fusion target tracking algorithm based on kernel-correlated filtering for video .
We propose a multi-task learning framework for sentence representations that combines the inductive biases of diverse training objectives in a single model that improves on previous methods.
In this paper, we propose a novel method for semantic image inpainting which generates the missing content by conditioning on the available data.
In this paper, we propose a novel semi-fragile data hiding-based technique for real-time sensor data integrity verification and tamper detection and localization.
We propose a fully unsupervised Convolutional Auto-Encoder based LiDAR Odometry (CAE-LO) that detects interest points from spherical ring data using 2D CAE and extracts features from multi-resolution voxel model using 3DCAE.
We propose a simple yet effective pose transformation GAN by utilizing the Residual Learning method without any additional feature learning to generate a given human image in any arbitrary pose.
Iterative Generative Adversarial Networks for image-to-image transformation and 3D manipulation .
We extended a CNN by adding recurrent connections to different layers of the CNN to allow spatial representations to be remembered and accumulated over time, leading to a hierarchical and distributed model of process memory as an integral part of visual processing.
Unifying latent variable sampling and conditioning not only yields samples of higher quality, but also helps the model to avoid posterior collapse.
We review, categorize, analyze, and provide a detailed performance evaluation of the latest convolutional-neural network-based crowd-counting techniques.
We address the problem of graph-based semi-supervised learning in the presence of severely limited labeled samples, and propose a new framework, called {\em Shoestring, that improves the learning performance through semantic transfer from these very few labeled samples to large numbers of unlabeled samples.
We propose two sequential probabilistic video frame analysis approaches to improve the segmentation performance of the existing algorithms.
Availability of large training datasets was essential for the recent advancement and success of deep learning methods.
We propose an approximate manifold defense mechanism, called RBF-CNN, for image classification without the need for expensive adversarial training.
We address these three important aspects of a good summary via a reinforcement learning approach with two novel reward functions: ROUGESal and Entail, on top of a coverage-based baseline.
We propose a novel method for online segmentation of video sequences that incorporates temporal data. We also introduce a novel convolutional gated recurrent unit.
In this paper, I implemented a model with Bi-directional attention flow layer connected with a Multi-layer LSTM encoder, connected with one start-index decoder and one conditioning end- index decoder.
We use local estimates of reliable (dis-)similarities to initially group samples into compact surrogate classes and use local partial orders of samples to classes to link classes to each other.
We present an efficient approach to measure the confidence of decision-making steps by statistically investigating each unit's contribution to that decision.
The goal of this paper is to advance the state-of-the-art of articulated pose estimation in scenes with multiple people. We propose (1) improved body part detectors that generate effective bottom-up proposals for body parts; (2) novel image-conditioned pairwise terms that allow to assemble the proposals into a variable number of consistent body part configurations.
We present a fast and robust method of solving the gradient or Laplacian with minimal error, which can be used for gradient domain editing.
We propose a Multi-sentiment-resource Enhanced Attention Network (MEAN) to alleviate the problem by integrating three kinds of sentiment linguistic knowledge.
We propose an alternative notion of distance between datasets that is model-agnostic, does not involve training, can compare datasets even if their label sets are completely disjoint and has solid theoretical footing.
We addressed the problem of age estimation from single facial gray-scale image since the color information appeared as not significant in considered low resolution images.
A novel quantized maximum a posteriori (Q-MAP) denoising method, where the source distribution is fully known, is proposed.
In this paper, we present a new method for 3D face recognition using range data.
We demonstrate that, starting from the simple assumption that a scene is composed of multiple entities, it is possible to learn to segment images into interpretable objects with disentangled representations.
We introduce {\alpha}-Rank, a principled evolutionary dynamics methodology for the evaluation and ranking of agents in large-scale multi-agent interactions, grounded in a novel dynamical game-theoretic solution concept called Markov-Conley chains (MCCs).
We present a robust and real-time monocular six degree of freedom relocalization system that localizes from high level features and is robust to difficult lighting, motion blur and different camera intrinsics where point based SIFT registration fails.
We propose the active co-tracking framework for tracing-by-detection, in which the main classifier of the tracker labels samples of the video sequence, and only consults auxiliary classifier when it is uncertain.
This paper proposes a novel model, the Interaction Canonical Correlation Network (ICCN), to learn multimodal embeddings for sentiment analysis and emotion recognition.
We propose to improve the sample diversity of a pre-trained class-conditional generator by modifying its class embeddings in the direction of maximizing the log probability outputs of a classifierPre-trained on the same dataset.
In this paper, we propose a regularization method that applies both image manipulation and feature map regularization based on patches, which improves the performance of the model.
A novel automatic detection of diabetic retinopathy and maculopathy in eye fundus images by employing fuzzy image processing techniques.
This paper proposes a region-of-interest (ROI)-based sampling algorithm in on-road environments for autonomous driving that effectively distributes samples in the road, object, and background areas.
We propose a collaborative learning framework for deblurring-related image kernels, which can be used for image interpolation and edge-preserved smoothing.
We introduce Cooperative Vision-and-Dialog Navigation, a dataset of over 2k embodied, human-human dialogs situated in simulated, photorealistic home environments.
Detecting human in a crowd is a challenging problem due to the uncertainties of occlusion patterns. In this paper, we propose to handle the crowd Occlusion problem in human detection by leveraging the head part.
We present a new approach to the problem of estimating the 3D room layout from a single panoramic image, trained for predicting 1D layout, outperforms previous state-of-the-art approaches.
We propose a deep neural model to leverage type hierarchy and relations of entities in Knowledge Base and detect topic entities correctly.
We propose Circulant Binary Embedding (CBE) which generates binary codes by projecting the data with a circulant matrix and uses Fast Fourier Transformation to speed up the computation.
We investigate the synthesizability of dynamic texture samples and learn classifiers to select the most suitable method to synthesize them.
We address the rarely addressed case of monocular height estimation, where camera parameters and scene geometry is unknown, by mining explicit height labels and propagating them to additional images.
We present IBN-Net, a novel convolutional architecture, which remarkably enhances a CNN's modeling ability on one domain (e.g. GTA5) as well as its generalization capacity on another domain without finetuning.
We propose a novel multi-receptive field attention (MRFA) module that utilizes filters of various sizes to help network focusing on informative pixels.
Automated method to segment blood vessels of fundus retinal image using probabilistic modelling and adaptive histogram equalisation .
We present PR-DARTS, a NAS algorithm that discovers strong network configurations in a much larger search space and a single day.
A review of the state of the art in feature-based retinal image analysis.
We propose in this paper an integrated framework consisting of bottom-up and top-down attention mechanisms that enable attention to be computed at the level of salient objects and/or regions.
We propose a novel approach for 3D shape completion by synthesizing multi-view depth maps from a set of fixed viewing angles as our shape representation.
We propose a novel correlation filter-based tracker in this paper, in which the temporal relatedness is reconciled under a multi-task learning framework and the multiple feature cues are modeled using a multiview learning approach.
We propose a novel active learning strategy whereby the learning algorithm searches for effective architectures on the fly, while actively learning. We apply our strategy using three known querying techniques.
We present a generative model based on a deep recurrent architecture that combines recent advances in computer vision and machine translation and that can be used to generate natural sentences describing an image.
In this paper, we propose a new differentiable Neural Architecture Search method based on Proximal gradient descent (denoted as NASP)
We develop a novel learning scheme called Harmonization, where latent model parameters are jointly learned from each other to exploit strong complementarity among different modalities and GPLVM components.
Deep Multimodal Clustering for Unsupervised Audiovisual Learning in the Unconstrained Environment .
We propose a framework to deal with limited labeled training data and demonstrate it on the application of vision-based vehicle control using a teacher-student learning paradigm.
BiLingUNet uses language to customize visual filters and outperforms approaches that concatenate a linguistic representation to the visual input.
We present an improved version of our algorithm for detection of 3D bounding boxes of vehicles, their tracking and subsequent speed estimation and an extended experimental evaluation of speed estimation.
In this paper, we propose a novel language representation model called SentiLR, which introduces word-level linguistic knowledge including part-of-speech tag and prior sentiment polarity from SentiWordNet to benefit the downstream tasks in sentiment analysis.
This paper is focused on the assessment of the performance of a retinal vessel tree extraction method on different hardware platforms and architectures.
We devise an object-level attentional mechanism that can be used to determine relevant objects from a few trajectories or demonstrations, and then immediately incorporate those objects into a learned policy.
We present a novel framework for learning to interpret and generate language using only perceptual context as supervision using only ambiguous supervision.
We investigate the capacity control provided by dropout in various machine learning problems where it induces a data-dependent regularizer that, in expectation, equals the weighted trace-norm of the product of the factors.
We present our submission to the Microsoft Video to Language Challenge of generating short captions describing videos in the challenge dataset. Our model is based on the encoder--decoder pipeline, popular in image and video captioning systems.
We develop an open source, parse-based tool for converting large reading comprehension datasets to OpenIE datasets and release a dataset 35x larger than previously available by sentence count.
We thoroughly benchmark 18 ImageNet models using multiple robustness metrics, including the distortion, success rate and transferability of adversarial examples between 306 pairs of models.
We propose to enable black-box neural networks to justify their reasoning both for clean and for adversarial examples by leveraging attributes, i.e. visually discriminative properties of objects.
In this paper, we propose a novel distilled Siamese tracker framework to learn small, fast yet accurate trackers (students) by a teacher-students knowledge distillation model and a student-student knowledge sharing mechanism.
In this paper, we propose a solution HyPar to determine layer-wise parallelism for deep neural network training with an array of DNN accelerators.
Face verification in the presence of age progression is an important problem that has not been widely addressed. In this paper, we propose to use the active appearance model and gradient orientation pyramid (GOP) feature representation for this problem.
This paper introduces a high efficient local spatiotemporal descriptor, called gradient boundary histograms (GBH), which can better represent local structure and motion than other gradient-based descriptors.
In this paper, dual-resolution dual-path Convolutional Neural Networks (CNNs), named DualNets, are proposed to bump up the accuracy of those detection applications that are sensitive to computation payloads.
This paper provides a comprehensive survey of the characteristics which define and differentiate the types of MIL problems and provides insight on how the problem characteristics affect MIL algorithms, recommendations for future benchmarking and promising avenues for research.
We present KBLRN, a framework for end-to-end learning of knowledge base representations from latent, relational, and numerical features.
A general framework based on gradient boosting for learning an ensemble of regression trees that optimizes the sum of square error loss and naturally handles missing or partially labelled data.
We propose a new framework named correlation congruence for knowledge distillation (CCKD), which transfers not only the instance-level information but also the correlation between instances.
We propose the first deep latent variable model, called RICH, for learning Representation of Interpretable Compositional Hierarchies.
The recently proposed unlabeled-unlabeled (UU) classification method sometimes suffers from severe overfitting, which we would like to prevent in this paper.
In order to improve the predication accuracy with low execution time in the process of image depth map generation, we mainly investigate the unsupervised monocular image depth prediction.
We propose a nonparametric framework based on the beta process for discovering temporal patterns within a heterogenous video collection using quantized local motion descriptors.
We introduce 3DMatch, a data-driven local feature learner that jointly learns a geometric feature representation and an associated metric function from a large collection of real-world scanning data.
In this paper, we propose a sentence representation approximating oriented distillation framework that can distill BERT into a simple LSTM based model without specifying tasks.
In this paper, we propose a human-agent collaborative annotation approach that can efficiently generate per-pixel masks of semantic objects in tagged images with multi-granularity supervisions.
We introduce Data Associated Recurrent Neural Networks (DA-RNNs), a novel framework for joint 3D scene mapping and semantic labeling.
This paper describes Buddy Compression, a scheme to increase both the effective GPU memory capacity and bandwidth while avoiding the downsides of conventional memory-expanding strategies.
Instance-based adaptation allows us to customize an existing model to each incoming translation request to boost the system's performance at inference time.
People detection methods are highly sensitive to the perpetual occlusions among the targets. We provide a large-scale HD dataset named WILDTRACK which finally makes advanced deep learning methods applicable to this problem.
This paper presents a self-supervised framework for training interest point detectors and descriptors suitable for a large number of multiple-view geometry problems in computer vision.
We use Hierarchical Accumulation to encode parse tree structures into self-attention at constant time complexity, which improves on Transformer and Tree-LSTM.
Face recognition research is one of the most active topics in computer vision (CV), and deep neural networks (DNN) are filling the gap between human-level and computer-driven performance levels in face verification algorithms.
Exceptional preferences mining (EPM) is a crossover between two subfields of data mining: local pattern mining and preference learning. It is a variant of subgroup discovery, with rankings of labels as the target concept.
We propose Sparseout a simple and efficient variant of Dropout that can be used to control the sparsity of the activations in a neural network.
We show that the sample complexity of CNNs can be significantly improved by using 3D roto-translation group convolutions (G-Convs) instead of the more conventional translational convolutions.
We propose an end-to-end trainable comprehension network that uses spatial-aware dynamic filters to transfer knowledge from text to image, and effectively capture the spatial information of the specified object.
We propose a new automatic part-based object segmentation algorithm for non-deformable objects in natural backgrounds.
Joint learning sentence representations from multiple text classification tasks and combining them with pre-trained word-level and sentence level encoders result in robust sentence representations that are useful for transfer learning.
We propose a weakly-supervised approach that incorporates any available domain knowledge into the training process to form a Gated-VAE. The approach is applied to images of faces for the purpose of disentangling head-pose from facial expression.
We propose a Hierarchical recurrent neural network enhanced by residual learning that detects KB relations given an input question, achieving state-of-the-art accuracy for both single-relation and multi-relation questions.
We propose a novel algorithm named multi-linear tensor-based learning without tuning parameters (MTP) for gait recognition.
We propose the Swarm Optimized Block Architecture, combined with an enhanced adaptive particle swarm optimization (PSO) algorithm for deep CNN model evolution.
We propose three novel deep learning architectures, which are able to perform a joint detection and pose estimation, where we gradually decouple the two tasks.
In this paper, we present novel sharp attention networks by adaptively sampling feature maps from convolutional neural networks for person re-identification problems.
We propose large-scale pretrained audio neural networks trained on AudioSet for state-of-the-art performance in many tasks.
GANS are powerful generative models that are able to model the manifold of natural images. We leverage this property to perform manifold regularization by approximating the Laplacian norm using a Monte Carlo approximation that is easily computed.
Inferring and Executing Programs for Visual Reasoning proposes a model for visual reasoning that consists of a program generator and an execution engine to avoid end-to-end models. However, the authors do not evaluate the efficiency of focus map.
We propose to constrain the incoming weights of each neuron to be unit-norm, which is formulated as an optimization problem over Oblique manifold, and propose a simple yet efficient method to solve this problem.
This paper proposes an encoder-decoder network to disentangle shape features during 3D face reconstruction from single 2D images, such that the tasks of reconstructing accurate3D face shapes and learning discriminative shape features for face recognition can be accomplished simultaneously.
We propose a new approach to train decoders to regress the word embedding of the next word with respect to the previous ones instead of minimizing the log likelihood, which can generate longer fine-grained captions.
We propose a hybrid architecture that combines the image modeling strengths of the bag of words framework with the representational power and adaptability of learning deep architectures.
Adaptive Sparse Representation based Classification (ASRC) in which sparsity and correlation are jointly considered.
We propose a novel weakly supervised approach, namely, the Guided-Net, by incorporating robust ground control points for guidance, which achieves results comparable to those of semisupervised and supervised frameworks.
We propose a novel Attribute Knowledge Graph Convolutional Network (AttKGCN) for learning discriminative feature representations for person re-identification.
In recent years, person re-identification (PReID) has become a hot topic in computer vision duo to it is an important part in intelligent surveillance. Many state-of-the-art PReID methods are attention-based or multi-scale feature learning deep models. However, introducing attention mechanism may lead to some important feature information losing issue.
We propose a novel approach for using unsupervised boosting to create an ensemble of generative models, where models are trained in sequence to correct earlier mistakes.
We propose a new notion of `non-linearity' of a network layer with respect to an input batch that is based on its proximity to a linear system, which is reflected in the non-negative rank of the activation matrix.
We propose MacNet: a novel encoder-decoder supplementary architecture to the widely used attention-based sequence-to-sequence models for machine comprehension.
We introduce a model based on Bayesian generalization for analysing queries composed of multiple semantic examples, which yields better results than those using only single hierarchy.
This paper describes a Markov Random Field for real-valued image modeling that has two sets of latent variables, both of which can be used to gate the interactions between all pairs of pixels.
A locally adaptive translation method for knowledge graph embedding, called TransA, to find the optimal loss function by adaptively determining its margin over different knowledge graphs.
We train a bidirectional language model (BiLM) on unlabeled data and transfer its weights to "pretrain" an NER model with the same architecture as the BiLM, which results in a better parameter initialization of the NERmodel.
Post-processing strategies for age estimation using pre-trained deep networks can improve the performance of state-of-the-art techniques and achieve satisfactory results.
In this paper, we propose the first derivative free optimization method with importance sampling and derive improved complexity results on non-convex, convex and strongly convex functions.
We propose a CapsNet architecture that employs individual video frames for human action recognition without explicitly extracting motion information.
We investigate the representation ability, speed and bias/variance of BNNs through extensive experiments. Inspired by this investigation, we propose the Binary Ensemble Neural Network (BENN) which leverages ensemble methods to improve the performance of Bnns.
Convolutional Neural Networks experience catastrophic forgetting when optimized on a sequence of learning problems: as they meet the objective of the current training examples, their performance on previous tasks drops drastically. In this work, we introduce a novel framework to tackle this problem with conditional computation.
This paper introduces a new image-based handwritten historical digit dataset named Arkiv Digital Sweden (ARDIS). The images in ARDIS dataset are extracted from 15,000 Swedish church records which were written in various handwriting styles in the nineteenth and twentieth centuries.
We utilize part selection within clips and consider the bidirectional temporal information when modeling the temporal pattern using multiple layers of a long short-term memory framework, which can learn compositional representations in space and time.
We present a novel profiling approach to identify distinctive entity features in Knowledge Graphs that facilitates human understanding.
In this letter, we estimate perceived image quality using sparse representations obtained from generic image databases through an unsupervised learning approach through a patch-wise training approach.
We describe the current methodologies that use genetic interactions to identify novel targeted treatments for cancer.
We propose a unified generative adversarial network for face completion using multi-context structures.
We develop and present a systematic strategy to identify a multitude of external influence sources, characterize and quantify their impact and develop methods for automated identification in microseismic signals.
We propose a quantitative experimental evaluation aimed at highlighting the best performing approach under the two criteria of accuracy and efficiency for stereo vision algorithms.
We propose a novel method to detect vascular bifurcations in retinal fundus images using trainable filters that mimic the properties of shape-selective neurons in area V4.
We address this by changing the test-time behavior of neural networks using Deep k-Nearest Neighbors, a more robust uncertainty metric which we use to generate feature importance values.
In this paper, we propose a novel encoding method for the representation of human action videos, that we call Discriminative Action Vector of Locally Aggregated Descriptors.
HyGnn integrates a hybrid graph to jointly represent the multi-scale features for crowd density as well as its auxiliary task (localization) together and performing joint reasoning over a graph.
We propose a new active approach to activity recognition that continually re-prioritizes computation based on the accumulated history of observations and accounts for the transience of those observations.
This paper addresses the problem of HMC for both tree and DAG structured hierarchies whose labels do not necessarily reach a leaf node.
We propose a confidence regularized self-training framework for unsupervised domain adaptation. The code and models of this work are available.
We propose a novel application of automated texture synthesis in combination with a perceptual loss focusing on creating realistic textures rather than optimizing for a pixel-accurate reproduction of ground truth images during training.
We exploit the effective framework of structural SVM and extend it with an original scoring function that suitably scores the alignment of two given videos, and a loss function that quantifies the accuracy of a predicted alignment.
We propose a data-parallel variant of stochastic gradient descent that quantizes and encode gradients to lessen communication costs.
We introduce Neural Attentive Multiview machine that learns multiview item representations and similarity by employing a novel attention mechanism.
A novel approach that employs Semantic Web technologies to generate explanations for the output of black box recommender systems.
In this paper, we present the Hierarchy-of-Visual-Words (HoVW), a novel trademark image retrieval (TIR) method that decomposes images into simpler geometric shapes and defines a descriptor for binary trademark image representation by encoding the hierarchical arrangement of component shapes.
We address the problem of classifying food images with minimal data curation. We also tackle a key problems with weak labels and weakly Supervised learning.
We propose a novel training paradigm that employs the idea of weighting samples based on the above probability. Without any prior knowledge of noise, we can train high performance CNN models with large-scale FR datasets.
We leverage the multidomain structure of tensor signals and propose to acquire samples using a Kronecker-structured sensing function, thereby circumventing the curse of dimensionality.
In this work we focused on GAN-based solution for the attribute guided face synthesis. The proposed solution in its turn introducing novel latent space of unit complex numbers is able to provide diversity on the "birthday paradox" score 3 times higher than the size of the training dataset.
A number of novel genes and pathways that affect multimetal as well as metal-specific tolerance in eukaryotic cells.
We evaluate the language coverage and generalization abilities of the most common continuous sentence embeddings based on recurrent neural networks based on RNNs using a context-free grammar.
We propose a new supervised hashing framework, where the learning objective is to generate the optimal binary hash codes for linear classification. We reformulate the objective such that it can be solved substantially efficiently by employing a regularization algorithm.
We propose a deep cascaded multitask framework that exploits the inherent correlation between detection and alignment to boost up their performance.
We formulate group convolution pruning as finding the optimal channel permutation to impose structural constraints and solve it efficiently by heuristics. We also apply local search to exploring group configuration based on estimated pruning cost.
We address the Few-Shot Fine-Grained classification problem, which focuses on tackling the fine-grained classification under the challenging few-shot learning setting. A novel low-rank pairwise bilinear pooling operation is proposed to capture the nuanced differences between support and query images for learning an effective distance metric.
We develop a model of perceptual similarity judgment based on re-training a deep convolution neural network that learns to associate different views of each 3D object to capture the notion of object persistence and continuity in our visual experience.
Unsupervised analysis of temporal phases of facial expressions and facial action units and temporal alignment of a certain facial behavior.
We propose the very deep residual channel attention networks for image super-resolution.
We present an Adaptive O-CNN encoder and decoder for efficient 3D shape encoding and decoding.
In this paper we propose an efficient method for obtaining the rank configuration of the whole network to choose the right rank configuration.
Aging process causes evident alterations on human facial appearance. The wide degree of variations on facial appearance of different individuals affects the age estimation performance. In this context, age estimation performances of facial regions (eye, nose, mouth and chin, cheeks and sides of mouth) are investigated in this paper.
We find that 3.3% and 10% of the images from the CIFAR-10 and CIFar-100 test sets, respectively, have duplicates in the training set. This may incur a bias on the comparison of image recognition techniques with respect to their generalization capability.
We introduce a text-guided attention model for image captioning, which learns to drive visual attention using associated captions.
In this paper, we propose a novel space-time geometric representation of human landmark configurations and derive tools for comparison and classification.
We show that the generalization gap arises from the relatively small number of updates rather than the batch size, and can be completely eliminated by adapting the training regime used.
We propose two methods to learn cross-lingual language models (XLMs), one unsupervised that only relies on monolingual data, and one supervised that leverages parallel data.
We propose a novel deep neural network named FlowNet3D that learns scene flow from point clouds in an end-to-end fashion.
We propose joint optimization of latent codes and the weights of the generative network to solve compressive sensing.
We propose to use ensemble methods as a defense strategy against adversarial perturbations. We find that an attack leading one model to misclassify does not imply the same for other networks performing the same task.
This paper presents our computation model for predicting image memorability, which is based on a deep learning architecture designed for a classification task.
We develop a new method for regularising neural networks. We learn a probability distribution over the activations of all layers of a network and then insert imputed values into the network during training.
We propose EnSyth, a deep learning ensemble approach to enhance the predictability of compact neural network’s models.
We propose a novel network architecture called parallel extended-decoder path for semantic inpainting (PEPSI) network, which aims at reducing the hardware costs and improving the inPainting performance. In addition, we propose Diet-PEPSi that significantly reduces the network parameters while maintaining the performance.
We propose a multi-view hierarchical fusion network for 3D object retrieval and classification tasks.
In this paper we attempt to investigate the use of deep learning to predict crime rate directly from raw satellite imagery.
We propose training the models of two dual tasks simultaneously, exploiting the probabilistic correlation between them to regularize the training process to improve the practical performances of both tasks.
In this paper, we introduce a novel hierarchical aggregation design, for final pooling, that controls granularity of the learned representations w.r.t the actual granility of action categories.
We propose a graph pooling layer relying on the notion of edge contraction, which improves performance on graph classification.
We introduce two new Polish datasets for evaluating sentence embeddings and provide a comprehensive evaluation of eight sentence representation methods including Polish and multilingual models.
Combining advantages of both CTF and imbalanced data learning techniques for missing entry prediction, especially for entries with rare class labels.
We propose a new deep learning model, namely Channel Attention Residual U-Net, to accurately segment retinal vascular and non-vascular pixels.
We propose a learning procedure that allows detection models such as Faster R-CNN to learn motion features directly from RGB video data while being optimized with respect to a pose estimation task.
ENIGMA leverages differential expression analysis results to extract expression modules from perturbational gene expression data. The core parameters of the ENIGMA clustering procedure are automatically optimized to reduce the redundancy between modules.
Automatic detection of complex facial expressions using action units that compound expressions.
We compare three new datasets for question answering: SQuAD 2.0, QuAC, and CoQA, along several of their new features: unanswerable questions, multi-turn interactions, and abstractive answers.
We propose a variational discriminator bottleneck for adversarial learning that can be used for imitation learning, inverse reinforcement learning, and GAN training.
The Developmental Networks (DN) use Lobe Component Analysis (LCA) features developed not only from the image space X but also the action space Z to represent a set of trainer specified meanings (e.g., type and location).
A large number of reading comprehension (RC) datasets has been created recently, but little analysis has been done on whether they generalize to one another, and the extent to which existing datasets can be leveraged for improving performance on new ones.
We present a multi-scale conditional generative adversarial network that completes 512$\times$512 electron micrographs from partial scans.
In this paper, we propose a framework that performs intelligent data augmentation and assigns partial smoothing label to generated data for person re-identification.
We use a self-attention based emotion classification model to understand the phonetic bases of emotions by discovering the most attentive phonemes for each class.
We learn visual representations of deformable fabric by training dense object descriptors that capture correspondences across images of fabric in various configurations.
A structure-based level set method employing a modified phase map is introduced to obtain accurate skeletonization and segmentation of the retinal vasculature.
This paper proposed a semi-supervised model that can effectively utilise the unlabelled data in multi-task learning way in order to improve the performance of speech emotion recognition.
In this work we develop a framework for kernel machines that are efficient, accurate and are adaptive to modern parallel hardware, such as GPU.
A single session of VR-based ABM training did not change attentional bias and anxiety symptoms.
We combine both line and edge detection using quadrature filters across multiple scales for robust segmentation of blood vessels.
We investigate the challenging problem of domain generalization, i.e., training a model on multi-domain source data such that it can directly generalize to target domains with unknown statistics.
We propose a unified model which jointly trains on images and captions, and learns to generate new captions given either an image or a caption query.
D$^2$2HistoSketch can fast and memory-efficiently maintain a set of compact and fixed-size sketches of streaming histograms to approximate their Discriminative and Dynamic similarity.
We explore methods of producing adversarial examples on deep generative models such as the VAE and VAE-GAN architectures and demonstrate them against networks trained on MNIST, SVHN and CelebA.
We propose a simple-yet-effective method called Generative Low-bitwidth Data Free Quantization to remove the data dependence burden.
A novel hierarchical stereo matching algorithm is presented which gives disparity map as output from illumination variant stereo pair.
A novel deep learning based driving risk assessment framework for classifying dangerous lane change behavior in short video clips captured by a monocular camera.
Deep Spherical Quantization (DSQ), a novel method to make deep convolutional neural networks generate supervised and compact binary codes for efficient image search.
We present Regularized Linear Embedding (RLE), a novel method that projects a collection of linked documents (e.g. citation network) into a pretrained word embedding space and leverage a matrix of pairwise similarities providing complementary information.
Knowledge Distillation (KD) aims to distill the knowledge of a cumbersome teacher model into a lightweight student model. Its success is generally attributed to the privileged information on similarities among categories provided by the teacher model.
An effective person re-identification (re-ID) model should learn features that not only capture different spatial scales but also encapsulate a synergistic combination of multiple scales. In this paper, we develop novel CNN architectures to address both challenges.
In this paper, we propose a novel deep framework for part-level semantic parsing of freehand sketches, which makes three main contributions that are experimentally shown to have substantial practical merit.
We study unsupervised and supervised recognition of human actions in video sequences. We introduce two novel approaches outperforming state-of-the-art algorithms.
We introduce Fisher Vector encoding with Variational Auto-Encoder, a novel deep architecture that quantizes the local activations of convolutional layer in a deep generative model, by training them in an end-to-end manner.
We propose the use of nondeterministic classifiers to improve the reliability of classifications. The goal is to keep the set of predicted grades as small as possible.
This paper proposes a disparity sliding window approach which also uses depth information from a stereo camera for object detection.
This paper presents a generative representation of the motion of the human body parts to learn and classify human actions.
We propose to represent users by their distances to preselected users, namely landmarks, which allows to drastically reduce the computational cost associated with the similarity matrix.
We hypothesize that semantic propositional content is important component of human caption evaluation, and propose a new automated caption evaluation metric defined over scene graphs coined SPICE.
We propose a new triplet loss that allows distance ratios in the label space to be preserved in the learned metric space, and a triplet mining strategy adapted to metric learning with continuous labels.
We explore the interaction and potential synergy of hierarchical multilabel methods, data fusion methods, and cost-sensitive approaches on whole-ontology and genome-wide gene function prediction.
We propose a novel GAN, which consists of one generator G and two discriminators (D1, D2) to overcome gradient vanishing, divergence mismatching and mode collapse.
We propose a novel loop closure detection system that uses a custom deep CNN trained for place recognition.
The goal of this paper is to take a single 2D image of a scene and recover the 3D structure in terms of a small set of factors: a layout representing the enclosing surfaces as well as a set of objects represented in termsof shape and pose.
This paper proposes a crowd counting method using multiple CNNs specialized to a specific appearance.
In this paper, we propose a variational Bayesian method, called Variational Context, to solve the problem of complex context modeling in referring expression grounding.
We propose a novel self-supervised representation learning by taking advantage of a neighborhood-relational encoding (NRE) among the training data. We integrate our NRE component with an encoder-decoder structure for learning to represent samples considering their local neighborhood information.
We show that mutations in one paralog can have structural pleiotropic effects on both interactions, resulting in highly correlated responses of homomers and heteromers of paralogs to selection.
Several important tasks in medical image analysis can be stated in the form of an optimization problem whose feasible solutions are connected subgraphs. Examples include reconstruction of neural or vascular structures under connectedness constraints.
RGBD-GAN enables camera parameter conditional image generation and depth image generation from 2D images without any 3D annotations.
We propose a novel adaptive quantization method for training large scale machine learning models on parameter server that can accelerate the learning of a large scale neural network while keeping its prediction accuracies.
This paper describes a fast and accurate semantic image segmentation approach that encodes not only the discriminative features from deep neural networks, but also the high-order context compatibility among adjacent objects as well as low level image features.
Submodular extensions of an energy function can be used to efficiently compute approximate marginals via variational inference. The accuracy of the marginals depends crucially on the submodular extension.
We introduce point-supervised spatio-temporal localization of human actions in videos, which is effective at a fraction of box-supervision.
We focus on a novel loglet-SIFT descriptor for the parts representation in the De- formable Part Models (DPM) which improves the DPM using a supervised descent method.
The term Neural Architecture Search (NAS) refers to the automatic optimization of network architectures for a new, previously unknown task. In this work, we propose a generally applicable framework that introduces only minor changes to existing optimizers to leverage this feature.
We propose the use of partial convolutions for image inpainting, where the convolution is masked and renormalized to be conditioned on only valid pixels.
GO loss decomposes the convergence direction into two mutually orthogonal components, namely, tangential and radial directions, and conducts optimization on them separately.
We propose SEG-GRAD-CAM, a gradient-based method for interpreting semantic segmentation.
This paper proposes a Momentum Gradient Attack (MGA) against the GCN model, which can achieve more aggressive attacks with fewer rewiring links.
We propose a novel detection pipeline that further benefits from the two-stage cascade strategy for real-time applications such as pedestrian detection which is usually performed on low-consumption hardware.
We present a semi-handcrafted representation learning method for LIDAR point cloud using siamese LocNets, which states the place recognition problem to a similarity modeling problem and propose a global localization framework with range-only observations.
This paper proposes a new approach to model the temporal dynamics of a sequence of Face Image Descriptors (FID) and proposes different strategies to compute dynamics-based representation of FID.
We propose a regularized Geometry-Aware Generative Adversarial Network (GAGAN) which disentangles appearance and shape in the latent space, enabling the generation of images with realistic texture and shape.
The aim of this survey is an attempt to review the kind of machine learning and stochastic techniques and the ways existing work currently uses machine learning for the challenging problem of visual tracking.
We first propose a grid dropout method that randomly dropout/blackout some areas of the training image. Then we combine the objective of predicting the blackout patches with classification to take advantage of the spatial information.
MONAS and DPP-Net are multiple-objective architectures that optimize accuracy and other objectives imposed by devices, searching for neural architectures that can be best deployed on a wide spectrum of devices.
This paper addresses the problem of real-time action recognition in trimmed videos, for which deep neural networks have defined the state-of-the-art performance in the recent literature. We propose a dissimilarity-based optimized procedure for distributing the action classes over multiple specialized module networks.
We borrow tools from the field of adversarial robustness and propose a framework that permits to relate the features of the dataset with the distance of data samples to the decision boundary along specific directions.
We propose a semi-supervised approach to predict landmarks on low resolution images by learning them from labeled high resolution images, which improves the performance of algorithms relying on quality landmarks.
This paper aims to build a robust annotation tool that effectively and conveniently enables the segmentation and annotation of massive 3D data.
We consider the problem of duplicate detection: given a large data set in which each entry has multiple attributes, detect which distinct entries refer to the same real world entity in the absence of a priori knowledge of the number of unique entities in the data set.
We introduce a new hybrid quantum-classical associative adversarial network (QAAN) that combines a classical generative network with a small auxiliary quantum Boltzmann machine to achieve state-of-the-art performance.
We go one step further and leverage segmentation annotations to increase the number of object instances present on training data.
We propose a novel visual tracking algorithm, named MFCMT, based on a complementary ensemble model with multiple features, including Histogram of Oriented Gradients (HOGs), Color Names (CNs) and Color Histograms (CHs) for fast tracking.
We demonstrate that model networks themselves are unstable at low edge density and that graphlet-based measures correctly reflect this instability, and that biological networks are stable.
Collaborative Filtering over multi-dimensional contentaddressable space for fast recommendations .
We propose a model to learn visually grounded word embeddings (vis-w2v) to capture visual notions of semantic relatedness.
We show that with an appropriate factorization, and encodings of layout and appearance constructed from outputs of pretrained object detectors, a relatively simple model outperforms more sophisticated approaches on human-object interaction detection.
We propose a neural topical expansion framework, namely Persona Exploration and Exploitation (PEE), which is able to extend the predefined user persona description with semantically correlated content before utilizing them to generate dialogue responses.
We propose U2GNN, a novel graph embedding model leveraging on the strength of the recently introduced universal self-attention network, to learn low-dimensional embeddings of graphs which can be used for graph classification.
We propose DFW-Trace, a distributed Frank–Wolfe algorithm which leverages the low-rank structure of its updates to achieve efficiency in time, memory and communication usage.
We develop a simple yet meaningful graph representation for graph classification, and explore its effectiveness in graph classification.
Structured rank minimization method for dynamic behavior analysis in the presence of noisy behavioral cues descriptors and possibly unreliable annotations.
This paper presents a simple but effective coding scheme called Locality-constrained Linear Coding (LLC) in place of the VQ coding in traditional SPM, achieving state-of-the-art performance.
This paper addresses this problem by a novel Non-Maximum Suppression (NMS) algorithm to better refine the bounding boxes given by detectors.
We quantify, analyze and mitigate gender bias exhibited in ELMo's contextualized word vectors and explore two methods to mitigate such gender bias.
We show that low-dimensional factorization of a sentence-task label matrix can affect the ability of sentence embeddings to perform as sentence representations in a suite of classification tasks.
We train visual odometry model on synthetic data and do not use ground truth poses hence this model is considered unsupervised.
A face alignment pipeline based on two novel methods: weighted splitting for K-cluster Regression Forests and 3D Affine Pose Regression for face shape initialization.
We proposed an effective and efficient method for accurate vessel segmentation in color fundus images using encoder-decoder based octave convolution network using octave transposed convolution.
We propose the first method for certifiable (non-)robustness of graph convolutional networks with respect to perturbations of the node attributes and propose a robust semi-supervised training procedure.
Luminoso participated in the SemEval 2018 task on "Capturing Discriminative Attributes" with a system based on ConceptNet, an open knowledge graph focused on general knowledge.
In this paper, we propose a novel two-stream spatial-temporal person ReID (st-ReID) framework that mines both visual semantic information and spatial-Temporal information into a unified framework.
We propose a method for knowledge transfer between semantically related classes in ImageNet. Using self-assessment we can automatically return bounding-box annotations with high localization accuracy.
We propose a novel approach to efficiently remove filters in deep convolutional neural networks based on Partial Least Squares (PLS) and Variable Importance in Projection (VIP).
We propose a novel model aggregation with an attention mechanism considering the contribution of client models to the global model, together with an optimization technique that minimizes the weighted distance between the server model and client models.
We introduce NGra, the first parallel processing framework for graph-based deep neural networks that scales to large real graphs that none of the existing frameworks can handle directly.
We propose sequenced-replacement sampling (SRS) for training deep neural networks. We carry out replacement sampling but in a batched and sequenced way.
In this paper, we introduce stochastic substitute training, a gray-box approach that can craft adversarial examples for defenses which obfuscate gradients, even in white-box settings.
We introduce a semi-supervised method in which the crucial idea is to first generate implicit knowledge about the face appearance & shape from the large amounts of unlabeled images of faces available today.
We propose a variational attention mechanism for variational encoder-decoder, where the attention vector is modeled as normally distributed random variables.
In this paper we address a more realistic version of the natural language grounding task where we must both identify whether the phrase is relevant to an image and localize the phrase. We propose a Phrase R-CNN network for this task.
We address the ambiguity challenge by integrating two state-of-the-art collaborative filtering methods to enjoy the best of both worlds.
We propose a method to classify images from target classes with a small number of training examples based on transfer learning from non-target classes using Siamese nets.
This paper studies how to use error correcting codes (ECCs) to protect the weights of deep neural networks.
We present a new real-time approach to object detection that exploits the efficiency of cascade classifiers with the accuracy of deep neural networks.
We study the minimal context required to answer the question, and find that most questions in existing datasets can be answered with a small set of sentences. Inspired by this observation, we propose a simple sentence selector to select the minimalSet of sentences to feed into the QA model.
We reformulate the saliency prediction problem as a salient region \textit{segmentation} problem, allowing faster convergence than the classical regression problem, while performance is comparable to state-of-the-art.
3D hand and human pose estimation from a single depth map using a 3D convolutional neural network .
We address the issue of learning from synthetic domain randomized data effectively. We propose a novel algorithm which closes the loop between the synthetic generative model and the learner in an adversarial fashion, thus incorporating domain adaptation.
We propose multimodal knowledge base embeddings that use different neural encoders for this variety of observed data, and combine them with existing relational models to learn embeddlings of the entities and multimodAL data.
A new vehicle detection model based on YOLOv2 is proposed in this paper. It aims to extract vehicle-type information from pictures or videos containing vehicles.
We present a deep convolutional neural network for estimating the relative homography between a pair of images.
This paper proposes a novel attention-guided enhancement solution based on which an end-to-end multi-branch CNN is built.
We propose a Multiactivation Pooling Method to make the CNNs more accurate on classification tasks without increasing depth and trainable parameters.
We propose a unified, group-theoretic approach to tackle both pose and symmetries of an object, using a novel orbit metric to estimate the pose difference.
In this paper, we propose a novel single-shot detection framework of Bidirectional Pyramid Networks (BPN) towards high-quality object detection, which consists of two novel components: (i) a Biddirectional Feature Pyramid structure for more effective and robust feature representations; and (ii) a Cascade Anchor Refinement to gradually refine the quality of predesigned anchors for moreeffective training.
We introduce a model for bidirectional retrieval of images and sentences through a deep multi-modal embedding of visual and natural language data through a structured max-margin objective.
We address this challenge by combining the state-of-art deep learning method and semi-dense Simultaneous Localisation and Mapping (SLAM) based on video stream from a monocular camera.
We propose a transfer learning method for active appearance models, in which we select a subspace from the source that best describes the target space and augment the selected source subspace with the target subspace learned from a handful of test examples.
We provide an in-depth analysis of established and recently proposed single-label multiclass methods along with a detailed account of efficient optimization algorithms for them. We explore the transition from multiclass to multilabel learning.
In this paper, we propose a Ncut-based segmentation algorithm by integrating an adaptive similarity measure and spatial regularization.
We propose a label graph superimposing framework to improve the conventional GCN+CNN framework developed for multi-label recognition.
We introduce the channel and spatial reliability concepts to DCF tracking and provide a learning algorithm for its efficient and seamless integration in the filter update and the tracking process.
This paper proposes a novel MAP inference framework for Markov Random Field in parallel computing environments using Swarm Fusion, a natural generalization of the Fusion Move method.
A special section of the Journal of Electronic Imaging (JEI) will replace the conference proceedings for papers presented at the SPIE conference on Mobile Computational Photography (SPIE Conference 8667D).
Comparison of linear and nonlinear subspace methods for face representation and recognition in image and vision applications.
We present a novel high frequency residual learning framework, which leads to a highly efficient multi-scale network (MSNet) architecture for mobile and embedded vision problems.
We combine a 3D Convolutional Neural Network with body representations based on Euclidean Distance Matrices to achieve state-of-the-art results on RGB-D dataset.
Deep learning for real-time DFU localization using InceptionV2 .
We introduce a framework to efficiently make predictions about conjunctive logical queries -- a flexible but tractable subset of first-order logic -- on incomplete knowledge graphs, which can involve multiple unobserved edges, entities, and variables.
We propose a novel cooperative cross-stream network that investigates the conjoint information in multiple different modalities in an end-to-end learning manner.
We introduce a general method for improving the convergence rate of gradient-based optimizers that is easy to implement and works well in practice.
We propose a novel paradigm to link the optimization of several hybrid objectives through unified backpropagation to improve the classification performance in hybrid neural networks.
In this paper, we propose Latent Relation Language Models (LRLMs), a class of language models that parameterize the joint distribution over the words in a document and the entities that occur therein via knowledge graph relations.
Deep Regression-based User Image Detector for Facial Segment-based Face Detection .
We perform a case study of a 6-layer convolutional neural network running on a mixed-signal accelerator and evaluate its sensitivity to hardware specific noise.
We propose a novel multi-task deep network to learn generalizable high-level visual representations using adversarial learning.
We propose DialogWAE, a conditional Wasserstein autoencoder (WAE) specially designed for dialogue modeling.
Can we infer intentions and goals from a person's actions? As an example of this family of problems, we consider whether it is possible to decipher what a person is searching for by decoding their eye movement behavior.
We introduce a new approach for hard attention and find it achieves competitive performance on a recently-released visual question answering datasets, equalling and in some cases surpassing soft attention architectures while entirely ignoring some features.
We train a conditional generative model to extract both static and dynamic information from text and use it to generate plausible and diverse videos.
This paper presents an initial study which uses graphs to represent the actor's shape and graph embedding to convert the graph into a suitable feature vector.
We developed a minimum-cost circulation framework for solving the global data association problem, which plays a key role in the tracking-by-detection paradigm of multi-object tracking. This new framework has a better theoretical complexity bound and leads to orders of practical efficiency improvement.
We propose a statistical approach for adversarial detection in image classification based on comparison of features of a test image with the feature distribution of its class.
This paper derives analytically tractable privacy expressions for both stochastic gradient descent and Adam used in training deep neural networks, without the need of developing sophisticated techniques as [3] did.
We present an in-depth analysis of popular word embeddings (Word2Vec, GloVe, fastText and Paragram) in terms of their compositionality, as well as a method to tune them towards better compositionality.
We present READ, a new approach for obtaining essential spatial representation for any given district from high-resolution satellite imagery based on deep neural networks based on transfer learning.
We propose FrameRank, an unsupervised video summarization method that employs a frame-to-frame level affinity graph to identify coherent and informative frames to summarize a video, which achieves state-of-the-art results.
We propose a deep learning-based method for synthesizing a light field video from a monocular video and use it for conventional light field applications.
We propose novel KB completion models that exploit the structural and semantic context of knowledge graphs for enhanced contextual representation of knowledge.
We introduce a new problem of generating an image based on a small number of key local patches without any geometric prior. We construct adversarial networks to tackle this problem.
We propose a Feature Mask Network that uses ResNet high-level features to predict a feature map mask and then imposes it on the low-level Features to dynamically re-weight different object parts for a complementary feature representation.
The core of our approach, Pixel Consensus Voting, is a framework for instance segmentation based on the Generalized Hough transform. Pixels cast discretized, probabilistic votes for the likely regions that contain instance centroids.
In this paper, we propose Tag-Guided HyperRecNN/TreeLSTM, which introduces hypernetwork into RecNNs to take as inputs Part-of-Speech (POS) tags of word/phrase and generate the semantic composition parameters dynamically.
We propose an end-to-end capsule network for pixel level localization of actors and actions present in a video for text selected video segmentation.
We investigate the gains in precision and speed, that can be obtained by using Convolutional Networks for on-the-fly retrieval – where classifiers are learnt at run time for a textual query from downloaded images, and used to rank large image or video datasets.
We propose a novel attention mechanism to enhance Convolutional Neural Networks for fine-grained recognition. It learns to attend to lower-level feature activations without requiring part annotations.
We propose to use Isometric Mapping (ISOMAP) for dimensional reduction and utilize iterative quantization to reduce quantization loss during hashing process.
We propose an effective method for learning a highly contextualized, word-level sparse representation by utilizing rectified self-attention weights on the neighboring n-grams for lexically sensitive phrase encoding.
An effective and efficient face deblurring algorithm by exploiting semantic cues via deep convolutional neural networks (CNNs).
ADA inhibits CDK2 and is a potential candidate drug for the treatment of human colorectal cancer.
In low light condition, color (RGB) images captured by imaging systems suffer from severe noise causing loss of colors and textures. We propose multispectral fusion of RGB and NIR images using two stage convolutional neural networks (CNNs), called FusionNet.
This paper proposes a sequential prior in a discrete latent space which can generate more naturally sounding samples, improving the naturalness in random sample generation.
A popular large-scale gene interaction discovery platform is the Epistatic Miniarray Profile E-MAP. However, due to the limits of biotechnology, E- MAP studies fail to measure genetic interactions for up to 40% of gene pairs in an assay. We introduce a new interaction data imputation method called interaction propagation matrix completion IP-MC, which considers additional knowledge presented through a gene network.
This paper presents a widespread analysis of affective vocal expression classification systems. In this study, state-of-the-art acoustic features are compared to two novel Affective vocal prints for the detection of emotional states: the Hilbert-Huang-Hurst Coefficients and the vector of index of non-stationarity.
We propose a new motion descriptor that captures additional information on local motion patterns enhancing results based on differential motion scalar quantities, divergence, curl and shear features. We therefore also employ Fisher vector in this paper.
We propose high-level representation guided denoiser (HGD) as a defense against adversarial attacks.
In this paper, we propose a novel network design mechanism for efficient embedded computing.
We propose a novel multi-task Convolutional Neural Network for large-scale 3D reconstruction from consecutive monocular images.
We develop a domain adaptation method to adapt the source data to the unlabeled target domain and achieve state-of-the-art performance on semantic segmentation.
We propose a novel formulation that learns physical primitives by explaining both an object's appearance and its behaviors in physical events in an interpretable way.
We study the multi-round response generation in visual dialog systems, where a response is generated according to a visually grounded conversational history. We propose a novel training paradigm called Gold-Critic Sequence Training (GCST), a novel attention network called Recurrent Co-Attention Network, which can be effectively trained by using GCST.
We address semi-supervised video object segmentation, the task of automatically generating accurate and consistent pixel masks for objects in a video sequence, given the first-frame ground truth annotations. We present the PReMVOS algorithm (Proposal-generation, Refinement and Merging for Video Object Segmentation).
We are attempting to use machine learning to tackle the difficult task of matching an obi to a kimono, using the CNN machines drawing the most attention today.
We propose Attention Branch Network (ABN), which extends a response-based visual explanation model by introducing a branch structure with an attention mechanism and is trainable for visual explanation and image recognition.
We propose an accurate edge detector using richer convolutional features (RCF).
We evolve an image classifier that surpasses hand-designs for the first time, achieving state-of-the-art performance.
ImageNet pre-training has a positive effect on character recognition, style classification, manuscript dating, semantic segmentation, and content-based retrieval.
We propose a novel monocular visual odometry system called UnDeepVO in this paper. The system is able to estimate the 6-DoF pose of a monocular camera and the depth of its view by using deep neural networks.
We are interested in the task of generating multi-instrumental music scores. The Transformer architecture has recently shown great promise for this task, and we propose a pre-training technique to leverage the information in a large collection of heterogeneous music.
We use off-the-shelf architectures trained for face recognition to build facial descriptors for face attribute prediction.
Neural scene graph generators can learn effective visual relation features to facilitate grounding language to visual relations and subsequently improve the two end applications.
We propose a method to select (very few) paired training samples and achieve significant improvements in both supervised and unsupervised I2I translation settings over random selection.
We propose a multimodal model that uses textual features from the phrase generator and visual features from image pixels to produce labels in a predefined taxonomy.
Image co-segmentation is important for its advantage of alleviating the ill-pose nature of image segmentation through exploring the correlation between related images. Many automatic image co-Segmentation algorithms have been developed in the last decade, which are investigated comprehensively in this paper.
We focus on two research issues in entity search: scoring a document or snippet that potentially supports a candidate entity, and aggregating scores from different snippets into an entity score. We instead explore simple, robust, discriminative ranking algorithms and broad families of aggregation functions.
We study the problem of interactive segmentation and contour completion for multiple objects. The form of constraints our model incorporates are those coming from user scribbles (interior or exterior constraints) as well as information regarding the topology of 2-D space after partitioning (number of closed contours desired)
Point cloud is a widely used 3D data form, which can be produced by depth sensors, such as Light Detection and Ranging (LIDAR) and RGB-D cameras. Being unordered and irregular, many researchers focused on the feature engineering of point cloud.
This paper examines the effect that overfitting and influence have on the ability of an attacker to learn information about the training data from machine learning models, either through training set membership inference or attribute inference attacks.
CondConv improves performance and inference cost trade-off of several existing convolutional neural network architectures on both classification and detection tasks.
We extend the Motion Interchange Patterns (MIP) framework for action recognition with gradient-based descriptors to enhance invariance to light changes and achieve a better description of the motion's structure.
This work presents a new strategy for multi-class classification that requires no class-specific labels but instead leverages pairwise similarity between examples, which is a weaker form of annotation.
The automatic detection of an emotional state from human speech, which plays a crucial role in the area of human-machine interaction, has consistently been shown to be a difficult task for machine learning algorithms. In this paper, we develop a model to alleviate this limitation by leveraging a parallel combination of attention-based bidirectional long short-term memory recurrent neural networks with attention- based fully convolutional networks (FCN)
We introduce a weakly supervised co-segmentation technique for space-time co-located image collections. We take a distributed approach, where local belief models are propagated and reinforced with similar images.
We propose a novel loss function called 'Polarity loss', that promotes correct visual-semantic alignment for an improved zero-shot object detection.
We provide analytic and empirical evidence that correcting potentially errant non-distinct mappings that result from the softmax function can result in improving robustness characteristics on a stateof-the-art semantic segmentation model with minimal impact to performance and minimal changes to the code base.
This article improves recent methods for large scale image search based on Hamming embedding (HE) and weak geometric consistency constraints (WGC)
Large Generative Adversarial Networks trained on the complex Kinetics-600 dataset are able to produce video samples of substantially higher complexity than previous work.
A spatiotemporal attentional model that learns where to look in a video directly from human fixation data, without knowledge of the action in each video.
In this paper, we introduce variational Bayes-Adaptive Deep RL (variBAD), a way to meta-learn to perform approximate inference in an unknown environment, and incorporate task uncertainty directly during action selection.
Unsupervised denoising networks can be learned only with the corrupted image.
We propose to use whitening as a pre-processing step before learning features with STDP. Experiments on CIFAR-10 show that whitening allows STDP to learn visual features that are closer to the ones learned with standard neural networks.
In this paper, we reduce this excess complexity through successively removing nonlinearities and collapsing weight matrices between consecutive layers, and show that these simplifications do not negatively impact accuracy in many downstream applications.
We propose a fast method for hierarchical clustering and topic modeling using fast Rank-2 nonnegative matrix factorization and an efficient node splitting rule that recovers a flat clustering/topic modeling result in a fast and effective way.
We propose a novel Bi-level Dictionary Learning based Personalized Age Progression (BDL-PAP) method for personalized age progression.
This paper presents a novel adversarial deep neural network to estimate human poses from still images, such as those obtained from CCTV and the Internet-of-Things (IoT) devices.
We construct a new vector space that is positive scale-invariant and sufficient to represent ReLU neural networks so as to better facilitate the optimization process.
We present NoScope, a system for querying videos that can reduce the cost of neural network video analysis by up to three orders of magnitude via inference-optimized model search.
In the system of face recognition, the tradition method of data dimension reduction method is used to rearrange the face image vectors, resulting in the structural characteristics of the data itself lost and the recognition accuracy not high. In this paper, we develop a data dimension Reduction method based on tensor-multilinear discriminant subspace projection.
We present a detection rate optimized bit allocation (DROBA) principle for biometric template protection systems, which assigns more bits to discriminative features and fewer bits to nondiscriminatory features.
A self-sustaining CPG network for reinforcement learning that learns rhythmic motion more efficiently and across more general environments than the current multilayer perceptron baseline models.
In this paper, we propose a dual network to better utilize features among layers for visual tracking.
We provide a simple and efficient decoupling technique, that can be added on top of any black-box machine learning algorithm, to learn different classifiers for different groups.
We propose a new deep network structure for unconstrained face recognition. The proposed network integrates several key components together in order to characterize complex data distributions caused by face images with various qualities.
We address the challenge of sentiment analysis from visual content. In contrast to existing methods which infer sentiment or emotion directly from visual low-level features, we propose a novel approach based on understanding of the visual concepts that are strongly related to sentiments.
This paper argues that to extract the features used in neural networks to make decisions, it's important to look at the paths between clusters existing in the hidden spaces of neural networks.
APAC: the Augmented PAttern Classification, which is a way of classification using the optimal decision rule.
We introduce a novel method that enables parameter-efficient transfer and multitask learning using a small set of parameters.
This paper considers meta-learning problems, where there is a distribution of tasks, and we would like to obtain an agent that performs well (i.e., learns quickly) when presented with a previously unseen task sampled from this distribution.
We study vulnerabilities of a state-of-the-art face recognition system based on template reconstruction attack. We propose a neighborly de-convolutional neural network ( NbNet) to reconstruct face images from their deep templates.
We present an approach to transferring driving policies from simulation to reality via modularity and abstraction.
We propose a novel deep neural network architecture for point-wise, multi-class semantic labeling of semi-dense LiDAR data and propose an automated process for large-scale training data generation.
MX-LSTM captures the interplay between tracklets and vislets during the LSTM backpropagation, improving the trajectory forecasting performance.
A new conceptor network based classifier in classifying images.
We propose two generalized range move algorithms (GRMAs) for efficient optimization of MRFs.
We present a novel pairwise similarity measure that advances existing models by i) expanding traditional linear projections into affine transformations and ii) fusing affine Mahalanobis distance and Cosine similarity by a data-driven combination.
We compare interactions between NDF-RT and DrugBank and evaluate both sources against a reference list of 360 critical interactions, and compare them against a commercial source.
We present a deep learning framework for computer-aided lung cancer diagnosis. We discuss the challenges and advantages of our framework.
We propose a multi-agent reinforcement learning-based cooperative content caching policy for the MEC architecture when the users’ preference is unknown and only the historical content demands can be observed.
The goal of this paper is to analyze an intriguing phenomenon recently discovered in deep networks, namely their instability to adversarial perturbations, and provide a theoretical framework for analyzing the robustness of classifiers to the phenomenon, and show fundamental upper bounds on the robusts of classifier.
We propose Bilingual Lexicon Induction with Semi-Supervision (BLISS), a semi-supervised approach that relaxes the isometric assumption while leveraging both limited aligned bilingual lexicons and a larger set of unaligned word embeddings, as well as a novel hubness filtering technique.
Augmented Autonomous Driving Simulation (AADS) augments real-world pictures with a simulated traffic flow to create photo-realistic simulation images and renderings.
Data-driven turbulence models based on Reynolds-averaged Navier-Stokes equations with turbulence closures with varying slopes can be developed and validated using a data-driven dataset.
We propose a conceptually simple and efficient joint model of detection and tracking, called RetinaTrack, which modifies the popular single stage RetinaNet approach such that it is amenable to instance-level embedding training.
We propose an end-to-end ZSAR framework based on a structured knowledge graph, which can jointly model the relationships between action-attribute, action-action, and attribute-attribute.
In this paper, we propose a method for learning from only noisy-similarity-labeled data which generalizes for learning classifiers.
We try to analyze the main aspects that can increase the performance of the age estimation system, present the handcrafted-based models and deep learning- based models, and show how the evaluations are being conducted, discuss the proposed algorithms and models in the Age estimation process.
We explore an alternate approach of training using sparse LiDAR data as ground truth for depth estimation for fisheye camera.
We take a small step backwards in order to study an architecture with interesting trade-off between performance and computational complexity. We tackle every component of a neural captioning model and propose one or more solution that lightens the model overall.
We present Im2Pano3D, a convolutional neural network that generates a dense prediction of 3D structure and a probability distribution of semantic labels for a full 360 panoramic view of an indoor scene when given only a partial observation.
We propose a new algorithm called probabilistic ensembles with trajectory sampling (PETS) that combines uncertainty-aware deep network dynamics models with sampling-based uncertainty propagation to match state-of-the-art RL algorithms in terms of asymptotic performance.
 MP-Net separates sounds recursively in the order of average energy, removing the separated sound from the mixture at the end of each prediction, until the mixture becomes empty or contains only noise.
We propose the Universal Transformer (UT), a parallel-in-time self-attentive recurrent sequence model which can be cast as a generalization of the Transformer model and which addresses these issues.
This work explores how to use self-supervised learning on videos to learn a class-specific image embedding that encodes pose and shape information.
We propose a flexible Attribute Localization Module (ALM) to adaptively discover the most discriminative regions and learns the regional features for each attribute at multiple levels.
RetinaNet gives effective computation and accuracy trade-off for object detection and how to build a light-weight RetinaNet.
We present a new end-to-end network architecture for facial expression recognition with an attention model that uses a Gaussian space representation for expression recognition.
We examine the practice of joint training for neural network ensembles, in which a multi-branch architecture is trained via single loss.
A recent deep reinforcement learning algorithm based on off-policy training of deep Q-functions can scale to complex 3D manipulation tasks and can learn deep neural network policies efficiently enough to train on real physical robots.
DNA methylation patterns across different stages of lung adenocarcinoma (LUAD) using epigenetic subnetwork analysis.
Template update procedures for temporal variance due to aging process are effective and simple way to adapt to variations due to the aging process.
We propose a refinement of Natural Language Inference (NLI) that shifts away from categorical labels, targeting instead the direct prediction of subjective probability assessments, where items even with the same categorical label differ in how likely people judge them to be strictly impossible.
We propose a plan online and learn offline (POLO) framework for the setting where an agent, with an internal model, needs to continually act and learn in the world.
In this paper, we propose a novel CNN-RNN-based model, bi-modal multi-label learning(BMML) framework, based on the assumption that objects in a semantic scene always have high-level relevance.
We propose a novel Frequency Separation Network (FSN) for image super-resolution (SR), which uses four operations to perform information update and frequency communication between high-frequency and low-frequency features.
We propose Monte Carlo methods to quantize the weights and activations of pre-trained neural networks without any re-training.
We propose a novel filter pruning method that compresses CNN models by pruning filters with redundancy, rather than those with“relatively less” importance.
We introduce Moment Alignment Network (MAN), a novel framework that unifies the candidate moment encoding and temporal structural reasoning in a single-shot feed-forward network for natural language moment retrieval.
In this paper, we propose the canonical correlation kernel, that seamlessly integrates the advantages of lower dimensional representation of videos with a discriminative classifier like SVM.
This paper addresses the challenge of 6DoF pose estimation from a single RGB image under severe occlusion or truncation. We introduce a Pixel-wise Voting Network to regress pixel-wise vectors pointing to the keypoints and use these vectors to vote for keypoint locations.
Stochastic gradient algorithms are approximated in the weak sense by continuous-time stochastic differential equations. We exploit the continuous formulation together with optimal control theory to derive novel adaptive hyper-parameter adjustment policies.
We propose a compact and accurate super-resolution convolutional neural network that leverages cascading residual on the residual structure to focus on learning high-level features.
We introduce a new black-box attack achieving state of the art performances against InceptionV3.
We propose Continual-MAML, an online extension of the popular MAML algorithm, which is better suited to the new scenario than standard continual learning and meta learning.
We introduce a novel methodology for characterizing the performance of deep learning networks (ResNets and DenseNet) with respect to training convergence and generalization as a function of mini-batch size and learning rate for image classification.
We address the problem of learning accurate 3D shape and camera pose from a collection of unlabeled category-specific images. We train a convolutional network to predict both the shape and the pose.
This paper proposes a likelihood ratio classifier for histogram features that is optimal in Neyman-Pearson sense that outperforms chi-square distance measure.
We propose a deep multivariate mixture of Gaussians model for bounding box regression under occlusion. The mixture components potentially learn different configurations of an occluded part.
We present a deep neural network that sequentially predicts the pixels in an image along the two spatial dimensions and encodes the complete set of dependencies in the image.
We built an integrated and comprehensive Protein-Protein Interaction Network (PPIN) by merging several major databases. The set of linked proteins are found to be enriched for cancer-specific processes, and more likely so if they are more highly linked.
We show that it is possible to use the same filtering-based mean-field algorithm to speed up the optimisation of several continuous relaxations.
VoCoG, is an end-to-end intelligent system for collaborative viewing. It takes user conversation as input, making it non-intrusive.
We use a multimodal version of the SNLI dataset (Bowman et al, 2015) and compare"blind"and visually-augmented models of textual entailment. We show that visual information is beneficial.
We apply a deep transfer convolutional neural network (CNN) to identify a writer using handwriting text line images in English and Arabic languages.
We introduce a method for simultaneously classifying, segmenting and tracking object instances in a video sequence.
In this paper, we introduce a novel optimization algorithm, namely GADAM (Genetic-Evolutionary Adam), which learns deep neural network models based on a number of unit models generations by generations: it trains the unit models with Adam, and evolves them with genetic algorithm.
We combined biomedical literature and terminologies in a fast in-memory database to enable a fast and intelligent search through the ever-growing biomedical literature.
We propose a non-negative representation based discriminative dictionary learning algorithm for multicategory face classification.
There is a growing demand for large-scale Synthetic Aperture Sonar datasets. Unfortunately, the acquisition of SAS data is bottlenecked by the costly deployment of SAS imaging systems, and even when data acquisition is possible, the data is often skewed towards containing barren seafloor rather than objects of interest.
We propose a weakly supervised learning-based approach that can effectively learn to localize the discriminative evidence for a diagnostic label from weakly labeled training data.
In this paper we propose a novel decomposition method based on filter group approximation, which can significantly reduce the redundancy of deep convolutional neural networks (CNNs) while maintaining the majority of feature representation.
This paper extends the state-of-the-art label propagation framework by considering additional information of the form “the sample $i$ should not be assigned the label $k$”.
We have briefly discussed different CNN architectures for image classification task.
We introduce the EuroCity Persons dataset, which provides a large number of highly diverse, accurate and detailed annotations of pedestrians, cyclists and other riders in urban traffic scenes.
We propose a novel two-stage method that disentangles the class/identity from domain-differences, and we consider multiple types of domain-Difference.
This work investigates a novel dynamic learning-to-normalize (L2N) problem by proposing Exemplar Normalization (EN), which is able to learn different normalization methods for different convolutional layers and image samples of a deep network.
We introduce Multi-SimLex, a large-scale lexical resource and evaluation benchmark covering datasets for 12 typologically diverse languages, including major languages (e.g., Mandarin Chinese, Spanish, Russian) as well as less-resourced ones (such as Welsh, Kiswahili) for experimental evaluation and analysis.
We explore the importance of global relation reasoning in Human Pose Estimation (HPE) and propose GRR-GCN to efficiently capture the global relations among different body joints.
This paper presents a novel face representation and recognition approach. The face image is first decomposed by multi-scale and multi-orientation Gabor filters and local binary pattern (LBP) analysis is then applied on the Gabor magnitude responses.
We propose a hybrid attention mechanism for single-stage object detection.
We propose a language-grounded driving agent implementing a hierarchical policy using recurrent layers and gated attention that can successfully interpret language instructions and follow them safely.
We propose a domain adaptation approach for object detection that improves the state-of-the-art performance in this benchmark.
We investigate whether it is possible to leverage information from multiple datasets when performing frame-based action recognition, which is an essential component of real-time activity monitoring systems.
We propose adaptation of the replay buffer concept, borrowed from the off-policy learning setting, to create an on-policy reinforcement learning method, combining advantages of on- and off-Policy learning.
We introduce HULK, a multi-task energy efficiency benchmarking platform for responsible natural language processing.
In this paper, we propose a deep convolutional neural network (CNN) for anomaly detection in surveillance videos.
A structured HMM-like graphical model of the stereo matching problem can be used to choose the next disambiguating action with the greatest entropy reduction, or information gain.
We propose to exploit the proposal-proposal relations using Graph Convolutional Networks (GCNs) and learn powerful representations for the action classification and localization.
FreeAnchor updates hand-crafted anchor assignment to "free" anchor matching by formulating detector training as a maximum likelihood estimation (MLE) procedure.
This paper introduces a family of local feature aggregation functions and a novel method to estimate their parameters, such that they generate optimal representations for classification (or any task that can be expressed as a cost function minimization problem).
We investigate the role of representations and architectures for classifying 3D shapes in terms of their computational efficiency, generalization, and robustness to adversarial transformations, and propose a novel approach for generating adversarial perturbations of a 3D shape using a differentiable renderer.
We study first-order meta-learning of initializations for deep neural networks that must produce dense, structured predictions given an arbitrary amount of training data for a new task.
We propose a novel approach to multi-action recognition that performs joint segmentation and classification using a Gaussian mixture using robust low-dimensional action features.
AutoAugment has been a powerful algorithm that improves the accuracy of many vision tasks, yet it is sensitive to the operator space as well as hyper-parameters, and an improper setting may degenerate network optimization. To relieve the inaccuracy of supervision, we use knowledge distillation that refers to the output of a teacher model to guide network training.
We propose for the first time an unsupervised learning framework for consensus maximization in the context of solving 3D vision problems.
We present an online method that encodes long-term temporal dependencies across multiple cues over a temporal window that can be used for multi-target tracking.
We study the problem of multiclass classification with an extremely large number of classes (k), with the goal of obtaining train and test time complexity logarithmic in the number of Classes.
A semi-supervised human detection model based on Self-Enhanced R-CNN.
The BERT language model (LM) is surprisingly good at answering cloze-style questions about relational facts. We take issue with this and propose E-BERT, an extension of BERT that replaces entity mentions with symbolic embeddings.
We propose BigNAS, an approach that challenges the conventional wisdom that post-processing of the weights is necessary to get good prediction accuracies for neural architecture search.
We combine the l1-norm and l2-norm based regularizations in one Huber-type loss function, and then formulate an optimization problem in the Fourier Domain for fast computation, which enables the tracker to adaptively ignore the noisy features produced from occlusion and illumination variation.
Using audio embeddings for automated, topically coherent segmentation of radio shows.
We replace the traditional softmax attention mechanism with two alternative sparsity-promoting transformations: sparsemax, which is able to select the relevant regions only (assigning zero weight to the rest), and a newly proposed Total-Variation Sparse Attention (TVmax), which further encourages the joint selection of adjacent spatial locations.
We present a new architecture dubbed Convolutional Multi-way Associative Memory (CMAM) to tackle the limitation of current CRNNs. By leveraging recent memory accessing mechanisms in MANNs, our architecture demonstrates superior performance against other CRNN counterparts in three real-world long text OCR datasets.
We hypothesize that with proper priors to regulate learning, neural networks can automatically associate neurons in the intermediate layers with concepts that are aligned with real world concepts, when trained only with labels that associate concepts with top level neurons.
We propose to use the Spatial Layout of Words (SLoW) descriptor to boost visual word based image descriptors by exploiting contour cues.
We present an end-to-end synthetic neural network, containing a symmetric equilibrium generative adversarial network (SEGAN), multi-scale features refine blocks (MSFRB), and attention mechanism (AM) to enhance the performance on vessel segmentation.
Propagating trust values along trust relationships in social networks using a new relation based on previous performance of users in the social network.
An adversarial query is an image that has been modified to disrupt content-based image retrieval (CBIR), while appearing nearly untouched to the human eye. We introduce an innovative neural image perturbation approach, called Perturbations for Image Retrieval Error (PIRE), that is capable of blocking neural-feature-based CBIR.
We propose a scalable approach to learn video-based question answering (QA): answer a "free-form natural language question" about a video content using a large number of videos and descriptions freely available online.
We introduce an end-to-end framework for video analysis focused towards practical scenarios built on theoretical foundations from sparse representation, including a novel descriptor for general purpose video analysis.
We propose a self-supervised model-based RL method that generalizes effectively to never-before-seen robotic manipulation tasks and objects.
This paper proposes an original, intelligent, and high-performing image processing system for the simultaneous detection and segmentation of retinal RoIs.
Meta-NLG is a generalized optimization-based meta-learning approach for low-resource natural language generation, based on the MAML algorithm.
We present the Menpo 2D and Menpo 3D benchmarks, two new datasets for multi-pose2D and 3D facial landmark localisation and tracking. We introduce an elaborate semi-automatic methodology for providing high-quality annotations for both the menpo 2d and menpo3D benchmarks.
We evaluated various compositional models, from bag-of-words representations to compositional RNN-based models, on several extrinsic supervised and unsupervised evaluation benchmarks. We analyzed some of the evaluation datasets to identify aspects of meaning they measure and the characteristics of the various models that explain their performance variance.
ResiDen exploits dense blocks along with residual connections and uses auxiliary information from a FER network for FAU detection in the wild.
We propose the Evaluating Rationales And Simple English Reasoning benchmark to advance research on interpretable models in NLP that can reveal the `reasoning' underlying model outputs.
Temporal consistency is a key component to temporally consistent region assignment in videos.
Reconstructing the human interactome based on a priori definition of the protein nodes enabled us to identify the currently included part of the human “complete” proteome, and discuss the role of the proteins within the network topology with respect to their function.
The successive subspace learning (SSL) principle was developed and used to design an interpretable learning model, known as PixelHop method,for image classification in our prior work.
In this paper we show that by carefully making good choices for various detailed but important factors in a visual recognition framework using deep learning features, one can achieve a simple, efficient, yet highly accurate image classification system.
We propose a novel end-to-end learning framework named Multi-Veiw Prototype Network (MVPN) for 3D shape recognition.
We exploit recent advances in generative adversarial network (GAN) architectures to account for temporal correlations and generate adversarial samples that cause misclassification rates of over 80% for targeted activities.
We combine features extracted from pre-trained convolutional neural networks (CNNs) with the fast, linear Exemplar-LDA classifier to get the advantages of both: high detection performance of CNNs, automatic feature engineering, fast model learning from few training samples and efficient sliding-window detection.
Mutual Information-based Neuron Trimming approaches deep compression via pruning by enforcing sparsity based on the strength of the relationship between filters of adjacent layers.
We present a novel compact point cloud representation that is inherently invariant to scale, coordinate change and point permutation.
This paper addresses the problem of object discovery from unlabeled driving videos captured in a realistic automotive setting by mining object tracks using a generic object tracker.
We present a novel multitask learning framework that learns a disentangled representation of 3DMM parameters for a single face and performs joint face detection and retargeting for multiple faces.
We propose the scheme that mitigates the adversarial perturbation $\epsilon$ on adversarial examples crafted by the FGSM based attacks on ResNet-50 trained with ImageNet dataset.
In this paper, we propose the TBCNN-pair model, a tree-based convolutional neural network that captures sentence-level semantics; then heuristic matching layers like concatenation, element-wise product/difference combine the information in individual sentences.
This work proposes a solution based in the DCME technique to solve the instance segmentation with a single segmentation network.
In this paper we propose a new algorithm using the statistics of the spatio-temporal wavelet subbands to count people automatically in a crowded scenario.
We identified the novel Rac1 inhibitor ZINC69391 through a docking-based virtual library screening targeting Rac1 activation by GEFs. We further developed the novel analog 1A-116 by rational design and showed to be specific and more potent than parental compound in vitro.
This paper introduces a method for human action recognition based on optical flow motion features extraction. Automatic spatial and temporal alignments are combined together in order to encourage the temporal consistence on each action by an enhanced dynamic time warping algorithm. At the same time, a fast method based on coarse-to-fine DTW constraint is induced.
In this paper, we propose a model-free method for human action recognition via sparse spatiotemporal representation.
We present a scalable approach for Detecting Objects by transferring Common-sense Knowledge (DOCK) from source to target categories.
A modularized architecture search approach for deep neural networks.
We propose a Deep Landscape Forecasting (DLF) model which combines deep learning for probability distribution forecasting and survival analysis for censorship handling.
The research was partially supported by a gift from IBM Research, Department of Defense (U.S.A), and MITRE.
A novel method for blood vessel segmentation in retinal images using multiple methods.
In this work, we propose a mask propagation network to treat the video segmentation problem as a concept of the guided instance segmentation.
This paper proposes dynamic chunk reader (DCR), an end-to-end neural reading comprehension (RC) model that is able to extract and rank a set of answer candidates from a given document to answer questions.
We present an approach to learning features that represent the local geometry around a point in an unstructured point cloud that combine precision, compactness, and robustness.
We propose HUSC, a HUman Synthesis and Scene Compositing framework for the realistic synthesis of humans with different appearance, in novel poses and scenes.
Question semantic similarity (Q2Q) is a challenging task that is very useful in many NLP applications, such as detecting duplicate questions and question answering systems.
We propose a restart technique for stochastic gradient descent to improve its anytime performance when training deep neural networks.
We propose 3D-MiniNet, a novel approach for LIDAR semantic segmentation that combines 3D and 2D learning layers.
We propose a Triplet Online Instance Matching (TOIM) loss function, which lays emphasis on the hard samples and improves the accuracy of person ReID effectively.
In this paper, an effective approach is proposed for automatic 4D Facial Expression Recognition using a Riemannian method and magnifying them by a temporal filtering technique.
In this paper, we develop a new method that recognizes facial expressions, on the basis of an innovative local motion patterns feature, with three main contributions.
We propose two data augmentation methods that create additional training examples to help improve model explainability of existing sentiment classifiers.
This paper focuses on visual KWS for words unseen during training, a real-world, practical setting which so far has received no attention by the community.
We propose to learn a CNN which can perform lossy image compression at multiple bpp rates from a single CNN.
This paper presents a novel deep architecture for saliency prediction. We propose an architecture which combines features extracted at different levels of a Convolutional Neural Network (CNN) to predict saliency maps.
In this paper, we propose fixed point and Bregman iterative algorithms for solving the nuclear norm minimization problem and prove convergence of first of these algorithms.
This paper presents a computationally efficient method for the detection of optic nerve head in both color fundus and fluorescein angiography images in the presence of various structural, color, and intensity variations in such images.
A case study on attribute recognition of the heated metal mark image using computer vision and machine learning technologies.
We propose methods to effectively transfer knowledge from weakly labeled web audio data using a convolutional neural network.
We propose a unified statistical framework to test network properties of single and multiple genesets and integrate it into existing high-performance data analysis pipelines.
We propose a novel classification method that combines DBN and SVM to improve the accuracy of speech emotion recognition, including speech signal feature extraction and emotion classification.
We propose Regression-based Hypergraph, a novel hypergraph model which utilizes the regression models to construct the high quality hypergraphs.
We propose a distinctive-attribute extraction method that extracts attributes which explicitly encourage RNNs to generate an accurate caption. The method can be plugged into various models to improve their performance.
We address this problem by presenting and comparing different approaches for self-supervised pretraining of neural networks on unlabeled laparoscopic videos using temporal coherence.
We tackle the tasks of automatically identifying comparative sentences and categorizing the intended preference (e.g., "Python has better NLP libraries than MATLAB" => (Python, better, MATLAB).
In this paper, we propose a novel edge preserving and multi-scale contextual neural network for salient object detection in RGB-D.
A key challenge in structure-based discovery is accounting for modulation of protein-ligand interactions by ordered and bulk solvent. To investigate this, we compared ligand binding to a buried cavity in Cytochrome c Peroxidase, where affinity is dominated by a single ionic interaction, versus a cavity variant partly opened to solvent by loop deletion.
Exploiting multiple modalities for semantic scene parsing has been shown to improve accuracy over the singlemodality scenario. We propose to address this issue, by formulating multimodal semantic labeling as inference in a CRF and introducing latent nodes to explicitly model inconsistencies between two modalities.
We propose two novel KD methods based on structure-level information to reduce the gap between monolingual models and the unified multilingual model by distilling the structural knowledge.
We propose a framework to enable utilizing discrete multi-labels to control which features to be disentangled,i.e., disentangling label-specific fine-grained features for image manipulation.
We introduce Panoptic-DeepLab, a simple, strong, and fast system for panoptic segmentation, aiming to establish a solid baseline for bottom-up methods that can achieve comparable performance of two-stage methods while yielding fast inference speed.
This paper addresses this fundamental problem by directly modeling the temporal dynamics between language and all possible local image patches in an end-to-end approach for VQA.
We use reinforcement learning as a tool to optimize conditional computation policies, capturing the idea of wanting to have parsimonious activations while maintaining prediction accuracy.
We propose a novel FCN framework to integrate multilevel convolutional features recurrently with the guidance of object boundary information for salient object detection.
In this paper, we propose a novel probabilistic chain graph model (CGM) to marry SSL with latent factor model (LFM) to alleviate the label (i.e., rating) sparsity problem.
Vehicle 3D extents and trajectories are critical cues for predicting the future location of vehicles and planning future agent-motion based on those predictions.
This paper proposes MB-CNN, a memristive accelerator for binary convolutional neural networks that perform XNOR convolution in-situ novel 2R Memristive data blocks to improve power, performance, and memory requirements of embedded mobile devices.
We present a novel method for dimensionality reduction and recognition based on Linear Discriminant Analysis (LDA), which specifically deals with the Small Sample Size (SSS) problem in Computer Vision applications.
We propose a robust LSTM-Autoencoders (RLA) model to effectively restore partially occluded faces even in the wild.
This paper introduces hyperspherical prototype networks, which unify classification and regression with prototypes on hyperspheres as output spaces.
This article proposed a novel human identification method based on retinal images using fuzzy system with Manhattan distances of two feature vectors as input and similarity measure as output.
We propose a new reality oriented adaptation approach for urban scene semantic segmentation by learning from synthetic data. We achieve a new state-of-the-art of 39.4% mean IoU on Cityscapes dataset by adapting from the GTAV dataset.
This paper addresses issues in the nature of the training data target distributions, enabling prior networks to be successfully trained on classification tasks with arbitrarily many classes, as well as improving out-of-distribution detection performance.
In this work, we demonstrate that we can cast the problem of textual grounding into a unified framework that permits efficient search over all possible bounding boxes.
We propose a metric both strongly indicative of generalizability of local minima and effectively applied as a practical regularizer for DNNs.
This paper describes a novel approach to learning term-weighting schemes for text classification.
We quantify the agreement between curated interactions from 15 471 publications shared across nine major public databases, and explore the impact of divergent curation policies across databases.
We propose a Graph Property Sensing Network (GPS-Net) that fully explores these three properties for scene graph generation.
In this paper, we propose a differentiable pruning method via hypernetworks for automatic network pruning and layer-wise configuration optimization.
In this paper we describe experiments with the use of a tensorial representation from Gaussian receptive field responses for face recognition to estimate human age from facial images.
We propose a variational autoencoder for graphs that can learn and mimic the generative process of several well-known random graph models and can be used to create new molecules more effectively than several state of the art methods.
We use the max-margin classifier to learn an efficient hash function from training images belonging to seen classes which can efficiently encode images of unseen classes to binary codes.
We propose to optimally organize multiple similarity measures of global pedestrian and body part pairs with respect to different visual consistency measures (VCM) for person re-identification.
This work proposes Residual Knowledge Distillation (RKD), which further distills the knowledge by introducing an assistant (A)
We propose a novel generative adversarial network to address cross-resolution person re-ID, allowing query images with varying resolutions.
We revisit and compare existing few-shot learning methods for the low-shot facial expression recognition in terms of their generalisation ability via episode-training.
We propose a noise-resistant neural network for face recognition under noise.
We investigate the problem of strictly unsupervised video object segmentation, i.e., the separation of a primary object from background in video without a user-provided object mask or any training.
We propose a framework to design a light-weight neural multiplexer that given input and resource budgets, decides upon the appropriate model to be called for the inference.
We present MoVNect, a lightweight deep neural network to capture 3D human pose using a single RGB camera, which achieves both high accuracy and fast inference time.
We consider generation and comprehension of natural language referring expression for objects in an image. We propose two approaches to utilize models trained for comprehension task to generate better expressions.
We introduce a paradigm for nonlocal sparsity reinforced deep convolutional neural network denoising using standard pre-trained CNNs together with standard nonlocal filters.
We study data preconditioning, a well-known and long-existing technique, for boosting the convergence of first-order methods for regularized loss minimization.
In this paper, we propose a novel neural network for point cloud, dubbed GAPNet, to learn local geometric representations by embedding graph attention mechanism within stacked Multi-Layer-Perceptron layers.
Improving training data for event based CNNs that result in 25-40% boost in performance of existing state-of-the-art (SOTA) video reconstruction networks retrained with our method, and up to 80% for optic flow networks.
We develop a novel filter importance norm that incorporates the loss caused by the elimination of a component from the CNN.
We propose a new, unified formulation of the interactive semantic parsing problem, where the goal is to design a model-based intelligent agent. The agent maintains its own state as the current predicted semantic parse.
We propose a Bayesian model that takes into account the computational structure of neural networks and provides structured sparsity, e.g. removes neurons and/or convolutional channels in CNNs.
We show that low-rank factor decomposition can mitigate the challenges of high row-coherence, provided that its dictionary is configured properly.
In computer vision most iterative optimization algorithms, both sparse and dense, rely on a coarse and reliable dense initialization to bootstrap their optimization procedure. We overcome this problem and inject prior knowledge in a maximum a posterior (MAP) approach in order to obtain a dense reconstruction from sparse measurements.
We propose a strategy for building medical image classifiers using features from segmentation networks using curriculum learning.
The fruit fly Drosophila's olfactory circuit has inspired a new locality sensitive hashing algorithm that produces sparse high dimensional hash codes in a data-driven manner.
We propose a new framework for distortion-agnostic watermarking, where the image distortion is not explicitly modeled during training. Instead, the robustness of our system comes from two sources: adversarial training and channel coding.
In this paper, we establish a novel bottom-up cue named Convex Hull Overlap (CHO), and then propose an effective approach to detect salient regions using the combination of the CHO cue and global contrast cue.
We propose a cascade in which each stage consists of a mixture of regression experts. Each expert learns a customized regression model that is specialized to a different subset of the joint space of pose and expressions. The system is invariant to a predefined class of transformations.
In this paper, we introduce an anchor-box free and single shot instance segmentation method, which is conceptually simple, fully convolutional and can be used as a mask prediction module forinstance segmentation, by easily embedding it into most off-the-shelf detection methods.
This paper provides an extensive study on the availability of image representations based on convolutional networks (ConvNets) for the task of visual instance retrieval.
The κ-opioid receptor (KOR)-dynorphin system has been implicated in the control of affect, cognition, and motivation, and is thought to be dysregulated in mood and psychotic disorders.
We propose NUMA-aware multi-solver-based CNN design for accelerating deep learning neural networks on multi- and many-core CPU architectures.
We present a novel Temporal GANs conditioning on Captions, namely TGANs-C, in which the input to the generator network is a concatenation of a latent noise vector and caption embedding, and then is transformed into a frame sequence with 3D spatio-temporal convolutions.
We present a compositional model reminiscent of neural module networks that can perform chained logical reasoning.
Automatic Chemical Design leverages recent advances in deep generative modelling to provide a framework for performing continuous optimization of molecular properties. The goal of this thesis is to test the hypothesis that the origin of this pathology is rooted in the current formulation of Bayesian optimization.
We address the problem of segmenting and retrieving word images in collections of historical manuscripts given a text query given an end-to-end trainable model based on deep neural networks.
We show that it is better to learn how to sample. To do that, we propose a deep network to simplify 3D point clouds.
Particle filtering is a powerful approach to sequential state estimation and finds application in many domains, including robot localization, object tracking, etc. This paper introduces the Particle Filter Network, which encodes both a system model and a particle filter algorithm in a single neural network.
In computer vision related applications, video analysis of human walking motion is currently one of the most active research topics. The task of analyzing human walking can be divided into three distinct subtasks – human detection or segmentation, motion tracking and walking pose analysis.
We explore voxel-based models, and present evidence for the viability of voxellated representations in applications including shape modeling and object classification.
We propose a new evaluation measure, CrossLID, that measures the local intrinsic dimensionality (LID) of real-world data with respect to neighborhoods found in GAN-generated samples.
We propose to revisit knowledge transfer for training object detectors on target classes from weakly supervised training images, helped by a set of source classes with bounding-box annotations.
We report on the methods used in our recent DeepEnsembleCoco submission to the PASCAL VOC 2012 challenge, which achieves state-of-the-art performance on the object detection task.
This paper presents a novel system for ear recognition based on ensembles of deep CNN-based models and more specifically the Visual Geometry Group (VGG)-like network architectures for extracting discriminative deep features from ear images.
We show that changes in the geometry of the associated object manifolds underlie improved classification capacity, and shed light on the functional roles different levels in the hierarchy play to achieve it.
We propose a novel neural architecture Transformer-XL that enables learning dependency beyond a fixed length without disrupting temporal coherence.
We evaluate three different CNN architectures along with three learning approaches to train them for hieroglyph classification, which is a very challenging task due to the limited availability of segmented ancient Maya glyphs.
Meta-training GANs for few shot image-to-image translation on hair color attribute synthesis .
We propose a novel interpretation of residual networks showing that they can be seen as a collection of many paths of differing length. Moreover, residual networks seem to enable very deep networks by leveraging only the short paths during training.
In this paper, we present a syntactic string matching approach to solve the frontal face recognition problem, which can perform non-sequential string matching between two Stringfaces.
We propose a random temporal skipping strategy for multirate videos.
We present a joint model based on deep learning that is designed to inpaint the missing-wedge sinogram of electron tomography and reduce the residual artifacts in the reconstructed tomograms.
In this paper, we introduce a new deep Convolutional neural network (ConvNet) module that promotes competition among a set of multi-scale convolutional filters, where we replace the original collaborative pooling stage with a competitive pooling represented by a maxout activation unit.
We propose a novel end-to-end cascaded network of CNNs to jointly learn crowd count classification and density map estimation.
Multi-modal Factorized Bilinear Pooling for Visual Question Answering .
We build a simple person recognition framework that leverages convnet features from multiple image regions (head, body, etc.). We propose new recognition scenarios that focus on the time and appearance gap between training and testing samples.
Adversarial examples pose a threat to deep neural network models in a variety of scenarios, from settings where the adversary has complete knowledge of the model and to the opposite "black box" setting. Since these types of attacks rely on repeated queries to the model to estimate gradients over input dimensions, we investigate the use of randomization to thwart such adversaries from successfully creating adversarial examples.
We propose XPipe, an efficient asynchronous pipeline model parallelism approach for multi-GPU DNN training.
CASED improves the optimization of deep nodule segmentation models by allowing them to first learn how to distinguish nodules from their immediate surroundings, while continuously adding a greater proportion of difficult-to-classify global context.
We propose a novel method to search optimized active regions from the three kinds of active regions to classify basic expressions accurately.
We propose a novel structured matrix decomposition model with two structural regularizations that capture the image structure and enforces patches from the same object to have similar saliency values, and boost the detection.
We propose a fully-automated approach that guides accurate mass segmentation from full mammograms at high resolution through a detection stage.
We propose a transfer learning approach optimized to keep into account that in each layer of a CNN some filters are more susceptible to image distortion than others. This significantly reduces the number of parameters to retrain.
This paper addresses generating counterfactual explanations with multimodal information with a novel neural network layer.
We propose a new CNN model by incorporating a Parametric Sigmoid Norm layer just before the final fully-connected layer.
VGGNets have turned out to be effective for object recognition in still images. However, it is unable to yield good performance by directly adapting the VGGNet models trained on ImageNet dataset for scene recognition.
We present a hybrid neural-network for human face recognition which compares favourably with other methods. We analyze the computational complexity and discuss how new classes could be added to the trained recognizer.
We propose a strong baseline model for unsupervised feature learning using video data. For the first time, we show that such a model can predict non-trivial motions over short video sequences.
We propose a unified complete quantization framework for large-scale DNNs involving all data paths including W (Weights), A (Activation), G (Gradient), E (Error), U (Update), and BN.
We propose a meta-learning based generative model that naturally handles the limitations of ZSL/GZSL.
We unify state-of-the-art embedding models, such as ComplEx and TorusE, reinterpreting them as a variant of translation-based models for link prediction and propose a method for evaluating rules based on this idea.
We present the first crowdsourced data collection of dynamic, natural and spontaneous facial responses as viewers watch media online in under two months.
Multi-modal models that learn semantic representations from both linguistic and perceptual input outperform language-only models on a range of evaluations, and better reflect human concept acquisition.
This paper presents and analyses an algorithm that combines vessel segmentation and grouping of the extracted vessel segments and constructing retinal vascular trees with anatomical realism.
We propose a differentiable neural architecture search framework that uses gradient-based methods to optimize ConvNet architectures, avoiding enumerating and training individual architectures separately as in previous methods.
We propose to use multiple semantic dense representations instead of sparse representation as the target label for out-of-distribution detection.
We propose a new policy iteration theory as an important extension of soft policy iteration and Soft Actor-Critic, one of the most efficient model free algorithms for deep reinforcement learning. Supported by the new theory, arbitrary entropy measures, such as Tsallis entropy and Renyi entropy, can be utilized to properly randomize action selection while fulfilling the goal of maximizing expected long-term rewards.
Automated facial expression recognition on mobile phones using the Facial Landmarks descriptor and the Center of Gravity descriptor.
Pseudo-LiDAR-based 3D object detection for monocular 3D scene understanding .
We propose a new strategy for pooling and sampling GNNs using graphon pooling which preserves the spectral properties of the graph and improves upon other pooling techniques.
We propose a sequential neural encoder with latent structured description (SNELSD) for modeling sentences.
MetaRomance, a rule-based cross-lingual parser for Romance languages submitted to CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependen- ::: cies.
Scene recognition is an image recognition problem aimed at predicting the category of the place at which the image is taken. In this paper, a new scene recognition method using convolutional neural network (CNN) is proposed.
In this paper, a graph embedding-based denoising extreme learning machine autoencoder is proposed for capturing the structure of the inputs.
This thesis proposes two different approaches to improve the detection performance in the relatively light-weight way. The main focus of improving detection performance is proposing DNNs with extra layers and novel topological connections.
We propose a novel deep network structure called "Network In Network" (NIN) to enhance model discriminability for local patches within the receptive field.
We address an anomaly detection setting in which training sequences are unavailable and anomalies are scored independently of temporal ordering. We define anomalies as examples that can be distinguished from other examples in the same video, our definition inspires a shift in approaches from classical density estimation to simple discriminative learning.
A family of super deep networks, referred to as residual networks or ResNet, achieved record-beating performance in various visual tasks such as image recognition, object detection, and semantic segmentation. The ability to train very deep networks naturally pushed the researchers to use enormous resources to achieve the best performance. In this paper, we propose âˆS-ResNet that allows us to automatically discard redundant layers.
We propose a simple yet effective Horizontal Pyramid Matching (HPM) approach to fully exploit various partial information of a given person, so that correct person candidates can be identified even if key parts are missing.
We propose DENse Feature Indicator, a universal module that helps 3D detectors focus on the densest region of the point clouds in a boundary-aware manner in a real-time scenario.
We study the problem of learning a navigation policy for a robot to actively search for an object of interest in an indoor environment solely from its visual inputs.
In this paper, we propose an effective and robust method of spatial feature extraction for acoustic scene analysis utilizing partially synchronized and/or closely located distributed microphones.
3D point cloud classifiers are weak to adversarial attacks, but they are also easily defensible compared to 2D image classifiers.
In recent years, correlation filter (CF)-based tracking methods suffer from unwanted boundary effects because of the periodic assumption of the training and detection samples. In this paper, we present a novel CF-based tracking method to resolve this issue by dynamically and adaptively correcting the weights of learning CFs and fusing them together to promote a more robust tracking.
We propose a network module for learning embeddings of the environment's dynamics in a self-supervised way.
The Weakly Supervised Person Dataset (WSPD) pre-trained model has 13.38% better accuracy than the same model trained on the fully supervised ImageNet and EuroCity Persons datasets, respectively.
Understanding images with people often entails understanding their interactions with other objects or people. To that end, we explore ways to learn the generic, action-independent connections between (a) representations of a person's pose, gaze, and scene cues and (b) the interactee object's position and scale.
We propose a new fully convolutional neural network that learns salient edges and saliency labels in an end-to-end fashion for complex scenes with complex compositions, multiple salient objects, and diverse scales.
We introduce Bidirectional latent-variable models for multi-task learning, achieving state-of-the-art accuracy on both high-level recognition and low-level grouping tasks.
We propose a novel attention based fully convolutional network for speech emotion recognition.
We propose an Ecologically-Inspired GENetic (EIGEN) approach that uses the concept of succession, extinction, mimicry, and gene duplication to search neural network structure from scratch with poorly initialized simple network and few constraints.
AttoNets, a family of highly efficient deep neural networks for on-device edge deep learning, created via human-machine collaborative design.
Comunicacio presentada a: 6th Workshop on Argument Mining celebrat l'1 d'agost de 2019 a Florencia, Italia.
We first introduce a weight normalization approach for GAN training that significantly improves the stability, efficiency and the quality of the generated samples.
In this work, we propose a novel Focused Dynamic Attention (FDA) model to provide better aligned image content representation with proposed questions.
We propose a new automated data augmentation method that automates the process by finding optimal DA policies using Bayesian optimization.
We propose FSNet, a deep generative model for image-based face swapping.
We propose to estimate the missing node representations from the available content representations, and conversely, to use them to learn a linear transformation from a set of aligned content and node representations.
In this work, loss-sensitive learning approach and resampling techniques were applied to counter the negative effects of imbalanced laparoscopic data on training the CNN model.
In this paper, we present a model which takes as input a corpus of images with relevant spoken captions and finds a correspondence between the two modalities. We employ a pair of convolutional neural networks to model visual objects and speech signals at the word level.
We present an algorithm for detecting protein complexes from large protein-protein interaction networks with improved accuracy than previous methods.
We introduce SparseMAP: a new method for sparse structured inference, and its natural loss function, which automatically selects only a few global structures.
We propose an object detection method using context for improving accuracy of detecting small objects.
We investigate multi-speaker modeling for end-to-end speech synthesis and study the effects of different types of state-of-the-art neural speaker embeddings on speaker similarity for unseen speakers.
Image captioning models are becoming increasingly successful at describing the content of images in restricted domains. However, if these models are to function in the wild - for example, as assistants for people with impaired vision - a much larger number and variety of visual concepts must be understood. To address this problem, we propose a novel algorithm for training sequence models, such as recurrent neural networks, on partially-specified sequence data.
This paper describes a new parameter server, called GeePS, that supports scalable deep learning across GPUs distributed among multiple machines, overcoming these obstacles.
We extend SAC to a richer class of probability distributions through normalizing flows, which we show improves performance in exploration, sample complexity, and convergence.
We address the compression of networks after domain transfer. We show that domain transfer leads to large shifts in network activations and that it is desirable to take this into account when compressing.
We propose a novel method for automatic context window composition based on a gradient analysis, which leads to effective DNN training under reverberant conditions.
We propose 3D visual feature representations and 3D object bounding boxes supervised by moving and watching objects move, without any human annotations.
In this paper, we propose a multi-branch and high-level semantic network by gradually splitting a base network into multiple different branches.
We show that uncertainty based active learning heuristics are not effective for CNNs even in an oracle setting. We propose a simple but effective method, choosing a set of images to label such that they cover the set of unlabeled images as closely as possible.
We propose a novel learning mechanism to enforce structure in the prediction via consensus, guided by a robust loss function that forces pixel objects to be consistent with each other.
We propose the Multi-Perspective Inferrer (MPI), a novel NLI model that reasons relationships from multiple perspectives associated with the three relationships.
We introduce a data-driven approach for interactively synthesizing in-the-wild images from semantic label maps using simple but classic tools for matching scene context, shapes, and parts.
This paper addresses both issues in a single model, the robust autoencoder, which learns a nonlinear subspace that captures the majority of data points, while allowing for some data to have arbitrary corruption.
This paper proposes a region-based approach that estimates feature importance in terms of appropriately segmented regions. By fusing the saliency maps generated from multi-scale segmentations, a more class-discriminative and visually pleasing map is obtained.
We introduce nGraph-HE2, an extension to the Intel nGraph compiler that enables privacy-preserving inference on standard, pre-trained models using their native activation functions and number fields.
This paper investigates how to leverage deep reinforcement learning to tackle whole-body mobile manipulation tasks in unstructured environments using only on-board sensors.
We propose MonoGRNet for the amodal 3D object detection from a monocular RGB image via geometric reasoning in both the observed 2D projection and the unobserved depth dimension.
We propose to use a Bayesian Neural Network for estimating an image dependent proposal distribution. Compared to a standard Gaussian random walk proposal, we can significantly reduce the number of samples needed to perform facial image analysis.
This paper proposes a novel object detection framework named Grid R-CNN, which adopts a grid guided localization mechanism for accurate object detection.
This paper reports a GPU-based parallelized implementation of the PatchMatch Stereo algorithm which reconstructs highly slanted leaf and stalk surfaces of sorghum at high speed from high-resolution stereo image pairs.
We study a D-PSGD algorithm and provide the first theoretical analysis that indicates a regime in which decentralized algorithms might outperform centralized algorithms for distributed stochastic gradient descent.
We propose an instance-segmentation framework that can accurately localize functionality and affordance of individual object parts.
We present an unsupervised learning framework for the task of monocular depth and camera motion estimation from unstructured video sequences.
Automated breast cancer multi-classification from histopathological images using structured deep learning model.
We propose a new region-of-interest (RoI) feature extraction strategy, named Shape-aware RoIAlign, which focuses feature extraction within a region aligned well with the shape of the instance- of-interest rather than a rectangular RoI.
This paper introduces SuperGlue, a neural network that matches two sets of local features by jointly finding correspondences and rejecting non-matchable points.
We present a novel perspective to unsupervised saliency detection through learning from multiple noisy labeling generated by weak"weak"and"noisy"unsupervised handcrafted saliency methods, in a probabilistic way.
We focus on parsing the content of both the input text and the synthesized image thoroughly to model the text-to-image consistency in the semantic level in an object-aware manner.
Novelty detection is the problem of identifying whether a new data point is considered to be an inlier or an outlier. We take a probabilistic approach and effectively compute the novelty probability.
This paper focuses on improving face recognition performance by a patch-based 1-to-N signature matcher that learns correlations between different facial patches.
This paper presents a simple but effective scheme called multi-scale orderless pooling (MOP-CNN) for improving CNN activations without degrading their discriminative power.
We present a transformation-grounded image generation network for novel 3D view synthesis from a single image and achieve significantly better results than existing methods.
We propose a multi-task spatio-temporal network that can jointly tackle saliency estimation, action recognition and video summarization.
We show that adversarial robustness and generalization are not necessarily contradictory goals, and that both robust and accurate models are possible.
In this paper we propose a regularized formulation of this problem, and derive a correct greedy algorithm that is similar in efficiency to existing greedy methods for the unregularized problem, while remaining efficient for practical use.
Deep neural networks (DNN) have revolutionized the field of natural language processing (NLP)
In this paper, we focus on fine-grained recognition of vehicles mainly in traffic surveillance applications. Our approach is based on 3-D bounding boxes built around the vehicles. The bounding box is used to normalize the image viewpoint by “unpacking” the image into a plane.
We present a learnt system for multi-view stereopsis. We leverage the underlying 3D geometry of the problem through feature projection and unprojection along viewing rays.
This paper explores the training of image-recognition systems on large numbers of images and associated user comments, without using manually labeled images.
We propose a new layer which is placed between fully connected layers and convolutional layers, called as Chanel Max Pooling, which improves classification accuracies of deep neural networks on fine-grained vehicle classification in the situation that a massive of parameters are reduced.
We propose a general approach to optimize anchor boxes for object detection, which allows the anchors to automatically adapt to the data distribution and the network learning capability.
We present a single-shot, bottom-up approach for whole image parsing that generalizes the tasks of semantic and instance segmentation and achieves state-of-the-art performance.
In this paper, we first introduce a strategy to represent the SQL query as a directed graph and then employ a graph-to-sequence model to encode the global structure information into node embeddings, achieving state-of-the-art performance.
This paper examines how far state-of-the-art machine vision algorithms can be used to retrieve common visual patterns shared by series of paintings.
We propose a method to generate large mini-batch sizes for GAN training, inspired by the use of Coreset-selection in active learning.
We tackle the problem of learning robotic sensorimotor control policies that generalize to visually diverse and unseen environments. Our method combines multitask learning on action selection and an auxiliary binary classification objective, together with a convolutional neural network architecture that uses an attentional mechanism to avoid distractors.
We present an adaptive regularization algorithm that can be effectively applied to the optimization problem in deep learning framework.
We propose a Multimodal Semantic Attention Network(MSAN), a new encoder-decoder framework incorporating multimodal semantic attributes for video captioning.
We show how to achieve guarantees similar to standard compressed sensing but without employing sparsity, using generative models.
Face aging simulation using hidden factor analysis joint sparse representation for age-progressed images .
We propose a semi-supervised attribute learning framework which progressively boosts the accuracy of attributes only using a limited number of labeled data.
In this paper, we first propose a probabilistic formulation of OpenQA, based on a three-level hierarchical structure, i.e., the question level, the paragraph level and the answer span level. Then a Hierarchical Answer Spans Model (HASQA) is designed to capture each probability.
Using kernel trick, we propose a non-linear discriminative dictionary learning technique which utilizes both labeled and unlabeled data for learning dictionaries in the high-dimensional feature space.
We use conditional generative adversarial networks to achieve cross-modal audio-visual generation of musical performances of different instruments.
We present a novel approach to fully automated reconstruction of tree structures in noisy 2D images.
In this paper, we propose a novel framework --- deep verifier networks (DVN) to verify the inputs and outputs of deep discriminative models with deep generative models.
We apply a new document-query evaluation methodology to evaluate experts retrieval from a set of queries sampled directly from the experts documents.
This paper presents an in-depth study of the problem by examining the differences and complementarities of two related but distinct approaches to this task: textonly neural machine translation and image captioning.
We observe that artificially inducing sparsity in the gradients of the gates in an LSTM cell has little impact on the training quality. We use structured sparsity to accelerate the forward pass of neural networks.
Zero-shot learning (ZSL) aims to recognize objects of novel classes without any training samples of specific classes, which is achieved by exploiting the semantic information and auxiliary datasets.
We propose a detection-based method for object counting that does not need to estimate the size and shape of the objects and that outperforms regression-based methods.
A latent-variable model is introduced for text matching, inferring sentence representations by jointly optimizing generative and discriminative objectives.
We characterize the dimensional properties of adversarial regions, via the use of Local Intrinsic Dimensionality (LID), and show that an LID-based method can outperform several state-of-the-art detection measures.
This paper proposes a learning-based algorithm for detecting reenactment based alterations.
In this paper we propose the Filter Response Normalization (FRN) layer, a novel combination of a normalization and an activation function, that can be used as a replacement for other normalizations and activations.
Detecting actions in untrimmed videos with temporal structures using structured segment network .
We propose a generative machine comprehension model that learns jointly to ask and answer questions based on documents based on a sequence-to-sequence framework.
Learning online adaptation in the context of model-based reinforcement learning for continuous control tasks.
We leverage the sparsity structure of computation masks and propose a novel tiling-based sparse convolution algorithm for 3D object detection.
We introduce the Scratchpad Mechanism, a novel addition to the sequence-to-sequence (seq2seq) neural network architecture and demonstrate its effectiveness in improving the overall fluency of seq2seq models for natural language generation tasks.
We proposed a method that exploits the depth cue in the backscatter components of stereo pairs, as an additional constraint for recovering the 3-D scene structure.
Integrating functional preferences of proteins and the graph topology of PPI network, we formulate the problem of identifying protein complexes into a constrained optimization problem.
We propose a video backdoor attack that can manipulate state-of-the-art video models with high success rates by poisoning only a small proportion of training data.
We propose a noise estimation building block for multimodal representation learning that is based strictly on the inherent correlation between different modalities and achieves comparable results to state-of-the-art performance on five different benchmark datasets.
Machine reading comprehension (MRC), which requires a machine to answer questions based on a given context, has attracted increasing attention with the incorporation of various deep-learning techniques over the past few years. Although research on MRC based on deep learning is flourishing, there remains a lack of a comprehensive survey summarizing existing approaches and recent trends, which motivated the work presented in this article.
Deep Anchored Convolutional Neural Network (DACNN) allows to reduce the model size tremendously, more precisely, the network is compressed in memory by a factor of L.
We propose an end-to-end framework for training domain specific models (DSMs) to obtain both high accuracy and computational efficiency for object detection tasks.
Depth information is important for autonomous systems to perceive environments and estimate their own state. Traditional depth estimation methods, like structure from motion and stereo vision matching, are built on feature correspondences of multiple viewpoints. Meanwhile, dense depth maps are estimated from single images in an end-to-end manner.
Unsupervised image-to-image translation (UNIT) aims at learning a mapping between several visual domains by using unpaired training images. To overcome these limitations, we propose GMM-UNIT, which is based on a content-attribute disentangled representation where the attribute space is fitted with a GMM.
We propose Cross-modal Adaptive Message Passing (CAMP), which adaptively controls the information flow for message passing across modalities, which improves state-of-the-art methods.
This paper presents a framework for predicting affordances of object parts of unseen categories, with application to robot manipulation.
We show that existing augmentations induce a significant discrepancy between the typical size of the objects seen by the classifier at train and test time. We then propose a simple yet effective and efficient strategy to optimize theclassifier performance when the train andtest resolutions differ.
This paper proposes a simple yet efficient Self-Cure Network (SCN) which suppresses the uncertainties efficiently and prevents deep networks from over-fitting uncertain facial images.
We present a study of the parallel speed up and convergence rates of learning achieved with native parallel execution on a leadership-class HPC system.
In this paper, we propose a novel framework for answering science exam questions, which mimics human solving process in an open-book exam.
We propose an Adaptive Training Sample Selection (ATSS) to automatically select positive and negative training samples according to statistical characteristics of object.
In this paper, we propose an approach to generate such explanations in which training data is augmented to include, in addition to features and labels, explanations elicited from domain users.
We present a stability-based approach for filter-level pruning of CNNs that reduces the number of FLOPS and GPU memory footprint.
Contextual representation models have achieved great success in improving downstream natural language processing tasks. However, these language-model-based encoders are difficult to train d...
We show that ensemble of weak defenses is not sufficient to provide strong defense against adversarial examples.
We present a new approach to 3D object representation where a neural network encodes the geometry of an object directly into the weights and biases of a second 'mapping' network.
We propose a new meta-learning method with few tuned hyper-parameters and simple structure of a meta-learner (one hidden layer MLP network) for robust learning.
We propose a novel moderate positive sample mining method to train robust CNN for person re-identification, dealing with the problem of large variation.
This paper introduces a deep architecture for segmenting 3D objects into their labeled semantic parts.
In this paper we introduce the ice-start problem, i.e., the challenge of deploying machine learning models when only little or no training data is initially available, and acquiring each feature element of data is associated with costs.
The implementation of 3D stereo matching in real time is an important problem for many vision applications and algorithms. The current work, extending previous results by the same authors, presents an integrated architecture suitable for implementation with Field Programmable Gate Array (FPGA) logic.
We introduce PlatonicGAN to discover the 3D structure of an object class from an unstructured 2D images, i.e., where no relation between photos is known, except that they are showing instances of the same category.
In this paper, a key-segment descriptor and a temporal step matrix model are proposed to semantically present the temporal-spatial skeleton data.
Synthetic genetic interactions in Caenorhabditis elegans reveal redundancy among functional modules on a global scale.
We find that SSL methods differ in sensitivity to the amount of labeled and unlabeled data, and that performance can degrade substantially when the unl labeled dataset contains out-of-class examples.
We propose Neural State Machine, a novel data-driven framework to guide characters to achieve goal-driven actions with precise scene interactions.
In this paper, we introduce a generalized neural network-based recommender framework that is easily extendable by additional networks.
In this paper, we propose a modularity based community detection framework for heterogeneous networks.
We address the unsupervised learning of several interconnected problems in low-level vision: single view depth prediction, camera motion estimation, optical flow, and segmentation of a video into the static scene and moving regions.
We introduce a novel network reparameterization based on the Kronecker-factored eigenbasis (KFE), and then apply Hessian-based structured pruning methods in this basis.
In this paper, we propose one lightweight action recognition architecture based on deep neural networks just using RGB data.
A new population-guided parallel learning scheme for off-policy reinforcement learning.
In this paper, we propose a new method to estimate the happiness intensity of people in an image.
In this letter, we propose PointTrackNet, an end-to-end 3-D object detection and tracking network, to generate foreground masks,3-D bounding boxes, and point-wise tracking association displacements for each detected object.
This paper proposes a real-time embedded fall detection system using a DVS(Dynamic Vision Sensor) that has never been used for traditional fall detection, a dataset for fall detection using that, and an optimized deep learning network to detect falls using DVS.
This paper studies the unsupervised setting of re-ID, which does not require any labeled information and thus is freely deployed to new scenarios.
We propose convolutional multimodal LSTM to encode the sequential interactions between individual words, visual information, and spatial information for image segmentation.
This paper proposes a simple, yet very effective method to localize dominant foreground objects in an image, to pixel-level precision.
We propose a simple extension to the ReLU-family of activation functions that allows them to shift the mean activation across a layer towards zero. Combined with proper weight initialization, this alleviates the need for normalization layers.
We propose a Clustered Detection (ClusDet) network that unifies object cluster and detection in an end-to-end framework and achieves promising performance in both efficiency and accuracy.
We take an additional step toward holistic scene understanding with monocular cameras by learning depth and motion alongside with semantics, with supervision for the latter provided by a pre-trained network distilling proxy ground truth images.
We present a novel many-to-many face reenactment framework, named FaceSwapNet, which allows transferring facial expressions and movements from one source face to arbitrary targets.
We evaluate online learning algorithms for large-scale visual recognition using state-of-the-art features which are preselected and held fixed.
We propose a novel method for detecting human-object interactions (HOIs) in social scene images in a weakly-supervised setting based on intention.
The counterfeit goods trade represents nowadays more than 3.3% of the whole world trade and thus it's a problem that needs now more than ever a lot of attention and a reliable solution that would reduce the negative impact it has over the modern society.
We fine-tune a convolutional neural network (CNN) trained on a large natural image recognition data-set (Imagenet ILSVRC2012) and transfer the learnt feature representations to cardiac view recognition.
In this paper, we propose Self Attention Grid (SAG) to discover the most informative parts from a high-resolution image using its internal representation.
This paper provides an extensive review of deep learning-based self-supervised general visual feature learning methods from images or videos for computer vision applications.
We identify an inherent ambiguity in the depth estimated from dual-pixel cues, and develop an approach to estimate depth up to this ambiguity. We estimate depth from a single camera by leveraging the dual- pixel auto-focus hardware that is increasingly common on modern camera sensors.
We use a set of COSFIRE filters to automatically detect vascular bifurcations in segmented retinal images. The filter output is computed as the weighted geometric mean of blurred and shifted Gabor filter responses.
The Long Short-Term Memory (LSTM) recurrent neural network is capable of processing complex sequential information since it utilizes special gating schemes for learning representations from long input sequences.
This study presents a new network (i.e., AbsPoseLifter) that lifts a 2D human pose to an absolute 3D pose in a camera coordinate system in a cascade fashion to achieve state-of-the-art 2D-to-3D pose lifting and 3Dhuman pose estimation.
We propose Shift R-CNN, a hybrid model for monocular 3D object detection, which combines deep learning with the power of geometry.
In this paper we present our system for the FEVER Challenge. The task of this challenge is to verify claims by extracting information from Wikipedia.
A systematic statistical approach including classical and exploratory data analyses on over 14000 images to measure the relative influence of the parameters allows their tuning based on the number of bad pixels.
By mitigating the class im-balance present in the data we demonstrate that a standard PointNet++ deep neural network can achieve higher performance at inference on validation data.
We present the first, to the best of our knowledge, non-linear 3D Morphable Models by learning joint texture and shape auto-encoders using direct mesh convolutions.
We propose a multi-label classification model based on Graph Convolutional Network (GCN) and propose a novel re-weighted scheme to create an effective label correlation matrix to guide information propagation.
This paper proposes a cross-camera adaptation framework (CCA), which smooths the bias by exploiting the common space between cameras for all samples for vehicle reID.
We present an efficient approach for leveraging the knowledge from multiple modalities in training unimodal 3D convolutional neural networks (3D-CNNs) for the task of dynamic hand gesture recognition.
In this paper, we present a novel siamese motion-aware network (SiamMan) for visual tracking, which consists of the Siamese feature extraction subnetwork, followed by the classification, regression, and localization branches in parallel.
A probabilistic definition of saliency is given in a form suitable for image matching.
We present a fast framework of Detection and Annotation for Vehicles (DAVE), which effectively combines vehicle detection and attributes annotation for urban traffic surveillance.
We propose to use multiple kernel matrices of a convolution layer on distinct analog arrays, and randomly divide parts of the compute among them, so that multiple Kernel matrices are trained in parallel.
We explain that the difficulties of training deep neural networks come from a syndrome of three consistency issues. We propose to address it with an intuitive, simple-to-implement, low footprint second-order method.
Recovering natural illumination from a single Low-Dynamic Range (LDR) image is a challenging task. To remedy this situation we exploit two properties often found in everyday images. First, images rarely show a single material, but rather multiple ones that all reflect the same illumination. Second, parts of the illumination are often directly observed in the background.
The spatial pooling method such as spatial pyramid matching (SPM) is very crucial in the bag of features model used in image classification. To improve SPM, we develop an extension model of Gauss mixture model to estimate the spatial layout distributions of visual vocabulary.
In this paper, an efficient particle swarm optimisation method named EPSOCNN is proposed to evolve CNN architectures inspired by the idea of transfer learning.
We propose a robust visual tracking method based on multilayer convolutional features and correlation filtering, which effectively solves the problem of adaptive estimating of target size.
We propose a new technique that boosts the convergence of training generative adversarial networks by using an additional layer called the gradient layer.
We propose an approach for learning a compact view-invariant embedding space from 2D joint keypoints alone, without explicitly predicting 3D poses, and use probabilistic embeddings to model this uncertainty.
Multilingual (or cross-lingual) embeddings represent several languages in a unique distributional vector space, enabling to search images by using text queries expressing information needs related to the (visual) content of images.
We propose a new computationally efficient transfer learning approach using classification layer features of pre-trained CNNs by appending layer after existing classification layer.
This paper introduces an updated version of the well-known Virtual KITTI dataset which provides multiple sets of images containing RGB, depth, class segmentation, instance segmentation and flow data.
An end-to-end approach attempts to achieve autonomous driving using a single, comprehensive software component.
We propose a random-forest based, cascaded regression model for face alignment by using a locally lightweight feature, namely intimacy definition feature, which achieves state-of-the-art performance.
We propose an interaction mechanism between a teacher and two students to generate more reliable pseudo labels for unlabeled data, which are beneficial to semi-supervised facial landmark detection.
We present a genetic algorithm that is enhanced with a neural network (DNN) based discriminator model to improve the diversity of generated molecules and at the same time steer the GA.
Spatiotemporal and motion features are two complementary and crucial information for video action recognition. In this work, we aim to efficiently encode these two features in a unified 2D framework by introducing a simple yet effective STM network.
Automatic extraction of synonymous collocation pairs from text corpora is a challenging task of NLP. In order to search collocations of similar meaning in English texts, we use logical-algebraic equations.
In this paper we propose a novel, more discriminative, descriptor that includes not only local feature representation, but also information about the geometric layout of neighbouring keypoints.
We propose the superhierarchy algorithm which is able to generate multi-scale superpixels as accurately as the state-of-the-art methods but with one to two orders of magnitude speed-up.
In this paper, we describe ROOT 18, a classifier using the scores of several unsupervised distributional measures as features to discriminate between semantically related and unrelated words, and then to classify the related pairs according to their semantic relation.
A robust retinal image enhancement algorithm via a dual-tree complex wavelet transform (DTCWT) and morphology-based method in this paper.
We propose Image-Semantic-Transformation-Reconstruction-Circle(ISTRC) model, a novel and powerful method using facenet's Euclidean latent space to understand the images.
Grid-GCN uses a novel data structuring strategy, Coverage-Aware Grid Query (CAGQ), for fast and scalable point cloud learning.
In this paper, we propose a direct method and train a Convolutional Neural Network that when, at test time, is given a pair of images as input it produces a dense motion field F at its output layer.
This paper reports unprecedented success on the Grade 8 New York Regents Science Exam, where for the first time a system scores more than 90% on the exam's non-diagram multiple choice (NDMC) questions.
We present c-M2DP, a fast global point cloud descriptor that combines color and shape information, and perform loop closure detection using it.
In this paper, we propose a new convolutional layer called Depthwise-STFT Separable layer that can serve as an alternative to the standard depthwise separable convolutionAL layer.
We find that diffusion state distance (DSD), our recent diffusion-based metric for measuring dissimilarity in PPI networks, has natural extensions that incorporate confidence, directions and can even express coherent pathways by calculating DSD on an augmented graph.
We apply data uncertainty learning to face recognition, such that the feature (mean) and uncertainty (variance) are learnt simultaneously, for the first time.
Adversarial attacks on deep neural networks (DNNs) have high success rates only when the information of the attacked DNN is well-known or could be estimated by structure similarity or massive queries.
We propose a salient vocabulary construction algorithm to select visual words from a global point of view, and form compact descriptors to represent discriminative histograms in the neighborhoods.
We present Sentence-BERT, a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity.
We propose a two-faceted solution to this problem that achieves compelling results on 3D shape recognition and retrieval.
We study the predictability, rigorously defined in an information-theoretic sense, of the final cultural groups (i.e. who ends up in which group) from the knowledge of the initial cultural traits.
We propose a communication game where two agents, native speakers of their own respective languages, jointly learn to solve a visual referential task. The emergent translation is interactive and multimodal.
The centrosome is the main microtubule-organizing center of animal cells, which plays key roles in critical cellular processes ranging from cell division to cellular signaling. Accordingly, defects in the structure and function of centrosomes cause various diseases such as cancer and primary microcephaly.
We propose XGPT, a new method of Cross-modal Generative Pre-Training for Image Captioning that is designed to pre-train text-to-image caption generators through three novel generation tasks, including Image-conditioned Masked Language Modeling (IMLM), Image-Conditioned Denoising Autoencoding (IDA), and Text-conditionED Image Feature Generation (TIFG).
In this paper, we point out the existence of some patterns of inappropriate labels, and propose a novel method for correcting such labels with a teacher model trained on such incomplete data.
We propose a meta-learning framework that explicitly constrains the learning on a sampled classification task to reduce the classification error on a randomly sampled unseen classification task with a bilevel optimization scheme.
Generative adversarial networks can use chaotic time series for latent variables of a GAN, whereby the inherent nature of chaos could be reflected or transformed into the generated data.
We propose a novel iterative learning framework for training CNNs on datasets with open-set noisy labels, which can robustly train CNNs.
Multimodal Sarcasm Detection Dataset (MUStARD), a multimodal sarcasm detection dataset, compiled from popular TV shows.
In this paper, three novel classification algorithms aiming at (semi-)supervised action classification are proposed.
We introduce a framework for algorithmic auditing that supports artificial intelligence system development end-to-end, to be applied throughout the internal organization development lifecycle.
This paper addresses a fundamental problem of scene understanding: How to parse the scene image into a structured configuration (i.e., a semantic object hierarchy with object interaction relations) that finely accords with human perception.
We introduce a novel RGB-D patch descriptor designed for detecting coplanar surfaces in SLAM reconstruction. Experiments show that our learned descriptor outperforms alternatives extended for this task by a significant margin.
We introduce ParlAI (pronounced "par-lay"), an open-source software platform for dialog research implemented in Python, available at this http URL.
We propose a new minimal path model associated with a dynamic Riemannian metric embedded with an appearance feature coherence penalty and an adaptive anisotropy enhancement term.
Integration of reinforcement learning and imitation learning is an important problem that has been studied for a long time in the field of intelligent robotics. In this paper, we propose a probabilistic generative model framework for reinforcement learning with multiple types of rewards and multiple optimality emissions and apply it to generative adversarial imitation learning.
This paper introduces an autonomous surveying scheme to collect, analyze, and map the image-based distress data in real time using a convolutional neural network that classifies several types of cracks.
Fashion is an increasingly important topic in computer vision, in particular the so-called street-to-shop task of matching street images with shop images containing similar fashion items.
We propose Guided Upsampling Network which can efficiently process high-resolution images in real-time while attaining state-of-the art performances.
We develop learning-based approaches to induce causal knowledge in the form of directed acyclic graphs, which can be used to contextualize a learned goal-conditional policy to perform tasks in novel environments with latent causal structures.
In the geographical edge caching, where base stations (BSs) and users are distributed as Poisson point process (PPP) and the caching performance is measured using average success probability (ASP), we consider the content popularity (CP) prediction problem to maximize the ASP.
An improved SRN face detector by combining these useful techniques together and obtain the best performance on widely used face detection benchmark WIDER FACE dataset.
We present a model for expression classification based on facial landmarks dynamics that can handle complex expression classes.
We propose a Deep Point-to-Subspace Metric Learning (DPSML) framework to project a sketch into a feature vector and a 3D shape into a subspace spanned by a few selected basis feature vectors.
Using a convolutional neural network to predict sound textures associated with a given video frame to improve image classification .
We propose to combine the two steps of energy minimization in order to improve stereo matching results.
We combine the benefits of both approaches, and propose the use of perceptual loss functions for training feed-forward networks for image transformation tasks.
We introduce SCORES, a recursive neural network for shape composition that learns a coherent and plausible 3D shape, despite large incompatibilities among the input parts.
We probe word-level contextual representations from four recent models and investigate how they encode sentence structure across a range of syntactic, semantic, local, and long-range phenomena.
We visualize multiple two-stream architectures to show that local detectors for appearance and motion objects arise to form distributed representations for recognizing human actions in video.
A cost-effective implementation of Convolutional Neural Nets on the mobile edge of the Internet-of-Things (IoT) requires smart optimizations to fit large models into memory-constrained cores. The objective of this work is to make an assessment of such memory-bounded implementations and to show that most are centred on specific parameter settings that are found difficult to be implemented on a low-power RISC.
In this study, we investigate how to design a deep-learning based high-performance traffic light detection system.
Using evolutionary algorithms for micro-expression recognition task.
We study utilising facial visual saliency maps to classify different facial expressions into different emotions.
We address the highly challenging problem of video object segmentation. We propose a novel approach based on a dedicated target appearance model that is exclusively learned online to discriminate between the target and background image regions.
We propose an on-demand learning algorithm for training image restoration models with deep convolutional neural networks that can generalize across difficulty levels.
In this paper, we investigate issues involving Faster R-CNN for pedestrian detection. We discover that the Region Proposal Network performs well as a stand-alone pedestrian detector, but surprisingly, the downstream classifier degrades the results.
We propose a quadratic video interpolation method which exploits the acceleration information in videos and generates more accurate interpolation results.
We present Any-Precision Deep Neural Networks, which are trained with a new method that empowers learned DNNs to be flexible in any numerical precision during inference, without performance degradation.
We examine the intersection between weak supervision and active learning, which allows the learner to actively select examples and query for manual annotations as extra supervision to improve the model trained under weak supervision.
We propose a soft-weighted anchor-free detector that outperforms state-of-the-art anchor-based detectors in terms of speed and accuracy.
We propose a novel architecture, Multiple Block Convolutional Highways, which achieves improved accuracy on multiple popular benchmark datasets.
We propose a novel deep learning architecture for regressing disparity from a rectified pair of stereo images using deep feature representations.
We propose PatchVAE, a bottleneck formulation that encourages mid-level style representations in the VAE framework for unsupervised learning for recognition.
In this paper, we aim at tackling the problem of crowd counting in extremely high-density scenes, which contain hundreds, or even thousands of people, using a Density-Aware Network.
We propose a new architecture called a cascading network that is capable of distributing a deep neural network between a local device and the cloud while keeping the required communication network traffic to a minimum.
This paper aims to propose novel deep end-to-end networks for long-term 6-DoF Visual Odometry task.
To advance models of multimodal context, we introduce a simple yet powerful neural architecture for data that combines vision and natural language in a unified architecture.
We tackle the problem of local optimisation of CQA frameworks and propose a three fold approach, which applies feature selection techniques with supervised machine learning approaches in order to identify the best performing components efficiently.
Learning semantic attributes for person re-identification and description-based person search .
We propose a simple neural architecture for natural language inference that uses attention to decompose the problem into subproblems that can be solved separately.
We propose a deep learning based framework to learn objects composition from photos with high aesthetic qualities, where an anchor region is detected through a convolutional neural network (CNN) with the Gaussian kernel to maintain the interested objects' integrity.
We propose Multimodal Transformer Networks (MTN) to encode videos and incorporate information from different modalities.
We propose a multiple kernel fuzzy c-means algorithm that is immune to ineffective kernels and irrelevant features and can be used for soft clustering.
A novel distance function between images assessing whether they are from the same basic-level category.
We propose a novel adaptive convolution method for GAN that learns the upsampling algorithm based on the local context at each location to address this problem.
We address the problem of camera global relocalization in a prior 3D line-feature map from a single image, in a GNSS denied context and with no prior pose estimation.
Pre-trained language models can be fine-tuned for text emotion recognition, achieving an accuracy of 69.5% on Task 4A of SemEval 2017, improving upon the previous state of the art.
We propose the first anchor-free and NMS-free object detection model called weakly supervised multimodal annotation segmentation (WSMA-Seg), which utilizes segmentation models to achieve an accurate and robust object detection in images.
We propose a privacy-preserving method for teacher ensembles that uses more informative network outputs under differential private stochastic gradient descent and provide provable privacy guarantees.
We propose a two-stage approach to detect and estimate 3D human poses, which separates SV pose detection from MV 3D pose estimation, allowing us to utilize each dataset for the right task.
We develop a generative model in which each sequence belongs to a class, and sequences from a given class pass through a common set of stages, where each sequence evolves at its own rate. We then develop a scalable algorithm to infer classes of sequences.
We propose a simple indicator reward function for goal-conditioned reinforcement learning, which can be used to accelerate convergence in continuous state spaces.
Compositional generalization of seq2seq models using convolutional networks is not clear-cut.
This paper reviews the GAN based methods for person re-identification focuses on the related papers about different GANbased frameworks and discusses their advantages and disadvantages.
In this paper, we propose a novel generative model named Stacked Generative Adversarial Networks (SGAN), which is trained to invert the hierarchical representations of a bottom-up discriminative network, leveraging the powerful discrim inative representations to guide the generative process.
We perform a thorough empirical study of four state-of-the-art paradigms on two photorealistic simulated 3D environments. We present a taxonomy of key exploration methods and a standard framework.
We study the cloze-style machine reading comprehension in the clinical medical field and propose a Gated Dilated Convolution with Attention model, which consists of a gated dilated convolution module and an attention mechanism.
We propose full-resolution residual network for progressive image inpainting, which is proved to be effective for irregular holes.
We regard the evolving landmark data as a high-dimensional path and apply Non-linear path signature techniques to provide an expressive, robust, non-linear, and interpretable representation for the sequential events.
We introduce Class Feature Pyramids, a method that traverses the entire network structure and incrementally discovers kernels at different network depths that are informative for a specific class.
The proposed deep label distribution learning method effectively utilizes label ambiguity in both feature learning and classifier learning, which help prevent the network from overfitting even when the training set is small.
We propose SASE-FE, the first dataset of facial expressions that are either congruent or incongruent with underlying emotion states. We propose a method that aggregates features along fiducial trajectories in a deeply learnt space.
In the yeast Saccharomyces cerevisiae, components of the High Osmolarity Glycerol (HOG) pathway are important for the response to diverse stresses including response to endoplasmic reticulum stress, which is produced by the accumulation of unfolded proteins in the lumen of this organelle.
We propose a novel method for completing the appearance of occluded objects that combines both segmentation and generation of invisible parts.
We propose a simple and effective metric learning method for large-scale person re-identification, which gets rid of the pairwise constraints.
A hybrid synthesis between HMM and exemplar-based voice conversion has been proposed. The experimental results show that the proposed method outperforms state-of-the-art HMM synthesis using global variance.
We propose a novel low-shot transfer detector (LSTD), where we leverage rich source-domain knowledge to construct an effective target-domain detector with very few training examples.
We propose a Region-Aware deep model for vehicle Re-ID, which learns discriminative features from local regions.
Compact neural networks are inclined to exploit “sparsely-connected” convolutions, such as depthwise convolution and group convolution for employment in mobile applications. To address this issue, we present two novel operations named merging and evolution to leverage the inter-group information.
We introduce Elastic, a simple, efficient and yet very effective approach to learn a dynamic scale policy from data. Our results show major improvement for images with scale challenges.
ASHA exploits parallelism and aggressive early-stopping to tackle large-scale hyperparameter optimization problems in distributed computing settings.
The objective of this article is to study the problem of pedestrian classification across different light spectrum domains (visible and far-infrared) and modalities (intensity, depth and motion) and to compare the state-of-the-art features in a multi-modality setup.
We propose a novel 3D extension of Gradient Location and Orientation Histograms that provides discriminative local features representing not only the gradient orientation, but also their relative locations.
This paper introduces a CNN-based feature detector based only on information embedded inside a CNN trained on standard tasks (e.g. classification).
We propose an end-to-end framework for fashion outfit compatibility prediction and diagnosis, based on type-specified outfit dataset and CNN.
The long-tail distribution of the visual world poses great challenges for deep learning based classification models on how to handle the class imbalance problem. In this work, we decouple the learning procedure into representation learning and classification, and systematically explore how different balancing strategies affect them for long-tailed recognition.
This paper provides a framework to hash images containing instances of unknown object classes, information of which is available only through the textual corpus.
Generating high-resolution, photo-realistic images has been a long-standing goal in machine learning. In this paper we extend this method by introducing an additional prior on the latent code, improving both sample quality and sample diversity, leading to a state-of-the-art generative model that produces high quality images at higher resolutions (227 × 227) and does so for all 1000 ImageNet categories.
In this paper, motivated by focal loss designed for the classification model, we propose the triplet focal loss for person ReID.
This work proposes a hardware system for mapping a uniformly-sampled sensor to a space-variant one, and a software-based, foveal attention mechanism that can guide segmentation.
We introduce a variant of the MAC model (Hudson and Manning, ICLR 2018) with simplified set of equations that achieves comparable accuracy, while training faster.
We introduce a novel 2-bits quantization with provably least squares error, in which values are mapped to -1 and 1. We provide a unified framework to analyze different scaling strategies.
We propose Sparse Sinkhorn Attention, a new efficient and sparse method for learning to attend that is competitive with vanilla attention.
We investigate the use of empowerment in the presence of an extrinsic reward signal and propose a unified Bellman optimality principle for empowered reward maximization.
In this paper, we present a so-called interlaced sparse self-attention approach to improve the efficiency of the \emph{self-att attention} mechanism for semantic segmentation.
We are the first to show that embodied adversarial reinforcement learning agents playing cache, a variant of hide-and-seek, in a high fidelity, interactive, environment, learn representations of their observations encoding information such as occlusion, object permanence, free space, and containment, moving closer to biologically motivated learning strategies.
We propose a Content-aware Adversarial Attack Generator (CAG) to achieve real-time, low-cost, enhanced-robustness and high-transferability adversarial attack.
This paper addresses the problem of recognizing human actions in video sequences for home care applications. As we focus on recognizing subtle differences in behaviour of patients, we propose a novel method which significantly enhances the discriminative properties of bag-of-words technique.
We introduce Spatial-Temporal Memory Networks for video object detection. We release our code and models at this URL.
Linear Discriminant Analysis (LDA) is a very common LDA technique for dimensionality reduction problems as a preprocessing ::: step for machine learning and pattern classification applications.
We investigate generation of gender specific caption words (e.g. man, woman) based on the person's appearance or the image context. We introduce a new Equalizer model that ensures equal gender probability.
This paper presents a method of pairwise multi-layer networks for multi-field categorical data, which widely exists with various applications.
We propose a coastline extraction method based on convolutional neural networks, which can effectively extract the coastline automatically.
An increasingly large amount of multimodal content is posted on social media websites such as YouTube and Facebook everyday. In order to cope with the growth of such so much multimmodal data, there is an urgent need to develop an intelligent multi-modal analysis framework that can effectively extract information from multiple modalities.
This work contributes a new latent tree learning model based on shift-reduce parsing, with competitive downstream performance and non-trivial induced trees.
We propose a discriminative shared Gaussian process latent variable model for multiview and view-invariant classification of facial expressions from multiple views.
We present a scenario where semantic similarity is not enough, and we devise a neural approach to learn semantic relatedness.
We introduce a simple but effective adversarial framework for generating a complete target sequence, a scenario that has not been addressed so far, and apply it to a state-of-the-art neural model that provides natural language explanations.
Learning rich representation from data is an important task for deep generative models such as variational auto-encoder (VAE), and progressive learning improves disentangling of hierarchical representations.
This paper proposes a robust vectorized convolutional neural network (CNN) model that introduces an attention mechanism for extracting features in the region of interests(ROIs) of the face.
We introduce the Neural Photo Editor, an interface that leverages the power of generative neural networks to make large, semantically coherent changes to existing images without loss of feature quality.
We present a new benchmark dataset for video question answering (VideoQA) for event-centric questions that require understanding temporal relation between multiple events in videos. We also tackle VideoQA problem in the new dataset, referred to as MarioQA, by proposing spatio-temporal attention models.
This paper addresses the problem of single image depth estimation (SIDE), focusing on improving the quality of deep neural network predictions, without introducing extra information into the training stage.
This paper provides the first approach to learn a highly unconstrained mapping from source to target by maximizing (conditional) dependence of residuals - the difference between data and its translated version - and protected characteristics.
In this paper, we propose an effective and robust method for acoustic scene analysis based on spatial information extracted from partially synchronized and/or closely located distributed microphones while taking into account whether any pairs of microphones are synchronized.
We study the problem of model extraction in natural language processing, in which an adversary with only query access to a victim model attempts to reconstruct a local copy of that model.
We present a novel, fully-discriminative method for curvilinear structure segmentation that simultaneously learns a classifier and the features it relies on.
In this paper, we propose Weight Standardization (WS) to accelerate deep network training in micro-batch training.
This paper introduces an effective processing framework for ICP (Image Cloud Processing) to powerfully cope with the data explosion in image processing field.
The HUPO-PSI has further developed the PSI-MI XML schema to enable the description of highly detailed molecular interaction data and facilitates data exchange between databases and users without loss of information.
We introduce the concept of depth-based blurring to achieve an aesthetically acceptable distortion when reducing bitrate in image coding.
We propose a GAN design which models multiple distributions effectively and discovers their commonalities and particularities.
AIM AND OBJECTIVE ::: Vinca domain of tubulin protein is the potential target for different microtubule targeting drugs (MTD) and we rendered the in-silico insight through the development of a robust pharmacophore model followed by the QSAR, Molecular Docking and Molecular Dynamics simulations.
We propose a deep neural network that directly consumes unordered points along the centreline of a branching structure, to identify the topology of the represented structure in a single-shot.
We proposed an end-to-end dilated inception network for visual saliency prediction which captures multi-scale contextual features effectively with very limited extra parameters.
We present a novel approach for the task of human pose transfer, which aims at synthesizing a new image of a person from an input image of that person and a target pose.
We introduce a new invariant for stereo reconstruction called light transport constancy, which allows completely arbitrary scene reflectance (BRDFs), which can be used to formulate a rank constraint on multiview stereo matching.
In this paper, we design a novel loss function, namely support vector guided softmax loss (SV-Softmax), which adaptively emphasizes the mis-classified points (support vectors) to guide the discriminative features learning.
In this paper, we propose a method for creating synthetic datasets with a configurable number of users that mimic the characteristics of already existing ones.
We propose a multi-task model to address the poor performance, that combines caption generation and image--sentence ranking, and uses a decoding mechanism that re-ranks the captions according their similarity to the image.
Neural Machine Translation systems are known to degrade when confronted with noisy data, especially when the system is trained only on clean data. In this paper, we show that augmenting training data with sentences containing artificially-introduced grammatical errors can make the system more robust to such errors.
In this paper, we propose two strategies for designing a compact deep network that maintains the required level of performance even after minimizing the computations.
We propose position-velocity encoders (PVEs) which learn---without supervision---to encode images to positions and velocities of task-relevant objects.
This paper presents a novel Python library ChemTS that explores the chemical space by combining Monte Carlo tree search and an RNN.
We propose a guided dropout regularizer for deep networks based on the evidence of a network prediction that penalizes high saliency neurons that are most relevant for model prediction.
We propose a hybrid network for weakly-supervised instance segmentation, which achieves significantly performance improvement both on the small object instances and large ones.
In this paper, we propose a constrained linear data-feature mapping model as an interpretable mathematical model for image classification using convolutional neural network such as the ResNet.
This paper presents a Ship Semantic Information-Based, Image Similarity Calculation System (Ship-SIBISCaS), which constitutes a first step towards the automatic identification of maritime flow irregularities.
We introduce autoregressive implicit quantile networks (AIQN), a fundamentally different approach to generative modeling that implicitly captures the distribution using quantile regression, without incurring a loss of sample diversity.
We propose a simple, yet effective, method for the temporal detection of activities in temporally untrimmed videos with the help of untrimed classification.
A state-of-the-art multi-view face detector based on Cascade Deformable Part Models (CDPM).
This paper introduces a convolutional sentence kernel based on word embeddings. Experiments on six sentence datasets showed statistically significant higher accuracy over the standard linear kernel.
We explore and evaluate a new approach to learning with label noise in intrinsically high-dimensional data, based on using neighbor occurrence models for hubness-aware k-nearest neighbor classification.
We present a theoretical grounded set of noise-robust loss functions that can be seen as a generalization of mean absolute error.
Soft-NMS improves state-of-the-art in object detection from 39.8% to 40.9% with a single model.
Adversarial robustness can be improved by training networks to form coarse impressions based on the information in higher bit planes, and use the lower bit planes only to refine their prediction.
We present a single network method for panoptic segmentation. This method combines the predictions from a jointly trained semantic and instance segmentation network.
We introduce a mechanism, called concept whitening (CW), to alter a given layer of the network to allow us to better understand the computation leading up to that layer.
We use a novel objectness criterion to rank the resulting candidate boxes, such that high-ranking boxes have strong gradients along all edges.
We propose a scalable learning scheme for a probabilistic generative model for collaborative filtering, which improves on current state of the art.
This paper presents a new nonlocal cost aggregation method for stereo matching using inner color correlation.
A cascade-based approach for face alignment based on multi-regressors collaborative optimization.
We generalize latent convex tensor decomposition (LCTD), a practically widely-used CTD model, and prove its exact-recovery property.
We introduce the channel attention mechanism into the Siamese network to better learn the matching model and, during the online tracking phase, we design an initial matting guidance strategy in which: 1) the superpixel matting algorithm is applied to extract the target foreground in the initial frame, and 2) the matted image with foreground only is fed into the network and fused with the original feature.
Pseudo ground truth corrected with motion cue for unsupervised video object segmentation training.
We present a novel representation learning framework that generates an end-to-end photo-sketch mapping through structure and texture decomposition and produces the final result via probabilistic fusion scheme.
We propose an imitation learning framework from raw video demonstrations, that reduces the dependence on hand engineered reward functions, by jointly learning the feature extraction and separation estimation steps using generative adversarial networks.
We propose a novel perspective to discover parameter redundancy among channels and accelerate deep CNNs via channel pruning via hierarchical clustering of channels.
We propose a semi-supervised auto-encoding transformation method that learns from both labeled and unlabeled data based on the embedded representations by decoding both spatial and non-spatial transformations.
We present the polypharmacology browser (PPB), a web-based platform which predicts possible targets for small molecules by searching for nearest neighbors using ten different fps describing composition, substructures, molecular shape and pharmacophores.
We apply a quantitative method to select the main contributions to the field and make use of bibliographic coupling metrics to identify research frontiers and map promising research directions.
A global average pooling(GAP) based adversarial Faster-RCNN is proposed to generate the hard samples and enhance the performance of object detection algorithm.
In this paper, we propose a novel CNN architecture named ISGAN to conceal a secret gray image into a color cover image on the sender side and exactly extract the secret image out on the receiver side.
We propose a discriminative Lasso (referred to as dLasso) in which sparsity and correlation are jointly considered. The new method can select features (or stimuli) that are correlated more strongly with the response but are less correlated with each other.
A novel, adaptive ground-aware, and cost-effective 3D Object Detection pipeline is proposed.
We present a novel approach to perform the unsupervised domain adaptation through forward-backward cyclic training, which iteratively computes adaptation from source to target via backward hopping and from target to source via forward passing.
This work presents a probabilistic deep neural network that combines LiDAR point clouds and RGB camera images for robust, accurate 3D object detection.
We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into 1000 different classes.
We propose a semi-supervised learning scheme that only uses the data that contains the ordinary scenes of video surveillance videos of regular scenes.
We propose a new HTL method based on a deep matrix completion framework, where kernel embedding of distributions is trained in an adversarial manner for learning heterogeneous features across domains.
We propose a novel hybrid Local Multiple system LM-CNN-SVM based on Convolutional Neural Networks CNNs and Support Vector Machines SVMs due to their powerful feature extraction capability and robust classification property, respectively.
The paper focuses on the identification of different objects in a pair of images taken from the same environment, which is challenging and has wide application. We propose a single deep convolutional neural network to solve this problem.
We propose a novel framework to generate constrained sentences via Gibbs Sampling. The candidate sentences are revised and updated iteratively, with sampled new words replacing old ones.
3D-atom pair fingerprints based on through-space distances (3DAPfp) are suitable for stereoselective searches for shape and pharmacophore analogs in large databases.
We introduce the adversarially learned inference (ALI) model, which jointly learns a generation network and an inference network using an adversarial process. We illustrate the ability of the model to learn mutually coherent inference and generation networks.
We extend Variational Dropout to the case when dropout rates are unbounded, propose a way to reduce the variance of the gradient estimator and report first experimental results with individual drop out rates per weight.
In this paper, we propose a novel query expansion approach for improving transferbased automatic image captioning.
This paper addresses the problem of video object segmentation, where the initial object mask is given in the first frame of an input video. We propose a novel spatio-temporal Markov Random Field model defined over pixels to handle this problem.
In this paper, we leverage the dense and structured Bird Eye View (BEV) representation of LIDAR point clouds to efficiently search for objects of interest in 3D space.
This paper addresses this concern by developing novel metrics to evaluate trajectories and the environments without relying on any SLAM or motion estimation algorithm.
We propose an improved activation function, which we name the natural-logarithm-rectified linear unit (NLReLU), which uses the parametric natural logarithmic transform to improve ReLU.
We introduce a novel modeling framework, Copula Ordinal Regression (COR), that leverages the power of copula functions and CRFs, to detangle the probabilistic modeling of AU dependencies from the marginal modeling of the AU intensity, enabling joint learning and inference of intensities of multiple AUs.
We propose an elegant and practical clustering approach for unsupervised person re-identification based on the cluster validity consideration which can discover the underlying patterns in data.
We introduce a novel architecture which includes an efficient ‘position refinement’ model that is trained to estimate the joint offset location within a small region of the image. This refinement model is jointly trained in cascade with a state-of-the-art ConvNet model for improved accuracy in human joint location estimation.
We propose a new method for unsupervised domain adaptation using pairwise similarity learning.
In this paper, we introduce a novel task of cross-modal consistency verification in real-world news and present a multimodal approach to quantify the entity coherence between image and text.
We present a novel deep-learning-based algorithm for interactive object selection which can reduce user interactions to just a few clicks.
We propose ShapeShifter, an attack that tackles the more challenging problem of crafting physical adversarial perturbations to fool image-based object detectors like Faster R-CNN.
In this work we introduce a time- and memory-efficient method for structured prediction that couples neuron decisions across both space at time.
In this paper, we present a new method for recognizing tones in continuous speech for tonal languages.
We propose to condition imitation learning on high-level command input. We evaluate different architectures for conditional imitation learning in vision-based driving.
We improved the method by means of a criterion for automatic channel selection, using a single compression ratio for the entire model in place of per-layer model analysis.
In this paper, we present the PS^2-Net -- a locally and globally aware deep learning framework for semantic segmentation on 3D scene-level point clouds.
We resort to human visual demands of sharp edges and propose a two-phase edge-aware deep network to improve deep image deblurring.
We propose a novel person re-identification method, which consists of a reliable representation called semantic region representation (SRR), and an effective metric learning with mapping space topology constraint (MSTC)
This paper proposes the idea of using a generative adversarial network (GAN) to assist a novice user in designing real-world shapes with a simple interface.
We propose a new CogQA framework for multi-hop question answering in web-scale documents, which efficiently handles millions of documents.
A novel aggregation algorithm with residual-based reweighting to defend federated learning against adversarial attacks.
This work deals with the challenging task of activity recognition in unconstrained videos. This work proposes a novel framework that maintains the temporal structure of sequences and allows comparison of sequences of different lengths and random alignment.
We propose linear filtration as a computationally efficient sanitization method for class-wide deletion requests for classification models.
We propose a sound mathematical apparatus to formally integrate global structured computation into deep computation architectures while preserving the validity and efficiency of an end-to-end training framework.
We propose an heterogeneous multi-task learning framework for human pose estimation from monocular image with deep convolutional neural network.
This paper introduces Deep Incremental Boosting, a new technique derived from AdaBoost, specifically adapted to work with Deep Learning methods, that reduces the required training time and improves generalisation.
We study the effect of structural variation in graph data on the predictive performance of graph kernels under increasing synthetic structural errors and introduce a novel, noise-robust graph kernel that performs modestly better.
We propose an efficient approach for semantic segmentation of a video into object and non-object categories and use geometric cues which are indicative of the presence of object boundaries to gather the evidence about objects.
We present a hybrid neural network architecture that supports the estimation of binocular disparity in a cyclopean, head-centric coordinate system without explicitly establishing retinal correspondences.
We train a single category-agnostic neural network from scratch to produce a complete image-based shape representation from one view of a generic object in a single forward pass.
We introduce a novel approach to identify salient object regions in videos via object proposals, based on object-level saliency cues.
This paper presents a novel supervised dimensionality reduction approach for facial feature extraction called (2D)2LDALPP. The proposed method effectively combines alternative 2DLDA with alternative2DLPP.
We propose YouQuek, an annotated QA dataset for instructional videos based on the recent YouCook2 dataset.
We introduce a novel architecture, called Conditional Prior Network (CPN), and show how to train it to yield a conditional prior. We seek to learn richer priors on the set of possible flows that are statistically compatible with an image.
This paper states the case for the principle of minimal necessary data: If two recommender algorithms achieve the same effectiveness, the better algorithm is the one that requires less user data. Applying this principle involves carrying out training data requirements analysis.
We present RoofN3D which provides a new 3D point cloud training dataset that can be used to train machine learning models for different tasks in the context of 3D building reconstruction.
In this work we explore how fine-grained differences between the shapes of common objects are expressed in language, grounded on 2D and/or 3D object representations.
In this paper, we propose an accurate positioning siamese network (FPSiam) for real-time object tracking.
We achieve robustness to occlusions and viewpoint changes by combining training data from all viewpoints to train classifiers that estimate action labels independently over sets of HOG blocks.
We propose Yum-me, a personalized nutrient-based meal recommender system designed to meet individuals’ nutritional expectations, dietary restrictions, and fine-grained food preferences.
We propose to help weakly supervised object localization for classes where location annotations are not available, by transferring things and stuff knowledge from a source set with available annotations.
We propose a novel network structure for learning the SR mapping function in an image transform domain while adapting the design of transform basis to the training image set.
We propose a Dynamic SGD method for elastic distributed training that achieves stabilized performance when varying the number of GPUs from 8 to 128.
We integrate both aspects and enable arbitrary-subject talking face generation by learning disentangled audio-visual representation.
We present a semi-handcrafted representation learning method for LiDAR point clouds using siamese LocNets, which states the place recognition problem to a similarity modeling problem, and propose a global localization framework.
In this paper, we present ImmuNeCS, an attempt at addressing these issues with a simple, flexible, and efficient way of building deep learning models automatically, and we demonstrate its effectiveness in the context of convolutional neural networks.
This paper presents critical steps in developing this pipeline, including (1) a new in the wild emotion dataset, the PRIORI Emotion Dataset, collected from everyday smartphone conversational speech recordings, (2) activation/valence emotion recognition baselines on this dataset (PCC of 0.71 and 0.41, respectively), and (3) significant correlation between predicted emotion and mood state for bipolar disorder.
We propose an algorithm that efficiently discovers sparse, compact representations of input features or classifiers from a vast sea of candidates, with important optimality properties, low computational cost and excellent accuracy in practice.
We propose an advanced object proposal network in favour of translation-invariance for objectness classification, translation-variance for bounding box regression, large effective receptive fields for capturing global context and scale-invaries for dealing with a range of object sizes.
We present a principled approach for picking a set of posts that promotes relevant and diverse content while effectively turning down the noise created by redundant posts.
We propose a Generative Transfer Network (GTNet) for zero shot object detection (ZSD), which can learn large-scale seen domain knowledge.
We introduce a self-supervised deep learning-based VIO and depth map recovery approach (SelfVIO) using adversarial training and self-adaptive visual-inertial sensor fusion.
We present a weakly supervised approach to automatically obtain spatio-temporal annotations of an actor in action videos and demonstrate promising results compared to several baseline methods.
We propose a novel image-based metric to estimate the relatedness of words, and demonstrate the promise of this method through comparative evaluations on three standard datasets.
We propose a joint CTC-Attention model (JCM), which maps attribute labels into sequences to learn the semantic relationship among attributes.
This paper shows that a simple baseline based on a Bag-of-Words representation learns surprisingly good knowledge graph embeddings.
We propose a generalization of convolutional neural networks (CNN) to irregular domains, through the use of a translation operator on a graph structure.
We propose a novel fully convolutional neural network using diverse deep supervision (DDS) for semantic edge detection.
This paper proposes PL-SLAM, a stereo visual SLAM system that combines both points and line segments to work robustly in a wider variety of scenarios, particularly in those where point features are scarce or not well-distributed in the image.
MANGA: Method Agnostic Neural-policy Generalization and Adaptation, that trains dynamics conditioned policies and efficiently learns to estimate the dynamics parameters of the environment given off-policy state-transition rollouts in the environment.
We propose Neural Forest Learning (NFL), a novel deep learning based random-forest-like method. We achieve superior performance on 7 machine learning datasets when compared to random forests and GBDTs.
We show that pre-training on a large diverse set of noisy data can result in even a simple CNN model improving over the current state-of-the-art DNN architectures.
In this work we design a neural network for recognizing emotions in speech, using the IEMOCAP dataset.
The amount of data available in the world is growing faster than our ability to deal with it. In this paper we focus on one of the fundamental machine learning tasks, empirical risk minimization (ERM), and provide faster algorithms with the help from the clustering structure of the data.
In this paper, we propose a Hierarchical Inference Network (HIN) to make full use of the abundant information from entity level, sentence level and document level.
We address the problem of learning classifiers from structured relational data that are annotated with relevant meta data. We show how to cope with some of the challenges presented by partial specification.
We proposed Weld, a common runtime for existing data analytics libraries that performs key physical optimizations such as pipelining under existing, imperative library APIs, and evaluate its impact on realistic data science workloads.
We present Direct Binary Embedding (DBE), a simple yet very effective algorithm to learn binary representation in an end-to-end fashion.
We propose a framework to identify information-leaking features via information density estimation. Once these features are identified, we sequentially pass them through a targeted obfuscation mechanism with a provable leakage guarantee.
A multi-level matching and aggregation network (MLMAN) for few-shot relation classification.
Using sentence embeddings with GANs for text generation based on gradient penalty functions and f-measures.
We propose a nested recurrent neural network model for English spelling error correction and generate pseudo data based on phonetic similarity to train it.
This paper proposes a new method of person re-identification to fuse the recognition results of multiple features at the rank level, thus improving the accuracy of candidate targets.
We propose a deep recognition algorithm based on the ensemble deep learning model that achieves test accuracy of 71.11% better than other competitors.
We propose a new local algorithm for dense stereo matching of gray images using a subset of pixels from the large window for matching.
This paper proposes a hardware-oriented adaptive window size disparity estimation algorithm and its real-time reconfigurable hardware implementation that targets HR video with high quality disparity results.
We build a system for generating high-resolution 256 $\times$ 256 images of food conditioned on their recipes.
This paper proposes the stochastic quantization (SQ) algorithm for learning accurate low-bit DNNs.
We present two new Mixture Models and derive their Expectation-Maximization and Fisher Vector expressions and achieve state-of-the-art results.
PhaseCond, an architecture of multi-layered attention models, consists of multiple phases each implementing a stack of attention layers producing passage representations and an inner or outer fusion layers regulating the information flow.
This paper presents a new video summarization approach that integrates an attention mechanism to identify the significant parts of the video, and is trained unsupervisingly via generative adversarial learning.
This paper proposes the problem of point- and-count as a test case to break the what-and-where deadlock. We propose two alternatives, one that counts first and then point, and another that works the other way around.
This article evaluates the extension of a dependency parser that performs joint syntactic analysis and multiword expression identification.
We propose a novel framework that combines accurate localization and robust identification of specific keypoints in a sports field filmed by a moving and uncalibrated camera without using a priori knowledges of the position and orientation of the camera.
A PD-specific network atrophy network score at baseline predicts progression of motor, cognitive, and global outcome in PD, and is a stronger predictor of prognosis than any of the other tested biomarkers.
Priming deep neural networks by pre-training them with synthetic face images improves both the generalization performance as well as the dataset efficiency of neural networks.
Event-based cameras can measure intensity changes (called ‘events’) with microsecond accuracy under high-speed motion and challenging lighting conditions. In this paper, we propose a simple and effective approach to reconstruct a high frame-rate, sharp video from a single blurry frame and its event data.
Transfer learning is becoming the de facto solution for vision and text encoders in the front-end processing of machine learning solutions. In this paper, we analyze the efficiency of transfer learning in visual reasoning.
Microlocal analysis provides deep insight into singularity structures and is often crucial for solving inverse problems, predominately in imaging sciences.
This paper briefly describes fundus photography, publicly available retinal databases, pre-processing and post-processing techniques for automated blood vessel segmentation in retinal images.
We propose an end-to-end pruning method for image captioning models equipped with visual attention that achieves sparsity levels up to 97.5% without significant performance loss.
In this paper, we propose a new stereo matching method using the population-based Markov Chain Monte Carlo.
We propose Decorrelated Batch Normalization (DBN), which not just centers and scales activations but whitens them, improving the performance of BN.
We present an image caption system that addresses new challenges of automatically describing images in the wild.
We present an SBD technique based on spatio-temporal Convolutional Neural Networks (CNN) and a new dataset containing more than 3.85 million frames.
We develop a new edge detection algorithm that addresses two important issues in this long-standing vision problem: (1) holistic image training and prediction; and (2) multi-scale and multi-level feature learning.
We develop a framework for learning multiple tasks simultaneously, based on sharing features that are common to all tasks, achieved through the use of a modular deep feedforward neural network consisting of shared branches.
We present a new paradigm for real-time object-oriented SLAM with a monocular camera. Contrary to previous approaches, that rely on object-level models, we construct category- level models from CAD collections which can be incorporated into a generic monocular SLAM framework.
Convolutional neural networks have recently advanced the state of the art in many tasks including edge and object boundary detection. However, in this paper, we demonstrate that they can be fooled by adversarial examples.
We propose FCLT - a fully-correlational long-term tracker which localizes the target in each frame and re-detects the target when it is lost.
We propose a pooling of off-the-shelf object classifiers to recognize scenes in images without using any scene images as training data.
In many classification problems it is desirable to output well-calibrated probabilities on the different classes. We propose a robust, non-parametric method of calibrating probabilities called SplineCalib that utilizes smoothing splines to determine a calibration function.
We propose a discriminator in a fully convolutional manner to differentiate the predicted probability maps from the ground truth segmentation distribution with the consideration of the spatial resolution.
We propose an intermediate state-Part-Centric Heatmap Triplets-based HEMlets-based human pose and shape recovery pipeline that addresses the uncertainty of lifting the detected 2D joints to the 3D space.
We propose a novel and flexible anchor mechanism named MetaAnchor for object detection frameworks.
The paper approaches the problem of image-to-text with attention-based encoder-decoder networks that are trained to handle sequences of characters rather than words.
In this paper, we present a computationally efficient method to estimate dense depth maps from sparse measurements, and propose an alternating direction method of multipliers for depth map reconstruction.
A semantic filter based on faster region-based convolutional neural network is proposed to solve the outlier problem in RANSAC based F-matrix calculations, as low-quality feature correspondences are effectively decreased.
We propose an integrated framework to identify learning engagement from three facets: affect, behavior and cognitive state, which are conveyed by learner's facial expressions, eye movement behaviors and the overall performance during short video learning session.
We present a multi-label CNN ensemble, Deepwound, trained to classify wound images using only image pixels and corresponding labels as inputs.
In this paper, a novel supervised online hashing scheme termed Hadamard Matrix Guided Online Hashing is proposed.
We propose a regularization method that alleviates the language prior problem of current VQA models by adopting a pair-wise learning strategy, which improves the model performance.
We propose a structured two-stream attention network to answer a free-form or open-ended natural language question about the content of videos.
We propose a new class of active learning algorithms that only adopted information after training, based on the information during training, named sequential-based method.
We propose Self-Supervised Temporal Domain Adaptation (SSTDA), which uses self-supervised auxiliary tasks (binary and sequential domain prediction) to jointly align cross-domain feature spaces embedded with local and global temporal dynamics, achieving better performance than the state-of-the-art method.
We explore the problem of selectively forgetting a particular subset of the data used for training a deep neural network. We propose a method for"scrubbing"the weights clean of information about a particular set of training data.
We propose two computational methods based on the concept of training set expansion for reconstructing complete networks of interactions between biological objects by extrapolating from a limited number of high-confidence examples.
This paper aims at synthesizing multiple realistic-looking retinal ( or neuronal) images from an unseen tubular structured annotation that contains the binary vessel (or neuronal) morphology.
We propose a small yet relatively precise text extraction method which works in a fully-convolutional manner and produces results at multiple scales.
We focus on the task of multi-hop reading comprehension where a system is required to reason over a chain of multiple facts.
We improve the ability of ZSL to generalise across domain shift in both model- and data-centric ways by formulating a visual-semantic mapping with better generalisation properties and a dynamic data re-weighting method.
We propose a novel approach for generating region proposals for performing face detection based on a pooling-based approach.
We present QBEES, a novel framework for defining entity similarity based on structural features, so-called aspects and maximal aspects of the entities, that naturally model potential interest profiles of a user submitting an ambiguous query.
A novel adaptively connected neural network (ACNet) to improve the traditional convolutional neural networks (CNNs)
We use gaze and EEG features to augment models of named entity recognition, relation classification, and sentiment analysis for NLP.
We combine two kinds of features extracted from the spatio-temporal interest points with context-aware kernels for action recognition and propose a multiple kernel learning algorithm for the task.
In this paper, a novel and generic fusing ASW framework for stereo matching.
In this paper, we propose SREdgeNet, edge enhanced single image SR network, that was inspired by conventional SR theories so that average effect could be avoided not by changing loss, but by changing the SR network property with the same l1 loss.
This paper proposes a novel high-resolution talking face generation model for arbitrary person by discovering the cross-modality coherence via Mutual Information Approximation.
We investigate the generalizability of deep learning based on the sensitivity to input perturbation, and propose a simple and effective regularization method, referred to as spectral norm regularization, which penalizes the high spectral norm.
This paper proposes a principled probabilistic framework to generate 3D point clouds by modeling them as a distribution of distributions.
We present strategies to leverage transfer learning using datasets from the open domain, (e.g. SNLI) and incorporate domain knowledge from external data and lexical sources for generalization in specialized domains.
We propose a supervised hashing method Bilinear Discriminant Analysis Hashing (BDAH) for high-dimensional data. The proposed method can achieve comparable accuracy to the state-of-the-art supervised hashing schemes.
We study the problem of directly generating the 3D shape surface of rigid and non-rigid shapes using deep convolutional neural networks.
We propose an efficient approach to fuse multi-scale deep representations, called convolutional fusion networks (CFN), which can obtain consistent improvements towards the transferring tasks.
We present a full-stack optimization framework for accelerating inference of CNNs (Convolutional Neural Networks) and validate the approach with field-programmable gate arrays implementations.
We explore the ideas of software blocking, asynchronous local optimizations, and heuristics of simulated annealing to improve the performance of k-means clustering.
In bibliometrics studies, there often exists certain relationships between the data items that can allow us to recover missing data items and correct erroneous data. We propose algorithms that extend inference by information propagation.
We explore metrics to evaluate the robustness of real-world adversarial attacks, in particular adversarial patches, to changes in environmental conditions.
We compare approaches in computer vision and computational neuroscience for inducing brightness and color constancy based on their ability to improve recognition.
We propose a novel cloud-based HyperOpt (CHOPT) framework which can efficiently utilize shared computing resources while supporting various HyperOpt algorithms.
We propose a new formulation for modeling the intersection of back-projection rays of axial cameras through a 5×5 essential matrix that enables a better understanding of some particular axial configurations and leads to a new set of polynomial equations that proves to be useful in constraining the motion estimation.
We study scene recognition from 3D point cloud (or voxel) data, and show that it greatly outperforms methods based on 2D birds-eye views.
National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences <|TLDR
In this paper, we describe how scene depth can be extracted using a hyperspectral light field capture (H-LF) system, using a new spectral-invariant feature descriptor and its companion matching metric we call bidirectional weighted normalized cross correlation.
We investigate the use of a fill-in-the-blank task to learn context independent representations of entities from the text contexts in which those entities were mentioned and demonstrate successful results on four domains.
We propose to recover the scene flow by coupling the optical flow estimation in both cameras with dense stereo matching between images, thus reducing the number of unknowns per image point.
In this paper we study nonconvex and nonsmooth optimization problems with semi-algebraic data, where the variables vector is split into several blocks of variables.
We introduce Multee, a general architecture that can effectively use entailment models for multi-hop QA tasks, which require reasoning with multiple sentences.
We present an elegant and robust way to determine pose by training a multi-loss convolutional neural network on 300W-LP, a large synthetically expanded dataset, to predict intrinsic Euler angles (yaw, pitch and roll) directly from image intensities.
We present a new Architecture-aware Knowledge Distillation (AKD) approach that finds student models (pearls for the teacher) that are best for distilling the teacher model.
We propose the Relational Tucker3 (RT) decomposition for multi-relational link prediction in knowledge graphs, which decouples entity and relation embeddings, allows parameter sharing across relations, and does not make use of a predefined sparsity pattern.
We introduce an additional lightweight bias-only model which learns dataset biases and uses its prediction to adjust the loss of the base model to reduce the biases.
In this paper, we propose Greedy AutoAugment as a highly efficient searching algorithm to find the best augmentation policies for increasing the accuracy of classification results.
We propose a hierarchy-constrained locally adaptive knowledge graph embedding based link prediction method, called hTransA, by integrating hierarchical structures into the predictive work.
We propose a novel RF Block (RFB) module, which takes the relationship between the size and eccentricity of RFs into account, to enhance the feature discriminability and robustness.
We address the problem of activity detection in continuous, untrimmed video streams using a three-dimensional fully convolutional network, then generate candidate temporal regions containing activities, then generates selected regions into specific activities.
We present flattened convolutional neural networks that can effectively substitute for 3D filters without loss of accuracy.
In this survey, we provide a first comprehensive survey of the RDF dataset profile features, methods, tools and vocabularies.
We introduce the notion of local dense connectivity, allowing for increased growth rate at a fixed network capacity, can achieve a more efficient reuse of features and lead to higher accuracy in dense architectures.
We propose an unsupervised method to infer the scene structure from a single stereo image while only a single image is required.
This paper presents a framework for localization or grounding of phrases in images using a large collection of linguistic and visual cues.
MaskLab combines box detection, semantic segmentation, and direction prediction for instance segmentation.
Facial expression causes different parts of the facial region to change over time and thus dynamic descriptors are inherently more suitable than static descriptors for recognising facial expressions. In this paper, we extend the spatial pyramid histogram of gradients to spatio-temporal domain to give 3-dimensional facial features and integrate them with dense optical flow to give a spatiotemporal descriptor.
We consider the problem of neural semantic parsing, which translates natural language questions into executable SQL queries. We introduce a new mechanism, execution guidance, to leverage the semantics of SQL.
We propose a new stereo algorithm that employs a significantly more efficient network architecture that delivers competitive accuracy at significantly higher speeds.
We present a deep hierarchical architecture in conjunction with a mini-batch proposal selection mechanism that allows a network to detect both traffic lights and signs from training on separate traffic light and sign datasets.
We present BubbleView, a methodology to replace eye-tracking with mouse clicks. Participants are presented with a series of blurred images and click to reveal "bubbles" - small, circular areas of the image at original resolution, similar to having a confined area of focus like the eye fovea.
We train encoder-decoder model using synthetic sentence pairs and original sentence pairs, with no changes to the network architecture.
We consider the problem of how to improve automatic target recognition by fusing the naive sensor-level classification decisions with"intuition,"or context, in a mathematically principled way.
A novel framework of two-path deep semi-supervised learning is proposed where one path is for supervised learning and the other is for unsupervised Learning and these two paths implemented with convolutional neural networks are jointly optimized to complete semi-Supervised learning.
We propose a new architecture coined as Gram-Net, which leverages global image texture representations for robust fake image detection. Experimental results on several datasets demonstrate that our Gram-net outperforms existing approaches.
We present a conditional U-Net for shape-guided image generation, conditioned on the output of a variational autoencoder for appearance, while preserving shape.
We present a new dataset for fruit detection, segmentation, and counting in orchard environments, together with human annotations.
We propose a new approach to GANs to achieve an improved performance with additional robustness to its so-called and well recognized mode collapse.
We present a comprehensive survey of the methods that have been proposed to date, thus providing a platform for further development of this area.
We propose conditional self-attention, a neural network module designed for conditional dependency modeling for query-based summarization.
We propose a novel network structure named trackNet that can directly detect a 3D tube enclosing a moving object in a video segment by extending the faster R-CNN framework.
This paper aims to present how to utilize the Neural Network to build a Reader and introduce some classic models, analyze what improvements they make and future research directions.
We propose a new spatiotemporal attention model that automatically discovers a diverse set of distinctive body parts using temporal attention.
Adaptive locality-based weighted collaborative representation (ALWCR) for image classification.
We apply a state-of-the-art unsupervised learning algorithm to the noisy and extremely imbalanced xView data set to train a feature extractor that performs well on both common and rare classes.
SoPa combines neural representation learning with weighted finite-state automata (WFSAs) to learn a soft version of traditional surface patterns.
We propose a semi-supervised learning (SSL)-based training methodology for object detection, which makes use of automatic labeling of un-annotated data by applying a network previously trained from an annotated dataset.
The Probabilistic Object Detection Challenge evaluates object detection methods using a new evaluation measure, Probability-based Detection Quality (PDQ), on a new synthetic image dataset. We present our submission, a fine-tuned version of Mask-RCNN with some additional post-processing.
Deep learning techniques for image compression with a higher MS-SSIM may actually be perceptually worse than engineered compression schemes with a lower MS- SSIM.
We propose the Stepwise Image-Topic Merging Network (simNet) that makes use of the two kinds of attention at the same time for image captioning.
We show that generative models can be used to capture visual geometry constraints statistically. We use this fact to infer the 3D shape of object categories from raw single-view images.
We describe an approach for unsupervised learning of a generic, distributed sentence encoder that can produce highly generic sentence representations that perform well in practice.
GRAD-Net learns semantic representations by exploiting both local and global structures of image manifold in an unsupervised fashion in a novel way.
This paper presents a method for face detection in the wild, which integrates a ConvNet and a 3D mean face model in an end-to-end multi-task discriminative learning framework.
We propose a generative adversarial network for video generation that learns motion and content decomposition in a supervised manner.
In this paper we investigate whether Deep Convolutional Neural Networks, which have obtained state of the art results on the ImageNet challenge, are able to perform equally well on three different art classification problems.
This paper proposes a deep multi-speaker text-to-speech (TTS) model for spoofing speaker verification (SV) systems.
In this paper, we propose a novel emotion-relevant critical subnetwork selection algorithm and investigate three EEG functional connectivity network features: strength, clustering coefficient, and eigenvector centrality.
We propose Graph2Gauss - an approach that can efficiently learn versatile node embeddings on large scale (attributed) graphs that show strong performance on tasks such as link prediction and node classification.
A large body of recent work has investigated the phenomenon of evasion attacks using adversarial examples generated from out-of-distribution inputs, where the addition of norm-bounded perturbations to the test inputs leads to incorrect output classification. In this paper, we demonstrate the success of open-world evasion attacks.
We propose a spatially adaptive multiscale variable exponent-based variational PDE method that overcomes current shortcomings, such as over smoothing and staircasing artifacts, while still retaining and enhancing edge structures across scale.
Unsupervised learning paradigm to reconstruct 3D models from a single 2D image, which is free of manually annotated pairwise input image and its associated 3D model.
We propose an alternative, provably correct, algorithm for addressing a union of at most $m$ arbitrary-dimensional subspaces, based on the idea of descending filtrations of subspace arrangements.
We propose a novel tree-based method which can provide logarithmic complexity w.r.t. corpus size even with more expressive models such as deep neural networks.
We present a simple way to detect fake face images using only a few annotated training samples and even achieved good accuracies.
We propose a novel feature enhancing technique called Multi-skIp Feature Stacking (MIFS), which stacks features extracted using a family of differential filters parameterized with multiple time skips and encodes shift-invariant characteristics into the feature space.
We propose to tackle the mode collapse problem in generative adversarial networks (GANs) by using multiple discriminators and assigning a different portion of each minibatch, called microbatch, to each discriminator to make the microbatch discrimination harder to achieve.
We present a new 360° panoramic object detection dataset, 360-Indoor, which is a new benchmark for visual object detection and class recognition in 360° indoor images.
We propose a fully automated, probabilistic and occlusion-aware 3D morphable face model adaptation framework following an analysis-by-synthesis setup.
We present an end-to-end network (Reduced & Super-Resolution Network, RSRNet) for reduced-resolution and super-resolution without any cheap interpolation.
We propose a novel multi-modal, multi-step referential game, where the sender and receiver have access to distinct modalities of an object, and their information exchange is bidirectional and of arbitrary duration.
We perform extensive experiments across a variety of NLP tasks that aim to assess the degree to which attention weights provide meaningful explanations for predictions.
We propose a novel feature representation which captures statistics of pairwise co-occurring local spatio-temporal features and focuses on geometric and appearance relations among the features.
This paper proposes the notion of topological centrality (TC) reflecting the topological positions of nodes and edges in general networks, and proposes an approach to calculating the topology centrality.
We prove that, under analytic assumptions, sparsifying gradients by magnitude with local error correction provides convergence guarantees, for both convex and non-convex smooth SGD.
The rapid development of digital imaging and computer vision has increased the potential of using the image processing technologies in ophthalmology. A review of how computer-aided approaches may be applied in the diagnosis and staging of glaucoma disease.
Recommendation systems today exert a strong influence on consumer behavior and individual perceptions of the world.
This paper proposes a proof-of-concept deep learning computer vision framework for measuring human activities quantitatively in POS and demonstrates a case study of the proposed framework using the Detroit Riverfront Conservancy (DRFC) surveillance camera network.
In real-world applications, e.g. law enforcement and video retrieval, one often needs to search a certain person in long videos with just one portrait. In this paper, we aim to tackle this challenge and propose a novel framework which takes into account the identity invariance along a tracklet, thus allowing person identities to be propagated via both the visual and the temporal links.
This paper proposes an efficient, automatic, physically-based augmentation pipeline to vary sensor effects --chromatic aberration, blur, exposure, noise, and color cast-- for synthetic imagery to increase the size and variability of training data.
We present Dynamic Self-Attention Network (DySAT), a novel neural architecture that operates on dynamic graphs and learns node representations that capture both structural properties and temporal evolutionary patterns.
We study how to connect deep networks with graph decomposition into an end-to-end trainable framework for pattern recognition and graph reasoning.
Poetwannabe, a chatbot submitted by the University of Wroclaw to the NIPS 2017 Conversational Intelligence Challenge, in which it shared the first place.
In this paper we report on the context and evaluation of a system for an automatic interpretation of sightings of individual western lowland gorillas (Gorilla gorilla gorilla) as captured in facial field photography in the wild.
We present and evaluate Deep Private-Feature Extractor (DPFE), a deep model which enables the user to prevent certain sensitive information from being shared with a service provider while preserving the privacy of sensitive information.
We propose a new, efficient and robust algorithm for object scene flow estimation, through making two technical contributions.
In this paper, we introduce a deep encoder-decoder network, named SalsaNet, for efficient semantic segmentation of 3D LiDAR point clouds.
We identify an evolutionarily conserved synthetic lethal interaction between SOD1 and both BLM and CHEK2 in two distinct cell models and propose novel drug targets and lead therapeutic compounds.
We present a neighborhood similarity layer (NSL) which induces appearance invariance in a network when used in conjunction with convolutional layers.
We present an end-to-end network for fast panoptic segmentation, which does not require computationally costly instance mask predictions or rule-based merging operations.
Stereo matching techniques aim at reconstructing disparity maps from a pair of images. An efficient local stereo matching algorithm has been chosen from the literature and implemented on a c6678 DSP.
In this paper, we introduce a general framework, S2DNAS, which can transform various static CNN models to support dynamic inference via neural architecture search.
Segmentation of images is often posed as a variational problem. As such, it is solved by formulating an energy functional depending on a contour and other image derived terms.
This paper models object occlusion with an AND-OR structure which captures the regularities of different Occlusion configurations (i.e., the different combinations of object part visibilities).
A lightweight deep Convolutional Neural Network for face detection, designed with a view to minimize training and testing time, and outperforms previously published deep convolutional networks in this task, in terms of both effectiveness and efficiency.
In this paper, we propose a novel training procedure and a thresholding test strategy, towards robust detection of adversarial examples.
We propose AdvGAN to generate adversarial examples with generative adversarial networks (GANs), which can learn and approximate the distribution of original instances.
We train a multi-view ELM network by employing automatically created facial regions of interest to this end.
We revisit several sample-based evaluation metrics for generative adversarial networks, and address the problem of how to evaluate the evaluation metrics.
We apply a GAN-based style transfer method to an existing photorealistic style transfer algorithm, we achieve state-of-the-art synthetic-to-real domain adaptation results.
We explore the problem of using light fields as input for saliency detection.
We adapt the training process to produce compatible and hence reusable network components that are compatible across tasks.
This article reports on an investigation of the use of convolutional neural networks to predict the visual attention of chess players, using multiscale features.
We propose a collaborative training scheme for image obfuscation that maximizes the distribution discrepancy between the original image domain and the encrypted image domain, leading to satisfactory defense against the attack of deep recognition models.
We propose a two-head CNN consisting of one common feature extractor and two classifiers which have different decision boundaries but can classify in-distribution samples correctly.
In this paper, we propose a semi-supervised large scale fine-grained detection method, which only needs bounding box annotations of a smaller number of coarse- grained classes and image-level labels for training, and can detect all classes at nearly fully-super supervised accuracy.
We formulate the global labeling problem with a novel densely connected Markov random field and show how to encode various intuitive potentials in a way that is amenable to efficient mean field inference.
We present experiments supporting the existence of logical structure in the hidden state vectors of "aggregation readers" such as Attentive Reader and Stanford Reader.
This paper proposes a multimodal cascaded generative adversarial networks (PMC-GANs) to generate realistic and diversified pedestrian images and augment pedestrian detection data.
Overton automates the life cycle of model construction, deployment, and monitoring by providing a set of novel high-level, declarative abstractions.
We examine a different fidelity term for Tikhonov regularization, which encourages agreement between the projection of the optimization variable onto the row space of the linear operator and the pseudo-inverse of thelinear operator applied on the observations.
We propose 4 insights that help to significantly improve the performance of deep learning models that predict surface normals and semantic labels from a single RGB image.
We propose an AU synthesis framework that combines the well-known 3D Morphable Model (3DMM), which intrinsically disentangles expression parameters from other face attributes, with models that adversarially generate 3DMM expression parameters conditioned on given target AU labels, in contrast to the more conventional approach of generating facial images directly.
In this paper, we propose an algorithmic approach named Overlap-Local-SGD (and its momentum variant) to overlap the communication and computation so as to speedup the distributed training procedure.
We propose Pixel-In-Pixel (PIP) Net for facial landmark detection based on heatmap regression.
Pose tracking is an important problem that requires identifying unique human pose-instances and matching them temporally across different frames of a video. However, existing pose tracking methods are unable to accurately model temporal relationships and require significant computation, often computing the tracks offline. We present an efficient Multi-person Pose Tracking method that only relies on keypoint information without using any RGB or optical flow information.
We present a novel end-to-end partially supervised deep learning approach for video anomaly detection and localization using only normal samples using only Gaussian Mixture Models.
We propose decoupled parallel backpropagation algorithm for deep learning optimization with convergence guarantee for training deep neural networks.
Automatic recognition of facial expression is a necessary step toward the design of more natural human-computer interaction systems.
We present Panoptic-DeepLab, a bottom-up and single-shot approach for panoptic segmentation that achieves state-of-the-art results.
We propose a new deep approach to Kalman filtering which can be learned directly in an end-to-end manner using backpropagation without additional approximations.
This letter proposes a novel bottom-up interactive fusion structure which introduces an interaction stream to bridge the modality-specific encoders and introduces a residual fusion block (RFB) to formulate the interdependences of the encoder.
In this paper, we propose a novel approach to deblurring from stereo videos, where the motion cues from scene flow estimation and blur information could reinforce each other, and produce superior results than the conventional scene Flow estimation or stereo deblring methods.
We show that filters can be computed as linear combinations of smaller number of separable ones, thus greatly reducing the computational complexity at no cost in terms of performance.
We propose a pattern-mining approach to the problem of identifying mid-level elements within images, motivated by the observation that such techniques have been very effective, and efficient, in achieving similar goals when applied to other data types.
A geometry-aware GAN architecture for face attribute transfer with unpaired data.
We propose a Multi-Instance-Learning (MIL) approach for weakly-supervised learning problems, where a training set is formed by bags (sets of feature vectors or instances) and only labels at bag-level are provided.
A novel optical flow based framework for real-time motion detection in non-stationary scenes.
An overview of the last advances on food detection and an optimal model based on the GoogLeNet architecture, Principal Component Analysis, and a Support Vector Machine that outperforms state of the art on two public food/non-food datasets.
We propose a multi-view spectral clustering framework that synergistically combines multiple models together. We show that the performance can be substantially improved in this way.
We propose a new end-to-end trainable model for lossy image compression which incorporates a hierarchical auto-regressive model and incorporates saliency in the images and focuses on reconstructing salient regions better.
In this paper, we propose the Deep Regulated Convolutional Network (RC-Net), a deep network composed of regulated sub-network blocks cascaded by skip-connections, to overcome this bottleneck.
We present the first single-network approach for 2D~whole-body pose estimation, which entails simultaneous localization of body, face, hands, and feet keypoints.
We propose Stacked Generative Adversarial Networks (StackGAN) to generate 256x256 photo-realistic images conditioned on text descriptions.
This paper initiates the study of high performance execution of Deep Neural Networks (DNNs) in TEEs by efficiently partitioning DNN computations between trusted and untrusted devices.
We propose a pairwise adaptive phase quantization (APQ) method, together with a long-short (LS) pairing strategy, which aims to maximize the overall detection rate.
A common approach in content based video information retrieval is to perform automatic shot annotation with semantic labels using pre-trained classifiers. One of the methods to bridge this semantic gap is to expand the original user query using knowledge bases.
We develop a geometry-consistent generative adversarial network (GcGAN), which enables one-sided unsupervised domain mapping.
We present a practical method for protecting data during the inference phase of deep learning based on bipartite topology threat modeling and an interactive adversarial deep network construction.
We show that traditional counterfactual estimators such as capped importance sampling and normalised importance sampling are not having satisfying bias-variance compromises in the context of personalised product recommendation for online advertising.
An edge-guided method for depth image SR which preserves sharpness of edges and effectively avoid generating blurry and ragged edges when SR is performed.
We propose a probabilistic generative neural dependency model with valence that combines the benefits of both generative and discriminative techniques and achieves competitive accuracy compared with state-of-the-art unsupervised dependency parsing.
We empirically evaluate facial representation based on statistical local features, Local Binary Patterns, for person-independent facial expression recognition.
We introduce a generative adversarial network-based model for end-to-end vehicle control which can be used to transfer knowledge to new weather conditions without the need of new ground truth data.
We demystify the reverse-mode form of AD that generalizes backpropagation in neural networks, and propose an efficient implementation that combines the performance benefits of TensorFlow with the expressiveness of pure library approaches.
We propose a computationally inexpensive algorithm to reuse the filters of a face network for a task it was ::: not trained for.
We use a Shape Boltzmann Machine for the task of modeling foreground/background (binary) and parts-based (categorical) shape images.
Our goal is to incorporate interactions across multiple sentences to generate realistic questions for long documents. We outperform state-of-the-art methods on question generation.
In this paper, we propose BatchEnsemble, an ensemble method whose computational and memory costs are significantly lower than typical ensembles.
We propose a novel algorithm that repeats the density ratio estimation and f-divergence minimization for generative adversarial networks.
In this work, we tackle the problem of car license plate detection and recognition in natural scene images. Inspired by the success of deep neural networks (DNNs) in various vision applications, here we leverage DNNs to learn high-level features in a cascade framework, which lead to improved performance on both Detection and recognition.
We propose recurrent skipping networks for knowledge graph embedding. RSNs integrate recurrent neural networks (RNNs) with residual learning to efficiently capture the long-term relational dependencies of entities.
We propose a large-scale photo tagging system for Flickr that leverages the power of large amounts of noisy data for training.
We introduce P2P-NET, a general-purpose deep neural network that learns geometric transformations between point-based shape representations from two domains (e.g., meso-skeletons and surfaces).
A genome-scale analysis of genetic interactions using the Synthetic Genetic Array revealed a broad network of 245 synthetic sick/lethal interactions reflecting that many processes are required when Glc7 function is compromised.
We use the Essential matrix, obtained using Nister's Five Point Algorithm, for enforcing meaningful geometric constraints on the loss, rather than using it as labels for training.
In order to facilitate the accesses of general users to knowledge graphs, an increasing effort is being exerted to construct graph-structured queries of given natural language questions over knowledge graphs with large scales.
Differential privacy (DP) training mechanisms such as gradient clipping and noise addition have disproportionate effect on the underrepresented and more complex subgroups, resulting in a disparate reduction of model accuracy.
This paper proposes a generative adversarial network for pose transfer, i.e., transferring the pose of a given person to a target one.
A new time-domain audio-visual architecture for target speaker extraction from monaural mixtures.
We survey various knowledge distillation (KD) strategies for simple classification tasks and implement a set of techniques that claim state-of-the-art accuracy.
This paper presents a fully automatic approach to fitting a generic facial model to detailed range scans of human faces to reconstruct 3D facial models and textures with no manual intervention.
We study a natural self-supervision constraint for directed map networks called path-invariance, which enforces that composite maps along different paths between a fixed pair of source and target domains are identical.
We present LAMAL, a simple yet effective method for LLL based on language modeling that simultaneously learns to solve the task and generate training samples.
We taxonomize the space of model extraction attacks around two objectives: \emph{accuracy}, i.e., performing well on the underlying learning task, and \empp{fidelity}, i,e., matching the predictions of the remote victim classifier on any input.
This paper focuses on improving the performance of current convolutional neural networks in visual recognition by building chains of local binary neural networks after one global neural network.
We develop a new variant of LSD-SLAM capable of performing monocular tracking and mapping in high-speed low-framerate situations such as those of the KITTI datasets.
Incorporating lexical constraints into the model’s output to generate meaningful and coherent sentences has many applications in dialogue system, machine translation, image captioning.
We put forward a zero-shot image annotation model, to reduce the demand for the images with novel labels and alleviate the strong bias in the generalized zero- shot setting.
Adversarial examples are known to have a negative effect on the performance of classifiers which have otherwise good performance on undisturbed images. In this paper, we propose applying JPEG2000 compression as an alternative and systematically compare the classification performance of adversarial images compressed using JPEG2000.
Automatic question generation from text using the neural encoder-decoder model .
Inspiration from the functions of shape-selective V4 neurons can be used to design trainable filters for visual pattern recognition that generalize and discriminate between numerous objects.
The objective of this work is to reconstruct the 3D surfaces of sculptures from one or more images using a view-dependent representation. To this end, we train a network, SiDeNet, to predict the Silhouette and Depth of the surface given a variable number of images.
We formulate a novel hierarchical context network (HCN) architecture that can be trained and deployed efficiently while achieving competitive model generalization capability.
We propose a generic family of building blocks for capturing high order correlations from high dimensional input video space and propose a new LEarnable hiGh Order block that captures spatiotemporal correlation in a feedforward manner.
Generating paraphrases of the input question with the goal that at least one of them will be correctly mapped to a knowledge-base query.
We extend existing ASR methods by using images and video titles to adapt a recurrent neural network (RNN) language model with a longshort term memory (LSTM) network for n-best ASR.
We address the new and challenging task of facial sketch-to-image synthesis with multiple controllable attributes.
In a model extraction attack, an adversary steals a copy of a remotely deployed machine learning model, given oracle prediction access. To extract a high-accuracy model, we develop a learning-based attack exploiting the victim to supervise the training of an extracted model.
A method for estimating the pose of cars in a scene jointly with the ground plane that supports them using a statistical atlas.
Backpropagation-based visualizations have been proposed to interpret convolutional neural networks (CNNs), however a theory is missing to justify their behaviors. We develop a theoretical explanation revealing that GBP and DeconvNet are essentially doingpartial image recovery which is unrelated to the network decisions.
We tackle the blackbox issue of deep neural networks in the settings of reinforcement learning (RL) where neural agents learn towards maximizing reward gains in an uncontrollable way.
We present a novel approach to geolocating images on a 2-D map based on learning a low dimensional embedded space, which allows a comparison between an image captured at a location and local neighbourhoods of the map.
We attempt to understand and compare the peculiarities of existing end-to-end neural models on the Stanford Question Answering Dataset (SQuAD) by performing quantitative as well as qualitative analysis of the results attained by each of them.
We propose a novel dual path multi-scale fusion network architecture with attention mechanism that can perform accurate count estimation as well as present high-resolution density maps for highly congested crowd scenes.
A novel model with a hierarchical photo-scene encoder and a reconstructor for the task of album storytelling.
This paper reviews the existing image inpainting approaches, that were classified into three subcategories, sequential- based, CNN-based, and GAN-based methods. In addition, for each category, a list of methods for different types of distortion on images are presented.
We present a novel optimization strategy for training neural networks which we call "BitNet" which circumvents the discrete parameter space by optimizing a relaxed continuous and differentiable upper bound of the typical classification loss function.
In this paper, we propose a Lossless Attention Model (LLAM) for convolutional neural networks (CNN) to extract attention-aware features from faces.
We use machine learning methods to construct emotional arcs in movies, calculate families of arcs, and demonstrate the ability for certain arcs to predict audience engagement.
We present a novel approach to dialogue state tracking and referring expression resolution tasks. We develop our model for query reformulation using a pointer generator network and a novel multi-task learning setup.
PointNet has revolutionized how we think about representing point clouds. For classification and segmentation tasks, the approach and its subsequent extensions are state-of-the-art. To date, the successful application of PointNet to point cloud registration has remained elusive. In this paper we argue that PointNet itself can be thought of as a learnable "imaging" function.
This paper explores the use of self-ensembling for visual domain adaptation problems.
We propose a novel architecture using 3DConvNets trained with the progressive training paradigm that has been able to generate realistic high resolution 3D scenes of rooms, bedrooms, offices etc. with various pieces of furniture.
We proposed a convenient patch-based two-stage transfer method for retinal vessel segmentation, based on the information bottleneck theory.
CollaGAN convert the image imputation problem to a multi-domain images-to-image translation task so that a single generator and discriminator network can successfully estimate the missing data using the remaining clean data set.
We propose an efficient temporal module, termed as Temporal Enhancement-and-Interaction (TEI Module), which could be plugged into the existing 2D CNNs (denoted by TEINet) and achieve a good recognition accuracy on these datasets but still preserve a high efficiency.
This paper proposes the use of supervised and unsupervised machine learning techniques, aiming to eliminate non-relevant information as well as identify the correlation between fault injection results and application and platform characteristics.
We introduce a simple yet effective operation, termed Temporal-Spatial Mapping (TSM), for capturing the temporal evolution of the frames by jointly analyzing all the frames of a video.
This paper presents a novel approach for video-based person re-identification using multiple Convolutional Neural Networks (CNNs) that extract a compact yet discriminative appearance representation from several frames.
We train a standard object detector on a small, normally packed dataset with data augmentation techniques. This low data baseline achieves satisfactory results.
Pose Conditioned Dendritic Convolution Neural Network (PCD-CNN) for face pose localization .
We propose a novel 'Pairwise discriminative task', which attempts to learn the similarity and distinction between two audios rather than specific labels.
We define a new image captioning task, PERSONALITY-CAPTIONS, where the goal is to be as engaging to humans as possible by incorporating controllable style and personality traits.
Cascade framework of Region Proposal Networks, referred to as C-RPNs, which adopts multiple stages to mine hard samples while extracting region proposals and learn stronger classifiers.
In this paper, we investigate the principles of embedding learning between the given reference and the predicted sequence to tackle the challenging semi-supervised video object segmentation. We propose Collaborative Video Object Segmentation by Foreground-Background Integration approach.
Knowledge graphs are used to represent relational information in terms of triples. To enable learning about domains, embedding models, such as tensor factorization models, can be used to make predictions of new triples, assuming a lower bound on the size of the embeddings.
A novel and generic solution based on boundary erosion for detecting clusters in arbitrary shapes.
We propose a novel framework, learning to DIScriminate Perturbations (DISP), to identify and adjust malicious perturbations, thereby blocking adversarial attacks for text classification models.
We propose to find line co-occurrence statistics from the centerlines of blood vessels in retinal images and show its remarkable similarity to a well-known probabilistic model for connectivity pattern in the primary visual cortex.
We model video summarization as a quadratic assignment problem, using rewards based on frame interestingness, plot coherency, audio-visual match, and cut properties.
This paper presents an efficient module named spatial bottleneck for accelerating the convolutional layers in deep neural networks.
We propose a novel paradigm that efficiently perceives accurate 3D object shape by incorporating visual and tactile observations, as well as prior knowledge of common object shapes learned from large-scale shape repositories.
This paper proposes a novel unified framework that jointly exploits the feature relationships and the class relationships for improved categorization performance for video categorization.
This paper addresses the modeling and simulation of progressive changes over time, such as human face aging. Leveraging recent adversarial image translation methods, we construct a chain of transformers that map images from one age domain to the next.
In this work, we address the challenging video scene parsing problem by developing effective representation learning methods given limited parsing annotations.
We proposed a method to predict user rating based on the hypotesis that the rating of the node in the network corresponded to the most important nodes which are connected to it.
In this paper, we devise multiple variants of bottleneck building blocks in a residual learning framework that exploits all the variants of blocks but composes each in different placement of ResNet, following the philosophy that enhancing structural diversity with going deep could improve the power of neural networks.
We use dual-modal fundus images and develop a cascade refined U-net (CRU-net) to improve the arteriovenous segmentation.
This paper shows that evolutionary algorithms can discover novel activation functions that outperform ReLU. Replacing ReLU with evolved activation functions results in statistically significant increases in network accuracy.
We consider how to jointly analyze such probe functions over different shapes, and how to discover common latent structures using a neural network, even in the absence of any correspondence information.
We study the problem of learning physical object representations for robot manipulation. In this paper, we propose DensePhysNet, a system that actively executes a sequence of dynamic interactions and uses a deep predictive model over its visual observations to learn dense, pixel-wise representations that reflect the physical properties of observed objects.
We present a unified, efficient and effective framework for point-cloud based 3D object detection, achieving state-of-the-arts detection rate.
We propose a novel caching strategy for cache-aided ultra-dense network that uses a deep Q-network to improve the system EE.
In this paper, we propose a solution for group re-identification that grounds on transferring knowledge from single person re-Identification to group re -identification by exploiting sparse dictionary learning.
We propose GlobalTrack, a pure global instance search based tracker that performs full-image and multi-scale search of arbitrary instances with only a single query as the guide.
In this paper, we propose VLASE, a framework to use semantic edge features from images to achieve on-road localization.
We propose to use 9 overlapping patches per image which cover the entire face region which significantly reduces the training time.
In this work we use the novel Dense Gradient Based Features (DeGraF) as the input to a sparse-to-dense optical flow scheme.
In this paper, we have proposed a novel method for stereo disparity estimation by combining the existing methods of block based and region based stereo matching.
We propose a novel multimodal approach based solely on convolutional neural networks for aligning images with their captions by directly convolving raw characters.
A new Highly Efficient Regression (HER) model for re-identification with human-in-the-loop that is fast and scalable.
We address the opportunity to maximize the utility of an overall computing system by employing reinforcement learning to guide the configuration of the set of interacting modules that comprise the system. We show significant improvement in both real-world and synthetic pipelines across a variety of reinforcement learning techniques.
This paper presents a novel eye localization approach which explores only one-layer convolution map by eye template using a BP network and achieves state-of-the-art results.
We introduce EigenRec, a versatile and efficient latent factor framework for top-N recommendations that includes the well-known PureSVD algorithm as a special case.
In this paper, we propose a novel parametric nonlinear analysis cosparse model (NACM) with which a unique feature vector will be much more efficiently extracted.
We propose a novel method for obtaining sentence-level embeddings that are semantically close to the original sentence and outperforms state-of-the-art.
Crowdsourcing is a relatively economic and efficient solution to collect annotations from the crowd through online platforms. However, workers' attention level changes over time, and the ignorance of which can affect the reliability of the annotations. We propose a probabilistic model that takes into account workers attention to estimate the label quality.
We propose Prototype Refinement Network (PRNet) to attack the challenge of few-shot segmentation. PRNet learns to bidirectionally extract prototypes from both support and query images.
We propose a novel face recognition method via meta-learning that can directly handle new unseen domains without any model updating.
The paper proposes a novel method for detection of macula in medical image of human eye – retinal fundus images, that can be used in ophthalmology for detecting various eye’s diseases as glaucoma, diabetic retinopathy or macula oedema.
We address the problem of describing people based on fine-grained clothing attributes. We propose a novel double-path deep domain adaptation network and an enhanced RCNN-based detector to localize human bodies in images.
Predicting county-level mortality rates in the U.S. using satellite images.
We address the problem of parameter estimation and energy minimization for a region-based semantic segmentation model using diverse data.
We propose a new partially supervised training paradigm, together with a novel weight transfer function, that enables training instance segmentation models on a large set of categories all of which have box annotations, but only a small fraction ofwhich have mask annotations.
This paper presents Kernel Graph Attention Network (KGAT), which conducts more fine-grained evidence selection and reasoning for the fact verification task.
This paper proposes CuRTAIL, an end-to-end computing framework for characterizing and thwarting adversarial space in the context of Deep Learning (DL).
This paper presents a novel approach to simultaneously compute the motion segmentation and the 3D reconstruction of a set of 2D points extracted from an image sequence.
In this paper, we propose a modification of the PGD method for adversarial training and demonstrate that models can be trained much more efficiently without any loss in accuracy on natural and adversarial samples.
We introduce the Treebank of Learner English (TLE), the first publicly available syntactic treebank for English as a Second Language (ESL), which provides manually annotated POS tags and Universal Dependency trees for 5,124 sentences from the Cambridge First Certificate in English (FCE) corpus.
Minimum squared error based classification (MSEC) method establishes a unique classification model for all the test samples. However, this classification model may be not optimal for each test sample.
We present a new perspective on gaze-assisted image captioning by studying the interplay between human gaze and the attention mechanism of deep neural networks. We then propose a novel split attention model that integrates human gaze information into an attention-based long short-term memory architecture.
We propose a framework to exploit acoustic information in tandem with lexical data of an utterance for speech emotion classification task.
We propose a novel Spatial-Temporal Attention (STA) approach to tackle the large-scale person reidentification task in videos.
We propose a novel Happiness Entailment Recognition system that can analyze a user's happy moments and propose sustainable suggestions for the user that may lead to an overall improvement in her well-being.
LCNN is a lookup-based convolutional neural network that encodes convolutions by few lookups to a dictionary that is trained to cover the space of weights in CNNs.
We introduce DenseBox, a unified end-to-end FCN framework that directly predicts bounding boxes and object class confidences through all locations and scales of an image.
In this work, we introduce a new problem, named as story-preserving long video truncation, that requires an algorithm to automatically truncate a long-duration video into multiple short and attractive sub-videos with each one containing an unbroken story.
We present the first genome-wide functional gene network in Drosophila melanogaster, which includes 20,000 functional relationships among 5,021 genes.
We propose an efficient and modular neural architecture for the Visual Question Answering task with focus on the CNN module.
We summarize and discuss such challenges as well as give answers where appropriate options are available in the literature.
We propose a simple and effective approach to compress large Transformer (Vaswani et al, 2017) based pre-trained models, termed as deep self-attention distillation, which is effective and flexible for the student.
We present AutoFoley, a fully-automated deep learning tool that can be used to synthesize a representative audio track for videos.
We tackle the problem of modeling sequential visual phenomena. We extend cycle consistency to loop consistency and alleviate difficulties associated with learning in the resulting long chains of computation.
We find that DNNs trained with mixup are significantly better calibrated -- i.e., the predicted softmax scores are much better indicators of the actual likelihood of a correct prediction -- than DNN trained in the regular fashion.
We propose an alternative that combines the simplicity of BC with the robustness of adversarial imitation learning, which generalizes to out-of-distribution states.
We propose an off-policy algorithm that learns general-purpose skills by combining unsupervised representation learning and reinforcement learning of goal-conditioned policies for self-supervised practice.
We show that simple convolutional autoencoders built upon only standard network components can outperform state-of-the-art methods which employ adversarial training and sophisticated loss functions.
We propose a variational autoencoder for generative models on graphs that can output a probabilistic fully-connected graph of a predefined maximum size directly at once.
We propose the concept of the image knowledge graph (IKG) to incorporate the semantic association and the scene association to fully consider the relations between objects (external and internal).
In the last years, most dense stereo matching methods use evaluation on the Middlebury stereo vision benchmark datasets. In this paper, different matching costs on the Semi-Global Matching algorithm are evaluated and compared using the common Middlebury datasets, aerial and satellite datasets.
We present a novel and robust exemplar-based face detector that integrates image retrieval and discriminative learning, achieving state-of-the-art performance.
In this letter, we propose a protocol for an automatic food recognition system that identifies the contents of the meal from the images of the food.
We introduce a generative model that generates images from natural language descriptions, while attending to relevant words in the description.
We propose Discriminator Soft Actor Critic, a soft Q imitation learning algorithm that learns from only a small amount of expert data and sampling data.
We use modern and classical machine learning techniques together with a dataset consisting of 85 videos of human semen samples and related participant data to automatically predict sperm motility.
Mask R-CNN using multi-task learning, transfer learning, and data augmentation techniques achieve 0.96 DICE coefficient.
We propose a novel preprocessing method and a novel facial landmarks' representation aiming to improve the facial emotion detection accuracy.
We propose to use a dedicated network branch to predict the object/non-object mask and then combine its prediction with the input image to produce the density map for crowd counting problem.
We propose CALM, Continuous Adaptive Learning for Language Modeling: techniques to render models which retain knowledge across multiple domains.
We propose a graph-based approach using audio features for clustering diverse sound collections obtained when querying large online databases.
Weakly supervised annotations alone suffice to reach high-quality object boundaries without using any object-specific boundary annotations.
We introduce the concept of natural leakage to measure the intrinsic reliance of a task on a protected variable. To address this, we use adversarial training to remove unwanted features corresponding to protected variables from intermediate representations in a deep neural network.
We introduce a fully context-aware architecture that captures the entire available past context for each pixel using Parallel Multi-Dimensional LSTM units and aggregates it using blending units.
We propose to use a combination of triplet and large-margin Gaussian mixture (L-GM) loss to tackle the drone-based person re-identification problem, which is collected by using a drone.
We propose a new preprocessing pipeline named multiple-channels-multiple-landmarks (MCML), aiming to synthesize color fundus images from a combination of vessel tree, optic disc, and optic cup images.
We propose 3-D scene graph as an environment model and an environment graph construction framework. We claim the following characteristics for a versatile environment model: accuracy, applicability, usability, and scalability.
This paper attempts to address the problem of recognizing human actions while training and testing on distinct datasets, when test videos are neither labeled nor available during training.
We exploit the rich tag information available on the e-commerce websites to locate the attention of database images. Novel deep convolutional neural network architectures are proposed to learn the attention weights and then extract effective representations.
We train a convolutional neural network over a set of labeled texts and use score vectors to localize the task-specific words and phrases from short texts by exploiting their class labels.
To accelerate research on adversarial examples and robustness of machine learning classifiers, Google Brain organized a NIPS 2017 competition that encouraged researchers to develop new methods to generate adversarial Examples and defend against them.
In this paper, we show that even the latest version of precision and recall metrics are not reliable yet. We propose density and coverage metrics that solve the above issues.
HyperFace is an algorithm for simultaneous face detection, landmarks localization, pose estimation and gender recognition using deep convolutional neural networks (CNN).
We propose a model compression framework for efficient training and inference of deep neural networks on embedded systems.
We introduce the multi-time-scale (MTS) method to increase temporal flexibility without increasing the number of trainable parameters compared to standard convolutional layers.
We propose a novel pseudo-convolutional policy gradient based method for sequence-to-sequence (seq2seq) problem for lip-reading.
We propose a self-attention-masking semantic decomposition method which is able to learn an attribute attention mask for each attribute.
In this paper we propose to augment a modern neural-network architecture with an attention model inspired by human perception that improves adversarial robustness and behavior.
We study the convergence behaviors of a wide array of ML models and algorithms under delayed updates, revealing the rich diversity of the effects of staleness on the convergence of ML algorithms.
We apply a recent feature selection algorithm to optimize a differentiable version of the SVM loss with sparsity constraints. We use nonlinear univariate response functions to obtain a nonlinear decision boundary with feature selection.
A robust 3D-LiDAR-based method for road curb detection and tracking in a structured environment is proposed.
This paper describes the semiglobal matching (SGM) stereo method. It uses a pixelwise, mutual information (Ml)-based matching cost for compensating radiometric differences of input images.
We introduce Patch Gaussian, a simple augmentation scheme that adds noise to randomly selected patches in an input image that improves robustness and accuracy while retaining the ability to take advantage of relevant high frequency information.
We address personalized recommendation problems for which one-bit comparison data of user preferences for different items as well as the different user inclinations toward an item are available.
In this paper, we explore using linear rational splines as a replacement for affine transformations used in coupling layers in normalizing flows.
A speech emotion recognition algorithm based on multi-feature and Multi-lingual fusion is proposed to resolve low recognition accuracy caused by lack of large speech dataset and low robustness of acoustic features in the recognition of speech emotion.
We formulate these four components into a joint deep learning framework and propose a new deep network architecture for pedestrian detection.
We present a novel neural network architecture which generates an output sequence conditioned on an arbitrary number of input functions, enabling scalable and effective training.
We propose a novel multi-scale residual hierarchical dense network for single image super-resolution.
We analyse the combinatorial complexity of the problem, and develop a novel lifted algorithm to effectively resolve marker pose ambiguities, without discarding any marker observations.
This paper introduces the problem of multiple object forecasting (MOF), in which the goal is to predict future bounding boxes of tracked objects, rather than trajectories alone.
We propose a ladder network based audio event classifier for people with hearing loss.
This paper proposes a recognition method for LIDARs based on only a few detection planes and uses Fourier descriptor to characterize a scan plane and Convolutional Neural Network for classification.
We propose an approach for occluded pedestrian detection that achieves state-of-the-art results on CityPersons and Caltech datasets.
We propose one novel Context-Gated Convolution (CGC) to explicitly modify the weights of convolutional layers adaptively under the guidance of global context.
Neural network architectures with memory and attention mechanisms exhibit certain reasoning capabilities required for question answering. Based on an analysis of the DMN, we propose several improvements to its memory and input modules.
We consider the problem of learning high-level controls over the global structure of sequence generation, particularly in the context of symbolic music generation with complex language models. We present the Transformer autoencoder, which aggregates encodings of the input data across time to obtain a global representation of style from a given performance.
A work-in-progress snapshot of learning with a 15 billion parameter deep learning network on HPC architectures applied to the largest publicly available natural image and video dataset released to-date.
We study the emergence of cooperative behaviors in reinforcement learning agents by introducing a challenging competitive multi-agent soccer environment with continuous simulated physics and applying an evaluation scheme grounded by game theoretic principals.
We propose a bimodal identification system that combines two inexpensive and widely accepted biometric traits, namely face and voice information, for a good compromise between computational costs and overall performance.
We address this issue and develop a general attention mechanism for visual dialog which operates on any number of data utilities.
We consider a simple approach to encapsulate such common sense knowledge using co-occurrence statistics from web documents in order to improve object recognition and localization.
We quantify the confidence of the region classifiers in the context of a non-parametric k-nearest neighbor (k-NN) framework for semantic segmentation by using a strangeness measure.
An analysis of different techniques for recognizing and detecting objects under extreme scale variation is presented. Based on this analysis, we propose to train and test detectors on the same scales of an image-pyramid.
This article exposes the failure of some big neural networks to leverage added capacity to reduce underfitting, leading to underfitting.
Adaptive learning rate clipping to stabilize neural network training with stochastic gradient descent .
We show that existing relational models (implicitly or explicitly) either use simple numerical aggregators that lose great amounts of information, or correspond to naive Bayes, logistic regression, or noisy-OR that suffer from overconfidence. We propose new simple aggregators and simple modifications of existing models that empirically outperform the existing ones.
We broaden this focus to include Sentence-level Revision (SentRev) as a new writing assistance task, where sentences require adjustment to the information included or major rewriting and propose a new crowdsourced evaluation dataset.
Object location is fundamental to panoptic segmentation as it is related to all things and stuff. How to integrate object location in both thing and stuff segmentation is a crucial problem. In this paper, we propose object spatial information flows to achieve this objective.
We exploit an intriguing property of large overparameterized neural networks: While they are capable of perfectly fitting the noisy data, gradient descent fits clean labels faster than noisy ones. Thus, training and early stopping on noisy labels resembles training on clean labels.
This paper introduces Integrated Triaging, a framework that prunes almost all context in early layers of a network, leaving the remaining (deep) layers to scan only a tiny fraction of the full corpus.
This paper describes the joint submission of Inria and Xerox to their joint participation to the FGCOMP'2013 challenge.
We present a deep generative model of question-answer (QA) pairs for machine reading comprehension. We introduce two independent latent random variables into our model in order to diversify answers and questions separately.
This paper provides a non-systematic review of the progress of forecasting in social settings.
In this paper, we propose a pose grammar to tackle the problem of 3D human pose estimation.
We propose unrestricted adversarial examples, a new threat model where the attackers are not restricted to small norm-bounded perturbations.
We propose a semantic, class-specific approach to re-rank object proposals, which can consistently improve the recall performance even with less proposals.
We propose a simple but effective loss, named equalization loss, to tackle the problem of long-tailed rare categories by simply ignoring those gradients for rare categories.
We perform the first ever cross-lingual embedding between Pidgin and English, providing three major contributions.
We propose a deep learning method to estimate per-pixel depth and its uncertainty continuously from a monocular video stream, with the goal of effectively turning an RGB camera into an RGB-D camera.
This paper proposes SesameBERT, a generalized fine-tuning method that enables the extraction of global information among all layers through Squeeze and Excitation and enriches local information by capturing neighboring contexts via Gaussian blurring.
We look into how such a small change within the sentence text affects its representation in the continuous space and how such alterations are reflected by some of the popular sentence embedding models.
A novel pyrazolopyrimidine-based allosteric KRAS inhibitor that binds to activated KRAS with sub-micromolar affinity and disrupts effector binding, thereby inhibiting KRAS signaling and cancer cell growth.
We prove that the weight decay term $\frac{1}{2}\lambda||{\boldsymbol{W}}||^2$ merely modulates the effective learning rate for improving objective optimization, and has no influence on generalization when the weight normalization family is compositely employed.
Stereo vision is a 3D imaging method that allows quick measurement of plant architecture. This study identified several challenges to adapt the method to natural field conditions.
We propose a new dense local stereo matching framework for gray-level images based on an adaptive local segmentation using a dynamic threshold.
We present an automatic 3D face recognition approach which can accurately differentiate between expression deformations and interpersonal disparities and hence recognize faces under any facial expression.
We propose the Focus-Aspect-Polarity model to structure the process of capturing subjectivity in image processing, and introduce a novel dataset following this way of modeling.
This work extends the personalized PageRank model invented by Brin and Page to a family of PageRank models with various damping schemes. The response in PageRank distribution to variation in damping mechanism is then characterized analytically and quantitatively on 6 large real-world link graphs.
In this work, we combined both a tree and a NetVLAD (vector of locally aggregated descriptors) in order to design new deep model. The new architecture exposes a novel hyperparameter called the tree branch factor, which grants additional control over model complexity and on the maps codependency.
We propose a novel framework that deals with novelty detection for multiple-scene image sets, and propose an algorithm that employs multiple one-class models for detecting novel wildlife scenes.
The Transformer self-attention network has recently shown promising performance as an alternative to recurrent neural networks in end-to-end (E2E) automatic speech recognition systems. In this paper, we extend it towards an entire online E2E ASR system by introducing an online decoding process inspired by monotonic chunkwise attention (MoChA) into the Transformer decoder.
We first investigate whether motion representations are indeed missing in the spatial stream of 3D CNNs, and propose a new method for combining both models into a single stream that achieves state-of-the-art performance.
We propose a new random forest algorithm, called xRF, to select good features in learning RFs for high-dimensional data.
A semi-supervised sparse coding framework to collect a diverse set of images with minimal human effort, which can be used to both create a dataset from scratch or enrich an existing dataset with diverse examples.
We study the problem of learning conditional generators from noisy labeled samples, where the labels are corrupted by random noise.
We propose a kernel-based framework for computing components from a set of surface normals. We also propose a new mapping function based upon the cosine distance.
We present an end-to-end deep Convolutional Neural Network for recognizing group activities that utilizes the information in spatial relations between individual persons in image or video.
We present a simple, fully-convolutional model for real-time instance segmentation that achieves 29.8 mAP on MS COCO at 33.5 fps evaluated on a single Titan Xp.
We develop a fast video object segmentation algorithm that requires no finetuning, auxiliary inputs or post-processing, and segments a variable number of objects in a single forward-pass.
This paper introduces a novel approach to texture synthesis based on generative adversarial networks (GAN) which extend the structure of the input noise distribution by constructing tensors with different types of dimensions.
We propose a novel stochastic gradient descent based approach to minimize the loss with respect to an oracle that achieves lower oracle error compared to existing methods.
We propose a novel loss function based on Mumford-Shah functional that can be used in deep-learning based image segmentation without or with small labeled data.
Semantic Generative Adversarial Networks for pixel-level accurate semantic image generation .
This paper introduces a method for simultaneous semantic segmentation and pedestrian attributes recognition.
We propose a latent ranking approach that takes into account not only the distinctive visual cues in popular images, but also those in unpopular images, and allows for insight into the semantics of image popularity on social networks.
We introduce a probabilistic framework for solving sequential decision making problems ranging from Bayesian optimisation to contextual bandits and reinforcement learning that captures predictive uncertainty during the decision making process.
Network-based machine learning approaches can identify promising disease candidate genes even if no prior knowledge about the disease or phenotype is available.
Affinity Capture of Polyribosomes followed by RNA sequencing (ACAPseq) for identifying PPIs.
We propose four types of object boundary segmentation masks that provide position information in a different manner than that done by object detection algorithms, Additionally, we investigated the effect of the proposed bounding shape masks on instance segmentation.
We propose to use bounding box annotations to highlight the feature map of foreground objects by erasing background noise with a novel Mask loss, in which process $L_{2}$ norm is further incorporated to avoid degenerated features.
In this paper, an accurate method to estimate number of bits and quality of intra frames is proposed, which can be used for bit allocation in a rate-control scheme.
We tackle the problem of estimating optical flow from a monocular camera in the context of autonomous driving, using instance-level segmentation and convolutional nets.
Person independent and pose invariant estimations of facial expressions and action unit (AU) intensity estimation.
DeepSeeNet simulates the human grading process by first detecting individual AMD risk factors (drusen size, pigmentary abnormalities) for each eye and then calculating a patient-based AMD severity score using the AREDS Simplified Severity Scale.
We propose an approach called Deep Sensor Cloning (DSC) to use Convolutional Neural Networks in conjunction with inexpensive sensors to replicate the 3D point-clouds that are created by expensive LIDARs.
UDP-sugars serve as ultimate precursors in hundreds of glycosylation reactions (e.g. for protein and lipid glycosolation, synthesis of sucrose, cell wall polysaccharides, etc.)
We propose the Variational Bi-domain Triplet Autoencoder that learns a joint distribution of objects from different domains. We extend the VBTAs objective function by the relative constraints or triplets that sampled from the shared latent space.
We propose a new building block, IdleBlock, which naturally prunes connections within the block. To fully utilize the IdleBlock we break the tradition of monotonic design in state-of-the-art networks, and introducing hybrid composition.
Genome-wide gene expression and variants at a patient-level can be used for drug prediction .
This paper presents a novel method to distill knowledge from a deep pose regressor network for efficient Visual Odometry (VO) using teacher loss as a confidence score.
We propose a Hard-Aware Point-to-Set (HAP2S) loss with soft hard-mining scheme for person re-identification.
We leverage knowledge distillation during the pre-training phase and show that it is possible to reduce the size of a BERT model by 40%, while retaining 97% of its language understanding capabilities and being 60% faster.
This paper makes two contributions to Bayesian machine learning algorithms. Firstly, we propose stochastic natural gradient expectation propagation (SNEP), a novel alternative to expectation propagation, which allows scalable and robust Bayesian learning in cases where a data set is stored in a distributed manner across a cluster, with each compute node containing a distributed subset of data.
We propose a new correlation-based measure for subpixel accuracy which incorporates both mentioned requirements.
Lamina-associated polypeptide 1 (LAP1) is a type II transmembrane protein of the inner nuclear membrane encoded by the human gene TOR1AIP1. To date, LAP1 has not been fully elucidated but analysis of its interacting proteins will permit unraveling putative associations to specific cellular pathways and cellular processes.
We present a generic, efficient and iterative algorithm for interactively clustering classes of images and videos based upon a simple descriptor on which nearest neighbour classification can be performed.
Data-driven sparse models have been shown to give superior performance for image classification tasks.
We propose GQBE (Graph Query By Example), a method for querying knowledge graphs by example, without requiring users to form complex graph queries.
A self-generated composition of visual scenes through the synthesis loop, combined with the object persistence constraint, can provide opportunities for neural networks to discover new relevant patterns in the data, and become more flexible in dealing with novel situations.
A disposable razor has its head formed with a rearwardly directed pocket to receive the forward portion of the head of a second razor to its rear, so as to protect the cutting edge or edges of the second razor.
We propose a novel ResNet-like architecture that combines multi-scale context with pixel-level accuracy for semantic image segmentation.
In this paper, we propose a novel approach for the design of feedback controllers using Reinforcement Learning (RL) and Hybrid Zero Dynamics (HZD).
We propose DetNet, a novel backbone network specifically designed for object detection and instance segmentation.
We develop an actor-critic approach in which the actor recurrently predicts one instance mask at a time and utilises the gradient from a concurrently trained critic network to explore the action space.
We investigate the trade-off between the encoding bitrate and the achievable accuracy of CNN-based video classification models that directly ingest AVC/H.264 and HEVC encoded videos.
Deep neural networks have improved image classification dramatically over the past decade, but have done so by focusing on performance measures that treat all classes other than the ground truth as equally wrong.
We propose an unsupervised learning architecture under coupled consistency conditions to estimate depth, ego-motion, and optical flow.
We propose to use both types of attention for image captioning.
The objective of this paper is to rectify any monocular image by computing a homography matrix that transforms it to a bird's eye (overhead) view.
A theoretical analysis proving that distributed learning over unreliable network can achieve comparable convergence rate to centralized or distributed learningover reliable networks.
Sequential alignment is a practical solution to dealing with language evolution in sequential decision-making tasks.
We propose a new task of unsupervised action detection by action matching. A pair of video segments are matched if they share the same human action.
In this paper, we propose an approach utilizing sequence-to-sequence learning model trained with unsupervised Cycle-GAN to perform the transformation between the phoneme posteriorgram sequences for different speakers.
This paper proposes a discriminant-based sparse optimization learning model that integrates discriminant and sparsity together.
In this paper, we propose BundleNet, a framework of sequential structure (named bundle-module, see Fig. 1) for deep neural networks to handle label noise.
We propose a novel framework to perform fine-grained land use mapping at the city scale using ground-level images and use geo-referenced image collections to better understand location.
We propose an automatic visual concept discovery algorithm using parallel text and visual corpora, it filters text terms based on the visual discriminative power of associated images, and groups them into concepts using visual and semantic similarities.
We propose a novel model which can inherently learn canonical graph representations, thus ensuring that semantically similar scene graphs will result in similar predictions.
We introduce new zero-aliasing constraints that completely eliminate this aliasing problem by ensuring that the optimization criterion for a given CF corresponds to a linear correlation rather than a circular correlation in the time/spatial domain.
We propose a novel module called fine-grained fusion with distractor suppression to exploit the local features towards better representation of a specific video clip.
We describe a method for visual question answering which is capable of reasoning about contents of an image on the basis of information extracted from a large-scale knowledge base.
Uncertainty estimation for structured prediction tasks within a unified and interpretable probabilistic ensemble-based framework.
This paper brings together the latest advancements in object detection and in crowd engineering into a principled framework for accurately and efficiently localizing objects in images.
We introduce a novel DCNN approach, consisting of two stages, that is fully three-dimensional end-to-end and utilizes the state-of-the-art in object detection.Early detection of pulmonary nodules in computed tomography (CT) images is essential for successful outcomes among lung cancer patients.
We present diffusion maps for textual network embedding (DMTE), integrating global structural information of graph to capture the semantic relatedness between texts, with a diffusion-convolution operation applied on the text inputs.
A deep residual network, built by stacking a sequence of residual blocks, is easy to train, because identity mappings skip residual branches and thus improve information flow. To further reduce the training difficulty, we present a simple network architecture, deep merge-and-run neural networks.
We present a machine vision-based fMRI decoding approach for arbitrary objects, using the machine vision principle that an object category is represented by a set of features rendered invariant through hierarchical processing.
This paper provides a benchmark corpus (xSLUE) with an online platform for cross-style language understanding and evaluation.
In unsupervised novelty detection, a model is trained solely on the in-class data to reconstruct it exclusively, differentiating it from out-class by the reconstruction error. To solve this, we propose Compact Surjective Encoding AE (CSE-AE). In this model, the encoding of any input is constrained into a compact manifold by exploiting the deep neural net's ignorance of the unknown.
This paper proposes a hardware-oriented adaptive window size disparity estimation algorithm and its real-time reconfigurable hardware implementation that targets HR video with high quality disparity results.
In this paper, we propose a novel method based on deep reinforcement learning to progressively refine the low-level features and high-level relations of group activities for group activity recognition.
We introduce a Winograd layer in place of a standard convolution layer and exploit the sparsity, achieving up to 31.7 effective TFLOP/s in 32-bit precision on a latest Intel Xeon CPU.
We propose a novel and general network structure that reduces confusion errors in more direct manner and apply the network for semantic segmentation.
Detection of humans and estimation of their 2D poses from a single image are challenging tasks. This is especially true when part of the observation is occluded. We propose a novel template representation where the body is divided into five body-parts.
We propose a novel attentive sequence to sequence translator (ASST) for clip localization in videos by natural language descriptions.
We propose a novel segmentation model that injects visual priors into semantic segmentation architectures, allowing them to segment out new target labels without retraining.
We introduce NYC3DCars, a rich dataset for vehicle detection in urban scenes built from Internet photos drawn from the wild, focused on densely trafficked areas of New York City.
We present OctNet, a representation for deep learning with sparse 3D data which enables both deep and high resolution networks without compromising resolution.
We propose Dynamic ReLU, a dynamic rectifier whose parameters are input-dependent as a hyper function over all input elements.
We propose a light-weight robust fine-tuning neural network-based classifier architecture called FDFtNet, which can be easily combined with existing image classification networks and finetuned on a few datasets.
Eigendecomposition within a network requires the ability to explicitly encode known notions of geometry, instead of having the network implicitly learn them from data.
We introduce InverseFaceNet, a deep convolutional inverse rendering framework for faces that jointly estimates facial pose, shape, expression, reflectance and illumination from a single input image in a single shot.
In this paper, we propose a new algorithm, namely a manifold guided generative adversarial network (MGGAN), which leverages a guidance network on existing GAN architecture to induce generator learning all modes of data distribution.
The evaluation of a user's social influence is essential for various applications in online social networks (OSNs). We propose a fine-grained feature-based social influence evaluation model.
We propose a way that would enable machine learning based threat prevention models to bridge that gap by being able to tune against a deep generative adversarial network (GAN), which takes up the role of a malware author and generates new types of malware.
We introduce a tracking-by-detection method that integrates a deep object detector with a particle filter tracker under the regularization framework where the tracked object is represented by a sparse dictionary.
In recent years, the popularity of depth sensors and 3D scanners has led to a rapid development of point clouds. Semantic segmentation of point cloud, as a key step in understanding 3D scenes, has attracted extensive attention of researchers. In this paper, we provide a survey covering various aspects ranging from indirect segmentation to direct segmentation.
An end-to-end deep convolutional neural network for image harmonization, which can capture both the context and semantic information of the composite images during harmonization.
Recognizing pedestrian attributes is an important task in computer vision community due to it plays an important role in video surveillance. The goal of this paper is to review existing works using traditional methods or based on deep learning networks.
We present an end-to-end deep learning framework for X-ray image diagnosis.
We present Lux, a distributed multi-GPU system that achieves fast graph processing by exploiting the aggregate memory bandwidth of multiple GPUs and taking advantage of locality in the memory hierarchy of multi-gpu clusters.
Data arrangement are modified according to the similarity of input-output pattern in Adaptive Structural Learning method of Deep Belief Network.
We present an approach that extends Mask R-CNN with five novel optimization techniques for improving the mask generation branch and reducing the conflicts between the mask branch and the detection component in training.
We utilize the process of attribute detection to generate corresponding attribute-part detectors, whose invariance to many influences like poses and camera views can be guaranteed.
The use of deep Recurrent Convolutional Neural Networks (RCNN) for odometry estimation using only 2D laser scanners.
In this paper, we aim to provide an empirical characterization of the reasons why and how Wikipedia cites external sources to comply with its own verifiability guidelines.
We hypothesize that knowledge graphs enhance the semantic feature extraction of neural models, thus optimizing the translation of entities and terminological expressions in texts and consequently leading a better translation quality.
This paper addresses the problem of 3D human pose estimation in the wild. We introduce an image-based synthesis engine that artificially augments a dataset of real images with 2Dhuman pose annotations using 3D Motion Capture data.
This paper presents a novel mid-level representation for action recognition, named spatio-temporal aware non-negative component representation (STANNCR), which incorporates the spatial-Temporal information.
This paper considers the task of articulated human pose estimation of multiple people in real world images. We propose a partitioning and labeling formulation of a set of body-part hypotheses generated with CNN-based part detectors.
We present a tree-structured network architecture for large-scale image classification. The proposed structure can be built from any existing convolutional neural network.
We propose a gating scheme that controls the feature maps of a single denoising network according to the noise level at the test phase, without changing the network parameters.
Vehicle Re-ID has recently attracted enthusiastic attention due to its potential applications in smart city and urban surveillance. However, it suffers from large intra-class variation caused by view variations and illumination changes, and inter-class similarity especially for different identities with the similar appearance. To handle these issues, in this paper, we propose a novel deep network architecture, which guided by meaningful attributes including camera views, vehicle types and colors.
This paper addresses the task of set prediction using deep learning. We define a likelihood for set distribution and learn its parameters using a deep neural network.
We propose an obscured face hallucination network that restores the low-resolution(LR) obscured face images from 1/4 missing area LR face images with a challenging scaling factor of 8x.
 DRAGON leverages the page-faulting mechanism on the recent NVIDIA GPUs by extending capabilities of CUDA Unified Memory (UM) to transparently compute on terabyte datasets residing in NVM.
This paper aims to conduct traffic analysis using UAV-based videos and deep learning techniques to measure the consequences of traffic congestion.
We present a generic family of lightweight global descriptors for modeling the interactions between positions across different dimensions with negligible computational complexity and parameters.
Structured Fusion Networks first learn neural dialog modules corresponding to the structured components of traditional dialog systems and then incorporate these modules in a higher-level generative model.
We propose a fast and accurate deep network-based object tracking method, which combines feature representation, template tracking and foreground detection into a single framework for robust tracking.
Continual learning for task-incremental classification, where tasks arrive in a batch-like fashion, and are delineated by clear boundaries.
In this work we address the task of semantic image segmentation with Deep Learning and make three main contributions that are experimentally shown to have substantial practical merit.
We present a novel method called Contextual Pyramid CNN (CP-CNN) for generating high-quality crowd density and count estimation by explicitly incorporating global and local contextual information of crowd images.
We propose to increase the expressiveness of the latent distributions and to use higher capacity likelihood models.
We propose REFIT, a unified watermark removal framework based on fine-tuning, which does not rely on the knowledge of the watermarks and even the watermarking schemes.
We decompose the evidence lower bound to show the existence of a term measuring the total correlation between latent variables. We use this to motivate our $\beta$-TCVAE (Total Correlation Variational Autoencoder) objective for learning disentangled representations, requiring no additional hyperparameters.
An improved FCM algorithm based on morphological reconstruction and membership filtering (FRFCM) that is significantly faster and more robust than FCM.
We propose an improved training procedure for Wasserstein-GANs which utilizes orthogonality-based regularization to further increase its generalization capability.
We address the problem of phrase grounding by learning a multi-level common semantic space shared by the textual and visual modalities and exploit multiple levels of feature maps of a Deep Convolutional Neural Network, as well as contextualized word and sentence embeddings.
We propose a novel category anchor-guided UDA model for semantic segmentation, which explicitly enforces category-aware feature alignment to learn shared discriminative features and classifiers simultaneously.
We explore mechanisms of incorporating part-of-speech tag guided attention, convolutional n-grams, triplet attention interactions between the image, question and candidate answer, and structured learning for VQA Real Multiple Choice.
We propose Single-Path NAS, a novel differentiable NAS method for designing device-efficient ConvNets in less than 4 hours.
We present a novel method to analyze and quantify changes in the retinal blood vessel structure in patients diagnosed with glaucoma or with DR.
PROXTONE is a novel and fast method for optimization of large scale non-smooth convex problem, for example training of sparse deep neural network (sparse DNN) or sparse CNN.
We propose a novel measure-based method which allows measuring the local abnormality in a video by combining semantic information (inherited from existing CNN models) with low-level Optical-Flow.
We establish a large-scale public dataset for stereo reconstruction and segmentation with incidental satellite images and assess their performance.
We propose to exploit pixelated object semantics to guide image colorization, and achieve state-of-the-art results.
We introduce second-order vector representations of words, induced from nearest neighborhood topological features in pre-trained contextual word embeddings, and analyze the effects of using them as input features in two deep language processing models.
We introduce a novel weakly supervised object detection (WSOD) paradigm to detect objects belonging to rare classes that have not many examples using transferable knowledge from human-object interactions.
We introduce a multi-stage architecture for temporal action segmentation task that captures long-range dependencies and achieves state-of-the-art results on three challenging datasets.
Automated driving systems (ADSs) promise a safe, comfortable and efficient driving experience. However, fatalities involving vehicles equipped with ADSs are on the rise.
We introduce MASSES, a multi-component evaluation metric for the task of Visual Question Answering (VQA) that accounts for all these issues.
In this paper we evaluate the quality of the activation layers of a convolutional neural network (CNN) for the generation of object proposals and propose a method for proposing object locations that combines the best of both worlds.
We propose a simple, yet highly-effective Deep k-NN defense against both feature collision and convex polytope clean-label attacks on CIFAR-10.
We propose a method based on the encoder-decoder framework, named Reference based Long Short Term Memory (R-LSTM), aiming to lead the model to generate a more descriptive sentence for an image by introducing reference information.
Shortcut-upsampling block allows our model to be only 121M and achieve excellent performance on 3D face reconstruction and dense alignment.
We propose to accelerate the Bayesian optimization approach to hyperparameter tuning for neural networks by taking into account the relative amount of information contributed by each training example.
This paper presents an end-to-end framework, SK-Net, to jointly optimize the inference of spatial keypoint with the learning of feature representation of a point cloud for a specific point cloud task.
Deep ensembles explore diverse modes in function space, while random initializations explore only a single mode predictions-wise.
We propose to use the concept of the Hamming bound to derive the optimal criteria for learning hash codes with a deep network.
This paper presents a novel approach to the design of explainable recommender systems. A method for learning and reduction of the fuzzy recommender is proposed along with feature encoding.
In this paper, we propose a collaborative learning (CL) method, which is a flexible strategy to achieve bidirectional model assistance for two models using a mutual knowledge base (MKB).
We propose two new, natural formulations for joint query interpretation and response ranking that exploit bidirectional flow of information between the knowledge base and the corpus, using probabilistic language models.
We apply DeepCluster to the unsupervised training of convolutional neural networks on large datasets like ImageNet and YFCC100M.
We perform a case study on the effect that systematic sentence transformations (e.g. active to passive voice) have on the automatic metric scores.
We introduce a new entity-aware neural comprehension model augmented with external relational memory units. Our model learns to dynamically update entity states in relation to each other while reading the text instructions.
We propose a bi-level semantic representation analyzing method for efficient multimedia event detection with promising results.
Pseudo-task augmentation uses pseudo-tasks to improve performance on single-task learning problems.
Cluster-based Large Margin Local Embedding (CLMLE), when combined with a simple k-nearest cluster algorithm, shows significant improvements in accuracy over existing methods on both face recognition and face attribute prediction tasks that exhibit imbalanced class distribution.
This paper presents an efficient handwriting identification system which combines scale-invariant feature transform (SIFT) and RootSIFT descriptors in a set of Gaussian mixture models (GMMs).
We propose a simple and elegant method, Trans-DLR, whose main idea is dynamic learning rate control during training.
We present an approach for unsupervised training of CNNs in order to learn discriminative face representations. We obtain millions of face pairs from hundreds of videos without using any manual supervision.
We conduct an in-depth exploration of different strategies for doing event detection in videos using convolutional neural networks (CNNs) trained for image classification.
We propose an efficient content-based medical image retrieval (CBMIR) system for multimodal medical imaging data from various types of imaging modalities by using the technique of artificial intelligence.
A no-reference quality metric to quantify image noise and blur and its application to fundus image quality assessment.
We prove quantitative convergence rates at which discrete Langevin-like processes converge to the invariant distribution of a related stochastic differential equation. We show that the key properties of these processes depend on the potential function and the second moment of the additive noise.
This paper presents an entirely unsupervised interest point training framework by jointly learning detector and descriptor, which takes an image as input and outputs a probability and a description for every point.
In this paper, we formulate transparent object matting as a refractive flow estimation problem, and propose a deep learning framework, called TOM-Net, for learning the refractive Flow.
In this paper, we propose a method to learn a minimizing geodesic within a data manifold using an autoencoder network to map data samples into latent space and perform interpolation via an interpolation net-work.
We propose a fashion landmark detection network with a global-local embedding module that learns advanced deep feature representations for accurate landmark detection.
We propose to use Tree-MoE layers for face alignment with cascaded regression, firstly for emphasizing relevant, more specialized feature extractors depending of a high-level semantic information, and secondly as an overall more robust regression layer.
Improving discriminativeness of features so their activations are high on the foreground and low elsewhere. Boosting inference with an ensemble of experts guided with gradient of loss incurred when segmenting the support images in testing.
We introduce a deep convolutional neural networks (CNN) architecture to classify facial attributes and recognize face images simultaneously via a shared learning paradigm to improve the accuracy for facial attribute prediction and face recognition performance.
We introduce a class of convolutional neural networks that utilize recurrent neural networks (RNNs) as convolution filters that naturally capture compositionality.
This paper presents a deep model approach for face age progression that can efficiently capture the non-linear aging process and automatically synthesize a series of age-progressed faces in various age ranges.
We propose a black-box adversarial attack aiming at minimizing $l_0$-distance to the original image. We adapt the Projected Gradient Descent attack to integrate componentwise constraints.
Bidirectional Encoder Representations from Transformers (BERT) reach state-of-the-art results in a variety of Natural Language Processing tasks. We present a layer-wise analysis of BERT's hidden states.
A systematic study of the diversity and biases present in specific datasets and its effect on cross-dataset generalization across 5 pose datasets.
We focus on increasing the performance of binary neural networks without prior knowledge and a much simpler training strategy.
In this paper, we examine an item weighting approach to improve long-tail recommendation.
In this paper we propose a novel approach to estimate dense optical flow from sparse lidar data acquired on an autonomous vehicle using a three-block architecture of multiscale filters.
We view LAMBADA as a reading comprehension problem and apply comprehension models based on neural networks. Though these models are constrained to choose a word from the context, they improve the state of the art.
The Web of Linked Data is characterized by linking structured data from different sources using equivalence statements, such as owl:sameAs, as well as other types of linked properties. The ontologies behind these sources, however, remain unlinked.
Automatic question generation aims at the generation of questions from a context, with the corresponding answers being sub-spans of the given passage. In this work, we propose a variant of the self-attention Transformer network architectures model to generate meaningful and diverse questions.
In this paper, the pre-trained ResNet-50 architecture and the Class Activation Map (CAM) technique are employed in breast cancer classification and localization respectively.
This paper constructs a general framework of deep octonion networks (DONs) and provides the main building blocks of DONs. DONs are then used in image classification tasks for CIFAR-10 and CIFar-100 data sets.
We address the problem of 3D object mesh reconstruction from RGB videos by optimizing object meshes for multi-view photometric consistency while constraining deformations with a shape prior.
Monocular Depth Estimation is usually treated as supervised and regression problem when it actually is very similar to semantic segmentation task since they both are fundamentally pixel-level classification tasks.
In this paper we propose a Hierarchical Rule Induction Network (HriNet), which extracts multiple granularity rule embeddings at different levels and integrates them through a gated embedding fusion module.
We consider the problem of low-rank tensor decomposition of incomplete tensors that has applications in many data analysis problems, such as recommender systems, signal processing, machine learning, and image inpainting.
We propose a Siamese tracking algorithm with deep features and robust feature fusion (SiamDF) that improves the tracking performance and performs favorably in both robustness and accuracy.
In this paper, we introduce Block Switching (BS), a defense strategy against adversarial attacks based on stochasticity. BS replaces a block of model layers with multiple parallel channels.
We introduce a category-level adversarial network for domain adaptation in semantic segmentation, aiming to enforce local semantic consistency during the trend of global alignment.
We propose a class expert generative adversarial network (CE-GAN) for imbalance data classification.
In this study, we address the challenge of measuring the ability of a recommender system to make surprising recommendations, without resorting to making a direct comparison with another algorithm.
We explore how well the multilingual BERT model performs on several languages across several tasks: a diagnostic classification probing the embeddings for a particular syntactic property, a cloze task testing the language modelling ability to fill in gaps in a sentence, and a natural language generation task testing for the ability to produce coherent text fitting a given context.
We propose an attention-injective deformable convolutional network for crowd understanding that can address the accuracy degradation problem of highly congested noisy scenes.
In this article, we propose a new method for localizing optic disc in retinal images.
This paper introduces a new method for learning and inferring sparse representations of depth (disparity) maps from data corrupted with spatially varying noise or uncertainty, such as that obtained by laser range scanners or structured light depth cameras.
We develop a novel deep cascade learning model, which progressively evolves from the documentlevel and paragraph-level ranking of candidate texts to more precise answer extraction with machine reading comprehension, which improves on state-of-the-art methods.
We propose Part-based Convolutional Baseline, a convolutional baseline for person retrieval.
A continual learning benchmark for remote sensing image scene classification, a new method of constructing a large-scale remote sensing Image scene classification database, and several mainstream continual learning methods.
In this paper, a weakly supervised learning approach is used to reduce the shift between training on real and synthetic data, allowing us to use only a fraction of the training samples.
In this paper, we propose a novel algorithm named Latently Invertible Autoencoder (LIA) to address the above two issues in one framework.
We explore the task of recognizing peoples' identities in photo albums in an unconstrained setting. We propose the Pose Invariant PErson Recognition method, which accumulates the cues of poselet-level person recognizers trained by deep convolutional networks to discount for the pose variations.
Object-based factorizations provide a useful level of abstraction for interacting with the world. We present a paradigm for learning object-centric representations for physical scene understanding without direct supervision.
This paper presents an adaptive image sampling algorithm based on Deep Learning (DL) which can be extended and used to speed up raster scanning such as the X-Ray fluorescence (XRF) image scanning process.
We propose a novel reinforced data selector based on the actor-critic framework to select high-quality source domain data to help the transfer learning model.
The objective of this paper is self-supervised learning of spatio-temporal embeddings from video, suitable for human action recognition.
GN-Net: a network optimized with the novel Gauss-Newton loss for training weather invariant deep features, tailored for direct image alignment.
We present a class of extremely efficient MobileFaceNets, which use less than 1 million parameters and are specifically tailored for high-accuracy real-time face verification on mobile and embedded devices.
We propose novel methods with a neural model of $P(path|w_1, w_2)$ to solve the lexical semantic relations between word pairs.
We propose novel KB completion models that exploit the structural and semantic context of knowledge graphs for enhanced contextual representation of knowledge.
We investigate the possibility to supply to the deficiency in the number of data by means of data augmentation techniques, working on the recent Kvasir dataset of endoscopical images of gastrointestinal diseases.
Stereo vision-based moving object detection and tracking, utilizing symmetric mask-based discrete wavelet transform to deal with illumination changes, low memory requirement, and fake motion avoidance.
In this paper, we define the "relative value of data" via the Shapley value, as it uniquely possesses properties with appealing real-world interpretations, such as fairness, rationality and decentralizability. The LSH-based approximation algorithm can accelerate the value calculation process even further. We propose an algorithm based on Locality Sensitive Hashing, which is up to three orders of magnitude faster than baseline approximation algorithm.
We introduce methods to propagate and fuse uncertainty information in a multi-stage Bayesian convolutional neural network (CNN) architecture for computer-aided detection (CAD) of pulmonary nodules.
Crosslingual word embeddings represent lexical items from different languages in the same vector space, enabling transfer of NLP tools. We address these drawbacks in an EM style training algorithm.
In this paper, we explore to train object detectors from scratch robustly. We propose the Root-ResNet backbone network, which makes full use of the information from original images.
We propose using GPU-accelerated RL simulations as an alternative to CPU ones for speeding up Deep RL.
In this paper, we present a simultaneous detection and tracking algorithm that is simpler, faster, and more accurate than the state of the art. CenterTrack is simple, online (no peeking into the future), and real-time.
We proposed a novel framework for single image SR tasks aiming at these issues, which consists of blind blurring kernel estimation (BKE) and SR recovery with anchored space mapping.
We are interested in counting the number of instances of object classes in natural, everyday images. We build dedicated models for counting designed to tackle the large variance in counts, appearances, and scales of objects found in natural scenes.
We propose an online robust subspace averaging algorithm for principal component analysis and propose an efficient online RPCA algorithm.
This paper proposes a deep neural network architecture to address the FER problem across multiple well-known standard face datasets.
We compared three types of seizure prediction models in terms of different objectives. Our main objective is to analyze the competition format, and to propose improvements.
This paper addresses three problems in building HTR systems: data, efficiency, and integration. We address the problem of obtaining sufficient amounts of high quality training data.
We propose a novel training method, distance-based learning from errors (DBLE), for improving confidence calibration of DNNs.
A Deep neural network based Sparse Measurement Matrix (DSMM) is learned by the proposed convolutional network to reduce the sampling computational complexity and improve the CS reconstruction performance.
We propose an end-to-end framework called PENCIL, which can update both network parameters and label estimations as label distributions, which is more general and robust than existing methods and is easy to apply.
We propose a method, based on reinforcement learning, for transferring DST models to new domains without turn-level supervision. We also show our method can improve models trained using turn- level supervision.
We introduce the orthographic feature transform, which enables us to escape the image domain by mapping image-based features into an orthographic 3D space and achieve state-of-the-art performance on the KITTI 3D object benchmark.
This paper presents a method to automatically and efficiently detect face tampering in videos, and particularly focuses on two recent techniques used to generate hyper-realistic forged videos: Deepfake and Face2Face.
We introduce "relational captioning," a novel image captioning task which aims to generate multiple captions with respect to relational information between objects in an image.
We have developed a Convolutional Neural Network (CNN) based classifier for FLS-images and compared its performance to classical methods and hand-crafted features.
WEPSAM: Weakly Pre-Learnt Saliency Model on ImageNet for weakly pre-learing .
In this paper, we propose a novel deep neural network architecture named ENet (efficient neural network), created specifically for tasks requiring low latency operation.
Combining fast and slow methods in different parts of the scene improves frame rates while maintaining accuracy in the most task-relevant areas.
We study the problem of multi-person pose estimation in natural images. We give a novel integer program formulation of the multi- person pose estimation problem, in which variables correspond to assignments of parts in the image to poses.
We propose an instance-based approach to improve deep transfer learning in a target domain by focusing on the influence of training samples.
In this paper, we elaborate on the benefits and shortcomings of four state-of-the-art evaluation infrastructures on search and recommendation tasks and introduce an evaluation infrastructure concept design aiming at reducing the shortcomings in shared tasks for search and recommender systems.
A key step to driver safety is to observe the driver's activities with the face being a key step in this process to extracting information such as head pose, blink rate, yawns, talking to passenger which can then help derive higher level information.
We propose deep meta-learning to integrate the representation power of deep learning into few-shot learning, which improves vanilla meta- learning.
In this paper, we propose a spatio-temporal contextual network, STC-Flow, for optical flow estimation.
We propose the concept of docking haptics, in which different types of haptic devices are dynamically docked at run time, where the potential feedback depends on the user's location.
We address the task of unsupervised domain adaptation in semantic segmentation with losses based on the entropy of the pixel-wise predictions.
We propose a novel clustering algorithm, named REFCMFS, which develops a robust loss as the data-driven item and imposes a $L_0$-norm constraint on the membership matrix to make the model more robust and sparse flexibly.
We propose a Region Refinement Module (RRM) that optimizes salient region prediction by incorporating supervised attention masks in the intermediate refinement stages. To further refine boundary areas, we propose a Boundary Refinement Loss (BRL) that adds extra supervision for better distinguishing foreground from background.
We present weight normalization: a reparameterization of the weight vectors in a neural network that decouples the length of those weight vectors from their direction.
We propose a new network architecture called Hierarchical Cross Network (HCN) for person re-identification.
This paper describes the University of Sheffield’s submission to the WMT17 ::: Multimodal Machine Translation shared task and investigates the effect of replacing the commonly-used image embeddings with an estimated posterior probability prediction.
We propose SegMatch, a reliable place recognition algorithm based on the matching of 3D segments.
We introduce and tackle the problem of zero-shot object detection (ZSD), which aims to detect object classes which are not observed during training. We follow a principled approach by adapting visual-semantic embeddings for ZSD.
In this work, we propose to model the interaction between visual and textual features for multi-modal neural machine translation (MMT) through a latent variable model, a stochastic embedding of an image and its description in a foreign language.
We propose an end-to-end framework to learn the convolutional features and perform the tracking process simultaneously, which enables learned CNN features are tightly coupled with tracking process.
We introduce Human-eYe Perceptual Evaluation (HYPE), a human metric that is (1) grounded in psychophysics research in perception, (2) reliable across different sets of randomly sampled outputs from a model, (3) results in separable model performances, and (4) efficient in cost and time. We test HYPE across four state-of-the-art generative adversarial networks.
We devise an optimization method, called Kalman Optimization for Value Approximation (KOVA) that can be incorporated as a policy evaluation component in policy optimization algorithms. KOVA minimizes a regularized objective function that concerns both parameter and noisy return uncertainties.
We propose a novel task-aware pre-tuning step running between language model (e.g., BERT) pre-training and domain-specific fine-tunation for leveraging reviews as a source to build an agent that can answer multi-turn questions.
The Pix2pix and CycleGAN losses have vastly improved the qualitative and quantitative visual quality of results in image-to-image translation tasks.
We propose a DTCWT ScatterNet Convolutional Neural Network (DTSCNN) formed by replacing the first few layers of a CNN network with a parametric log based DTC WT Scatternet.
In this paper, we propose a deep neural model which is designed in the light of different aspects of developmental learning of emotional concepts to provide an integrated solution for internal and external emotion appraisal.
We propose a novel adversarial learning approach for counting objects via scale-aware adversarial Density Adaption.
This paper proposes a novel model and dataset for 3D scene flow estimation with an application to autonomous driving.
We propose a lightweight deep learning framework that can automatically estimate the crowd density level and adaptively choose between different counter networks for different density domains.
We use kernel machines with a kernel on i.i.d. sample set from an underlying feature distribution for classification, regression, anomaly detection, and low-dimensional embedding.
We present the Overlapping Domain Cover (ODC) notion for kernel machines, as a set of overlapping subsets of the data that covers the entire training set and optimized to be spatially cohesive as possible.
We propose to learn image features by training ConvNets to recognize the 2d rotation that is applied to the image that it gets as input.
We propose an attention mechanism that learns to softly weight the multi-scale features at each pixel location, which improves state-of-the-art performance on semantic image segmentation.
We propose a method for offline training of neural networks that can track novel objects at test-time at 100 fps at a state-of-the-art performance.
We introduce one-shot texture segmentation: the task of segmenting an input image containing multiple textures given a patch of a reference texture given a synthetic data set.
LR-nets (Local reparameterization networks), a new method for training neural networks with discrete weights using stochastic parameters.
Recent work on Web-extracted data sets has produced an interesting new source of structured Web data. The ExDB, YAGO, and WebTables data sets all have schema items numbering in the millions.
We use small baseline multiflash illumination to produce a rich set of feature maps that enable the acquisition of discontinuity preserving point correspondences in stereo imagery.
We propose Content-Aware ReAssembly of FEatures (CARAFE), a universal, lightweight and highly effective operator to fulfill this goal.
We propose a novel universal NST approach that separately models each sub-style that exists in a given style image (or a collection of style images). This allows for better modeling the subtle style differences within the same style image and then using the most appropriate sub- style (or mixtures of different sub-styles) to stylize the content image.
We propose a learning approach to construct multidimensional projections, which is faster than SNE-class methods and can be used to learn any projection technique.
KnightReid is a large and real-scenario person re-identification dataset for night scenario.
We present BlockBERT, a lightweight and efficient BERT-based model that is designed to better modeling long-distance dependencies.
We reduce structured prediction to a sequence of unconstrained prediction problems and demonstrate that this approach is capable of automatically discovering priors on shape, contiguity of region predictions and smoothness of region contours from data without any a priori specification.
We study the pixel discretization defense method, including more sophisticated variants that take into account the properties of the dataset being discretized. Our results again show poor resistance against the strong attacks.
We propose a novel strategy for leveraging gradient-based interpretability in the realm of adversarial examples, where we use insights gained to aid adversarial learning.
In this work, we propose an efficient and effective approach for unconstrained salient object detection in images using deep convolutional neural networks.
We explore and evaluate the use of data augmentation techniques, specifically skew and gamma correction, from a practical real-world standpoint to extend the existing model and provide more robust performance.
A fundamental, and still largely unanswered, question in the context of Generative Adversarial Networks (GANs) is whether GANs are actually able to capture the key characteristics of the datasets they are trained on. In this paper, we propose new techniques that employ a classification-based perspective to evaluate synthetic GAN distributions and their capability to accurately reflect the essential properties of the training data.
We provide a qualitative and quantitative comparison among three of the most popular and most comprehensive DL frameworks (namely Google's TensorFlow, University of Montreal's Theano and Microsoft's CNTK) and measure the performance of their implementations of different DL algorithms.
We propose a Truncated CauchyNMF loss that handle outliers by truncating large errors, and develop a robustly learn the subspace on noisy datasets contaminated by outliers.
We present a self-supervised method to segment unknown objects from a robotic gripper in RGB video sequences by exploiting motion and temporal cues.
This paper addresses the challenging problem of estimating the general visual attention of people in images. Our proposed method is designed to work across multiple naturalistic social scenarios and provides a full picture of the subjects attention and gaze.
A well-known method for completing low-rank matrices based on convex optimization has an additional restriction that the data points must be represented as linear combinations of the bases in a dictionary constructed in advance.
We address semantic segmentation of road-objects from 3D LiDAR point clouds from an end-to-end pipeline based on convolutional neural networks (CNN)
We propose an efficient approach that learns a transition matrix that refines a sentence embedding vector to reflect the latent semantic meaning of a sentence to achieve state-of-the-art performance.
We propose an active learning scheme that learns the re-ID model and updates the annotation set iteratively.
We investigate SMBO to identify architecture hyper-parameters of deep convolution networks (DCNs) object recognition.
We propose ETransR, a method which automatically learns entity and relation feature representations in continuous vector spaces, in order to measure the semantic relatedness of knowledge mentions for knowledge resolution.
Our method quantifies both the magnitude and the direction of depth estimate errors when viewing the scene. This enables us to improve the reconstruction accuracy.
We present a learned image compression system based on GANs, operating at extremely low bitrates. The model synthesizes details it cannot afford to store.
A framework to compare ontology learning systems that use Wikipedia as their main source of knowledge.
We study an open compound domain adaptation problem where the target is a compound of multiple homogeneous domains without domain labels, reflecting realistic data collection from mixed and novel situations.
Constrained Local Models (CLMs) are a well-established family of methods for facial landmark detection. In our work, we present a novel local detector that brings together the advantages of neural architectures and mixtures of experts in an end-to-end framework.
Interactomes of endolysosomal, non-selective cation channels, two-pore channels, and mucolipins regulate intracellular membrane dynamics and autophagy.
We introduce a statistically-motivated framework for normalization and compression of second-order representations, and propose to make use of a square-root normalization, which makes the distribution of the resulting representation converge to a Gaussian.
In this paper, we propose a novel algorithm for Single-hidden Layer Feed forward Neural networks training which is able to exploit information coming from both labeled and unlabeled data for semi-supervised action classification.
This paper aims to reduce the time to annotate images for panoptic segmentation, which requires annotating segmentation masks and class labels for all object instances and stuff regions.
The best summary of a long video differs among different people due to its highly subjective nature. In this paper, we introduce the task of generating contextually customized video summaries through simple text.
GPS, a simple but high-performing method for learning a policy of test-time augmentation, outperforms simple crops and flips.
In this paper, we tackle the problem of human pose estimation from still images, which is a very active topic, specially due to its several applications.
Image-to-image translation is the task of translating images between domains while maintaining the identities of the images. Cycle-consistent GANs solve this problem by using unpaired data. Such methods work well for translations that involve color and texture changes but fail when shape changes are required.
We treat the object selection problem as combinatorial optimization based on a Labeled LDA model, and then sample objects from each category considering their function diversity along with style compatibility, while regarding not only separate rooms, but also associations among rooms.
We propose a novel architecture that integrates a set of difference of Gaussians to attenuate high-frequency local components in the feature space to improve few-shot learning.
We propose a unified Bilateral-Branch Network (BBN) to take care of both representation learning and classifier learning simultaneously, where each branch does perform its own duty separately.
Learning depth and optical flow via deep neural networks by watching videos using geometric rules .
We propose a reciprocative learning algorithm to exploit visual attention for training deep classifiers for visual tracking.
We present a unified solution to address deep convolutional feature aggregation and image re-ranking by simulating the dynamics of heat diffusion by considering each deep feature as a heat source.
RankQA extends the conventional two-stage process in neural QA with a third stage that performs an additional answer re-ranking.
An automated way of grouping related properties into informational aspects using ontology structure for Linked Open Data project.
UNITER, a UNiversal Image-TExt Representation, learned through large-scale pre-training over four image-text datasets (COCO, Visual Genome, Conceptual Captions, and SBU Captions), which can power heterogeneous downstream V+L tasks with joint multimodal embeddings.
We propose a hierarchical recurrent neural network for video summarization, called H-RNN in this paper.
We propose three enhancements for CNN-based visual object detection for ADAS. The experimental results demonstrate the effectiveness of the proposed enhancements.
We propose an end-to-end unified framework, the Invertible Question Answering Network (iQAN), to leverage the complementary relations between questions and answers in images by jointly training the model on VQA and VQG tasks.
We propose a novel Semantic-aware Grad-GAN (SG-GAN) to perform virtual-to-real domain adaption with the ability of retaining vital semantic information.
Photosequencing aims to transform a motion blurred image to a sequence of sharp images. Adopting a computational photography approach, we propose to capture two short exposure images, along with the original blurred long exposure image to aid in the aforementioned challenges.
Optical flow is typically estimated by minimizing a data cost and an optional regularizer but a learned GMM that models the density of patches of warp error gives a much better fit than any existing assumption of constancy.
In this paper, we propose a new salient object detection method by introducing short connections to the skip-layer structures within the HED architecture within the Fully Convolutional Neural Network.
We propose an automatic method for key-frame selection based on the motion state of the vehicle, which can reduce data redundancy and improve the real-time performance and robustness of VO/VSLAM.
We present a system that incrementally builds a database of objects as a mobile agent traverses a scene. This allows us to create and improve object models on the fly.
We comprehensively investigate into the intra-domain variations of the target domain and propose to generalize the re-ID model w.r.t three types of the underlying invariance, i.e., exemplar-invariance, camera-Invariance and neighborhood-invarance.
Image reconstruction including image restoration and denoising is a challenging problem in the field of image computing. We present a new method, called X-GANs, for reconstruction of arbitrary corrupted resource based on a variant of conditional GANs.
We propose a new model called Multi-turn Inference Matching Network to perform multi-turn inference on different matching features.
We introduce Adversarial-and-attention Network (A3Net) for Machine Reading Comprehension.
Automated design of neural network architectures tailored for semantic image segmentation using fully convolutional networks.
We address the key question of how object part representations can be found from the internal states of CNNs that are trained for high-level tasks, such as object classification.
We develop an effective and efficient universal object detection system capable of working on various image domains, from human faces and traffic signs to medical CT images.
We propose an adversarial architecture related to the conditional GAN (cGAN) that generates sentences according to a given image (also called image captioning).
The Oxford Multimotion Dataset provides a number of multimotion estimation problems of varying complexity. It includes both complex problems that challenge existing algorithms as well as simpler problems to support development.
We propose a method that learns to perform table-top instance grasping of a wide variety of objects while using no real world grasping data, outperforming the baseline using 2.5D shape by 10%.
In this paper, we study the problem of constrained robust (min-max) optimization ina black-box setting, where the desired optimizer cannot access the gradients of the objective function but may query its values.
We explore and demonstrate how systematic JPEG compression can work as an effective pre-processing step in the classification pipeline to counter adversarial attacks and dramatically reduce their effects, without requiring knowledge about the model.
In this paper, we exploit multi-cue cascades for building a robust end-to-end visual tracking, which cascades each level response via fully exploring the complementary properties of different levels of learning.
We develop a spatial-semantic image search technology that enables users to search for images with both semantic and spatial constraints by manipulating concept text-boxes on a 2D query canvas.
In this paper we investigate the effect of image resolution on the error rates of a face verification system, the registration part and the entire system.
We propose SINet-Caption that learns to generate captions grounded over higher-order interactions between arbitrary groups of objects for fine-grained video understanding.
We propose MobileBERT for compressing and accelerating the popular BERT model while achieving competitive results on well-known benchmarks.
In this paper, we propose a set of novel geometrical features that are able to characterize different writers.
We propose a novel and efficient deep framework to boost multi-label classification by distilling knowledge from weakly-supervised detection task without bounding box annotations.
This paper proposes a high-confidence manipulation localization architecture that utilizes resampling features, long short-term memory (LSTM) cells, and an encoder-decoder network to segment out manipulated regions from non-manipulated ones.
In this report, we introduce an artificial dataset generator for Photo-realistic Blocksworld domain that performs fast and systematic symbolic reasoning.
We present a method to populate an unknown environment with models of previously seen objects, placed in a Euclidean reference frame that is inferred causally and on-line using monocular video along with inertial sensors.
We propose an end-to-end trainable Recurrent Neural Network for full mesh 3D human pose mesh recovery from monocular video.
We propose a hierarchical probabilistic model that could infer the true locations of facial features given the image measurements even if the face is with significant facial expression and pose.
We propose a novel open-domain QA system called Reinforced Ranker-Reader $(R^3)$, based on two algorithmic innovations. We report extensive experimental results showing that our method significantly improves on the state of the art.
We present an approach that complements text-based entailment models with information from KGs by (1) using Personalized PageR- ank to generate contextual subgraphs with reduced noise and (2) encoding them using graph convolutional networks.
We introduce Bert-Joint, i.e., a multi-lingual joint text classification and sequence labeling framework for intent detection and Slot Filling.
We re-formulate the problem as one of active testing, and examine strategies for efficiently querying a user so as to obtain an accu- rate performance estimate with minimal vetting.
We propose a graph-attention based solution for cross-lingual knowledge graph alignment, which outperforms previous state-of-the-art methods.
Graphs arise naturally in many real-world applications including social networks, recommender systems, ontologies, biology, and computational finance. This introduces important challenges for learning and inference.
We propose a framework based on nonparametric Bayesian learning method -- a sticky hierarchical Dirichlet process hidden Markov model(sticky HDP-HMM), and discover the relationship between driving scenarios and driving styles. We use the analysis of driving styles of autonomous vehicles to reflect the risk levels of driving scenarios to the vehicles.
In this paper, we propose a multimodal search engine that combines visual and textual cues to retrieve items from a multimedia database aesthetically similar to the query.
We propose a novel context-aware feature learning method for detecting pedestrians in crowds, with the purpose of making better use of context information for dealing with occlusion.
We focus on using large-batch data-parallelism synchronous SGD for fast DNN training without losing accuracy in the fixed epochs.
We address these two problems with a technique we call Gradient Blending, which computes an optimal blend of modalities based on their overfitting behavior and achieves state-of-the-art accuracy on various tasks.
In a world where traditional notions of privacy are increasingly challenged by the myriad companies that collect and analyze our data, it is important that decision-making entities are held accountable for unfair treatments arising from irresponsible data usage.
A framework for generating fake user profiles which, when incorporated in the training of a recommendation system, can achieve an adversarial intent, while remaining indistinguishable from real user profiles.
We present CAVBench, the first benchmark suite for the edge computing system in the CAVs scenario and use the suite to evaluate a typical edge computing platform.
Style variation has been a major challenge for person re-identification, which aims to match the same pedestrians across different cameras. To solve this problem, we propose a UnityStyle adaption method, which can smooth the style disparities within the same camera and across different camera.
We present a real-time approach for multi-person 3D motion capture at over 30 fps using a single RGB camera using novel selective long and short range skip connections.
This paper presents an introduction to Bag of Features, describes critical design choices, and surveys the BoF literature. Emphasis is placed on recent techniques that mitigate quantization errors, improve fea- ture detection, and speed up image retrieval.
We present an approach to learning a model-theoretic semantics for natural language tied to Freebase using an open predicate vocabulary and probabilistic database.
We develop a prediction model for video memorability, including complexities of video content in it. We also describe a novel experiment of predicting video sub-shot memorability.
In this paper, we propose a novel knowledge transfer method by treating it as a distribution matching problem, which improves the performance of student networks.
This work surveys the current state-of-the-art in VRU detection, covering topics such as benchmarks and datasets, object detection techniques and relevant machine learning algorithms.
We propose progressive stagewise training to improve the transfer of knowledge, without compromising on the metric.
We introduce a new dataset for joint reasoning about language and vision. The data contains 107,296 examples of English sentences paired with web photographs.
This work introduces a novel Convolutional Network architecture (ConvNet) for the task of human pose estimation, that is the localization of body joints in a single static image.
We propose simple yet effective domain adaptive text style transfer models, enabling domain-adaptive information exchange in the scenario where less data is available.
We propose a novel graph based ranking method to detect and segment salient object in a scene according to its relationship to image border (background) regions, i.e., the background feature.
This paper is about weakly supervised action segmentation, where the ground truth specifies only a set of actions present in a training video, but not their true temporal ordering.
This paper explores the potential of turning customer reviews into a large source of knowledge that can be exploited to answer user questions to help their purchase decision making.
We propose a large-margin Gaussian Mixture loss for deep neural networks in classification tasks.
We propose a new method to expose GAN-synthesized images using the locations of facial landmark points, based on observations that the facial parts configuration generated by GAN models are different from those of the real faces.
We developed a novel computational approach, ChromNet, to infer the chromatin network from a set of ChIP-seq datasets, which revealed previously known physical interactions.
A scale-constrained evaluation method that evaluates segmentation quality according to the specified target scale.
This paper introduces VolMap, a real-time approach for the semantic segmentation of a 3D LiDAR surrounding view system in autonomous vehicles.
We propose Adaptive Affinity Fields (AAF) to capture and match the semantic relations between neighbouring pixels in the label space in a best worst-case learning scenario.
In this paper, we utilize two state-of-the-art ConvNets, i.e., the very deep spatial net (VGGNet) and the temporal net from Two-Stream ConvNet, for action representation.
In this paper, we propose a methodology to build a global social service network based on Link data principles for reducing the using thresholds.
In this paper, we propose a new differentiable Neural Architecture Search method based on Proximal gradient descent (denoted as NASP)
We propose a simple extension to the skipgram model in which we introduce the concept of bridge-words, which are artificial words added to the model to strengthen the similarity between standard words and their noisy variants.
We investigate the connections between neural networks and simple building blocks in kernel space, and propose an algebra for creating compositional kernels from bags of features.
We propose an energy efficient inference engine (EIE) that performs inference on a compressed network model and accelerates the resulting sparse matrix-vector multiplication with weight sharing.
This paper describes an improved version of MobileNet, called Pyramid Mobile Network. They use Depthwise Separable Convolution in place of standard Convolution to reduce the size of networks.
We propose a probabilistic method to integrate these two types of IE projects where the structured knowledge bases benefit from the wide coverage of the semi-supervised IE projects and the latter benefits from the schema information of the former.
A computer vision system that recognizes the emotions ::: of a website’s user and customizes the context and the ::: presentation of this website accordingly.
In Conversational Question Answering (CoQA), humans propose a series of questions to satisfy their information needs. However, existing methods usually treat them uniformly, which may easily be biased by the dominant type of questions and obtain inferior overall performance. We propose an adaptive framework to handle these two types of questions in different ways based on their own characteristics.
The ChestXray14 dataset contains 112,120 frontal chest films, and the MURA dataset contains 40,561 upper limb radiographs.
We propose Meta-Sim, which learns a generative model of synthetic scenes, and obtain images as well as its corresponding ground-truth via a graphics engine.
This paper proposes Approximately Binary Clamping (ABC), which is non-saturating, end-to-end trainable, with fast convergence and can output true binary visual representations.
We seek a middle ground by learning a facial model from thousands of accurately aligned 3D scans. Our FLAME model (Faces Learned with an Articulated Model and Expressions) is designed to work with existing graphics software.
We propose a deep learning method for single image super-resolution (SR) that learns an end-to-end mapping between the low/high-resolution images.
We first study the link between the compact two-dimensional representation of the emotion known as arousal-valence, and discrete emotion classes (e.g. anger, happiness, sadness) used in the computer vision community.
We develop a novel saliency estimation technique as well as a novel neighborhood graph, based on optical flow and edge cues for unsupervised video segmentation.
We evaluate various factors that affect the discriminative ability of features extracted from CNNs and propose a new multi-scale image feature representation method to encode the image effectively.
We propose a SVDD based feature representation based on K-means clustering, based on which a robust representation can be derived.
Understanding protein complexes from experimentally obtained protein-protein interaction (PPI) networks.
We present an approach for learning a visual representation from the raw spatiotemporal signals in videos. Our representation is learned without supervision from semantic labels.
In visual tracking, a mature scale estimation method can greatly improve tracking performance and provide accurate target information for model training. In this paper, we propose a correlation-filter based visual tracking approach that reveals the missing link between scale estimation and the detection response.
We propose a novel Siamese EnergyNet structure to transfer knowledge from image domain to video domain using the class-discriminative spatial attention map.
Deep-Q-Learning bypasses the need for estimation of the hand-crafted states, and directly determine the best action base on the present retrieval status.
We propose a convolutional neural network system based on residual learning which significantly improves over the state-of-the-art in cell nuclei classification in renal cell cancer (RCC) and prostate cancer.
We propose a simple but efficient and effective network, named DENet, which is composed of two components, i.e., a detection network (DNet) and an encoder-decoder estimation network (ENet) for counting people or objects with significantly varying scales and densities.
We propose a general object counting method that does not use any prior category information. We learn from local image divisions to predict global image-level counts without using any form of local annotations.
Using generic descent maps, we derive a practical algorithm for minimizing Nonlinear Least Squares problems.
We propose an efficient depth estimation approach by first detecting and evaluating descriptors for interest points, then (b) learning to match and triangulate a small set of interest points and finally (c) densifying this sparse set of 3D points using CNN.
Real-time self-adaptive deep stereo system enabling competitive performance on heterogeneous datasets. We address this issue introducing a lightweight, yet effective, deep stereo architecture.
The task of action recognition or action detection involves analyzing videos and determining what action or motion is being performed in said video.
We provide a comprehensive investigation of different custom and off-the-shelf architectures as well as different approaches to generating feature vectors for offensive language detection. We also show that these approaches work well on small and noisy datasets.
We propose ReZero, a simple change to the architecture that initializes an arbitrary layer as the identity map, using a single additional learned parameter per layer, for faster signal propagation.
We introduce our method on DukeMTMC and show that simple hierarchical clustering with well-trained person re-identification features get good results on this dataset.
We present an efficient large margin piece-wise learning method which is both memory and computationally efficient.
We propose a new method for fusing LIDAR point cloud and camera-captured images in deep convolutional neural networks for 3D object detection.
We propose three types of regularizers that mitigate the effect of gradient masking by harnessing on properties that differentiate a robust model from that of a pseudo robust model.
Hyperparameter optimization is both a practical issue and an interesting theoretical problem in training of deep architectures. We show that at a negligible additional computational cost, results can be improved by sampling nonlocal paths instead of points in hyperparameter space, which can be mapped to an effective temperature.
In the context of 2D/3D registration, this paper introduces an approach that allows for matching features detected in two different modalities, photographs, and 3D models, by using a common 2D representation.
Data augmentation is widely used as a part of the training process applied to deep learning models, especially in the computer vision domain. Currently, common data augmentation techniques are designed manually. They break the data distribution and can be used to improve model performance.
We combine the recently proposed latent-space GAN and Laplacian GAN architectures to form a multi-scale model capable of generating 3D point clouds at increasing levels of detail.
We propose a new self-supervised CNN pre-training technique based on a novel auxiliary task called odd-one-out learning where we sample subsequences from videos and ask the network to learn to predict the odd video subsequence.
We propose Sideways, an approximate backpropagation scheme for training video models. We overwrite network activations whenever new ones, i.e., from new frames, become available.
We propose Blockout, a novel parametrization of hierarchical architectures that allows for structure learning via back-propagation.
We propose a novel scale-aware attention network to address crowd counting in images.
We propose a novel sparse gradient-based structured matrix decomposition model for salient object detection.
The goal of this paper is to develop state-of-the-art models for lip reading -- visual speech recognition. The recurrent and fully convolutional models are trained with a Connectionist Temporal Classification loss and use an explicit language model for decoding, the transformer is a sequence-to-sequence model.
In recent years visual object tracking has become a very active research area. An increasing number of tracking algorithms are being proposed each year. In the current study, we review latest trends and advances in the tracking area and evaluate the robustness of different trackers based on the feature extraction methods.
This paper presents a method to explain how input information is discarded through intermediate layers of a neural network during the forward propagation, in order to quantify and diagnose knowledge representations of pre-trained deep neural networks.
We present in this paper a novel approach for training deterministic auto-encoders by adding a well chosen penalty term to the classical reconstruction cost function. We show that this penalty term results in a localized space contraction which in turn yields robust features on the activation layer.
We study the issue of catastrophic forgetting in the context of neural multimodal approaches to Visual Question Answering (VQA) and propose a set of linguistically-informed VQA tasks, which differ by the types of questions involved.
We use 2D-2D point matches between images taken during different image conditions to train a convolutional neural network for semantic segmentation.
We introduce a Transition-Matrix-based Network (TraMNet) which relies on computing transition probabilities between anchor proposals while maximizing their overlap with ground truth bounding boxes across frames, and enforcing sparsity via a transition threshold.
A three-branch attention guided convolution neural network for thorax disease classification on chest X-ray images.
We present a joint convolutional neural pyramid model with large receptive fields for joint depth map super-resolution.
We measure the practical utility of this approach by fine-tuning pre-trained models to answer questions without access to external context or knowledge.
We present KERMIT, a simple insertion-based approach to generative modeling for sequences and sequence pairs, capable of matching or exceeding the performance of dedicated state-of-the-art systems across a wide range of tasks.
We propose a novel CNN-RNN framework for multi-label image classification that leverages label dependencies in an image.
This paper presents a new model that is able to Turn Cross-view Hashing into single-view hashing (TUCH), thus enabling the information of image to be preserved as much as possible.
We revisit this seemingly flawed idea from a radically different perspective. We embrace the omnipresence of adversarial examples and the numerical procedure of crafting them, and turn this harmful attacking process into a useful defense mechanism.
We present an approach to refine inaccurate 3D pose estimations and obtain more legitimate poses over the baselines.
We propose a framework for generating adversarial instances by convex programming which, for classification tasks, is able to recover variants of existing non-adaptive adversarial methods and derive novel algorithms.
We present the largest challenge dataset for QC, containing 7,787 science exam questions paired with detailed classification labels from a fine-grained hierarchical taxonomy of 406 problem domains, achieving state-of-the-art performance.
We propose an order-aware reweighting method to effectively train the triplet-based deep networks, which up-weights important triplets and down-weights the uninformative triplets.
The processing of images is currently moving from desktop implementation to mobile or embedded ones. In the case of automotive image processing, limited resources in memory or CPU frequency reduce the applicability of nowadays algorithms and possibility of real time processing.
We introduce a novel Flattening Module to produce high-resolution pixelwise prediction without either removing any subsampling operations or building a complicated decoder module.
We propose a method that segments the 3D feature trajectories based on their motion behaviours, and assigns them semantic labels using 2D-to-3D label transfer. We introduce a complete framework for static-map and dynamic objects' reconstruction.
Optimized balancing and augmentation can improve Action Unit detection in the wild.
We propose a novel training method called Learning with Ensemble Consensus (LEC) that eliminates noisy examples identified via consensus of perturbed networks.
We present a robust method for estimating the facial pose and shape information from a densely annotated facial image. The method relies on Convolutional Point-set Representation (CPR), a carefully designed matrix representation.
A system for rapidly creating customized object detectors from scratch given limited data.
In this paper, we propose a novel regional multi-person pose estimation (RMPE) framework to facilitate pose estimation in the presence of inaccurate human bounding boxes.
We present Deep Graph Infomax (DGI), a general approach for learning node representations within graph-structured data in an unsupervised manner in an competitive manner.
An assistive solution to assess incoming threats (e.g., robbery, burglary, gun violence) for homes using real-time video streams.
We present the 2016 ChaLearn Looking at People and Faces of the World Challenge and Workshop, which ran three competitions on the common theme of face analysis from still images, and the results achieved by the participants of the competitions.
Variational Autoencoders (VAEs) are a popular generative model, but one in which conditional inference can be challenging. In this paper we propose an idea we term cross-coding to approximate the distribution over the latent variables after conditioning on an evidence assignment to some subset of the variables.
We introduce a high-resolution equirectangular panorama dataset for object detection and propose a multi-projection variant of the YOLO detector.
We combine bottom-up saliency with actor’s head pose and gaze direction for predicting where observers look.
We present an end-to-end framework to settle data association in online Multiple-Object Tracking (MOT) using a neural network.
Robust Ordinal VAE incorporates the noisy pairwise ordinal comparisons in the disentanglement task in a real-world problem.
We study the compositional skills of people through language-like instruction learning tasks, showing that people can learn and use novel functional concepts from very few examples (few-shot learning), successfully applying familiar functions to novel inputs.
We present extensions to the DocQA model to allow incremental reading without loss of accuracy. The model also jointly learns to provide the best answer given the text that is seen.
We present a novel 12-layer deep convolutional network for image compression artifact suppression with hierarchical skip connections and a multi-scale loss function.
We provide the key atomic components for complex-valued deep neural networks and apply them to convolutional feed-forward networks and LSTMs and achieve state-of-the-art performance on audio-related tasks.
In this chapter we introduce cooperating techniques for environment perception and reconstruction based on dynamic point cloud sequences of a single rotating multi-beam Lidar sensor, which monitors the scene either from a moving vehicle top or from a static installed position.
We analyze transfer learning capabilities of Fully Convolutional Networks for slum mapping in satellite images.
We demonstrate the power of a simple combination of two common SSL methods: consistency regularization and pseudo-labeling for semi-supervised learning.
We introduce the "Energy-based Generative Adversarial Network" model (EBGAN) which views the discriminator as an energy function that attributes low energies to the regions near the data manifold and higher energies to other regions.
A fully automatic 3D face recognition algorithm is presented. Several novelties are introduced to make the recognition robust to facial expressions and efficient.
We propose ways to dynamically order the ground truth labels with the predicted label sequence. This allows for faster training of more optimal LSTM models.
We propose a new approach for bridging the gap between model-based and model-free reinforcement learning that leverages the generality and structure of a probabilistic dynamics model, but is also data-efficient and cost-savvy.
We analyze the state-of-the-art GC accuracy on three large datasets: MORPH, LFW and GROUPS. We discuss their respective difficulties and bias, concluding that the most challenging and wildest complexity is present in GROUps. We propose a solution based on local descriptors, beating any previously published results for this dataset.
We train two independent CNNs, a RGB network on web images and video frames and a second network using temporal information from optical flow for web-supervised learning.
Similarity Distribution based Online Hashing (SDOH), a supervised online hashing method that captures the intrinsic semantic relationship in Hamming space.
We present knowledge-based MRC in this paper, and build a new dataset consisting of 40,047 question-answer pairs. The annotation of this dataset is designed so that answering the questions requires understanding and the knowledge involved in a document.
We propose a novel appearance-based Object Detection system that is able to detect obstacles at very long range and at a very high speed (~300Hz), without making assumptions on the type of motion.
We address weakly-supervised video actor-action segmentation, which extends general video object segmentation (VOS) to additionally consider action labels of the actors.
In this paper, we propose Adversarial Feature Hallucination Networks (AFHN) which is based on conditional Wasserstein GenerativeAdversarial networks (cWGAN) and hallucinates diverse and discriminative features conditioned on the few labeled samples. Two novel regularizers, i.e., the classification regularizer and the anti-collapse regularizer, are incorporated into AFHN to encourage discriminability and diversity
We propose a novel Prototypical Adversarial Learning scheme for unsupervised domain adaptation and a unified framework for UDA.
We propose a cascade network that simultaneously learns to localize face regions specific to attributes and performs attribute classification without alignment.
This paper proposes Binary-decomposed DCNN, which accelerates computation of inference and decreases model size without the need for retraining.
A general formulation of the discrete counterpart of the Mumford–Shah functional, adapted to nonsmooth penalizations, fitting the assumptions required by the Proximal Alternating Linearized Minimization (PALM), with convergence guarantees.
We introduce a multi-stream convolutional neural network with temporal attention for environmental sound and audio scene classification and achieve new state-of-the-art performance.
We propose a novel cross-modal sketch-based video retrieval problem of fine-grained instance-level sketch- based video retrieval, where a sketch sequence is used as a query to retrieve a specific target video instance.
We propose a stochastic temporal model for video prediction in latent space, which can outperform state-of-the-art methods on challenging datasets.
A common technique to improve speed and robustness of learning in deep reinforcement learning (DRL) and many other machine learning algorithms is to run multiple learning agents in parallel. A neglected component in the development of these algorithms has been how best to arrange the learning agents involved to better facilitate distributed search.
We propose a dynamic batching method for dynamic computation graphs that yields up to 6.25 times speed-up on a common dynamic workload.
Multi-Modal Deep Clustering (MMDC), trains a deep network to align its image embeddings with target points sampled from a Gaussian Mixture Model distribution, providing direct cluster assignments of images without additional processing.
Our proposed adaptation and re-identification network (ARN) performs unsupervised domain adaptation, which leverages information across datasets and derives domain-invariant features for Re-ID purposes.
Multi-subspace SDM is proposed to equip SDM with a stronger capability for dealing with unconstrained faces.
We propose a progressive approach that explicitly accounts for the distinct DOFs among the body parts, yielding physically constrained and plausible pose-estimation results.
We automate the reward search with AutoRL, an evolutionary layer over standard RL that treats reward tuning as hyperparameter optimization and trains a population of RL agents to find a reward that maximizes the task objective.
We propose a Multi-task Sentence Encoding Model (MSEM) for the PI problem, wherein a connected graph is employed to depict the relation between sentences, and a multi-task learning model is applied to address both the sentence matching and sentence intent classification problem.
A novel method for fully automatic facial expression recognition in facial image sequences using multi-class AdaBoost and support vector machines.
Crowd counting is a challenging problem in the presence of huge crowd diversity across images and complex cluttered crowd-like background regions, where most previous approaches do not generalize well and consequently produce either huge crowd underestimation or overestimation. To address these challenges, we propose a new image patch rescaling module (PRM) and three independent PRM employed crowd counting methods.
A generic model for personalized multilevel exploration and analysis over large dynamic sets of numeric and temporal data.
We propose a new Winograd-domain pruning method, spatial-Winograd pruning, in which spatial-domain weights are pruned in a structured way, which efficiently transfers the spatial- domain sparsity into the Winog Rad domain and avoids Winogrand-domain retraining.
We build on the intuition that changes in the network structure are driven by dynamics at the level of groups of nodes.
Deep learning is a fast-growing machine learning approach to perceive and understand large amounts of data. In this paper, general information about the deep learning approach which is attracted much attention in the field of machine learning is given in recent years.
This paper introduces a statistical method to decide whether two blocks in a pair of images match reliably.
In this paper, we integrate CNNs with HRNNs, and develop end-to-end convolutional hierarchical RNNs for image classification.
We present a vision-based method to locate a vehicle within the road when no lane lines are present using only RGB images as input.
In this paper, we propose a structured feature learning framework to reason the correlations among body joints at the feature level in human pose estimation.
We present a novel hybrid method to avoid the distracted supervision paradox and achieve high-performance in semantic edge detection.
We introduce a search procedure based on a genetic algorithm in order to improve the approximation quality.
We propose to estimate 3D scene flow from unstructured point clouds using a deep neural network, and propose a translation equivariant representation to circumvent this problem.
In this paper, we propose computationally efficient algorithms for vertex representation learning that extend random walk based methods to dynamic graphs.
The problem of computing low rank approximations of matrices is considered. We formulate this as an optimization problem, which aims to minimize the reconstruction (approximation) error.
We study the design of multiple-choice based datasets where the learner has to select the right answer from a set of candidate ones including the target (\ie the correct one) and the decoys ( \ie the incorrect ones) and propose automatic procedures to remedy such design deficiencies.
In this paper, we propose a new video representation learning method, named Temporal Squeeze pooling, which can extract the essential movement information from a long sequence of video frames and map it into a set of few images, named Squeezed Images.
We present a new logic-based inference engine for natural language inference (NLI) called MonaLog, which is based on natural logic and the monotonicity calculus.
We present a new architecture and an approach for unsupervised object recognition that addresses the above mentioned problem with fine tuning associated with pretrained CNN-based supervised deep learning approaches while allowing automated feature extraction.
We propose a method termed TIIM (Top-k Impactful Itemsets Miner), which only requires specifying a user-defined number k to explore the top k itemsets with the most significantly differentially co-expressed genes between 2 conditions in a time course.
We address the person re-identification labeling issue by presenting novel deep representation learning without ID information across multiple cameras.
We describe the framework, challenges, and open questions surrounding the successful operationalization of machine learning based security detections in a cloud environment.
We propose Deep networks with Temporal Pyramid Pooling (DTPP), an end-to-end video-level representation learning approach, to address these problems.
We present a sequence-to-sequence recurrent neural networks (RNN) model for image caption generation.
In this paper, we propose a deep learning method for single infrared image optical noise removal.
We propose a novel gaze decomposition method and a single gaze point calibration method, motivated by our finding that the inter-subject squared bias exceeds the intra-subject variance for a subject-independent estimator.
This paper presents a binocular PTU (pan-tilt unit) camera video object tracking scheme using the MeanShift algorithm and the runtime disparity estimation.
We study the following problem: given the name of an ad-hoc concept as well as a few seed entities belonging to the concept, output all entity belonging to it. We develop novel probabilistic ranking methods that can model a new type of table-entity relationship.
We propose a two-step method that combines information retrieval techniques optimized for question answering with deep learning models for natural language inference in order to tackle the multiple-choice question answering problem.
In this paper, we propose a human action recognition method using HOIRM (histogram of oriented interest region motion) feature fusion and a BOW (bag of words) model based on AP clustering.
In this paper we propose a multi-task linear classifier learning problem called D-SVM (Dictionary SVM) using a dictionary of parameter covariance shared by all tasks to do multi-Task knowledge transfer among different tasks.
We propose a theoretical analysis of feature transform for style transfer.
We address these aforementioned problems by carefully designing the network architecture to preserve required spatial information throughout the network, while at the same time achieve large effective receptive field to extract multiscale contextual information.
We extend the classical Precision-Recall-Classfication framework for depth ordering problems and propose an extended framework called PRC for these problems.
Weighted Multi-Region Convolutional Neural Network for low-latency action recognition .
We propose Question Type-guided Attention (QTA), a VQA architecture that uses the information of question type to dynamically balance between bottom-up and top-down visual features to improve the performance.
Fashion is the way we present ourselves to the world and has become one of the world's largest industries. Given the rapid development, this paper provides a comprehensive survey of more than 200 major fashion-related works covering four main aspects for enabling intelligent fashion.
In this paper, we show that enforcing a relaxed local consistency constraint to the disparity fields, provided by fast 1D disparity optimization methods, yields much more rapidly, results comparable to those of the top-ranked approaches.
This invention relates to a bracket for retaining and supporting limp plastic bags as liners in a trash receptacle and includes two or more projections, upwardly extending, to engage openings within limp flexible plastic liner.
We propose new data augmentation methods to extend limited noisy data and further improve NMT robustness to noise while keeping the models small.
We leverage the power of automatic differentiation frameworks to make dense SLAM differentiable, opening up new possibilities in gradient-based learning.
We present Survival-OPT, a physical adversarial example algorithm in the black-box hard-label setting where the attacker only has access to the model prediction class label.
Siamese trackers learn the appearance model of the target in the first frame and then exploit the model to locate the target, especially in the background clutters scenarios.
We propose a novel two-stream network architecture for 3D model recognition and retrieval. The proposed network includes two sub-networks: a multi-view convolutional neural network that extracts the view information from the taken views, and an Visual Saliency model that defines the weight of views based on the similarity and differentiation information of multiple views.
The generalization error of deep neural networks via their classification margin is studied in this paper. Our analysis leads to the conclusion that a bounded spectral norm of the network's Jacobian matrix in the neighbourhood of the training samples is crucial for a deep neural network of arbitrary depth and width to generalize well.
We utilize the short-term residual learning method to improve the performance and robustness of networks for image denoising tasks, and insert residual dense blocks (RDBs) in each layer.
We formalize a new modular variant of current question answering tasks by enforcing complete independence of the document encoder from the question encoder, which addresses a key challenge in machine comprehension.
A recent paper [31] claims to classify brain processing evoked in subjects watching ImageNet stimuli as measured with EEG and to use a representation derived from this processing to create a novel object classifier. Our novel experiments and analyses demonstrate that their results crucially depend on the block design that they use.
We explore the importance of biologically significant facial landmarks for gender classification and propose a fully automatic gender classification algorithm that outperforms all existing techniques.
Reputation systems provide a promising way for building trust through social control in collaborative communities by harnessing the community knowledge in the form of feedback.
In this paper, a novel deep FG-SBIR model is proposed which differs significantly from the existing models in that: (1) It is spatially aware, achieved by introducing an attention module that is sensitive to the spatial position of visual details.
We propose a fully convolutional model to generate video sequences directly in the pixel domain using a stochastic fusion mechanism.
We propose a unified One-Pass Video Segmentation framework (OVS-Net), which seamlessly integrates object detection, object segmentation, and object re-identification in a unified pipeline.
We propose a technique for making Convolutional Neural Network-based models more transparent by visualizing input regions that are 'important' for predictions -- or visual explanations.
We present a single-image 3D face synthesis technique that can handle challenging facial expressions while recovering fine geometric details.
We propose a novel distillation method for lightweight neural network architectures that outperforms other known methods for the face recognition task on LFW and AgeDB-30 datasets.
In this paper, we propose a new regularisation approach to incorporate relation cardinality constraints to any existing neural link predictor without affecting their efficiency or scalability.
We proposed a large-scale annotated comics dataset and a new CNN-based detector for object detection task.
We propose a novel end-to-end network called WaveMsNet based on the multi-scale convolution operation and two-phase method for acoustic models recognition.
We propose a multi-label transfer learning approach based on LSTM to make predictions for several relations simultaneously and aggregate the losses to update the parameters.
We propose a Depth Information Guided Crowd Counting (DigCrowd) method to deal with crowded EDOF scenes.
This paper proposes an efficient stereo matching algorithm to improve the stereo matching accuracy in these regions.
We propose a new architecture leveraging fixed pretrained semantic segmentation networks to guide self-supervised representation learning via pixel-adaptive convolutions, while remaining in the self-Supervised regime.
Self-Net uses an autoencoder to learn a set of low-dimensional representations of the weights learned for different tasks and use these representations to generate high-fidelity recollections.
In this paper, we propose a novel Heterogeneous Graph Structural Attention Neural Network (HetSANN) to directly encode structural information of HIN without meta-path.
We propose a dense semantic robotic mapping technique that exploits sparse Bayesian models, in particular, the relevance vector machine, for high-dimensional sequential inference.
Stereo reconstruction from rectified images has recently been revisited within the context of deep learning. Here, we show that it is possible to take a holistic approach by training a fully end-to-end network which directly includes regularization in the form of a densely connected Conditional Random Field that acts as a prior on inter-pixel interactions.
We propose the Tensor Contraction Layer (TCL), the first attempt to incorporate tensor contractions as end-to-end trainable neural network layers.
We propose a deep network architecture and training procedures that allow us to stylize arbitrary-length videos in a consistent and stable way, and nearly in real time.
We propose an efficient local-to-global method to identify background, based on the assumption that as long as there is sufficient camera motion, the cumulative background features will have the largest amount of trajectories.
We propose a multi-view knowledge-based collaborative (MV-KBC) deep model to separate malignant from benign nodules using limited chest CT data.
We apply visualization techniques to observe how the model can capture different linguistic features and how these features can affect the performance of the model.
The proposed method treats the outputs of a number of deep learning sub-models as the views of the same target concept that can be linearly combined according to their complementarity.
NSGA-Net is a population-based search algorithm that explores a space of potential neural network architectures in three steps, namely, a population initialization step that is based on prior-knowledge from hand-crafted architectures, an exploration step comprising crossover and mutation of architectures, and finally an exploitation step that applies the entire history of evaluated neural architectures in the form of a Bayesian Network prior.
This paper presents a new Gaussian Processes (GPs)-based particle filter tracking framework. The framework non-trivially extends Gaussian process regression to transfer learning.
We propose a new kind of video descriptor, generated from the relationship between the trajectory’s optical flow with the gradient field in its neighborhood, capable to achieve the best known recognition rates for methods based on the self-descriptor constraint.
We propose a hierarchical approach for automatic age estimation from facial images, and provide an analysis of how aging influences individual facial components.
We use virtual screening against an ensemble of both crystal structures and comparative models to identify ligands for an allosteric peptide-binding site on the protein kinase PDK1 (the PIF pocket) in complex with 4.
In this paper, we propose to exploit a density-adaptive smooth kernel technique to perform efficient and effective re-ranking, in which the local density information around each gallery sample is elegantly exploited.
We propose a novel approach that combines a brain-computer interface (BCI) with GANs to generate a measure we call Neuroscore, which closely mirrors the behavioral ground truth measured from participants tasked with discerning real from synthetic images.
We present a self-supervised method for representation learning utilizing two different modalities given by RGB and optical flow.
A hierarchical reinforcement learning framework for video captioning, where a high-level Manager module learns to design sub-goals and a low-level Worker module recognizes the primitive actions to fulfill the sub-goal.
This paper presents a novel method to deal with the challenging task of generating photographic images conditioned on semantic image descriptions, which improves previous state of the arts on all datasets over different evaluation metrics.
In this work we attempt to learn manipulation policies in simulated environments. We follow recent work on domain randomization and augment synthetic images with sequences of random transformations.
We propose a hybrid framework for learning a decision module, which is agnostic to the mechanisms of perception, planning, and control modules. It learns the high-level driving decisions while bypassing the ambiguous annotation of high- level driving decisions.
ROPNN combines address space layout guided disassembly and deep neural networks to detect ROP payloads in HTTP requests, PDF files, and images, etc.
We define general linguistic intelligence as the ability to reuse previously acquired knowledge about a language's lexicon, syntax, semantics, and pragmatic conventions to adapt to new tasks quickly. Using this definition, we analyze state-of-the-art natural language understanding models and conduct an extensive empirical investigation to evaluate them against these criteria.
We propose an end-to-end generative framework which uses reduced Fisher Vectors (FVs) in conjunction with structured temporal models for the segmentation and recognition of video sequences.
We propose a novel GAN framework, namely TreeGAN, to incorporate a given Context-Free Grammar (CFG) into the sequence generation process.
In this work, we investigate the capabilities of such urban sensor modalities, both physical and social, in detecting a variety of local events of varying intensities (e.g., concerts) using statistical outlier detection techniques.
In this paper, we propose a weighted component-based feature descriptor and weight learning strategy for expression recognition in video sequences.
Social identity cues and goals rapidly shape implicit evaluations, even when the group assignments are arbitrary.
In this paper, we present a deep learning architecture which addresses the problem of 3D semantic segmentation of unstructured point clouds.
We propose a novel GAN variant called virtual conditional GAN (vcGAN) which is not only an ensemble GAN with multiple generative paths while adding almost zero network parameters.
We present an approach for building event-centric sub-collections from large archives, which includes not only the core documents related to the event itself but, even more importantly, documents describing related aspects (e.g., premises and consequences).
We propose a novel Edge-guided Non-local FCN (ENFNet) to perform edge guided feature learning for accurate salient object detection.
We evaluate and compare several tools for hyper-parameter optimization in the context of Multi Object Tracking (MOT) that have not been well studied in the literature.
We address the task of semi-supervised video object segmentation(VOS) and propose a novel pipeline called State-Aware Tracker(SAT), which can produce accurate segmentation results with real-time speed.
We address these challenges by developing a Content-Aware Representation Learning model (CARL) that captures both heterogeneous structural closeness and unstructured semantic relations among all nodes, as function of node content.
We present a novel approach to leverage large unlabeled datasets by pre-training state-of-the-art deep neural networks on randomly-labeled datasets.
A restricted adversarial example that modifies only a restricted area to cause misclassification by a DNN while minimizing distortion from the original sample.
A soft ordering approach for deep multitask learning, which learns how shared layers are applied in different ways for different tasks.
Adaptively Scaled Recurrent Neural Networks can learn and adjust scales based on different temporal contexts, making them more flexible in modeling multiscale patterns.
This paper aims to develop a novel learning strategy to find efficient feature embeddings while maintaining the balance of accuracy and model complexity.
We propose a cross-batch memory (XBM) mechanism that memorizes the embeddings of past iterations, allowing the model to collect sufficient hard negative pairs across multiple mini-batches - even over the whole dataset.
We propose a technique for producing "visual explanations" for decisions from a large class of CNN-based models, making them more transparent.
We introduce a manifold regularizer, named as Paired Softmax Divergence Regularization (PSDR), to penalize the Kullback-Leibler (KL) divergence between softmax outputs of similar inputs.
This paper aims at learning representations for long sequences of continuous signals using contrastive loss.
We modify a wide range of state-of-the-art collaborative filtering systems to make them scale and translation invariant and improve their accuracy without increasing their computational cost.
In this study, we propose a novel graph neural network, called propagate-selector (PS), which propagates information over sentences to understand information that cannot be inferred when considering sentences in isolation.
We proposed a CNN-based and fine-tuned convolutional neural network for automatically classi-fying breast densities on mammogram.
A paraphrase is a restatement of the meaning of a text in other words. In this paper, we propose a novel task iParaphrasing to extract visually grounded paraphrases, which are different phrasal expressions describing the same visual concept in an image.
We propose a principled method for gradient-based regularization of the critic of GAN-like models trained by adversarially optimizing the kernel of a Maximum Mean Discrepancy (MMD).
We propose Beneficial Perturbation Network (BPN), a method for overcoming catastrophic forgetting in neural networks.
We propose a generalization of the Kronecker product to stochastic neural networks and apply it to variational inference.
We propose a predictive and learning based online caching policy that can adapt to temporal variation of content popularity in practical systems due to the arrival of new contents and dynamics of user preference.
This paper accommodates the well-known Sparse Coding and Dictionary Learning approach to study time-varying shapes on the Kendall shape spaces of 2D and 3D landmarks. To overcome the inherent nonlinearity of the shape spaces, intrinsic and extrinsic solutions were explored.
This paper addresses the task of zero-shot image classification by formulating it as a metric learning problem, in which only pairs of image/attributes are given as ground truth.
We propose a data-driven method for recovering miss-ing parts of 3D shapes and recovering a high-resolution surface through a volumetric encoder-decoder architecture.
We develop Expectation-Maximization (EM) methods for semantic image segmentation model training under these weakly supervised and semi-supervised settings.
We propose a locally-transferred Fisher vector (LFV) method for texture classification, which incorporates the full capability of neural networks in feature learning.
We introduce a novel problem, single-image-guided 3D part assembly, along with a learningbased solution that leverages strong 2D-3D correspondences and assembly-oriented graph message-passing.
We propose a two-stage training dense point cloud generation network that generates a dense point Cloud from a single image, outperforms state-of-the-art works.
This paper presents a novel approach for estimating ego-motion of a vehicle in dynamic and unknown environments using tightly-coupled inertial and visual sensors.
We propose to construct control variates by learning neural networks to handle the cases when test functions are complex.
We address these limitations by proposing the TOlerance-based COmpression (TOCO) framework, which uses an in-depth analysis of the model, to maintain accuracy, in an active learning system.
Automatically classifying academic conference into semantic topic promises improved academic search and browsing for users.
P3O uses the effective sample size between the behavior policy and the target policy to control how far they can be from each other and does not introduce any additional hyper-parameters.
Unsupervised domain adaptation in person re-identification resorts to labeled source data to promote the model training on target domain, facing the dilemmas caused by large domain shift and large camera variations.
Optical flow, semantic segmentation, and surface normals represent different information modalities, yet together they bring better cues for scene understanding problems. In this paper, we study the influence between the three modalities.
We present a unifying framework for designing and analysing distributional reinforcement learning (DRL) algorithms in terms of recursively estimating statistics of the return distribution.
We propose a simple algorithm to train stochastic neural networks to draw samples from given target distributions for probabilistic inference, where a neural sampler is adaptively trained to approximate the likelihood.
We propose a novel online framework for active semi-supervised spectral clustering that selects pairwise constraints as clustering proceeds, based on the principle of uncertainty reduction.
We present a unified point-based framework for 3D point cloud segmentation that effectively optimizes pixel-level features, geometrical structures and global context priors of an entire scene for achieving higher performance.
We study the student-teacher strategy, in which a small and fast student network is trained with the auxiliary information provided by a large and accurate teacher network.
We present Marathon Environments, a suite of open source, continuous control benchmarks implemented on the Unity game engine, using the Unity ML- Agents Toolkit.
We investigate how to learn a kernel matrix for high dimensional data that lies on or near a low dimensional manifold. The kernel matrix is constructed by maximizing the variance in feature space subject to local constraints.
We introduce the new concept of mirror tracking to measure the robustness of a tracker and identify its over-fitting scenarios, and propose a new benchmark dataset and evaluation toolkit that can be used to measure failure recovery.
Neural language models (NLMs) exist in an accuracy-efficiency tradeoff space where better perplexity typically comes at the cost of greater computation complexity and shorter battery life.
We propose a Semantic Pixel-Level Adaptation Transform (SPLAT) approach to detector adaptation that efficiently generates cross-domain image pairs and can learn transformations with or without densely labeled data in the source.
We propose the 3D Pose Forecasting Network (3D-PFNet), a 3D pose forecasting network that combines recent advances on single-image human pose estimation and sequence prediction.
This paper describes a novel hierarchical attention network for reading comprehension style question answering, which aims to answer questions for a given narrative paragraph.
A novel online agent that learns a set of behavioral constraints by observation and uses these learned constraints as a guide when making decisions in an online setting while still being reactive to reward feedback.
We present DetectFusion, an RGB-D SLAM system that runs in real-time and can robustly handle semantically known and unknown objects that can move dynamically in the scene, while tracking and reconstructing them.
In this paper, we propose a novel iterative multi-task framework to complete the segmentation mask of an occluded vehicle and recover the appearance of its invisible parts.
PPI networks of differentially expressed (DE) genes in post mortem brain tissue samples of patients with Parkinson's disease. Hitherto unreported 37 PD disease markers were identified based on their topological significance in the networks.
A loss function focused on disparity and environment depth data reconstruction, and a Generative Adversarial Network (GAN) architecture able to deal with occluded information inference.
We propose a simple but effective multi-source domain generalization technique based on deep neural networks by incorporating optimized normalization layers specific to individual domains.
Our goal is to equip a dialogue agent that asks questions about a visual scene with object detection skills. We use Mask R-CNN object features as a replacement for ground-truth annotations in the Guesser module.
We propose a neural Modular Task-oriented Dialogue System(MTDS) framework, in which a few expert bots are combined to generate the response for a given dialogue context, in an end-to-end fashion.
We propose a multi-stream multi-task network to take advantage of using feature representations from preceding frames in a video sequence for joint learning of segmentation, depth, and motion.
MetaGenRL distills the experiences of many complex agents to meta-learn a low-complexity neural objective function that affects how future individuals will learn.
We propose an unsupervised learning approach to learn features from unlabeled point cloud "3D object" dataset by using part contrasting and object clustering with deep graph neural networks.
We propose Generative Latent Flow (GLF), which uses an auto-encoder to learn the mapping to and from the latent space, and an invertible flow to map the distribution in the latent Space to simple i.i.d noise.
We present a labelling-efficient method of training a CNN-based fish-detector on relatively small numbers (4,000) of project-domain underwater fish/no-fish images from 20 different habitats.
We propose a two-stage kin-face generation model to predict the appearance of a child given a pair of parents given a random selection process.
The task of fine-grained visual classification (FGVC) deals with classification problems that display a small inter-class variance such as distinguishing between different bird species or car models. The aim is to enhance the performance of a backbone CNN such as ResNet by including three efficient and lightweight components specifically designed for FGVC.
We propose a novel selective privacy preserving paradigm that allows users to custom define the scope and extent of their individual privacies, by marking their personal ratings as either public (which can be shared) or private (which are never shared and stored only on the user device).
We propose Multi-Task Zipping (MTZ), a framework to automatically merge correlated, pre-trained deep neural networks for cross-model compression.
We propose a hierarchical deformable part model for face detection and landmark localization that explicitly models part occlusion.
We introduce contextual decomposition (CD), an interpretation algorithm for LSTMs that captures the contributions of combinations of words or variables to the final prediction of an LSTM, without any changes to the underlying model.
A key challenge in the social network community is the problem of network generation -- that is, how can we create synthetic networks that match characteristics traditionally found in most real world networks?
We explore how to learn from multi-modality and propose cross-modal UDA (xMUDA) where we assume the presence of 2D images and 3D point clouds for 3D semantic segmentation.
We propose a latent bag of words (BOW) model for paraphrase generation.
Conditional generation without retraining the model using latent constraints .
We propose to obfuscate the images so that humans are not able to recognize their detailed contents, while machines can still utilize them to train new models.
In this paper, we propose the Coarse-grain Fine-grain Coattention Network (CFC), a new question answering model that combines information from evidence across multiple documents.
We introduce Recombinator Networks where coarse features inform finer features early in their formation such that finer features can make use of several layers of computation in deciding how to use coarse features.
In this paper, we present our latest progress in Emotion Recognition techniques, which combines acoustic features and facial features in both non-temporal and temporal mode in a multimodal fashion.
An age-progression module that can age-progress deep face features output by any commodity face matcher improves the closed-set identification accuracy of FaceNet and CosFace.
We investigate the cause of this phenomenon, identifying strong cues for predicting labels solely based on the claim, without considering any evidence. We create an evaluation set that avoids those idiosyncrasies.
We present a novel iterative disparity refinement process for stereo matching and apply it to the initially estimated disparity map to improve the overall quality of stereo matching.
This paper presents an approach for estimating the Semantic Textual Similarity of full English sentences as specified in Shared Task 2 of SemEval-2015.
We present DeblurGAN, an end-to-end learned method for motion deblurring.
We propose a non-adaptive Normalization Propagation technique for removing internal covariate shift in deep networks.
We present an end-to-end audiovisual model based on residual networks and Bidirectional Gated Recurrent Units (BGRUs) which simultaneously learns to extract features directly from the input image pixels and audio waveforms and performs within-context word recognition.
Our goal is to significantly speed up the runtime of current state-of-the-art stereo algorithms to enable real-time inference. Towards this goal, we developed a differentiable PatchMatch module that allows us to discard most disparities without requiring full cost volume evaluation.
In this paper, we present a frequency domain neural network for image super-resolution.
A comparative study of CNN-based super-resolution models for space-based space surveillance.
We propose a deep end-to-end learning framework for monocular depth estimation, which learns the direct mapping from a color image to the corresponding depth map.
We study a classification scheme that applies the soft-thresholding nonlinear mapping in a dictionary, followed by a linear classifier. A novel supervised dictionary learning algorithm tailored for this low complexity classification architecture is proposed.
We propose a first attempt at alleviating the need for re-training. Rather than fixing the network at training time, we train a ``Dynamic-Net'' that can be modified at inference time.
This report presents very deep two-stream ConvNets for action recognition, by adapting recent very deep architectures into video domain.
We propose a hybrid model that combines graphical inference with a learned inverse model, which we structure as in a graph neural network, while the iterative algorithm as a whole is formulated as a recurrent neural network.
An empirical study on the benefit of encoding 15,000 object categories for action using 6 datasets totaling more than 200 hours of video and covering 180 action classes.
The rise of multi-million-item dataset initiatives has enabled data-hungry machine learning algorithms to reach near-human semantic classification at tasks such as object and scene recognition. Here we describe the Places Database, a repository of 10 million scene photographs labeled with scene semantic categories and attributes.
We propose a Layered Memory Network (LMN) that represents frame-level and clip-level movie content by the Static Word Memory module and the Dynamic Subtitle Memory module.
Transfer learning, in which a network is trained on one task and re-purposed on another, is often used to produce neural network classifiers when data is scarce or full-scale training is too costly. When using lifelong learning strategies, this process preserves the robustness of the source network while achieving high accuracy.
We introduce a purely feed-forward architecture for semantic segmentation that exploits statistical structure in the image and in the label space without setting up explicit structured prediction mechanisms.
This paper presents methods of modeling and predicting face recognition (FR) system performance based on analysis of similarity scores.
Seed propagation-based stereo matching can reduce ambiguity occuring when a pixel from one image has different putative correspondents in the other one due to difficult areas.
We propose a protocol applicable on a large scale to predict novel DDIs based on similarity of drug interaction candidates to drugs involved in established DDIs.
We propose a hierarchical attention model by utilizing both of the global CNN features and the local object features for more effective feature representation and reasoning in image captioning.
This survey focuses on Data Augmentation, a data-space solution to the problem of limited data.
We propose an end-to-end video SR network to super-resolve both optical flows and images in a coarse- to-fine manner.
A typical architecture for end-to-end entity linking systems consists of three steps: mention detection, candidate generation and entity disambiguation. In this study we propose an extreme simplification of the entity linking setup that works surprisingly well.
We propose a novel three-dimensional fusion hierarchical reconstruction method that utilizes a multi-view feature combination method and a hierarchical prediction strategy to unify the single view and any number of multiple views 3D reconstructions.
This paper tackles RGBD based gaze estimation with Convolutional Neural Networks (CNNs) and proposes a CNN-based multi-task learning framework to simultaneously refine depth images and predict gaze points.
We propose two simple but surprisingly effective modifications to the standard visual question answering models that allow them to make use of weak supervision in the form of unanswered questions associated with images and a simple data augmentation strategy inspired by our insights.
We propose a Fractional Heatmap Regression for high-resolution video-based face alignment and pose estimation.
We propose the Automated Problem Identification (API) algorithm, which uses an evolutionary algorithm interface to TensorFlow to manipulate a deep neural network to decide if a dataset represents a classification or a regression problem.
This paper presents a method for estimating disparity images from a stereo image sequence in an accurate and temporally consistent fashion.
We present Temporal Sequence Distillation (TSD), which distills a long video sequence into a very short one for transmission, while maintaining high recognition accuracy, when accessing only a few frames.
In this paper, we propose a novel single-branch attentive network architecture RNN-Rasterization-CNN (Sketch-R2CNN for short) to fully leverage the dynamics in sketches for recognition.
This paper presents a novel approach for automatically generating image descriptions: visual detectors, language models, and multimodal similarity models learnt directly from a dataset of image captions.
This paper proposes a method for improving the detection accuracy while supporting a real-time operation by modeling the bounding box of YOLOv3, which is the most representative of one-stage detectors, with a Gaussian parameter and redesigning the loss function.
We propose a network optimization strategy inspired by both of the developmental trajectory of children's visual object recognition capabilities, and Bar (2003), who hypothesized that basic level information is carried in the fast magnocellular pathway through the prefrontal cortex (PFC) and then projected back to inferior temporal cortex (IT), where subordinate level categorization is achieved.
We propose a region-based approach for detecting occlusion between two consecutive frames.
We propose a novel neural decision tree based on Dirac symbol, which embeds conditioned variables that only occur in the condition of branch and employs complex neural networks to generate the output.
We propose a new encoder-decoder approach to learn distributed sentence representations from unlabeled sentences that performs well in practice.
We revisit the algorithm introduced in [1] and present a deep interpretation of this framework that achieves state-of-the-art under such challenging scenarios.
We propose a deep autoencoder framework which regresses linear, high dynamic range data from non-linear, saturated, low dynamic range panoramas and recover the HDR after the fact via a novel, learning-based inverse tonemapping method.
We address unsupervised learning of scene depth and robot ego-motion where supervision is provided by monocular videos, as cameras are the cheapest, least restrictive and most ubiquitous sensor.
A comparison of two state-of-the-art visual odometry systems for use in an agricultural field environment.
We propose a novel approach which learns grounding by reconstructing a given phrase using an attention mechanism, which can be either latent or optimized directly.
This work was performed under the following financial assistance award: 60NANB18D279 from U.S. Department of Commerce, National Institute of Standards and Technology, and also funding from SAP SE .
A novel graph-neural-network-based system to effectively represent large-scale 3D point clouds with the applications to autonomous driving.
We extend the recent reward augmented maximum likelihood approach to token-level loss smoothing and propose improvements to the sequence-level smoothing approach.
We exploit an efficient algorithm for structured edge prediction to extract regions from structured edge detection and propose a hierarchical grouping method for effective detection and recognition problems.
We introduce HypE, a convolution-based embedding method for knowledge hypergraph completion where each relation is defined on any number of entities, and demonstrate its effectiveness.
Grempt is a graph regularized meta-path based transductive regression model for heterogeneous networks.
We propose an efficient and yet flexible non-local relation representation based on a novel class of graph neural networks, which can be used for visual recognition tasks.
The content of today's social media is becoming more and more rich, increasingly mixing text, images, videos, and audio. It is an intriguing research question to model the interplay between these different modes in attracting user attention and engagement, and determine the relative performance of author vs. content features.
Binary neural networks have attracted tremendous attention due to the efficiency for deploying them on mobile devices.
We provide a new perspective on knowledge distillation based on a decision boundary, which is one of the most important component of a classifier.
We present a novel method to generate synthetic human part segmentation data using easily-obtained human keypoint annotations, and achieve state-of-the-art results.
We combine two existing objective functions to make images and captions close in a joint embedding space while adapting the alignment of word embeddings between existing languages in our model.
This paper proposes an innovative framework to learn a nonlinear 3DMM model from a large set of unconstrained face images, without collecting 3D face scans.
In this paper, we study object detection using a large pool of unlabeled images and only a few labeled images per category, named “few-example object detection"
This paper presents a novel progressive Retinex framework, in which illumination and noise of low-light image are perceived in a mutually reinforced manner, leading to noise reductionlow-light enhancement results.
We propose a new OOD detection approach that can be easily applied to an existing classifier and does not need to have access to OOD samples.
This paper presents a novel framework for designing support vector machines (SVMs), which does not impose restriction on the SVM kernel to be positive-definite and allows the user to define memory constraint in terms of fixed template vectors.
The EpiReader is an end-to-end neural model for machine comprehension of text, outperforming previous neural models.
We generalize the interactive-predictive approach, typically applied in to machine translation field, to tackle other multimodal problems namely, image and video captioning.
We present a new dataset and models for comprehending paragraphs about a changing world along with a full annotation of entity states (location and existence) during those changes (81k datapoints).
This paper describes our submission to the 2017 BioASQ challenge. We participated in Task B, Phase B which is concerned with biomedical question answering (QA).
We present a neural model for question generation from knowledge base triples in a "Zero-Shot" setup, that is generating questions for triples containing predicates, subject types or object types that were not seen at training time.
We propose an adversarial defense mechanism for deep neural networks that is non-differentiable and robust to adversarial attacks.
Supervised learning from training data with imbalanced class sizes, a commonly encountered scenario in real applications such as anomaly/fraud detection, has long been considered a significant challenge in machine learning. Motivated by recent progress in curriculum and self-paced learning, we propose to adopt a semi-supervised learning paradigm by training a deep neural network to selectively add unlabelled data together with their predicted labels to the training dataset.
We sought to develop a stool detection and tracking system using computer vision and deep convolutional neural networks that could be used by patients, providers, and researchers in the assessment of chronic gastrointestinal (GI) disease.
We propose a frame-by-frame but computationally efficient approach for video object segmentation by clustering visually similar generic object segments throughout the video.
Neural networks for natural language reasoning have largely focused on extractive, fact-based question-answering and common-sense inference.
This paper proposes an adapted structure of MapReduce programming model using MPI for multimedia indexing.
We propose a method for predicting social tags from MP3 files, allowing for insertion of previously unheard music into recommender systems.
Sketching is more fundamental to human cognition than speech. Deep Neural Networks (DNNs) have achieved the state-of-the-art in speech-related tasks but have not made significant development in generating stroke-based sketches in vector format.
Datasets are an integral part of contemporary object recognition research. They have been the chief reason for the considerable progress in the field, not just as source of large amounts of training data, but also as means of measuring and comparing performance of competing algorithms.
We explore the impact of semantic manipulation on DNNs predictions by manipulating the semantic attributes of images and generate"unrestricted" adversarial examples which fool the learner.
This paper studies the case where the annotations are in the format of question-answering (QA) and proposes an effective way to learn useful representations for other tasks.
We present a comprehensive approach to evaluating the performance of 10 state-of-the-art recently-developed VPR techniques, which utilizes three standardized metrics: Matching Performance b) Matching Time c) Memory Footprint. Together this analysis provides an up-to-date and widely encompassing snapshot of contemporary approaches to the VPR problem.
We propose an approach to build a network that captures the putative mechanisms at play in the given condition, by using datasets from multiple experiments studying the same phenotype, and validate the results in two ways.
This paper addresses the problem of 3D human pose estimation from a single image. We show that more precise pose estimates can be obtained using NxN distance matrices, and formulating the problem as a 2D-to-3D distance matrix regression.
We do not speak word by word from scratch; our brain quickly structures a pattern like \textsc{sth do sth at someplace} and then fill in the detailed descriptions.
We propose a latent class-conditional noise model that naturally embeds the noise transition under a Bayesian framework. We then deduce a dynamic label regression method to iteratively infer latent labels, to stochastically train the classifier and to model the noise.
ICR-Mo is a genetic determinant of transferable colistin resistance in Moraxella species.
We take one of the simplest inference methods, a truncated max-product Belief Propagation, and add what is necessary to make it a proper component of a deep learning model: We connect it to learning formulations with losses on marginals and compute the backprop operation.
We propose a semantic-aware architecture which can translate artworks to photo-realistic visualizations, thus reducing the gap between visual features of artistic and realistic data.
This paper addresses the problem of evaluating learning systems in safety critical domains such as autonomous driving, where failures can have catastrophic consequences. Our approach focuses evaluation on adversarially chosen situations, while still providing unbiased estimates of failure probabilities.
We introduce MultiWOZ 2.1, a new multi-domain dialogue dataset with user dialogue acts and state-of-the-art state tracking models.
We consider the tracking problem as a special type of object detection problem, which we call instance detection. With proper initialization, a detector can be quickly converted into a tracker by learning the new instance from a single image.
We propose a small DNN architecture called SqueezeNet that achieves AlexNet-level accuracy with 50x fewer parameters.
In this work, we formulate a Joint Recurrent Learning (JRL) model for exploring attribute context and correlation in order to improve attribute recognition given small sized training data with poor quality images.
We present the results from the second shared task on multimodal machine translation and multilingual image description. Nine teams submitted 19 systems to two tasks.
We propose a novel learning framework for domain-transfer learning based on both instances and attributes.
The CLEVR dataset of natural-looking questions about 3D-rendered scenes has recently received much attention from the research community, but state-of-the-art models often do not exhibit systematicity after being trained on CLEVR.
This paper presents a new hybrid algorithm for retinal vessels segmentation on fundus images. The proposed algorithm overcomes the difficulty when dealing with the challenging situations.
In this paper, we present a method for real-time multi-person human pose estimation from video by utilizing convolutional neural networks.
We develop a structured spatial attention mechanism which is end-to-end trainable and can be integrated with any feed-forward convolutional neural network.
This paper proposes a series of new approaches to improve generative adversarial network (GAN) for conditional image synthesis.
We analyze the performance of different sentiment classification models on syntactically complex inputs like A-but-B sentences, using contextualized ELMo embeddings.
We propose a robust scene text detection method with adaptive text region representation.
We propose simple yet efficient mixture of pre-processing experts (MoPE) model to handle various image distortions including low resolution and noisy images.
This paper proposes an alternative approach based on a novel type of recurrent neural network, specifically designed for sequence labeling tasks where the data is hard to segment and contains long-range bidirectional interdependencies.
We present a new Active Learning approach for classifying objects from streams of 3D point cloud data that is independent on the data order.
We develop a hierarchical deep network architecture and the corresponding loss that can be trained from weak supervision, such as bounding boxes or image level labels, as well as from strong per-pixel supervision.
We propose two schemes that exploit the synthetic data to boost the performance of crowd counting in the wild, and propose a crowd counting method via domain adaptation.
We propose a modified dynamic time warping (DTW) algorithm that compares gesture-position sequences based on the direction of the gestural movement.
Obstacle detection systems use vehiclemounted sensors to detect obstuctions, such as other vehicles, bicyclists, pedestrians, road debris, or animals, in a vehicle’s path and alert the driver. These systems also help drivers to get a large visibility area when the visibility conditions is reduced such as night, fog, snow, rain, ...
We pose this problem as a rank minimization problem, where the goal is to decompose the corrupted data matrix as the sum of a clean, self-expressive, low-rank dictionary plus a matrix of noise/outliers.
Pruning filters is an effective method for accelerating deep neural networks (DNNs), but most existing approaches prune filters on a pre-trained network directly which limits in acceleration. In this paper, we add an extra cluster loss term in the loss function which can force filters in each cluster to be similar online.
Pre-trained DNNs with active label querying can be used for cost-effective training of DNN models.
In this paper, we propose a novel approach to learn 3D human mesh reconstruction without any ground truth meshes.
We present a novel approach leveraging a task-independent intrinsic reward function trained on spontaneous smile behavior that captures positive affect. The policy based on intrinsic affective rewards successfully increases the duration of episodes, the area explored and reduces collisions.
We infer and generate three-dimensional (3D) scene information from a single input image and without supervision.
We develop a novel methodology for using the semantics-aware higher-order layers of deep neural networks for recognizing specific places from within a reference database for extreme perceptual challenges that involve both great viewpoint change and environmental appearance change.
Unsupervised Neural Architecture Search using only images, but no human-annotated labels.
We propose a Pose-driven Deep Convolutional (PDC) model to learn improved feature extraction and matching models from end to end.
We propose the first, to the best of our knowledge, joint multi-view convolutional network to handle large pose variations across faces in the wild, and elegantly bridge face detection and facial landmark localisation tasks.
This work introduces a new approach to localize anomalies in surveillance video using a Siamese convolutional neural network to learn a distance function.
This paper proposes Bayesian mosaic, a parallelizable composite posterior for scalable Bayesian inference on a broad class of multivariate discrete data models.
A systematic review of retinal imaging and image analysis methods and their clinical implications.
Recurrent Level Set (RLS) 1 to employ Gated Recurrent Unit under the energy minimization of a variational LS functional for semantic segmentation in the wild.
We advance the state-of-the-art approaches by developing a context-aware attentive neural network approach for entity linking on Wikidata.
This paper presents a case study of adapting the RMPE pose estimation network to the domain of the DARPA Communicating with Computers (CWC) program [3], as represented by the EGGNOG data set.
This work aims at modeling how the meaning of gradable adjectives of size (`big', `small') can be learned from visually-grounded contexts.
We introduce Resnet in Resnet (RiR), a deep dual-stream architecture that generalizes ResNets and standard CNNs and is easily implemented with no computational overhead.
We propose a unified view of normalization techniques, as forms of divisive normalization, which includes layer and batch normalization.
This work presents an end-to-end trainable deep bidirectional LSTM (Long-Short Term Memory) model for image captioning.
In this paper, we propose a new concept called hyper-path-based random walks to preserve the structural information of hyper-networks according to the analysis of the indecomposability.
We propose a novel approach to build on-the-fly knowledge bases in a query-driven manner, by dynamically acquiring relevant facts as timely and comprehensively as possible.
We present a multimodal video database annotated with sensory and semantic saliency, events, cross-media semantics, and emotion, for training and evaluation.
We consider dialogue state as an explicit fixed-sized memory, and propose a selectively overwriting mechanism for more efficient DST.
Multi-modal distributional models learn grounded representations for improved performance in semantics. In this study, we systematically compare deep visual representation learning techniques, experimenting with three well-known network architectures.
This paper proposes an image super-resolution reconstruction method based on registration for subpixel-shifted images acquisition.
Proteomics techniques have been used to generate comprehensive lists of protein interactions in a number of species. This gap can be bridged by combining data from proteomics experiments with data from established structure determination techniques.
Automatic dietary assessment based on vision-based approaches and techniques .
Multilingual BERT is surprisingly good at zero-shot cross-lingual model transfer, in which task-specific annotations in one language are used to fine-tun the model for evaluation in another language.
We propose a model-free deep reinforcement learning method that leverages a small amount of demonstration data to assist a reinforcement learning agent.
In this paper, we propose an anchor-free lesion detector. The anchor mechanism is removed and lesions are formalized as single keypoints.
This paper proposes a biologically-inspired recurrent neural network, called shuttleNet, which can beat state-of-the-art methods for sequence learning.
This paper presents an innovative UDA-based person re-identification network that is capable of adapting images at both spatial and pixel levels simultaneously.
In this paper, we propose a novel application of Generative Adversarial Networks (GAN) to the synthesis of cells imaged by fluorescence microscopy and propose new models with casual dependencies between image channels that can generate multi-channel images.
We propose ViPR, a novel architecture for long-term 6DoF VO that leverages synergies between absolute pose estimates (from PoseNet-like architectures) and relative pose estimates by combining both through recurrent layers.
This paper introduces the idea of sparse representation into the architecture of the deep learning network and comprehensively utilizes the sparse representation of well multidimensional data linear decomposition ability and the deep structural advantages of multilayer nonlinear mapping to complete the complex function approximation in the deep Learning model.
Fine-tuning BERT improves performance and generalization capability across downstream tasks, which leads to wider optima and easier optimization.
We propose an approach to compute a disentangled shape representation for a face image, which can be used for part-wise face editing while preserving the original identity of the subject.
In this paper, the edge caching problem in fog radio access networks (F-RAN) is investigated. We propose an online content popularity prediction algorithm by leveraging the content features and user preferences, and an offline user preference learning algorithm by using the"Online Gradient Descent"(OGD) method.
We explore an innovative strategy for image denoising by using convolutional neural networks (CNN) to learn pixel-distribution from noisy data.
We propose Additive Focal Variational Auto-encoder, a novel approach that can arbitrarily manipulate high-resolution face images using a simple yet effective model and only weak supervision of reconstruction and KL divergence losses.
We propose a method to identify the source and target regions of a copy-move forgery so allow a correct localisation of the tampered area.
We propose a Hierarchical Attention-based Crowd Counting Network that employs attention mechanisms at various levels to selectively enhance the features of the network.
We present two ideas that, in combination, enable adversarial training with the computationally less expensive Fast Gradient Sign Method (FGSM) and a learnable regularization step prior to the neural network.
In this paper, we consider the problem of subsampling and reconstruction of signals that reside on the vertices of a product graph, such as sensor network time series, genomic signals, or product ratings in a social network.
We propose a novel approach to segment hand regions in egocentric video that requires no manual labeling of training samples, improve state-of-the-art techniques, and improve robustness to noise.
In this paper, we explored the idea of employing a pre-trained convolutional neural network (CNN) model trained on large public datasets of general human poses and fine-tuning the model for in-bed pose estimation.
Comparison of synthetic image datasets for traffic sign detection and their applicability.
We proposed an end-to-end deep learning-based simultaneous localization and mapping system following conventional visual odometry pipelines while training them in an unsupervised manner.
The main obstacle to weakly supervised semantic image segmentation is the difficulty of obtaining pixel-level information from coarse image-level annotations. FickleNet explores diverse combinations of locations on feature maps created by generic deep neural networks.
We introduce super-fine attributes, which describe multiple, integral concepts of a single trait as multi-dimensional perceptual coordinates, improving image retrieval and closing the semantic gap.
We survey several strong studies in the recently years for 3-D human pose estimation based on the methods that use the Convolutional Neural Network (CNN) for 2-D pose estimation, and then using 3- d pose library for mapping the 2- D results into the 3D space.
We present a novel approach for supervised domain adaptation that is based upon the probabilistic framework of Gaussian processes (GPs) for facial expression classification.
We propose to utilize randomization at inference time to mitigate adversarial effects.
We focus on grounding (i.e., localizing or linking) referring expressions in images, e.g., "largest elephant standing behind baby elephant".
In this paper, we present a multimodal Recurrent Neural Network (m-RNN) model for generating novel sentence descriptions.
This paper introduces a concept of a trainable gate function and proposes a channel pruning method which finds automatically the optimal combination of channels using a simple gradient descent training procedure.
Generative adversarial networks (GANs) while being very versatile in realistic image synthesis, still are sensitive to missing modes and not capturing the full data distribution.
Emerging research in Neural Question Generation (NQG) has started to integrate a larger variety of inputs, and generating questions requiring higher levels of cognition.
We create a unified multi-view sentence representation learning framework, in which, one view encodes the input sentence with a Recurrent Neural Network (RNN), and the otherview encodes it with a simple linear model, and the training objective is to maximise the agreement specified by adjacent context information between two views.
We propose a novel approach for unsupervised zero-shot learning (ZSL) of classes based on their names.
We propose a module, called mixed context network, and show that our presented system outperforms most existing semantic segmentation systems by making use of this module.
We propose a method for room layout estimation that does not rely on the typical box approximation or Manhattan world assumption. Instead, we reformulate the geometry inference problem as an instance detection task.
We introduce three categories of sensors that may help improve the accuracy and reliability of an expression recognition system by tackling the challenges mentioned above in pure image/video processing, which may not be resolved by only analysing images/videos in FER system.
We propose an end-to-end network for action anticipation and forecasting with memory, to both anticipate the current action and foresee the next one.
The objective of this paper is self-supervised learning of feature embeddings suitable for matching correspondences along the videos, which we term correspondence flow.
We propose novel models using deep neural networks (DNNs) to automatically learn effective patterns from categorical feature interactions and make predictions of users’ ad clicks.
We propose an image based end-to-end learning framework that helps lane-change decisions for human drivers and autonomous vehicles.
In this paper, a combination of 3D image and feature pyramid is exploited to integrate lower-level texture features with high-level semantic features, thus leading to a higher recall.
N-HANS is a Python toolkit for in the wild audio enhancement, including speech, music, and general audio denoising, separation, and selective noise or source suppression.
We propose a layer augmentation technique that adds shortcut connections with a linear gating mechanism, and can be applied to almost any network model. The augmentation introduces only one extra parameter per layer, and provides easier optimization by making degeneration into identity mappings simpler.
We propose a framework that learns a representation transferable across different domains and tasks in a label efficient manner in a metric learning-based approach.
We use two-dimensional maps to encode latent states in RNNs for image captioning, achieving better performance with comparable parameter sizes.
A new ensemble deep learning framework for imbalanced video data and event detection .
We present a novel feature fusion strategy that proceeds in a hierarchical fashion, first fusing the modalities two in two and only then fusing all three modalities for multimodal sentiment analysis.
We introduce the discussion mechanism into the multiagent communicating encoder-decoder architecture for Natural Language Generation (NLG) tasks and prove that by applying it, the communication between agents becomes more effective.
We balance between a measure of privacy and another of utility by leveraging adversarial learning to find a sweeter tradeoff.
In this work, novel approaches are proposed to train Deep Neural Networks for morphing detection: in particular generation of simulated printed-scanned images together with other data augmentation strategies and pre-training on large face recognition datasets, allowed to reach state-of-the-art accuracy on challenging datasets from heterogeneous image sources.
We propose a stroke controllable style transfer network that can achieve continuous and spatial stroke size control.
We introduce aPhysically Adversarial Intelligent Network (PAIN), wherein self-driving vehicles interact aggressively in the CARLA simulation environment, improving their resilience to environmental uncertainty and corner case failures resulting in collisions.
This paper presents a robust and efficient ALPR system based on the state-of-the-art YOLO object detector.
Neuron Importance-Aware Weight Transfer (NIWT) learns to map domain knowledge about novel “unseen” classes onto this dictionary of learned concepts and then optimizes for network parameters that can effectively combine these concepts.
Deep models are state-of-the-art for many vision tasks including video action recognition and captioning, but little is known about the evidence used to make such decisions. In this work, we devise a formulation that simultaneously grounds evidence in space and time, in a single pass.
We propose four different point cloud simplification methods which decimate the perceived point cloud by relying on class-specific local and global statistics still maintaining more points in the proximity of class boundaries.
We first propose a multi-view local descriptor, which is learned from the images of multiple views, for the description of 3D keypoints, and develop a robust matching approach, aiming at rejecting outlier matches based on the efficient inference via belief propagation on the defined graphical model.
In this paper, we propose a novel graph-based segmentation framework, called superpixel cut, for figure-ground segmentation.
We propose a transfer learning procedure, denoted NetTailor, in which layers of a pre-trained CNN are used as universal blocks that can be combined with small task-specific layers to generate new networks.
Neural Body Fitting (NBF) integrates a statistical body model within a CNN, leveraging reliable bottom-up semantic body part segmentation and robust top-down body model constraints.
In this paper, we propose a new inference model that estimates the latent vector from the feature of GAN discriminator from the latent translation.
We present an end-to-end trainable method for visual-inertial odometry which performs fusion of data at an intermediate feature-representation level.
This paper introduces the Geometry-Aware Generative Adversarial Networks (GAGAN) for incorporating geometric information into the image generation process.
We propose part-aware sampling, a method that uses human intuition for the hierarchical relation between objects. We demonstrate the power of our method on OID and compare the performance against a pretrained model.
We propose a method based on Stein's unbiased risk estimator for training DNN denoisers based only on the use of noisy images in the training data with Gaussian noise.
We introduce a regularized probabilistic Gaussian Mixture Model based on manifold structure for data clustering.
We propose Learning with Incremental Labels and Adaptive Compensation(LILAC), a novel approach to curriculum learning. LILAC emphasizes incrementally learning labels instead of incrementallylearning difficult samples.
In this paper, a two-layer fractional-order chaotic network, which can simulate the mechanism of visual selection and shifting, is established.
We propose a bimodal neural network architecture that combines audio and video signals for the synchronization task in mulsemedia applications.
We propose an approach to augment CNNs with out-distribution learning in order to reduce misclassification rate by rejecting adversarial examples in security sensitive and safety-critical systems using deep CNNs.
We propose a novel framework for the social recommendation over streaming environments that adaptively captures the behaviors of social users and their interactions with influential official accounts to predict their long-term and short-term interests.
We propose an adaptative weighting scheme that uses a tree-structured gate and an ensemble of deep regressors for face alignment.
We present an attack that maintains the imperceptibility property of adversarial examples while being outside of the certified radius, and fool certifiably robust networks.
We introduce user tagging credibility in the retrieval process to increase relevance by favoring images uploaded from users with good credibility estimates and diversify results by using a k-Means algorithm.
DeepMimic training method uses a small portion of labeled data and a large amount of unlabeled data for the training process, as expected in a real-world scenario, in order to achieve remarkable (classification) results.
We propose DAR-Net, a novel network architecture that focuses on dynamic feature aggregation and self-adaptive pooling.
This paper presents a detailed description of an advanced real-time correlation-based stereo algorithm running completely on the graphics processing unit (GPU) which is several times faster than commercially available CPU-based implementations.
We introduce a new method which models occlusion explicitly and a new warping way that facilitates the learning of large motion.
We present a theoretically grounded approach to train deep neural networks, including recurrent networks, subject to class-dependent label noise. We propose two procedures for loss correction that are agnostic to both application domain and network architecture.
We propose a new explanation for the apparent longevity of test data: Many proposed models are similar in their predictions and we prove that this similarity mitigates overfitting.
The landmark recognition problem is far from being solved, but with the use of features extracted from intermediate layers of Convolutional Neural Networks (CNNs), excellent results have been obtained.
Feature Hierarchy Encoder-Decoder Network for Face Detection (FHEDN)
We compare the performance of state of the art monocular SLAM systems on forest data and use visual appearance statistics to characterise the differences between forests and other environments, including a photorealistic simulated forest.
In this project, we aim to build a Text-to-Speech system able to produce speech with a controllable emotional expressiveness. We propose a methodology for solving this problem.
Using visual model-based learning for deformable object manipulation is challenging due to difficulties in learning plannable visual representations along with complex dynamic models. In this work, we propose a new learning framework that jointly optimizes both the visual representation and the dynamics model using contrastive estimation.
We explore new approaches to combining information encoded within the learned representations of autoencoders such that a resynthesised output is trained to fool an adversarial discriminator for real versus synthesised data.
We propose a scalable RRAM based in-memory computing design, termed XNOR-RRAM, which is fabricated in a 90nm CMOS technology with monolithic integration of RRAM devices between metal 1 and 2.
The task of associating images and videos with a natural language description has attracted a great amount of attention recently. Rapid progress has been made in terms of both developing novel algorithms and releasing new datasets. However, the state-of-the-art results on some of the standard datasets have been pushed into a regime where it has become more and more difficult to make significant improvement.
In this paper, we propose GIF2Video, the first learning-based method for enhancing the visual quality of GIFs in the wild.
In this paper, we propose to construct a local deep neural network for age and gender classification.
We propose Top-down Attention Action VLAD, a deep recurrent architecture with built-in spatial attention that performs temporally aggregated V LAD encoding for action recognition from videos.
We present ActionXPose, a novel 2D pose-based algorithm for posture-level Human Action Recognition (HAR) based on OpenPose detector from RGB videos.
This paper takes a holistic approach to conduct empirical comparison and analysis of four representative DL frameworks with three unique contributions.
We propose a semi-supervised self-training method to increase the amount of training data, prevent overfitting and improve the performance of deep models by proposing a novel selection algorithm.
We provide a comprehensive overview of related data visualization tools, existing techniques, as well as systems for the analyzing volumes of diverse scholarly data.
In this paper, we enrich the image information with textual data using image captions and external knowledge bases to generate more coherent answers.
In this paper, we study how to incorporate node diversity into influence maximization (IM) and propose two approximation algorithms based on non-monotonic submodular maximization and traditional IM respectively.
We focus on accelerating the matrix completion using faster randomized singular value decomposition (rSVD) for image inpainting and personalized recommender system, etc.
This study isolated novel genes and functions potentially involved in LMNA network of regulation that could be involved in laminopathies such as the Hutchinson-Gilford progeria syndrome.
We propose an efficient parallel framework for translating embedding methods, called ParTrans-X, which enables the methods to be paralleled without locks by utilizing the distinguished structures of knowledge graphs.
This paper tests the hypothesis that modeling a scene in terms of entities and their local interactions, as opposed to modeling the scene globally, provides a significant benefit in generalizing to physical tasks in a combinatorial space the learner has not encountered.
Stereo matching algorithms are nearly always designed to find matches between a single pair of images. A method is presented that was specifically designed to operate on sequences of images, and it ranks as one of the fastest and most accurate real-time stereo matching methods.
We propose a novel scheme for human action recognition in videos, using a 3-dimensional Convolutional Neural Network (3D CNN) based classifier.
Self-supervised pre-training with HN-labels can be used to replace ImageNet, while using 25x less images and without any manual labeling.
We consider the problem of uncertainty estimation in the context of (non-Bayesian) deep neural classification. We demonstrate that such techniques tend to introduce biased estimates for instances whose predictions are supposed to be highly confident. We develop an uncertainty estimation algorithm that selectively estimates the uncertainty of highly confident points, using earlier snapshots of the trained model.
We propose an enhanced perceptual super-resolution network that achieves state-of-the-art trade-off between distortion and perceptual quality for single image SR.
We present a framework for building speech-to-text translation using only monolingual speech and text corpora, in other words, speech utterances from a source language and independent text from a target language.
This paper focuses on the temporal aspect for recognizing human activities in videos; an important visual cue that has long been undervalued.
We present a general-purpose classifier for graphs, which is conceived on an interplay between dissimilarity representation, clustering, information-theoretic techniques, and evolutionary optimization algorithms. The improvement focuses on a specific key subroutine devised to compress the input data.
We develop an inference principle, named mixup inference (MI), for mixup-trained models, which can further improve the adversarial robustness for the models trained by mixup and its variants.
HyperCon is an image-to-video model transfer method that transforms any well-trained image model into a temporally consistent video model without fine-tuning.
In this paper, we propose Occupancy Networks, a new representation for learning-based 3D reconstruction methods. In contrast to existing approaches, our representation encodes a description of the 3D output at infinite resolution without excessive memory footprint.
Sample inefficiency of deep reinforcement learning methods is a major obstacle for their use in real-world applications. We propose a training procedure where policy networks are first trained on human data and later fine-tuned by reinforcement learning.
We propose a simple yet effective instance segmentation framework, termed CondInst (conditional convolutions for instance Segmentation), using dynamic instance-aware networks.
We introduce relational graph convolutional networks and apply them to two standard knowledge base completion tasks: link prediction and entity classification.
We introduce a Transformer Embedding Dialogue policy based on a transformer architecture, where the self-attention mechanism operates over the sequence of dialogue turns.
We show that estimating people flows across image locations between consecutive images and inferring the people densities from these flows instead of directly regressing them makes it possible to impose much stronger constraints encoding the conservation of the number of people, which significantly boost performance without requiring a more complex architecture.
We propose an unsupervised model-based disentanglement training, which learns to disentangle scene from lens occlusions and can regress the occlusion model parameters.
We propose a fast event-driven representation (EDR) that enables fast real-time inference/learning in video applications that require interaction between an agent and the world such as game-playing, virtual robotics, and domain adaptation.
We hypothesize that end-to-end neural image captioning systems work seemingly well because they exploit and learn distributional similarity in a multimodal feature space by mapping a test image to similar training images in this space and generating a caption from the same space.
Part-based representations have been shown to be very useful for image classification. Learning part-based models is often viewed as a two-stage problem. We unify the two stages and learn the image classifiers and a set of shared parts jointly.
In this paper, we propose MDNet to establish a direct multimodal mapping between medical images and diagnostic reports that can read images, generate diagnostic reports, retrieve images by symptom descriptions, and visualize attention, to provide justifications of the network diagnosis process.
We compare several features and parameter configurations and show that the modern representations based on Fisher encoding and convolutional neural network based features lead to comparable or even better performance than 3D methods.
We propose an efficient framework to address the clustering problem on Riemannian manifolds, which preserves the geometric structure of the original space, but is computationally efficient.
Neural Architecture Search for Semantic Image Segmentation using Gradient-based Architecture Search .
We proposed a novel generative adversarial net capable of learning the disentangled representation in a completely unsupervised manner, which captures more semantic representations.
We propose a dynamic clustering algorithm based on a multivariate Gaussian mixture model that efficiently imputes missing values to generate a "pseudo-complete" dataset.
We propose a model that embeds multi-relational graph data in the Poincare ball model of hyperbolic space, which captures simultaneous hierarchies.
Deep end-to-end visual semantic information pursuit, a visual scene semantic interpretation task combining visual perception and visual context reasoning.
We propose a curriculum learning strategy to gently change the training process from a fully guided scheme using the true previous token, towards a less guided scheme which mostly uses the generated token instead.
One-shot video-based person re-identification exploits the unlabeled data by using a single-labeled sample for each individual to train a model.
We introduce Multi-Camera Action Dataset (MCAD), which is designed to evaluate the open view classification problem under the surveillance environment, where the training and test data are often resemble similar environment conditions.
In this paper, we propose a novel neural approach for paraphrase generation, where we add residual connections between LSTM layers.
Data augmentation is a critical component of training deep learning models for object detection, and learning specialized data augmentation policies improve generalization performance.
We propose a novel domain generalization framework for the generalizable semantic segmentation task, which enhances the generalization ability of the model from two different views, including the training paradigm and the data-distribution discrepancy.
We solve the dosage and missing-wedge problems in electron tomography by combining generative adversarial models with state-of-the-art network architectures, improving the resolution to 0.71 angstrom.
We address the issue of speeding up the training of convolutional neural networks by studying a distributed method adapted to stochastic gradient descent.
We propose a Proposal-Free Network (PFN) to address the instance-level object segmentation problem, which outputs the instance numbers of different categories and the pixel-level information on 1) the coordinates of the instance bounding box each pixel belongs to, and 2) the confidences of each pixel, based on pixel-to-pixel deep convolutional neural network.
We explore an alternative way of identifying a target object using language referring expressions, ensuring temporally coherent predictions.
We introduce TMEM98, a putative transmembrane protein of unknown function, as an interaction partner and regulator of the GSK3-binding protein FRAT2, and show that it inhibits the FRat2-mediated induction of β-catenin/TCF signalling.
We investigate the properties of multidimensional probability distributions in the context of latent space prior distributions of implicit generative models and propose to use Cauchy distribution as the latent prior.
The results of application of several deep learning architectures for semantic image segmentation of traffic stereo-pair images are presented.
In this paper we empirically analyze the importance of sparsifying representations for classification purposes. We focus on those obtained by convolving images with linear filters, which can be either hand designed or learned.
In this paper, a two-stage method is introduced in which a coarse angle estimation is achieved through the use of the Convolutional Neural Network (CNN) approach, and a more precise angle is acquired via fuzzy logic.
We propose a scalable gradient-based EVOI optimization method for large item spaces, which achieves state-of-the-art performance across several domains.
In this paper, we propose a novel recurrent convolutional encoder-decoder network that is trained end-to-end on the task of rendering rotated objects from a single image.
We introduce the Object Relation Transformer, that builds upon this approach by explicitly incorporating information about the spatial relationship between input detected objects through geometric attention.
To apply general knowledge to machine reading comprehension, we propose an innovative MRC approach, which consists of a WordNet-based data enrichment method and an MRC model named as Knowledge Aided Reader.
Autoregressive generative models of images tend to be biased towards capturing local structure, and as a result they often produce samples which are lacking in terms of large-scale coherence. To address this, we propose two methods to learn discrete representations of images which abstract away local detail.
We propose a novel ASG2Caption model, which is able to recognise user intentions and semantics in the graph, and therefore generate desired captions according to the graph structure.
We define a novel context-dependent knowledge graph representation model for knowledge graph embedding, based on the notion of triple context used for embedding entities and relations.
A convolutional neural network-based multichannel end-to-end speech recognition system that uses residual connections and batch renormalization.
State-of-the-art models often make use of superficial patterns in the data that do not generalize well to out- of-domain or adversarial settings. In this paper, we show that if we have prior knowledge of such biases, we can train a model to be more robust to domain shift.
The recent advances in deep learning have made it possible to generate photo-realistic images by using neural networks and even to extrapolate video frames from an input video clip. In this paper, for the sake of both furthering this exploration and our own interest in a realistic application, we study imageto-video translation.
Deep learning (DL) systems are increasingly deployed in safety- and security-critical domains including self-driving cars and malware detection, where the correctness and predictability of a system's behavior for corner case inputs are of great importance. Existing DL testing depends heavily on manually labeled data and therefore often fails to expose erroneous behaviors for rare inputs.
We introduce the GeoSQA dataset for scenario-based question answering, where diagrams (e.g., maps, charts) have been annotated with natural language descriptions to benefit NLP research.
We propose new convolutional neural network models for environmental sound classification and achieved promising preliminary results on two datasets, including a public audio dataset and our real rainforest sound dataset.
Quantile normalisation is a popular normalisation method for data subject to unwanted variations such as images, speech, or genomic data. It applies a monotonic transformation to the feature values of each sample to ensure that after normalisation, they follow the same target distribution for each sample. We propose instead to couple the quantilenormalisation step with the subsequent analysis, and to optimise the target distribution jointly with the other parameters in the analysis.
In a social network, even about the same information the excitement between different users are different. If we want to spread a piece of new information and maximize the expected total amount of excitement, which seed users should we choose?
In this work we explore the use of shape-based representations as an auxiliary source of supervision for pose estimation and action recognition.
We study the problem of multilingual masked language modeling, i.e. the training of a single model on concatenated text from multiple languages, and show that transfer is possible even when there is no shared vocabulary across the monolingual corpora and also when the text comes from very different domains.
We propose a novel pruning loss to explicitly enforces the optimizer to focus on promising candidate filters while suppressing contributions of less relevant ones.
Automated retinal image analysis has been emerging as an important diagnostic tool for early detection of eye-related diseases such as glaucoma and diabetic retinopathy. In this paper, we have presented a robust methodology for optic disc detection and boundary segmentation, which can be seen as the preliminary step in the development of a computer-assisted diagnostic system for glauComa in retinal images.
We demonstrate how using data confounded in this way homogenizes user behavior without increasing utility.
We develop TwoWingOS (two-wing optimization strategy), a system that, while identifying appropriate evidence for a claim, also determines whether or not the claim is supported by the evidence.
We propose "Areas of Attention", a novel attention-based model for automatic image captioning.
We propose a novel neural network model that can segment abnormal hotspots and classify bone cancer metastases in the chest area in a semisupervised manner.
A transitive transfer method via multisource data with domain adaptation is proposed in this article to decrease the discrepancy between the source data and SAR targets.
We revisit the heatmap-offset aggregation method and propose the Offset-guided Network (OGN) with an intuitive but effective fusion strategy for both two-stages pose estimation and Mask R-CNN.
We present Falcon 2.0, a rule-based tool capable of accurately mapping entities and relations in short texts to resources in both DBpedia and Wikidata following the same approach in both cases.
We proposed a novel activation function named Tanh Exponential Activation Function (TanhExp) which can improve the performance for lightweight neural networks on image classification task significantly.
This paper provides a comprehensive review and in-depth analysis of 44 publicly available RGB-D-based action datasets, including 27 singleview datasets, 10 multi-view datasets and 7 multi-person datasets.
We present an empirical analogue to the Lipschitz constant of a feed-forward neural network, which we refer to as the maximum gain. We hypothesise that constraining the gain of a network will have a regularising effect.
We introduce the first model involving Adaptive Computation Time which provides a small performance benefit on top of a similar model without an adaptive component and enabling considerable insight into the reasoning process of the model.
This paper focuses on the low-resolution person REID task to relax the impractical assumption of pixel-to-pixel supervision in low and high resolution pedestrian image pairs, and propose a part-based Enhanced Super Resolution network for the task.
We propose a geometric matrix completion model that learns the similarities among matrix entries, computes the CRF potentials, solves the inference problem, and solves the MAP inference problem.
We develop a novel, tunable algorithm for mitigating the hidden, and potentially unknown, biases within training data.
We introduce Dubox, a new one-stage approach that detects the objects without prior box.
We propose a multi-task learning approach that enables to learn vision-language representation that is shared by many tasks from their diverse datasets. The representation is hierarchical, and prediction for each task is computed from the representation.
Learning visual features from unlabeled image data is an important yet challenging task, which is often achieved by training a model on some annotation-free information. This paper presents a novel approach which applies to jigsaw puzzles with an arbitrary grid size and dimensionality and solves them in an iterative manner, leading to better transfer performance.
Interactions play a key role in understanding objects and scenes, for both virtual and real world agents. We introduce a new general representation for proximal interactions among physical objects that is agnostic to the type of objects or interaction involved.
This article introduces publicly available datasets in scene text detection and recognition. The information is as of 2017.
This paper introduces a new architectural framework, known as input fast-forwarding, that can enhance the performance of deep networks.
Network initialized with weights from connectome reconstructions automatically discovered orientation and direction selectivity properties in T4 neurons and their inputs, while networks initialized at random did not.
We propose the Variational Shape Learner (VSL), a generative model that learns the underlying structure of voxelized 3D shapes in an unsupervised fashion.
We introduce a large-scale human-centric visual relationship detection dataset (HCVRD), which provides many more types of relationship annotation (nearly 10K categories) than the previous released datasets.
In this paper, we propose to integrate character embedding learning together with point-wise answer selection training, and then utilize convolutional neural networks for competitive performance.
We exploit the analogy between protein sequence alignment and image pair correspondence to design a bioinformatics-inspired framework for stereo matching based on dynamic programming.
This paper introduces a manually-annotated dataset for audio caption. The purpose is to automatically generate natural sentences for audio scene description and to bridge the gap between machine perception of audio and image.
We propose a novel technique for synthesizing samples with multiple labels for the (yet unhandled) multi-label few-shot classification scenario, which generalizes to labels unseen during training.
We propose a novel approach based on Convolutional Neural Networks (CNNs) to jointly predict depth maps and foreground separation masks used to condition Generative Adversarial Networks (GAN) for hallucinating plausible color and depths in the initially occluded areas.
We propose a control variate method to effectively reduce variance for policy gradient methods, which significantly improves the sample efficiency of state-of-the-art policy gradient approaches.
The concept of beauty has been debated by philosophists and psychologists for centuries, but most definitions are subjective and metaphysical, and deficit in accuracy, generality, and scalability. In this paper, we present a novel study on mining beauty semantics of facial attributes using big data, with an attempt to objectively construct descriptions of beauty in a quantitative manner.
We propose a simple method to address the degradation problem in deep networks where the presence of skip-connections is penalized by Lagrange multipliers in a principled manner.
We propose an end-to-end solution using fully convolutional networks (FCNs) for multi-class semantic segmentation, which will automatically segment melanoma, keratoses and benign lesions.
We propose a novel domain enriched deep network that learns geometric features specific to retinal images, and use them to perform pixel-level segmentation.
We present a monocular visual odometry (VO) algorithm which leverages geometry-based methods and deep learning in a robust manner.
We propose a Dual Generator Generative Adversarial Network (G$^2$GAN), a robust and scalable approach allowing to perform unpaired image-to-image translation for multiple domains using only dual generators within a single model.
We propose a multi-level relation detection strategy that utilizes human pose cues to capture global spatial configurations of relations and as an attention mechanism to dynamically zoom into relevant regions at human part level.
We present an efficient algorithm which allows the depth of searched architectures to grow gradually during the training procedure, achieving state-of-the-art performance on both the proxy dataset (CIFAR10 or CIFAR100) and the target dataset.
This work focuses on an efficient census filtering based local steromatching for images taken under varying radiometric conditions.
This paper introduces a new content-based, cross-modal retrieval method for video and music that is implemented through deep neural networks that leverages the relative distance relationship between intra-Modal samples.
The recently proposed SNLI-VE corpus for recognising visual-textual entailment is a large, real-world dataset for fine-grained multimodal reasoning. However, the automatic way in which it has been assembled gives rise to a large number of errors in the labels of this corpus.
We propose a novel deep convolutional neural network framework called deep augmented attribute network (DAAN) to learn augmented attribute features for cross-domain person re-identification task.
We present an attention-based modular neural framework for computer vision and apply it to several object tracking tasks.
In this paper, we present iDVO (inertia-embedded deep visual odometry), a self-supervised learning based monocular Visual odometry (VO) for road vehicles.
In this paper, we proposed to train a more generalized embedding network with self-supervised learning which can provide slow and robust representation for downstream tasks by learning from the data itself.
We developed a smartphone-based retinal image analysis system for point-of-care diagnostics that is able to load a fundus image, segment retinal vessels, analyze individual vessel width, and store or uplink results.
Autonomous vehicles commonly rely on highly detailed birds-eye-view maps of their environment, which capture both static elements of the scene such as road layout and dynamic elements such as other cars and pedestrians. In this work we present a simple, unified approach for estimating maps directly from monocular images using a single end-to-end deep learning architecture.
We propose a Graph-induced Prototype Alignment (GPA) framework to seek for category-level domain alignment via elaborate prototype representations.
In this paper, we propose an efficient approach to build a spiking version of deep residual network (ResNet), which represents the state-of-the-art convolutional neural networks (CNNs)
We propose RSN4EA (recurrent skipping networks for entity alignment), which leverages biased random walk sampling for generating long paths across KGs and models the paths with a novel recurrent skipping network.
We propose a dynamic divide-and-conquer adversarial training strategy for improving robustness of deep neural networks towards adversarial perturbation.
We propose a generative autoencoder that generalizes the idea of reversible generative models to unrestricted neural network architectures and arbitrary latent dimensionalities.
We propose GWAInet, a CNN-based solution for super-resolving face images guided by another unconstrained HR face image of the same person with possible differences in age, expression, pose or size.
In this work, we introduce a novel framework that employs cluster annotation to boost active learning by reducing the number of human interactions required to train neural networks.
We introduce an end-to-end deep multimodal convolutional-recurrent network for learning both vision and language representations simultaneously to infer image-text similarity.
Annotating Genes with Positive Samples (AGPS) for Gene Function Prediction .
Online multi-object tracking (MOT) has broad applications in time-critical video analysis scenarios such as advanced driver-assistance systems (ADAS) and autonomous driving. In this paper, the proposed system aims at tracking multiple vehicles in the front view of an onboard monocular camera.
We expand on this idea by forcing the method to explicitly align images to be classified to reference images representing the classes while simultaneously providing point-wise alignment information providing some understanding on what the network is capturing.
We propose an approach that automatically extracts information about two different domains, such as architecture and music, which are available in Linked Data repositories.
A large number of image and video saliency models, benchmarks, and datasets are reviewed and compared over two image benchmarks and two large scale video datasets.
We propose a framework for the OMRKBC process to automatically develop a comprehensive ontology-based machine-readable knowledge base system using well-built structural information.
This paper aims at synthesizing filamentary structured images such as retinal fundus images and neuronal images, as follows: Given a ground-truth, to generate multiple realistic looking phantoms.
We propose Vertex-Diminished Random Walk (VDRW) for imbalanced network analysis, based on which we propose a semi-supervised network representation learning framework.
In this paper, we propose a framework for semi-supervised 3D reconstruction, which performs favorably against state-of-the-art approaches in either supervised or semi-Supervised settings.
We focus on text classifiers and make them more interpretable by having them provide a justification, a rationale, for their predictions.
A hierarchical image contour extraction method that draws on the perceptual characteristics of the early vision for features such as edges, shapes, and colours.
We focus on region representation and propose to leverage region semantic representation which is more consistent with the question representation in attention mechanism.
We propose a novel graph metric for semantic entity-relationship networks. The proposed metric is defined via paths that maximize the log-likelihood of a restricted round trip.
We show that negative biases are a natural result of using a hidden layer whose responsibility is to both represent the input data and act as a selection mechanism that ensures sparsity of the representation.
We propose a novel end-to-end deep architecture for face landmark detection, based on a deep convolutional and deconvolutional network followed by carefully designed recurrent network structures.
We propose a new similarity-based descriptor, dubbed structural similarity cross-covariance tensor (SS-CCT), where self-similarities come into play: Here the entity to be measured and the exemplar are regions of the same object, and their similarities are encoded in terms of cross-Covariant matrices.
Instance-level video segmentation requires a solid integration of spatial and temporal information. We propose a novel approach that relies exclusively on the integration of generic spatio-temporal attention cues.
This paper considers the generic problem of dense alignment between two images, whether they be two frames of a video, two widely different views of a scene, two paintings depicting similar content, etc. Whereas each such task is typically addressed with a domain-specific solution, we show that a simple unsupervised approach performs surprisingly well across a range of tasks.
We propose a unified framework for person re-identification in large-scale multi-camera networks with minimal prior knowledge about the environments.
We propose an approach that utilizes omnidirectional videos to generate realistic, consistently annotated, short-term tracking scenarios with exactly parameterized motion patterns.
Ambiguous images are widely recognized as a valuable tool for probing human perception. Perceptual biases that arise when people make judgements about ambiguous images reveal their expectations abo
In this paper, we propose a novel method, named Curriculum Model Adaptation (CMAda), which gradually adapts a semantic segmentation model from light synthetic fog to dense real fog in multiple steps, using both labeled synthetic Foggy data and unlabeled real foggy data, improving the performance of state-of-the-art models.
We present our submission to the WMT19 Robustness Task. Our baseline system is the Charles University Transformer system trained for WMT18 shared task on News Translation.
We focus our attention on depth based semantic per-pixel labelling as a scene understanding problem and show the potential of computer graphics to generate virtually unlimited labelled data from synthetic 3D scenes.
Using multiple robots for exploring and mapping environments can provide improved robustness and performance, but it can be difficult to implement. In particular, limited communication bandwidth is a considerable constraint when a robot needs to determine if it has visited a location that was previously explored by another robot.
We propose a novel decomposition approach based on SVD, namely depth-wise decomposition, for expanding regular convolutions into depthwise separable convolutions while maintaining high accuracy.
We compared activations of convolutional layers of a DCNN trained for object and scene categorization with neural representations in human brain visual regions.
We analyze the propagation formulations behind the residual building blocks, which suggest that the forward and backward signals can be directly propagated from one block to any other block, when using identity mappings.
We investigate a wide range of computational model representations (37 in total), testing their categorization performance and their ability to account for the IT representational geometry. We compared the representational dissimilarity matrices (RDMs) of the model representations with the RDMs obtained from human IT.
Network in network (NiN) is an effective instance and an important extension of deep convolutional neural network. Instead of using a linear filter for convolution, NiN utilizes shallow multilayer perceptron, a nonlinear function, to replace the linear filter.
We propose a Denoiser and UPsampler Network as defenses for 3D adversarial point cloud classification, where the two modules reconstruct surface smoothness by dropping or adding points.
We present the Kernel Transformer Network (KTN) to efficiently transfer convolution kernels from perspective images to the equirectangular projection of 360° images.
In this paper we propose a novel bilinear pooling operation, which is used in intermediate layers of a temporal convolutional encoder-decoder net.
We propose an efficient learning strategy, which is to make student mimic features of teacher stage by stage, and show strong stability on various tasks.
We present a theoretical framework for analyzing this function space, and demonstrate how a basis for this space can be found using neural networks, enabling classical exploratory statistical techniques such as CA to be scaled via neural networks.
This paper presents a new disparity map refinement process for stereo matching algorithm and refinement stage that will be implemented by partitioning the place or mask image and re-projected to the preliminary disparity images.
We introduce the concept of unconstrained real-time 3D facial performance capture through explicit semantic segmentation in the RGB input. We adopt a state-of-the-art regression-based facial tracking framework with segmented face images.
Exploration is a key component of successful reinforcement learning, but optimal approaches are computationally intractable, so researchers have focused on hand-designing mechanisms based on exploration bonuses and intrinsic reward. In this work, we propose a strategy for encoding curiosity algorithms as programs in a domain-specific language and searching, during a meta-learning phase, for algorithms that enable RL agents to perform well in new domains.
In this paper, a novel framework is proposed for automatic facial expression analysis which extracts salient information from video sequences but does not rely on any subjective preprocessing or additional user-supplied information to select frames with peak expressions.
We present a data-driven approach for predicting the behavior of (i.e., profiling) a given non-linear audio signal processing effect, using time-domain samples.
We propose a new Progressive Cross-stream Cooperation (PCSC) framework to iterative improve action localization results and generate better bounding boxes for one stream (i.e., Flow/RGB) by leveraging both region proposals and features from another stream.
We propose and study a general framework for regularized Markov decision processes (MDPs) where the goal is to find an optimal policy that maximizes the expected discounted total reward plus a policy regularization term.
The ocean front has an important impact in many areas, it is meaningful to obtain accurate ocean front positioning, therefore, ocean front detection is a very important task.
A novel probabilistic model for visual place recognition that exploits the information available in visual observations, demonstrating robustness to perceptual aliasing and observation noise.
We present a novel convolutional neural network (CNN) design for facial landmark coordinate regression, in an appearance-sensitive manner without training multi-part or multi-scale models.
Attentive Item2vec employs a context-target attention mechanism in order to learn and capture different characteristics of user historical behavior (context) with respect to a potential recommended item (target), enabling a final neural attentive user representation.
We propose a novel end-to-end deep learning approach for image retrieval task, in which the network is trained to produce binary codes directly from image pixels without the need o f manual annotation.
We use two discriminators and one generator in the adversarial architecture in a zero-sum game to improve the performance of the generator output.
A new retinal fundus image enhancement method that can directly enhance color images.
We present a novel approach to answering sequential questions based on structured objects such as knowledge bases or tables without using a logical form as an intermediate representation.
In this paper, a novel and effective lip-based biometric identification approach with Discrete Hidden Markov Model Kernel is developed.
In this paper we propose a deep architecture for detecting people attributes (e.g. gender, race, clothing) in surveillance contexts.
We proposed an energy-efficient neuromorphic neuromorphic neural network that approximates a sparse coding operation at a minimal loss in accuracy and uses less energy to do the same work.
We present a weakly supervised algorithm for overcoming dataset bias for deep generative models.
We propose Graph Feature Network (GFN), a lightweight neural net defined on a set of graph augmented features. We prove that GFN can be derived by linearizing graph filtering part of GNNs, and leverage it to test the importance of the two parts separately.
We introduce a novel approach to this challenge, which we refer to as deep meta-reinforcement learning, in which recurrent networks can support meta-learning in a fully supervised context.
We introduce a loss term that encourages the network to capture the composability of visual sequences and show that it leads to representations that disentangle the structure of actions.
We aim to model the top-down attention of a convolutional neural network (CNN) classifier for generating task-specific attention maps for weakly supervised localization tasks.
We propose CaTDet, a system to speedup object detection by leveraging the temporal correlation in video.
We propose a simple yet efficient anchor-free instance segmentation, called CenterMask, that adds a novel spatial attention-guided mask (SAG-Mask) branch to anchor free one stage object detector (FCOS) in the same vein with Mask R-CNN.
We propose a predictive model that detects action-objects using EgoNet, a joint two-stream network that holistically integrates visual appearance (RGB) and 3D spatial layout (depth and height) cues to predict per-pixel likelihood of action- objects.
In this paper, we propose novel generative models for creating adversarial examples, slightly perturbed images resembling natural images but maliciously crafted to fool pre-trained models.
We propose an Adversarial Feature Deformation Module (AFDM) that learns ways to elastically warp extracted features in a scalable manner, boosting its capability to better learn highly informative features rather than trivial ones.
In this paper, we propose InterHAt that employs a Transformer with multi-head self-attention for high-order feature learning.
We propose a novel users rating-trendbased collaborative denoising auto-encoder (UT-CDAE) whichdetermines user-item correlations by evaluating rating-Trend(High or Low) of a user towards a set of items.
In this paper, we present a consistent comparative analysis of several representative few-shot classification algorithms, with results showing that deeper backbones significantly reduce the performance differences among methods on datasets with limited domain differences, a modified baseline method that surprisingly achieves competitive performance.
Driver fatigue is a major cause of traffic accidents. Automatic vision-based driver fatigue recognition is one of the most prospective commercial applications based on facial expression analysis technology. Generally, factors such as noise, illumination effects, image scaling, and redundant data affect the performance of facial expression recognition systems. In this paper, we have proposed an efficient algorithm, which not only capable of working with multi-scale images but also able to overcome the mentioned obstacles.
We propose a novel few-shot learning method called meta-transfer learning (MTL) which learns to adapt a deep NN for few shot learning tasks.
In this paper, we propose a novel approach for reconstructing point clouds from RGB images using a two-stage approach, where we first infer an object coordinate map from the input RGB image, and then obtain the final point cloud using a reprojection and completion step.
This paper introduces a sentence to vector encoding framework suitable for advanced natural language processing.
We propose a generative framework which takes on the video frame interpolation problem. It can be used instantly like conventional models.
This paper proposes a novel approach for action extraction in continuous unconstrained video, which has three parts: spatial location estimation, temporal action path searching; and spatial-temporal action compensation.
The field of Human Action Recognition has expanded greatly in previous years, exploring actions and interactions between individuals via the use of appearance and depth based pose information. The CONVERSE dataset presents conversational interaction classes that show little explicit relation to the poses and gestures they exhibit. In this study we discuss a method providing ground truth labelling for the set.
We propose to represent shapes using 2D functions, where the output of the function at each 2D location is a sequence of line segments inside the shape, and use this representation to learn 3D shape structures.
In this paper, we propose a fast FER algorithm for monitoring a driver's emotions that is capable of operating in low specification devices installed in vehicles.
We propose an unsupervised method to predict the distribution of a word in one domain, given its distribution in another domain.
In this paper, we propose a novel method, named Deep Image-to-Video Adaptation and Fusion Networks (DIVAFN), to enhance action recognition in videos.
We propose a stage-based execution strategy for efficient execution of hyper-parameter optimization algorithms that removes redundancy in the training process.
This study aims to compare different operations for creating relation representations from word-level representations for word analogy tasks.
We propose a novel convolutional LSTM model for crowd counting which captures both spatial and temporal dependencies and achieves state-of-the-art results.
We present a fully automated lung CT cancer diagnosis system, DeepLung, which achieves better performance than state-of-the-art approaches, and surpasses the average performance of four experienced doctors.
We develop and analyze a method to learn two-dimensional (2D) representations from videos through an autoencoder framework for action recognition purposes.
We propose a PCA based semi-supervised face recognition technique using edge histogram descriptor (EHD) features.
A structured pruning approach to crop unimportant filters or neurons of CNNs during the training stage.
We combine a deep CNN object localisation method, Faster Region-based convolutional neural network (R-CNN), with two potential real-time multi-object tracking methods in order to create a complete system that can autonomously localise and track individual pigs allowing for the extraction of metrics pertaining to individual pig behaviours from RGB cameras.
We propose ELASTICBSP a model that relaxes its strict synchronization requirement. The proposed model offers more flexibility and adaptability during the training phase, without sacrificing the accuracy of the trained model.
We propose xAT and xVAT, new adversarial training algorithms, that generate multiplicative perturbations to input examples for robust training of DNNs.
We enhance one-look regression counting models by regulating activation maps from the final convolution layer of the network with coarse ground-truth activation maps generated from simple dot annotations.
We propose POS-SCAN, a part-of-Speech enhanced image-text matching model for more grounded image captioning without strong supervision.
We propose an effective and efficient detection network to hunt pedestrians in crowd scenes without bringing extra computations in the inference stage.
We propose to incorporate adversarial dropout in generative multi-adversarial networks, by omitting or dropping out, the feedback of each discriminator in the framework with some probability at the end of each batch.
We introduce a new measure for unsupervised hypernym detection and directionality. The motivation is to keep the measure computationally light and portatable across languages.
We propose the recurrent metric network (RMNet), a convolutional neural Network-recurrent neural network-based similarity metric framework for the batch multi-object tracking.
We studied the performance of two types of acoustic features for emotion recognition: knowledge-inspired disfluency and nonverbal vocalisation features, and statistical Low-Level Descriptor (LLD) based features.
This paper proposes a novel two-step image alignment method based on deep learning and iterative optimization to address the above issue.
A retinal vessel segmentation method based on cellular neural networks (CNN) is proposed.
We propose the adaptive learning method of DBN that can determine the optimal number of hidden neurons and weights and/or layers according to the input space.
Understanding human behaviors is a challenging problem in computer vision that has recently seen important advances. Given the broad set of techniques used in video-based behavior understanding and the fast progress in this area, in this paper we organize and survey the corresponding literature, define unambiguous key terms, and discuss links among fundamental building blocks ranging from human detection to action and interaction recognition.
This paper establishes a new connection between FFNs and GMs. We characterize various benefits of having this connection.
In this paper, we present an approach called Pseudo-Encoded Stochastic Variational Inference (PE-SVI), to reduce the inference complexity of SVI during test time.
Spatial consistency information can be leveraged to detect adversarial examples robustly even when a strong adaptive attacker has access to the model and detection strategies.
In this paper we propose a novel approach (namely, Orthogonal Embedding CNNs, or OE-CNNs) to learn the age-invariant deep face features.
We propose a novel network named GCPANet to effectively integrate low-level appearance features, high-level semantic features, and global context features through some progressive context-aware Feature Interweaved Aggregation (FIA) modules and generate the saliency map in a supervised way.
Skip connections are an essential component of current state-of-the-art deep neural networks (DNNs) such as ResNet, WideResNet, DenseNet, and ResNeXt. Despite their huge success in building deeper and more powerful DNNs, we identify a surprising security weakness of skip connections in this paper.
We propose heuristics to automatically pre-identify candidate sentences that might contain literal occurrences of verbal VMWEs and apply them to existing treebanks in five typologically different languages.
The paper proposes a novel framework, multi-scale, deep inception convolutional neural network (MDCN), which focuses on wider and broader object regions by activating feature maps produced in the deep part of the network.
We extensively compare, qualitatively and quantitatively, 41 state-of-the-art models (29 salient object detection, 10 fixation prediction, 1 objectness, and 1 baseline) over seven challenging data sets for the purpose of benchmarking salient object Detection and segmentation methods.
We derive a relationship between network representation in energy-efficient neuromorphic architectures and block Toplitz convolutional matrices and propose a novel method to train binary networks using noisy-rectified linear units and binary activations.
We propose a novel algorithm goalGAIL, which incorporates demonstrations to speed up the convergence to a policy able to reach any goal, surpassing the performance of an agent trained with other Imitation Learning algorithms.
Discourse-Aware Semantic Self-Attention encoder for reading comprehension on long narratives.
We propose an embarrassingly simple approach to binary representation learning, by incorporating two fully-connected layers onto an arbitrary backbone network, whilst complying with the binary constraints during training.
We propose an Adversarial Domain Adaptation framework for Machine Reading Comprehension, where the source domain has a large amount of labeled data, while only unlabeled passages are available in the target domain.
Zero-Shot Classification (ZSC) equips the learned model with the ability to recognize the visual instances from the novel classes via constructing the interactions between the visual and the semantic modalities via constructing an efficient semantics-guided feature fusion model.
We propose a fine-grained feature imitation method exploiting the cross-location discrepancy of feature response for object detection.
Logit regularization can be used in conjunction with other methods for creating adversarial robustness at little to no marginal cost.
Adversarial examples expose vulnerabilities of machine learning models. We propose an efficient method to generate white-box adversarial examples that trick character-level and word-level neural models, improving test-time accuracy on clean examples.
We present a new method for identifying the latent categorization of items based on their rankings, with the communities corresponding to item categories.
We show that the simple regularization technique of randomly masking out square regions of input during training, which we call cutout, can improve the robustness and overall performance of convolutional neural networks.
This paper focuses on a novel and challenging detection scenario: A majority of true objects/instances is unlabeled in the datasets, so these missing-labeled areas will be regarded as the background during training. In this paper, we introduce a superior solution called Background Recalibration Loss (BRL) that can automatically re-calibrate the loss signals according to the pre-defined IoU threshold and input image.
We introduce a way to dynamically reduce the overhead of fetching and transporting training data with a method we term Progressive Compressed Records (PCRs). PCRs use an on-disk layout that enables applications to efficiently and dynamically access appropriate levels of compression at runtime.
In this paper we tackle the problem of image search when the query is a short textual description of the image the user is looking for. We propose various neural network models of increasing complexity that learn to generate, from a short descriptive text, a high level visual representation in a visual feature space.
We propose Active Rotating Filters (ARFs) that actively rotate during convolution and produce feature maps with location and orientation explicitly encoded.
We propose an interpretable recommendation model called Multi-Matrix Factorization (MMF), which addresses these two limitations and achieves the state-of-the-art prediction accuracy by exploiting common attributes that are present in different items.
In this paper we discuss several forms of spatiotemporal convolutions for video analysis and study their effects on action recognition.
Conditional Adversarial Networks based Dehazing of hazY images using generative adversarial networks for single image haze removal.
In this paper, a min-entropy latent model (MELM) is proposed for weakly supervised object detection.
A generative model optimized towards the plain log-likelihood objective is capable of efficient realistic-looking synthesis and manipulation of large images.
A new approach to handle privacy issues in eye videos by replacing the current identifiable iris texture with a different iris template in the video capture pipeline based on the Rubber Sheet Model.
We find that it is possible to train a real-world object detector that is accurate to 1.5 cm and robust to distractors and partial occlusions using only data from a simulator.
We propose a novel model called the label-noise robust image-to-image translation model (RMIT) that can learn a clean label conditional generator even when noisy labeled data are only available.
We employ a deep network to perform image completion, with adversarial training as well as perceptual and completion losses, and call it the Missing Data Encoder (MDE)
This paper shows how to augment a network trained on an existing synthetic dataset with large amounts of additional unlabelled data and obtain state-of-the-art results.
This review paper attempts to systematically summarize methodologies and discuss challenges for deep multi-modal object detection and semantic segmentation in autonomous driving research.
This work investigates three different loss functions for autoencoder-based pretraining of image encoders: The commonly used reconstruction loss, the more recent perceptual similarity loss, and a feature prediction loss proposed here; the latter turning out to be the most efficient choice.
We propose the Exemplar Guided & Semantically Consistent Image-to-image Translation (EGSC-IT) network which conditions the translation process on an exemplar image in the target domain, and apply Adaptive Instance Normalization to the shared content component, which allows us to transfer the style information of the target Domain to the source domain.
We address fundamental flaws in previously used metrics and show how Dynamic Time Warping (DTW), a long known method of measuring similarity between two time series, can be used for evaluation of navigation agents.
We use single-layer sub-networks and two different supervised loss functions to generate local error signals for the hidden layers, and we show that the combination of these losses help with optimization in the context of local learning.
A fully automatic approach for facial expression recognition based on points registration, localized patch extraction and LBP-TOP feature representation.
We use a conditional imitation learning algorithm to predict multiple feasible future trajectories both for the ego vehicle and neighbors through a probabilistic framework through an auxiliary loss.
Mini-batch based Stochastic Decorrelation Loss is proposed which can be applied to any network layer to provide soft decorrelation of activations.
We introduce the Neural Conditioner (NC), a self-supervised machine able to learn about all the conditional distributions of a random vector X.
We propose a simple yet effective method based on self-supervised learning that outperforms or is on par with most state-of-the-art algorithms, e.g. adversarial domain adaptation.
We propose to augment convolutional networks with self-attention, an attention mechanism that attends jointly to both features and spatial locations while preserving translation equivariance.
We explore the ConditionaL Neural Network (CLNN) and the Masked Conditiona l Neural Network for multi-dimensional temporal signal recognition.
We validated two new potent derivatives of propylthiouracil, both of which inhibit CYB5R3 activity in cultured cells.
We propose a new approach to estimate the maximal number of hyperplanes required to shatter a given sample, i.e., to separate every pair of points from one another, based on the recent contributions by Har-Peled and Jones in the dataset partitioning scenario.
This paper examines the effectiveness of feature modelling to conduct 2D and 3D face recognition using Gaussian Mixture Models.
A large-scale lesion image dataset with 32,735 lesions in 32,120 CT slices from 10,594 studies of 4,427 unique patients.
We address this challenge by designing an information-theoretic meta-regularization objective that places precedence on data-driven adaptation, and apply it in practical settings where standard meta-learning has been difficult to apply.
We propose Deep Back-Projection Networks (DBPN), that exploit iterative up- and downsampling layers, providing an error feedback mechanism for projection errors at each stage, providing superior results and in particular establishing new state of the art results for large scaling factors.
We introduce MUTAN, a multimodal tensor-based Tucker decomposition to efficiently parametrize bilinear interactions between visual and textual representations in VQA tasks.
We apply the role embedding algorithm, struc2vec, to a collection of social networks exhibiting either "loyal" or "vagrant" characteristics derived from Reddit.
We propose a new saliency metric based on the AUC property, which aims at sampling a more directional negative set for evaluation, denoted as Farthest-Neighbor AUC(FN-AUC), and propose a strategy to measure the quality of sampled negative set.
We probe the representational contribution of image features in an end-to-end neural modeling framework and study the properties of different types of image representations for image captioning tasks.
We propose an approach capable of generating images starting from a given text using conditional generative adversarial network (GAN) trained on uncaptioned images dataset.
We propose a self-organizing neural architecture for incrementally learning to classify human actions from video sequences.
We evaluate that claim for melanoma classification, over 9 CNNs architectures, in 5 sets of splits created on the ISIC Challenge 2017 dataset, and 3 repeated measures. The correlations we found were, to begin with, much smaller than those reported by existing art.
ConvNets and Imagenet have driven the recent success of deep learning for image classification. However, the marked slowdown in performance improvement combined with the lack of robustness of neural networks to adversarial examples and their tendency to exhibit undesirable biases question the reliability of these methods.
This paper shows that two commonly used evaluation metrics for generative models, the Fr\'echet Inception Distance (FID) and the Inception Score (IS), are biased -- the expected value of the score computed for a finite sample set is not the true value ofthe score. We then show how to extrapolate the score to obtain an effectively bias-free estimate.
We present a local stereo matching algorithm with an adaptive cost aggregation strategy based on a generalized bilateral filter model.
We incorporate the deformable convolution module to the traditional baseline to enhance the transformation modeling capability of deep CNNs for person re-identification task without additional supervision.
Adaptive locality preserving regression (ALPR) for classification.
Camera and lidar are important sensor modalities for robotics in general and self-driving cars in particular. The sensors provide complementary information offering an opportunity for tight sensor-fusion. PointPainting: a sequential fusion method to fill this gap.
In this paper, we propose a novel unsupervised intrinsic image decomposition framework, which relies on neither labeled training data nor hand-crafted priors. Instead, it directly learns the latent feature of reflectance and shading of the scene.
We explore how CERT, a computer expression recognition toolbox trained on a large dataset of spontaneous facial expressions (FFD07), generalizes to a new, previously unseen dataset (FERA), and propose a method for retraining CERT with a combination of old and new data.
In this article, we describe a method for optimizing control policies, with guaranteed monotonic improvement.
We propose multi-frame video-based self-supervised training of a deep network that learns a face identity model both in shape and appearance while (ii) jointly learning to reconstruct 3D faces.
We propose Memory-based Neighbourhood Embedding (MNE) to enhance a CNN feature by considering its neighbourhood.
An unsupervised method for domain-specific, single-image deblurring based on disentangled representations.
We propose a generic approach to counter language drift by using iterated learning, which drastically counters language drift as well as improves task completion metric.
We train a BERT-based Speech2Action classifier on over a thousand movie screenplays, to predict action labels from transcribed speech segments, without any additional supervision.
This paper is focused on studying the view-manifold structure in the feature spaces implied by the different layers of Convolutional Neural Networks (CNN)
In this paper, we propose a novel weakly supervised curriculum learning pipeline for multi-label object recognition, detection and semantic segmentation.
A fast implementation of the Singular Value Thresholding (SVT) algorithm for matrix completion.
In this paper, we focus on the coordinate representation in human pose estimation. We found that the process of coordinate decoding (i.e. transforming ground-truth coordinates to heatmaps) is surprisingly significant for human Pose estimation performance, which nevertheless was not recognised before.
We use the presented approach to train a vision-based autonomous driving system that substantially outperforms the state of the art on CARLA benchmark and the recent NoCrash benchmark.
In this paper, we propose a computationally simple, yet effective, framework to learn spatio-temporal feature embedding from unlabeled videos in an unsupervised setting.
We provide a learning algorithm based on refinement operators for the description logic ALCQ including support for concrete roles.
In this note, we verify the effectiveness of two of SimCLR's design improvements by implementing them in the MoCo framework.
We propose a deformable constellation model with correlation filters that treats the geometric and visual constraints within a single convex cost function and derive a highly efficient optimization for maximum a posteriori inference of a fully connected constellation.
We introduce a new video dataset called Toybox that contains egocentric (i.e., first-person) videos of common household objects and toys being manually manipulated to undergo structured transformations, such as rotation, translation, and zooming.
Random omitting half of the feature detectors on each training case improves performance on held-out test data.
We evaluate the use of Fisher vectors as an alternative to bag-of-word histograms to aggregate a small set of state- of-the-art low-level descriptors, in combination with linear classifiers, for action recognition.
A large body of research into semantic textual similarity has focused on constructing state-of-the-art embeddings using sophisticated modelling, careful choice of learning signals and many clever tricks. By contrast, little attention has been devoted to similarity measures such as Pearson correlation and cosine similarity.
We propose SplitNet, a method for decoupling visual perception and policy learning. We show dramatic improvements over baseline models on transferring between simulators.
We present a system for keyframe-based dense camera tracking and depth map estimation that is entirely learned.
We explore the utilization of a human-like cognitive style, i.e., building overall cognition for the image to be described and the sentence to be constructed, for enhancing computer image understanding.
We posit that user behavior during natural viewing of images contains an abundance of information about the content of images as well as information related to user intent and user defined content importance.
This paper demonstrates that max-pooling dropout is equivalent to randomly picking activation based on a multinomial distribution at training time. In light of this insight, we advocate employing probabilistic weighted pooling, instead of commonly used max-Pooling, to act as model averaging at test time.
We present a new approach towards ending this cycle where we "deflect'' adversarial attacks by causing the attacker to produce an input that semantically resembles the attack's target class. We then perform a study where participants are asked to label images produced by the attack.
A comparative study of four deep learning frameworks, namely Caffe, Neon, Theano, and Torch, on three aspects: extensibility, hardware utilization, and speed.
A morphological-based blood vessel extraction algorithm using adaptive-local analysis from colored retinal images for medical or human recognition.
We analyze the local convergence behavior of GAN training dynamics in a non-asymptotic way and propose the Jacobian Regularized GANs, which achieve near state-of-the-art results.
We build event detectors based solely on textual descriptions of the event classes.We also learn event detectors from very few positive and related training samples together with a small number of "related" videos.
We attempt to generate video captions that convey richer contents by temporally segmenting the video with action localization, generating multiple captions from multiple frames, and connecting them with natural language processing techniques, in order to generate a story-like caption.
This paper presents a pyramid histogram based confidence map that incorporates structure information into appearance statistics to improve the segmentation performance.
We demonstrate in this paper how an old idea, namely the 1-norm support vector machine (SVM) proposed more than 15 years ago, has several advantages over more recent work.
We employ a Deep Neural Network that is trained on our custom database of such sketches to detect UI elements in the input sketch. This two-step approach without the need for two trained models improves over other methods giving time-efficient results.
We propose a novel framework to do the feature representation learning and metric learning jointly and use linear Support Vector Machine for similarity learning.
We address the problem of distance metric learning in visual similarity search, defined as learning an image embedding model which projects images into Euclidean space where semantically and visually similar images are closer and dissimilar images are further from one another.
We propose adaptive variational dropout whose probabilities are drawn from sparsity-inducing beta Bernoulli prior, allowing each neuron to be evolved either to be generic or specific for certain inputs, or dropped altogether.
We propose three new benchmark RL domains that contain some of the complexity of the natural world, while still supporting fast and extensive data acquisition.
A robotic-ultrasound approach for automatic vertebral level detection, which provides both "tactile" and visual feedback during the procedure.
We present the TextFooler, a general attack framework, to generate natural adversarial texts and apply it to text classification and textual entailment.
We propose a novel cross-modal hashingarchitecture-deep neural decoder cross-Modal hashing (DNDCMH), which uses a binary vector specifying the presence of certainfacial attributes as an input query to retrieve relevant face images from a database.
We perform analysis of detection and counting of cars using a low-power IBM TrueNorth Neurosynaptic System using IBM's EEDN training framework.
We introduce two alternative linear transforms, orthogonal transformation and idempotent transformation, which directly connect convolutional layers close to input and those close to the output in deep neural networks, improving information flow and thus easing training.
Three dimensional convolutional neural networks (3D CNNs) have been established as a powerful tool to simultaneously learn features from both spatial and temporal dimensions, which is suitable to be applied to video-based action recognition.
We explore what is sufficient to build a fast and well-performed text matching model and propose to keep three key features available for inter-sequence alignment.
In this paper, we present a new Identity-preserving Face Recovery from Portraits (IFRP) method to recover latent photorealistic faces from unaligned stylized portraits.
We tackle the missing work on the in-depth analysis of style interpolation and propose a method that is more effective in controlling style strength.
We develop an algorithmic unsupervised-approach that automatically generates potential drug molecules given a prototype drug.
This paper addresses the problem of identifying generic objects and locating them in 3D from a mobile robot platform equipped with an RGB camera using a video object segmentation-based approach.
State-of-the-art models for language understanding already have, or can they easily learn, abilities such as boolean coordination, quantification, conditionals, comparatives, and monotonicity reasoning.
We propose a novel approach where each location in the image votes for the position of each keypoint using a convolutional neural net using a dense, multi-target votes.
We propose REGMAPR - a simple and general architecture for text matching that does not use inter-sentence attention that achieves state-of-the-art results on benchmark datasets.
We propose a novel activation function called Rectified Exponential Unit (REU) and propose the Parametric REU (PREU) to increase the expressive power of the REU.
This paper presents an extensive comparison of a variety of decoders for pixel-wise tasks ranging from classification, regression to synthesis.
FARM improves visual understanding and matching by incorporating the supervision of generation loss, and enhances visual matching by introducing a novel layer-to-layer matching mechanism to fuse aesthetic information more effectively.
We propose DeLiGAN, a novel GAN-based architecture for diverse and limited training data scenarios, which enables diversity in generated samples.
In this paper, we propose weighted Long Short-Term Memory adopted with convolutional neural network representations for three dimensional tennis shots recognition.
We propose a novel deep structured generative model which boosts generative adversarial networks (GANs) with the aid of structure information to capture the intrinsic structure in scenes and generate realistic images.
Adversarial training for network embedding so as to achieve model robustness and better generalization performance.
Object detection, as of one the most fundamental and challenging problems in computer vision, has received great attention in recent years. This paper extensively reviews 400+ papers of object detection in the light of its technical evolution.
We propose a self-supervised learning method that learns the spatio-temporal representation of a video by leveraging the variations in the visual appearance according to different playback speeds under the assumption of temporal coherence.
We propose an equalization loss to solve the long tail of rare categories problem on LVIS benchmark without any bells and whistles.
We propose a novel decomposition method, namely DAC, that reduces a large number of floating-point operations (FLOPs) while maintaining high accuracy of a pre-trained model.
In this paper, we propose a novel learning scheme for CNNs to simultaneously 1) reduce the model size; 2) decrease the run-time memory footprint; 3) lower the number of computing operations, without compromising accuracy.
This paper addresses the problem of simultaneous estimation of a vehicle's ego motion and motions of multiple moving objects in the scene–called eoru motions –through a monocular vehicle-mounted camera.
Fully-Automatic Facial Expression Recognition from still images is a challenging task as it involves handling large interpersonal morphological differences, and as partial occlusions can occasionally happen. We propose to train Random Forests upon spatially defined local subspaces of the face.
Learning GAN fingerprints towards image attribution: we systematically investigate the performance of classifying an image as real or GAN-generated.
An adversarial framework is proposed in this study to reconstruct the HR facial image by simultaneously generating an HR image with and without blur.
We study five straightforward approaches to achieve an optimal trade-off between accuracy and speed in face detection, using MobileNet-SSD as fast face detector and S3FD as accurate face detector.
The divergence triangle is a compact and symmetric objective function that seamlessly integrates variational learning, adversarial learning, wake-sleep algorithm, and contrastive divergence in a unified probabilistic formulation.
We propose a simple yet effective model for Single Image Super-Resolution (SISR), by combining the merits of Residual Learning and Convolutional Sparse Coding.
Siamese network based trackers formulate tracking as convolutional feature cross-correlation between target template and searching region. However, Siamese trackers still have accuracy gap compared with state-of-the-art algorithms.
Zero-shot text classification (0Shot-TC) is a challenging NLU problem to which little attention has been paid by the research community. We provide unified datasets, standardized evaluations, and state-of-the-art baselines.
We propose a novel supervised learning method to identify curvilinear structure based on a modified Hough forest framework.
In real-world applications, commercial off-the-shelf systems act as black boxes due to the inaccessibility of the model parameters which makes it challenging to fine-tune the models for specific applications.
This paper improves the first two steps. We propose a spatio-temporal bigraph-based multi-feature fusion algorithm for human activity recognition.
We measure the accuracy of CIFAR-10 classifiers by creating a new test set of truly unseen images. We find a large drop in accuracy (4% to 10%) for a broad range of deep learning models.
This paper proposes a novel Ghost module to generate more feature maps from cheap operations. The Ghost module can be taken as a plug-and-play component to upgrade existing convolutional neural networks.
We present a fully automatic approach to video colorization with self-regularization and diversity.
 exploiting operation importance for effective neural architecture search (EoiNAS)
We extend the method for loop closure detection, using the labels already available from local registration into NDT Histograms, and we present a SLAM pipeline based on Semantic assisted NDT and PointNet ++.
We propose a mixup-driven training regularization for region proposal based object detectors that improves robustness and generalizability.
We propose a novel compression method, AdaBERT, that leverages differentiable Neural Architecture Search to automatically compress BERT into task-adaptive small models for specific tasks.
We propose a novel CF-based optimization problem to jointly model the discrimination and reliability information for visual tracking and introduce a local response consistency regular term to emphasize equal contributions.
We propose to formulate point distribution model in terms of centripetal-parameterized Catmull-Rom spline, so that the model-based segmentation is augmented to permit quick edit, and the consequent shape is independent of scale.
Neural networks have achieved dramatic improvements in recent years and depict the state-of-the-art methods for many real-world tasks nowadays. One drawback is, however, that many of these models are overparameterized. Inspired by recently proposed magnitude-based pruning schemes and the Wald test from the field of statistics, we introduce a novel magnitude and uncertainty (M&U) pruning criterion that helps to lessen such shortcomings.
We expand upon the recently proposed explicit shape regression to allow usage and mixture of different feature channels, and include head pose information to improve detection performance in non-cooperative environments.
We first trace the decision-making process of this model and visualize saliency maps to understand which portion of the input influence it more for both classification and regression problems.
This work presents a theory and methodology for simultaneous detection of local spatial and temporal scales in spatio-temporal video data.
We propose a novel approach to map floating-point based DNNs to 8-bit dynamic fixed-point networks with integer power-of-two weights with no change in network architecture.
We propose a combination of surface-based pose estimation and deep generative models that allows us to perform accurate pose transfer, i.e. synthesize a new image of a person based on a single image of that person and a pose donor.
We propose a novel method for exploiting the semantic structure of text to answer multiple-choice questions. Representing multiple abstractions as a family of graphs, we translate question answering (QA) into a search for optimal subgraph that satisfies certain global and local properties.
In this paper, we tackle the problem of action recognition using body skeletons extracted from video sequences by Gramian matrices.
We propose using active learning based techniques to further improve the state-of-the-art semi-supervised learning MixMatch algorithm.
We propose a novel technique of learning another neural network, called MentorNet, to supervise the training of the base deep networks, namely, StudentNet.
We propose a multiple-object fusion tracker (MOFT), which uses a combination of 3D point clouds and corresponding RGB frames to overcome distortions in multiple object tracking.
The Mediator complex is an essential co-regulator of RNA polymerase II that is conserved throughout eukaryotes. Here we present the first study of Mediator in the pathogenic fungus Candida albicans.
We show that using a fixed dropout probability during training is a suboptimal choice. We thus propose a time scheduling for the probability of retaining neurons in the network.
Multi-choice reading comprehension is a challenging task, which involves the matching between a passage and a question-answer pair. This paper proposes a new co-matching approach to solve this problem.
We explore how the probabilistic outputs of a single-architecture deep network may be coupled to a probablistic tracker, taking the form of a particle filter, for medical image data analysis.
We explore how to enable machines to model 3D shapes like human modelers using reinforcement learning (RL).
In this paper, we propose a recursive framework to recognize facial expressions from images in real scenes.
This paper addresses the problem of community detection in networked data that combines link and content information for Bayesian inference.
The paper proposes a systematic way of determining the threshold value for reliable vessel segmentation which leads reliable vessel detection.
We leverage 3D scene flow, which can be estimated robustly even under adverse conditions, to induce accurate blur kernels via local homographies.
We propose a simple heuristic that guides the development of neural baseline systems for the extractive QA task for competitive performance compared with existing models.
In this paper, we propose a recurrent attention mechanism for VQA which utilizes dual (textual and visual) Recurrent Attention Units (RAUs).
This paper studies the problem of weakly-supervised crowd counting which learns a model from only a small amount of location-level annotations but a large amount of count- level annotations. We devise a simple-yet-effective training strategy, namely Multiple Auxiliary Tasks Training.
We propose a new paradigm for learning discriminative features by making full use of the human curation process on social networking services (SNSs).
Chest X-ray scan is a most often used modality by radiologists to diagnose many chest related diseases in their initial stages. The proposed system aids the radiologists in making decision about the diseases found in the scans more efficiently.
LDAM provides two affordances in combination: the ability to explore the set of maximally activating pre-images, and a GAN-style discriminator as a regularizer.
We introduce the concept of general discrimination, propose a novel and light-weighted method, namely soft fine-tuning, which improves the total discrimination ability on target domain and accelerates convergence.
HM-NAS generalizes existing weight sharing based NAS approaches and incorporates a hierarchical masking scheme that automatically learns the optimal architecture.
ApproxNet can adapt seamlessly at runtime to video content changes and changes in system dynamics to provide low and stable latency for object detection on a video stream.
We propose a novel neural architecture search strategy in channel-level instead of path-level and devise a search space specially targeting at object detection.
We propose an unsupervised incremental learning algorithm, TFusion, which is aided by the transfer learning of the pedestrians' spatio-temporal patterns in the target domain in order to incrementally optimize the classifiers based on the unlabeled data.
We find that the reported accuracies of the predictions are significantly over-estimated, and strongly dependent on the structure of the training and testing datasets used. We propose a positive set-specific method to create a balanced negative set maintaining the degree distribution for each protein.
This paper investigates the importance of visual cues in predicting the popularity of a public lecture, and proposes an attention-based long short-term memory network that achieves state-of-the-art prediction accuracy.
We propose a natural form of supervision, that capitalizes on the appearance constancy of a person among different frames (or viewpoints) for model-based human pose estimation.
We use Conditional Random Forests to capture low-level expression transition patterns for multi-view dynamic FER.
We propose a generic neural network layer structure employing multilinear projection as the primary feature extractor. The proposed architecture requires several times less memory as compared to the traditional CNN.
An end-to-end image edge detection algorithm using visual cross fusion (VCF) network to detect features first.
This paper presents an approach to refine noisy and sparse disparity maps from weakly-textured urban environments, enhancing their applicability in perception algorithms applied to autonomous vehicles urban navigation.
We propose DoPa -- a comprehensive CNN detection methodology for various physical adversarial attacks, which improves the CNN recognition process.
We propose a novel photo-realistic text-to-image generation model that implicitly disentangles semantics to both fulfill the high- level semantic consistency and low-level semantic diversity.
We propose an implicit gradient transport method for online stochastic optimization in the restricted setting where the Hessians of all component functions are equal.
We propose a new long-term tracking performance evaluation methodology and present a new challenging dataset of carefully selected sequences with many target disappearances.
Neural architecture search (NAS) for generative adversarial networks (GANs).
Stereo matching is a challenging problem with respect to weak texture, discontinuities, illumination difference and occlusions. Therefore, a deep learning framework is presented in this paper, which focuses on the first and last stage of typical stereo methods: matching cost computation and the disparity refinement.
We proposed a neural network-based method for drug-drug interaction prediction using various information about drugs.
We introduce a new type of knowledge -- cross sample similarities for model compression and acceleration. This knowledge can be naturally derived from deep metric learning model.
An end-to-end architecture that improves the discriminability of features of partially observed videos by assimilating them to features from complete videos for action prediction.
In this paper, we propose a novel multiclass classifier for the open-set recognition scenario, being suitable for open- set recognition.
A recurrent convolutional network for real-time video style transfer which incorporates a temporal consistency loss and overcomes the instability of prior methods.
We analyze that different methods based channel or position attention mechanism give rise to different performance on scale, and some of state-of-the-art detectors applying feature pyramid are integrated with various variants convolutions with many mechanisms to enhance information, resulting in increasing runtime.
We propose a multi-channel graph convolutional networks (MuchGCN) to compensate the loss caused by coarse-grained clustering and further advance GNN.
The knowledge of city exploration trails of people is in short supply because of the complexity in defining meaningful trails representative of individual behaviours and in the access to actionable data.
We propose a Lightweight Non-Local (LightNL) block by squeezing the transformation operations and incorporating compact features, which is 400x computationally cheaper than its conventional counterpart without sacrificing the performance.
We propose a novel framework based on dynamic temporal modeling of the relationship between video frames for crowd counting task.
We give an attempt to build a unified 8-bit training framework for convolutional neural networks from the aspects of accuracy and speed.
We show that only a fourth of the final layers need to be fine-tuned to achieve 90% of the original quality in pretrained language models, across standard tasks.
In this paper, we propose a novel feature learning framework for large-scale salient object detection under the guidance of lossless feature reflection.
We propose a regional latent semantic dependencies model (RLSD) for multilabel image classification, which achieves the best performance compared to state-of-the-art models.
Time-frequency representations are valuable in learning useful features for sound classification. We compare various popular signal processing methods to obtain this representation.
In this paper we propose a CNN architecture for semantic image segmentation that performs bilateral filtering, at multiple feature-scales, between superpixels in an image, while respecting image edges.
We present TagMe!, a social tagging front-end for Flickr images, that provides multifaceted tagging functionality: It enables users to attach tag assignments to a specific area within an image and to categorize tag assignments.
We present a simple neural rendering architecture that helps variational autoencoders (VAEs) learn disentangled representations.
This paper provides a review on deep learning methods for semantic segmentation applied to various application areas.
In this paper, we derive a novel algorithm to cluster HMMs based on the hierarchical EM (HEM) algorithm, which reduces learning times and memory requirements, while improving model robustness through better regularization.
A novel algorithm for reverse engineering of gene regulatory networks with large number of genes and limited number of data points.
This paper is the first work to perform spatio-temporal mapping of human activity using the visual content of geo-tagged videos.
We present a new technique for learning visual-semantic embeddings for cross-modal retrieval that improves state-of-the-art methods on MS-COCO and Flickr.
Temporally stable CNNs can be trained without the need for video material or expensive motion estimation.
Generative Collaborative Networks for Single Image Super-Resolution at large upscaling factors.
This paper develops a multi-task learning framework that attempts to incorporate the image structure knowledge to assist image inpainting, which is not well explored in previous works.
We present a novel paradigm for incrementally improving a robot's visual perception through active human-robot interaction.
We examine property norm prediction from visual, rather than textual, data, using cross-modal maps learnt between property norm and visual spaces.
Learning to recognize pedestrian attributes at far distance is a challenging problem in visual surveillance since face and body close-shots are hardly available; instead, only far-view image frames of pedestrian are given.
We propose a novel domain adaptation method that combines feature and pixel-level insights to achieve state-of-the-art results.
We present a new end-to-end layered architecture for Video QA, which is composed of a question-guided video representation layer and a generic reasoning layer to produce answer.
Spatial information is considered as the key information in many computer vision tasks including visual tracking. We propose the offset-adjustable deformable convolutional network for tracking.
We introduce a probabilistic tracking-based method for automatic vessel segmentation in retinal images.
Data size is the bottleneck for developing deep saliency models, because collecting eye-movement data is very time-consuming and expensive. We propose GazeGAN, a novel saliency model based on generative adversarial networks, which achieves state-of-the-art performance over multiple datasets.
We propose a stochastic answer network (SAN) to explore multi-step inference strategies in Natural Language Inference.
An image retrieval pipeline that uses attentive, local convolutional features and aggregates them using the Vector of Locally Aggregated Descriptors (VLAD) to produce a global descriptor.
We provide a novel clustering objective with pairwise constraints that can be used to train a deep clustering network; therefore the cluster assignments and their underlying feature representations are jointly optimized.
We aim at designing a domain-invariant stereo matching network that generalizes well to unseen scenes.
Jointly utilizing global and local features to improve model accuracy is becoming a popular approach for the person re-identification problem, because previous works using global features alone have very limited capacity at extracting discriminative local patterns.
We propose an adversarial reconstruction learning framework that prevents the latent representations decoded into original input data from the latent representation of deep networks.
In this paper, we introduce Factual Memory Network, which learns to answer questions by extracting and reasoning over relevant facts from a Knowledge Base.
In this paper, we present a simple and modularized neural network architecture, named interleaved group convolutional neural networks (IGCNets), in which the building block lies in a novel building block, a pair of two successive Interleaved Group convolutions.
We have developed a learning-based image transformation framework and successfully applied it to three common image transformation operations: downscaling, decolorization, and high dynamic range image tone mapping.
We present a novel jointly learned deep architecture for both facial attribute analysis and face detection.
Drug-induced prolongation of the QT interval on the electrocardiogram can lead to a potentially fatal ventricular arrhythmia known as torsades de pointes (TdP).
We construct multi-modal concept representations by concatenating a skip-gram linguistic representation vector with a visual concept representation vector computed using a deep convolutional neural network (CNN) trained on a large labeled object recognition dataset.
Noisy labels are very common in real-world training data, which lead to poor generalization on test data because of overfitting to the noisy labels. In this paper, we claim that such overfitting can be avoided by "early stopping" training a deep neural network before the noise labels are severely memorized.
We present a novel object detection pipeline for tabletop scenes, a common environment for assistive manipulators, using state-of-the-art techniques from robotics and computer vision.
A deep learning based automated image quality assessment method in the context of diabetic retinopathy (DR) to guide the photographer.
We interpret convolutional networks as adaptive filters and combine them with so-called MuxOut layers to efficiently upscale low resolution images.
This paper proposes a novel energy function for the boundary to keep the discontinuities and uses the Hopfield neural network to solve the optimization.
We propose to address these issues from selective transfer perspective for enhanced attribute editing and season translation.
We present an approach to automatically assign high-quality, realistic appearance models to large scale 3D shape collections, using the photos as reference.
In many descriptors, spatial intensity transforms are often packed into a histogram or encoded into binary strings to be insensitive to local misalignment and compact. Discriminative information, however, might be lost during the process as a trade-off. To capture the lost pixel-wise local information, we propose a new feature descriptor, Circular Center Symmetric-Pairs of Pixels (CCS-POP)
We present a novel Visual Question Answering approach that allows an image to be queried by means of a written question, achieving equal or higher accuracy compared to current methods.
We propose a novel loss function called the level set loss which improves the spatial details of segmentation results in a time and memory efficient way.
We propose a novel semi-supervised learning framework that utilises large amounts of unlabelled data to improve classification performance with minimal annotations.
We study the problem of unsupervised domain adaption in the universal scenario, in which only some of the classes are shared between the source and target domains.
We introduce a time series compression algorithm that achieves state-of-the-art compression ratios while requiring less than 1KB of memory and adding virtually no latency.
We present a GPU-accelerated library, dubbed CNNdroid, for execution of trained deep CNNs on Android-based mobile devices.
We present an online approach to efficiently and simultaneously detect and track 2D poses of multiple people in a video sequence that is runtime-invariant to input frame rate of camera.
We present the convolutional deep belief network, a hierarchical generative model which scales to realistic image sizes. This model is translation invariant and supports efficient bottom-up and top-down probabilistic inference.
A major challenge facing Computer Vision systems is providing the ability to accurately detect threats and recognize subjects and/or objects under dynamically changing network conditions. We propose novel models that characterize the face recognition accuracy in terms of video encoding parameters.
We provide a method for persistent, on-demand, ground truth, asset annotation of a game world.
We propose a novel sketch-specific data augmentation (SSDA) method that leverages the quantity and quality of the sketches automatically and achieves state-of-the-art results.
Crowd counting problem that counts the number of people in an image using attention-based deep learning.
We propose a principled Self-supervised Sample Mining (SSM) process for incorporating unlabeled or partially labeled data into the model learning while minimizing the annotating effort of users.
We propose an automatic evaluation protocol called QAGS (pronounced"kags") that is designed to identify factual inconsistencies in a generated summary and provide a natural form of interpretability.
A deep learning model can rapidly generate accurate clinical pathology classifications of knee MRI exams from both internal and external datasets. We then measured the effect of providing the model’s predictions to clinical experts during interpretation.
In this paper we present a novel filter, based on the existing COSFIRE filter, for the delineation of patterns of interest. It includes a mechanism of push-pull inhibition that improves robustness to noise in terms of spurious texture.
We propose a stepwise, label-based learning process for improving the efficiency of adversarial training for unsupervised video summarization.
In this paper, we present a lossy image compression architecture, which utilizes the advantages of convolutional autoencoder (CAE) to achieve a high coding efficiency.
We use Generative Adversarial Networks to impose structure in compressed sensing problems, replacing the usual sparsity constraint.
We propose to use deep learning technique to model a novel set to set (S2S) distance, in which the underline objective focuses on preserving the compactness of intra-class samples for each camera view, while maximizing the margin between the intra- class set and inter-class set.
We develop a novel deep architecture and GAN formulation to effectively bridge these advances in text and image modeling, translating visual concepts from characters to pixels.
We propose two solutions for efficiently adapting transformer language models as text summarizers, achieving new state of the art performance on three abstractive summarization datasets.
We introduce an adversarial auto-encoder based discriminator model which learns to match the data, reconstruction loss and the latent distributions of real and fake images to improve the quality of generated samples.
We propose a semi-supervised structured ensemble learning approach for contour detection built on structured random forests (SRF) with very limited training data.
We propose a new model for human trajectory prediction which can learn and predict human motion in crowded spaces such as a sidewalk, a museum or a shopping mall using a recurrent neural network LSTM model.
We present a new approach to reconstructing realistic super-resolved images with high perceptual quality, while maintaining the naturalness of the result.
A review of adversarial attack and defense methods for chest X-rays image classification.
We propose a set of methods for critiquing deep learning models and demonstrate their application for protein family classification, a task for which high-accuracy models have considerable potential impact.
We develop a self-training method with progressive augmentation framework (PAST) to promote the model performance progressively on the target dataset, achieving state-of-the-art Re-ID performance under the unsupervised cross-domain setting.
This paper presents a detailed review on malware detection approaches and recent detection methods which use these approaches.
In this paper, we focus on model generalization and adaptation for cross-domain person re-identification (Re-ID) using attention mechanism to adaptively extract the person features for every domain is of great effectiveness.
We propose a novel framework for domain specific video summarization based on what is important for a particular domain in addition to possessing other desired characteristics of a video.
We present a novel framework for edge-aware optimization that is an order of magnitude faster than the state of the art while maintaining comparable results.
We define three sub-Aspects of summarization: position, importance, and diversity and conduct an extensive analysis of the biases of each sub-aspect with respect to the domain of nine different summarization corpora (e.g., news, academic papers, meeting minutes, movie script, books, posts).
An empirical study that ablates various spatial attention elements within a generalized attention formulation, encompassing the dominant Transformer attention as well as the prevalent deformable convolution and dynamic convolution modules.
We analyzed the STAT1 interactome after streptavidin pull-down of biotagged STAT1 from human embryonic kidney 293T cells with and without activation.
In this paper, we propose a framework named FAB that takes advantage of structure consistency in the temporal dimension for facial landmark detection in motion-blurred videos.
This paper proposes a probabilistic ordinal link function model for ordinal regression, which improves the results of a nominal model and outperforms other robust proposals.
We treat domain information as explicit supervision and design an unpaired image-to-image translation framework, Domain-supervised GAN (DosGAN), which takes the first step towards the exploration of explicit domain supervision.
The advances in mass spectrometry-based proteomics technologies have enabled the generation of global proteome data from tissue or body fluid samples collected from a broad spectrum of human diseases. Comparative proteomic data identifies and prioritizes the proteins showing altered abundances, called differentially expressed proteins (DEPs), in disease samples. Protein biomarker candidates that can serve as indicators of disease states are then selected as key molecules among these proteins.
We propose SQuantizer, a new training method that jointly optimizes for both sparse and low-precision neural networks, achieving state-of-the-art accuracies using 4-bit and 2-bit precision.
We propose a method that learns to synthesize eye fundus images directly from data using adversarial learning.
We propose to combine VoiceLoop, an autoregressive SS model, with Variational Autoencoder (VAE) to model global characteristics of speech, enabling the expressiveness of the synthesized speech to be controlled in an unsupervised manner.
We introduce an end-to-end machine learning-based system for classifying autism spectrum disorder using representations of different facial attributes from convolutional neural networks, which are trained on images in the wild.
We propose a new approach for weakly supervised action segmentation based on a two branch network that achieves state-of-the-art results while being fully differentiable and faster to train.
We propose 3DRotNet: a self-supervised approach to learn spatiotemporal features from unlabeled videos, which can be transferred to improve video understanding tasks in small datasets.
A method for improving retention and drainage performance in a papermaking process using a hydrophilic dispersion polymer.
We equip the adversarial network with a "significance-aware information bottleneck (SIB)", to address the above problem. The new network structure, called SIBAN, enables a significance-aware feature purification before the adversarial adaptation, which eases the feature alignment and stabilizes the adversatorial training course.
This paper introduces the second DIHARD challenge, the second in a series of speaker diarization challenges intended to improve the robustness of diarisation systems to variation in recording equipment, noise conditions, and conversational domain.
We introduce weak self-training (WST) method and adversarial background score regularization (BSR) for domain adaptive one-stage object detection.
A review of state-of-the-art graph embedding techniques with insights.
We propose a novel graph-based approach for more flexible and diverse combinations of knowledge transfer. We also propose four gate functions that are introduced into loss functions.
Machine learning models are vulnerable to adversarial examples formed by applying small carefully chosen perturbations to inputs that cause unexpected classification errors. In this paper, we perform experiments on various adversarial example generation approaches with multiple deep convolutional neural networks.
We address this issue from the perspective of transfer learning, and design an object class model that explicitly leverages correlations between visual features to improve performance in simultaneous 2D object localization and viewpoint estimation.
 GearNN employs an optimization algorithm to identify a small set of"distortion-sensitive"DNN parameters, given a memory budget. Based on the distortion level of the input, GearNN adapts only the distortion-sensitive parameters, while reusing the rest of constant parameters across all input qualities.
We present a novel deep learning architecture for probabilistic future prediction from video, which allows sampling consistent, highly probable futures from a compact latent space.
We explore the task of learning to generate graphs that conform to a distribution observed in training data. We propose a variational autoencoder model in which both encoder and decoder are graph-structured.
We use AutoAugment to search for improved data augmentation policies, and achieve state-of-the-art accuracy on CIFAR-10 and ImageNet without additional data.
We propose a new method for creating computationally efficient and compact convolutional neural networks (CNNs, without compromising accuracy, by exploiting the sparsity of inter-layer filter dependencies.
This paper intends to fully exploit the correlations among different attributes by constructing a graph, and utilize the Graph Attention Layer (GAL) for exploring on the most relevant attribute feature and refining the task-dependant feature by considering other attributes.
We tackle this as a missing labels problem, marking pixels sufficiently away from the BB as belonging to the background and learning the labels of the unknown pixels.
We propose several metrics to measure robustness of classifiers to natural adversarial examples, including ones trained in conventional and robust ways.
We propose an alternative U-Net based discriminator architecture for generative adversarial networks that provides detailed per-pixel feedback to the generator while maintaining the global coherence of synthesized images, by providing the global image feedback as well.
We demonstrate that deep learning methods can determine the best focus position from 1-2 image samples, enabling 5-10x faster focus than traditional search-based methods.
The Pascal Visual Object Classes (VOC) challenge is a benchmark in visual object category recognition and detection, providing the vision and machine learning communities with a standard dataset of images and annotation.
We propose a Deep Reinforcement Learning framework based on three new intermediate rewards, namely goal-achieved, progressive and informativeness that encourage the generation of succinct questions, which in turn uncover valuable information towards the overall goal.
We tackle the complex problem of determining entailment relationships between case law documents, one of the tasks in the Competition on Legal Information Extraction and Entailment (COLIEE).
We propose a learning-based algorithm for stereo matching based on the observation that the matching behavior of each expert is determined by the image texture and the underlying scene structure.
This paper addresses the problem of representing multimedia information under a compressed form that permits efficient classification. The semantic coding problem starts from a subspace method where dimensionality reduction is formulated as a matrix factorization problem.
In this paper, the traditional model based variational methods and deep learning based algorithms are naturally integrated to address mixed noise removal problem.
The choice of a good topology for a deep neural network is a complex task, essential for any deep learning project. This task normally demands knowledge from previous experience, as the higher amount of required computational resources makes trial and error approaches prohibitive.
Shadow removal is an essential task for scene understanding. Many studies consider only matching the image contents, which often causes two types of ghosts: color in-consistencies in shadow regions or artifacts on shadow boundaries. In this paper, we tackle these issues in two ways. First, to carefully learn the border artifacts-free image, we propose a novel network structure named the dual hierarchically aggregation network~(DHAN)
We propose the combination of dense Histogram of Oriented Gradients (HOG features with Active Appearance Models (AAMs) that generalize well to unseen faces with illumination, identity and pose variations.
Neural Architecture Search methods are effective but often use complex algorithms to come up with the best architecture. We propose an approach with three basic steps that is conceptually much simpler.
We introduce PERCH, a new non-greedy algorithm for online hierarchical clustering that scales to both massive N and K, achieving a higher quality clustering than the strongest flat clustering competitor.
We propose a method to automatically discover and cluster action concepts, and learn their classifiers from weakly supervised image-sentence corpora.
In convolutional neural networks (CNNs), the filter grouping in convolution layers is useful to reduce the network parameter size.
We present semantic segmentation experiments with a model capable to perform predictions on four benchmark datasets: Cityscapes, ScanNet, WildDash and KITTI.
We present FAKTA which is a unified framework that integrates various components of a fact checking process: document retrieval from media sources with various types of reliability, stance detection of given claims, evidence extraction, and linguistic analysis.
This paper provides a comprehensive survey of Machine Learning Testing (ML testing) research.
We propose \mldas, a mixed-level reformulation for Neural Architecture Search that can be optimized efficiently and reliably, achieving state-of-the-art results.
We aim for zero-shot localization and classification of human actions in video. Where traditional approaches rely on global attribute or object classification scores, our main contribution is a spatial-aware object embedding.
This work aims to bridge these gaps by first reinforcement-learning a multi-fingered robotic grasping policy in simulation that operates in pixel space of the input: a single depth image.
We define an energy over whole stereo sequences and optimize their conditional random field (CRF) distributions using the mean-field approximation using fast, iterative spatio-temporal filtering.
The first step towards a wide-coverage tableau prover for natural logic is presented.
A novel stereo-based hand segmentation algorithm for 3D hand pose tracking/estimation.
We show how to improve semantic segmentation through the use of contextual information.
In this paper, we propose the error compensated quantized stochastic gradient descent algorithm to improve the training efficiency.
We present a new "learning-to-learn"-type approach that enables rapid learning of concepts from small- to-medium sized training sets and is primarily designed for web-initialized image retrieval.
We present paris, an approach for the automatic alignment of ontologies. The heart of the approach is probabilistic.
The ResNet34-3DRes18 model is a lightweight and efficient two-dimensional and three-dimensional fused model for behavior recognition based on video streams.
We propose a unified way to encode individual layers into vectors and bring them together to form an integrated description via LSTM, based on its architecture.
In this work, we present a fully automated lung computed tomography (CT) cancer diagnosis system, DeepLung, with 3D dual path network features.
The increasing amount of data on the Web, in particular of Linked Data, has led to a diverse landscape of datasets, which make entity retrieval a challenging task. Explicit cross-dataset links, for instance to indicate co-references or related entities can significantly improve entity retrieval.
We address the novel problem of estimating an occlusion-reasoned semantic scene layout in the top-view. We propose a convolutional neural network that learns to predict occluded portions of the scene layout.
We demonstrate Pseudo-task Regularization (PtR) which dynamically regularizes a convolutional network by simply attempting to regress image representations to a pseudo-target during fine-tuning.
We study the video super-resolution (SR) problem for two-stream action recognition networks, and propose two video SR methods for spatial and temporal streams respectively.
Pre-training students unlocks their generalization potential, surprisingly even for very compact networks.
We consider the problem of building high-level, class-specific feature detectors from only unlabeled data. Contrary to what appears to be a widely-held intuition, our experimental results reveal that it is possible to train a face detector without having to label images.
This paper proposes an alternative approach based on a learnable correlation operator that can be used to establish frame-to-frame matches over convolutional feature maps in the different layers of the network.
In this paper, we introduce a novel method to combine the advantages of both multi-task and curriculum learning in a visual attribute classification framework.
We propose an alternative formulation for estimating the GMM parameters using the sliced-Wasserstein distance, which gives rise to a new algorithm that can estimate high-dimensional data distributions more faithfully.
We propose a machine learning framework to obtain speech emotion representations by limiting the effect of speaker variability in the speech signals by using an entropy loss function.
We present a novel algorithm for deterministic motion trajectory segmentation by using epipolar geometry and adaptive kernel-scale voting.
We introduce Charades-Ego, a large-scale dataset of paired first-person and third-person videos, involving 112 people, with 4000 paired videos. This enables learning the link between the two, actor and observer perspectives.
This paper aims to review computerised X-ray security imaging algorithms by taxonomising the field into conventional machine learning and contemporary deep learning applications.
We propose an efficient adaptive dropout (named Evolutional dropout) that computes the sampling probabilities on the fly from a mini-batch of examples.
We propose to learn two representations for each node, and render each representation responsible for encoding the corresponding type of links, which is achieved by jointly embedding the network structure and inferring the type of each link.
Protein-protein interaction inhibitors of the Aurora-A/TPX2 complex might represent lead compounds for further development towards pioneering anti-cancer drugs and provide the proof-of-concept for a new exploitable strategy.
Pedestrian misalignment, which mainly arises from detector errors and pose variations, is a critical problem for a robust person re-identification (re-ID) system. To address this problem, this paper introduces the pose invariant embedding (PIE) as a pedestrian descriptor.
We propose a novel method to exploit more discriminative image similarity descriptor for person re-identification and propose a re-ranking strategy to improve performance.
This paper presents a new framework named network adjustment, which considers network accuracy as a function of FLOPs, so that under each network configuration, one can estimate theFLOPs utilization ratio for each layer and use it to determine whether to increase or decrease the number of channels on the layer.
We propose a curriculum-style learning approach to minimize the domain gap in semantic segmentation, which improves the models’ performance.
We address key challenges in proxy-based metric learning such as performance under extreme classification and describe techniques to stabilize and learn higher dimensional embeddings.
We study the problem of understanding the movements of objects as a result of applying external forces to them. We design a deep neural network model that learns long-term sequential dependencies of object movements caused by external forces.
We propose an end-to-end monocular depth estimation method using stereo methods, with two intriguing properties, namely i) geometrical constraints can be explicitly imposed during inference; ii) demand on labelled depth data can be greatly alleviated.
We provide an improved analysis of normalized SGD showing that adding momentum provably removes the need for large batch sizes on non-convex objectives, matching the best-known rates.
This paper proposes a facial expression recognition system using evolutionary particle swarm optimization (PSO)-based feature optimization. The system first employs modified local binary patterns, which conduct horizontal and vertical neighborhood pixel comparison, to generate a discriminative initial facial representation.
Drosophila melanogaster are known to live in a social but cryptic world of touch and odours, but the extent to which they can perceive and integrate visual information is a hotly debated topic. Here, we apply machine learning and show that individual D. melanogasters can re-identify conspecifics with surprising accuracy.
We propose an automated pulmonary nodule detection algorithm that combines progressive resolution and hierarchical saliency and achieve state-of-the-art detection score.
In standard generative adversarial network (SGAN), the discriminator estimates the probability that the input data is real. We show that this property can be induced by using a relativistic discriminator which estimate the probability of the given real data is more realistic than a randomly sampled fake data.
We present the first framework that makes use of Convolutional Neural Networks (CNNs) for odometry estimation fusing 2D laser scanners and mono-cameras.
We introduce a deep autoencoder network for point clouds, which outperforms the state of the art in 3D recognition tasks. We also design GAN architectures to generate novel point-clouds.
A promising paradigm for achieving highly efficient deep neural networks is the idea of evolutionary deep intelligence, which mimics biological evolution processes to progressively synthesize more efficient networks. In this study, we take a deeper look at the notion of synaptic cluster-driven evolution which guides the evolution process towards the formation of a highly sparse set of synaptic clusters in offspring networks.
In mathematical terms, an artificial neuron computes the inner product of a $d$ -dimensional input vector ${x}$ with its weight vector ${w$ and fires based on the result of this comparison.
We propose to learn motion priors for efficient video object detection.
In this paper, we propose and study matrix approximations that are explicitly expressed in terms of a small number of columns and/or rows of the data matrix, and thereby more amenable to interpretation in terms the original data.
We study whether and how visual grounding is useful in the presence of varying amounts of textual supervision in a low-resource setting.
This paper introduces a binary attention mechanism into image steganography to help alleviate the security issue, and in the meanwhile, increase embedding payload capacity.
We propose a learning-based method to adapt the source and target tensor representations directly, without vectorization.
We propose a generative model and a conditional variant built on such a disentangled latent space, which allows us to generate realistic samples corresponding to various objects in a high variety of views.
We propose a novel 2D-assisted self-supervised learning (2DASL) method that can effectively use "in-the-wild" 2D face images with noisy landmark information to substantially improve 3D face model learning.
We develop Boundary Attack++, a family of algorithms based on a novel estimate of gradient direction using binary information at the decision boundary for decision-based adversarial attack.
DasNets feedback structure can dynamically alter its convolutional filter sensitivities during classification, improving classification performance.
We propose a novel convolutional neural network (CNN) module to learn a stereo matching cost with a large-sized window without introducing the fattening effect.
Our proposed model, Aff2Vec provides a method for enriched word embeddings that are representative of affective interpretations of words.
We propose an approach to detangle people in multi-person images as a region assembly problem. It enforces that the composed body part regions of each person instance obey constraints on relative sizes, mutual spatial relationships, foreground coverage, and exclusive label assignments.
We propose to fine-tune a deep convolutional neural network using augmented dataset to extract features from partially colored hand-drawn sketches for query specification in a sketch-based image retrieval framework.
We propose a new end-toend attention-embedded neural network for image denoising, named as Residual Dilated Attention Network (RDAN)
This paper investigates the use of convolutional neural networks for the purpose of image foreground extraction from a dynamic environment using transfer learning for real-time operations.
Weakly supervised object localization using convolutional neural networks trained on only image labels.
Our goal is to develop a descriptor of local image structure that carries the maximally possible amount oflocal image information under morphological invariance.
We propose VisualBERT, a simple and flexible framework for modeling a broad range of vision-and-language tasks.
This paper automatically extracts properties and triples from Wikipedia categories so as to achieve a wider article coverage with less manual effort.
We propose a Transition-Aware Context Network (TACNet) to distinguish transitional states.
We propose a novel algorithm for unsupervised video-based person re-identification based on the Bayes Nearest Neighbor algorithm and Spearman distance.
TensorFlow Eager is a multi-stage, Python-embedded domain-specific language for hardware-accelerated machine learning, suitable for both interactive research and production.
In this paper, we propose a method that adjusts the confidence estimates of a general classifier such that they approach the probability of classifying correctly.
This paper presents a method for automatic video object segmentation based on the fusion of motion stream, appearance stream, and instance-aware segmentation.
We propose gated recurrent feature pyramid for the problem of learning object detection from scratch.
A survey of the learning to hash algorithms, categorize them according to the manners of preserving the similarities into: pairwise similarity preserving, multiwise similarity exploiting, implicit similarity preserving and quantization.
We address the problem of numerical difficulty in the large-size pattern classification case, where many local variations cannot be adequately handled by a single global model. We propose a multimodal localized piecewise subspace learning framework.
In this paper, we present TailorNet, a neural model which predicts clothing deformation in 3D as a function of three factors: pose, shape and style (garment geometry), while retaining wrinkle detail.
We propose a novel representation learning model which learns a representation of identity that depends only on body shape via adversarial learning and feature disentanglement.
We present an approach for generating (universal) adversarial perturbations that make the network yield a desired target segmentation as output.
In this paper, we propose to apply a novel method, namely Hybrid Orthogonal Projection and Estimation (HOPE), to CNNs in order to introduce orthogonality into the CNN structure.
We show through several theoretical and numerical results that GAN zero-sum games may not have any local Nash equilibria. We propose a new approach, which we call proximal training, for solving GAN problems.
We propose innovative methods, based on neural networks prediction, for improving the accuracy of the calculated PMV for fast forward movies with high motion.
We quantify the generality versus specificity of neurons in each layer of a deep convolutional neural network and report a few surprising results. Transferability of features decreases as the distance between the base task and target task increases, but that transferring features even from distant tasks can be better than using random features.
We use convolutional neural networks for pedestrian detection, and achieve state-of-the-art results.
Reparameterization of variational auto-encoders with continuous random variables is an effective method for reducing the variance of their gradient estimates. In contrast to previous works which resort to softmax-based relaxations, we propose to optimize it directly by applying the \emph{direct loss minimization} approach.
Generative Adversarial Networks have a surprising ability to generate sharp and realistic images, but they are known to suffer from the so-called mode collapse problem. In this paper, we propose a new GAN variant that overcomes this problem by encouraging the Discriminator to form clusters in its embedding space.
We explore using convolutional networks to create a model of an individual's personal preferences based on rated photos.
In this paper, we present a deep nonparametric Bayesian method to synthesize a light field from a single image.
We introduce a general consistency condition covering communication-reduced and asynchronous distributed SGD implementations. The proposed framework de-clutters the implementation-specific convergence analysis and provides an abstraction.
We present ProSLAM, a lightweight open-source stereo visual SLAM system designed with simplicity in mind.
A formalization of the notion of validity in autotagging evaluation, and a method to test it in general.
We propose a model-based RL approach to overcome the sparse-reward problem in the RL training process, which can assist next-word prediction and provide intermediate rewards for generator optimization.
We propose a learning-based approach for frame-to-frame monocular visual odometry estimation.
The rolB plant oncogene of Agrobacterium rhizogenes perturbs many biochemical processes in transformed plant cells, thereby causing their neoplastic reprogramming.
We propose a novel zero-shot method based on training an end-to-end model that fuses semantic attribute prediction with visual features to propose object bounding boxes for seen and unseen classes, improving its performance for novel and unseen objects.
We present a neural network model approach for multi-frame blind deconvolution. The discriminative approach adopts and combines two recent techniques for image deblurring.
A comprehensive study to evaluate the performance of deep learning based face representation under several conditions including the varying head pose angles, upper and lower face occlusion, changing illumination of different strengths, and misalignment due to erroneous facial feature localization.
We propose an efficient training methodology and incrementally growing DCNN to learn new tasks while sharing part of the base network.
We present a neural-network-based architecture for 3D point cloud denoising called neural projection Denoising (NPD)
We address two critical issues based on our empirical observations: Ineffective feature learning due to flat distributions of output importance scores for each frame, and training difficulty when dealing with longlength video inputs.
We introduce the SaaS Algorithm for semi-supervised learning, which uses learning speed during stochastic gradient descent in a deep neural network to measure the quality of an iterative estimate of the posterior probability of unknown labels, without attempting to infer the model parameters at first.
We show that RPC is sub-optimal for distributed deep learning computation, especially on an RDMA-capable network. The tensor abstraction and data-flow graph, coupled with RDMA network, offers the opportunity to reduce the unnecessary overhead (e.g., memory copy) without sacrificing programmability and generality.
We propose a novel weakly supervised learning method that models the video as a sequence of automatically mined, discriminative sub-events (eg. onset and offset phase for "smile", running and jumping for "highjump").
We present EpipolarPose, a self-supervised learning method for 3D human pose estimation, which does not need any 3D ground-truth data or camera extrinsics.
Adversarial Posterior Distillation of Stochastic Gradient Langevin Dynamics for Bayesian Neural Networks .
MLPerf Inference implements a set of rules and practices to ensure comparability across systems with wildly differing architectures. The first call for submissions garnered more than 600 inference-performance measurements from 14 organizations.
We propose a novel deep neural network (DNN)-based dense and sparse labeling (DSL) framework for saliency detection.
In this paper, we propose a novel multi-task learning method based on the deep convolutional network so that the relation among different tasks can be explored.
This paper addresses the problem of viewpoint estimation of an object in a given image. It presents five key insights that should be taken into consideration when designing a CNN that solves the problem.
We propose Multi-Level Factorisation Net (MLFN), a novel network architecture that factorises the visual appearance of a person into latent discriminative factors at multiple semantic levels without manual annotation.
We address these challenges by proposing a Knowledge-Enriched Transformer (KET), where contextual utterances are interpreted using hierarchical self-attention and external commonsense knowledge is dynamically leveraged using a context-aware affective graph attention mechanism.
We propose algorithms for intra-patient lesion matching and missing annotation mining. Experimental results validate their effectiveness.
We present a method to infer 3D pose and shape of vehicles from a single image from a fine-scaled representation of the image.
We combine two highly useful classes of variational autoencoders to model face images, while extracting natural and human-understandable features without labels.
This paper presents a novel approach to the facial expression generation problem. Building upon the assumption of the psychological community that emotion is intrinsically continuous, we first design our own continuous emotion representation with a 3-dimensional latent space issued from a neural network trained on discrete emotion classification.
We propose an end-to-end trainable text spotting approach named Text Perceptron. It unites text detection and the following recognition part into a whole framework, and helps the whole network achieve global optimization.
We examine the impact of a test set question's difficulty to determine if there is a relationship between difficulty and performance. We model difficulty using well-studied psychometric methods on human response patterns.
This paper aims to develop a novel cost-effective framework for face identification, which progressively maintains a batch of classifiers with the increasing face images of different individuals, and incorporates them into training under weak expert recertification.
We modify a recently proposed Multi-Grid Back-Projection (MGBP) architecture to work as a generative system with an input parameter that can control the amount of artificial details in the output.
We propose a novel cascaded region-based convolutional neural network to capture earthquake events in different sizes while incorporating contextual information to enrich features for each proposal.
This paper presents a classifier ensemble for Facial Expression Recognition using feature extraction and fine-tuning convolutional neural networks.
We introduce a quantitative and automated evaluation metric for sentence embedding interpretability, based on topic coherence methods.
We propose a novel end-to-end learning framework which is enhanced by learning other auxiliary tasks and an attention mechanism to relieve the overfitting problem in emotion recognition.
We present Dialogue Graph Convolutional Network (DialogueGCN), a graph neural network based approach to ERC.
We explore how to improve the classification accuracy of themodel without adding modules at the inference stage.
This study sought to computationally predict natural product-derived lead compounds with the potential to be developed further into potent drugs with better therapeutic efficacy.
In this paper, we propose a new framework for tackling face recognition problem as a deformable image registration and feature matching problem.
We propose to add the assumption of conditional independence to the framework of fully-connected CRFs, which speeds up inference and training by a factor of more then 100.
We apply deepfake technology to Parkinson's disease examination videos to de-identify subjects, and quantitatively show that face-swapping is reliable, and it keeps the keypoints almost invariant, significantly better than traditional methods.
This paper describes compact image descriptors enabling accurate object categorization with linear classification models, which offer the advantage of being efficient to both train and test.
This paper presents a new robust PCA method for foreground–background separation on freely moving camera video with possible dense and sparse corruptions.
We show that removing contested edges improves prediction accuracy and scalability in graph-regularized matrix factorization, remaining linear with respect to the number of non-zeros.
We propose an efficient and adaptive code-driven graph, which is updated by decoding in the context of an auto-encoder, which in turn propagates the updated network feedback for the encoder to learn an optimal encoder.
We challenge widely-held beliefs about evading face detection: do our old techniques such as blurring the face region or wearing "privacy glasses" still work?
We propose a weakly supervised and counterfactually resilient textual grounding system which is end-to-end trainable with only image-level annotations and performs much better in face of counterfactual inputs/queries.
In this paper we propose a novel environmental sound classification approach incorporating unsupervised feature learning from codebook via spherical $K$-Means++ algorithm and new architecture for high-level data augmentation.
We propose a simple extension, termed SGM-P, to utilize precomputed surface orientation priors for stereo matching and show that such priors can yield significant performance gains.
This paper describes a new variational method for estimating disparity from stereo images using a block-iterative structure.
We introduce switched linear projections for expressing the activity of a neuron in a ReLU-based deep neural network in terms of a single linear projection in the input space that completely determine the entire computation of the deep network.
In this paper we propose a model to learn multimodal multilingual representations for matching images and sentences in different languages, with the aim of advancing multilingual versions of image search and image understanding.
We propose RDSNet, a novel deep architecture for reciprocal object detection and instance segmentation that learns features jointly.
We generalize the recently proposed BERT to a multi-task learning setting: we couple BERT's masked language modeling and next sentence prediction objectives with the auxiliary binary word relation classification, through which we inject clean linguistic knowledge.
We propose a novel Recurrent Convolutional Network (RCN), which captures the temporal context across frames at each network level, while being causal and using fewer parameters.
We introduce a new pre-training task inspired by reading comprehension and an effort to avoid encoding general knowledge in the transformer network itself.
Unsupervised part-based weighting aggregation (PWA) method for image retrieval.
We describe our Alexa Prize system (called 'Alana') consisting of an ensemble of bots, combining rule-based and machine learning systems, and using a contextual ranking mechanism to choose a system response.
We present a novel unsupervised learning framework for single view depth estimation using monocular videos, and introduce a super-resolution network to solve the above two problems.
In this paper, we propose an Attentional Generative Adversarial Network (AttnGAN) that allows attention-driven, multi-stage refinement for fine-grained text-to-image generation.
We introduce a class-conditional domain adaptation method for semantic segmentation and demonstrate performance comparable to state-of-the-art methods.
We performed a cross-sectional study to investigate whether assessment of texture in DAT SPECT radiotracer uptake enables enhanced correlations with severity of motor and cognitive symptoms in Parkinson's disease.
We develop a general framework to quantify the effects of calculation errors on iterative-convergent algorithms and use this framework to design new strategies for checkpoint-based fault tolerance across a variety of ML models and training algorithms.
We propose an additionsubtraction twin-gated recurrent network (ATR) to simplify neural machine translation.
We propose a universal image reconstruction method to represent detailed images purely from binary sparse edge and flat color domain and achieve outstanding results on reconstructing realistic images and translating hand drawn drafts into satisfactory paintings.
We integrate architecture search with quantization (compression) policies for neural networks to find compact neural network models suitable for mobile devices.
We propose SAT (Show, Attend and Translate), an unified and explainable generative adversarial network equipped with visual attention that performs unpaired image-to-image translation for multiple domains.
We exploit Wikipedia and Freebase to collect training data in an unsupervised manner, where a neural network model is then learnt to select the most appropriate comparison dimension for a given superlative expression, and further determine its ranking order heuristically.
This paper proposes a novel multi-objective optimization method for evolving state-of-the-art deep CNNs in real-life applications, which automatically evolves the non-dominant solutions at the Pareto front.
In this paper, we propose an efficient method for obtaining the rank configuration of the whole network to choose the right rank configuration.
Soft Sampling re-weights the gradients of RoIs as a function of overlap with positive instances. This ensures that the uncertain background regions are given a smaller weight compared to hardnegatives.
We introduce a new pre-trainable generic representation for visual-linguistic tasks, called Visual-Linguistic BERT (VL-BERT for short).
Initial position estimation in global maps, which is a prerequisite for accurate localization, plays a critical role in mobile robot navigation tasks.
We present an approach for one-shot learning from a video of a human by using human and robot demonstration data from a variety of previous tasks to build up prior knowledge through meta-learning.
In this paper, we propose the recurrent models of visual co-attention that aim to simulate human eye movement, focusing on the sequential concurrent attention (co-att attention) regions of the same locations when comparing image pairs.
In this paper, we propose and develop deconvolution architecture for efficient FPGA implementation, which significantly improves the performance and power efficiency of CNN algorithms.
We build a new visual-inertial VSLAM/VISLAM benchmark for augmented reality and evaluate it on a series of evaluation criteria for AR applications.
A general learning-based framework for reliable landmark localization on 3-D facial data under challenging conditions (i.e., facial expressions and occlusions).
Machine vision is critical to robotics due to a wide range of applications which rely on input from visual sensors. To create the smart homes and systems of tomorrow, an overview about current challenges in the research field would be of use to identify further possible directions, created in a systematic and reproducible manner.
We propose ZINC08234189 and ZINC03871891 as novel small-molecule Met inhibitors for active state of c-Met kinase domain.
This paper presents a general refinement procedure that enhances any given depth map obtained by passive or active sensing, and proposes specific masks to tackle areas in the scene that require a special treatment.
This paper proposes an approach to use linked open data and Semantic Web technologies to address the heterogeneous data integration problem.
The SPOT 6-7 satellite ground segment includes a systematic and automatic cloud detection step in order to achieve state-of-the-art performance.
A simple warm restart technique for stochastic gradient descent to improve its anytime performance when training deep neural networks.
We study an interesting problem in training neural network-based models for natural language generation tasks, which we call the representation degeneration problem, and propose a novel regularization method to address it.
The ability to categorize is a cornerstone of visual intelligence, and a key functionality for artificial, autonomous visual machines. This problem will never be solved without algorithms able to adapt and generalize across visual domains.
This paper proposes a lane marking semantic segmentation method based on LIDAR and camera fusion deep neural network.
Automated blood vessel segmentation in retinal images using two convolutional neural networks chained to each other .
We propose and evaluate several strategies for achieving Zero-Shot VQA, including methods based on pretrained word embeddings, object classifiers with semantic embedDings, and test-time retrieval of example images.
Sparse representation has attracted much attention from researchers in fields of signal processing, image processing, computer vision, and pattern recognition. Many different algorithms have been proposed for sparse representation. The taxonomy of sparse representation methods can be studied from various viewpoints.
This paper proposes a novel transformation which changes the topology of the DL architecture such that it reaches an optimal cross-layer connectivity, which improves convergence speed to the desired accuracy.
Versatile Auxiliary Classifier with Generative Adversarial Network for Multi-Class Scenario .
We propose a multi-task transfer learning method for facial beauty prediction.
Credibilist SLAM based on Transferable Belief Model framework.
In this paper, we present a novel deep model named coarse-fine convolutional neural network for person re-identification in camera sensor networks, which jointly learns global and multi-scale local features simultaneously.
We propose a novel deep dual recurrent encoder model that utilizes text data and audio signals simultaneously to obtain a better understanding of speech data, and it thus utilizes the information within the data more comprehensively than models that focus on audio features.
Learning an embedding function for content-based image retrieval within the e-commerce domain using the triplet loss and an online sampling method that constructs triplets from within a minibatch.
This paper presents approaches aimed to improve the quality of far-field speaker verification systems in the presence of environmental noise, reverberation and b) reduce the system qualitydegradation for short utterances.
We present a novel architecture for individual word detection in scene images based on semantic segmentation, which avoids intensive post-processing, producing an end-to-end word detection system.
Attention mechanisms are widely used in current encoder/decoder frameworks of image captioning, where a weighted average on encoded vectors is generated at each time step to guide the caption decoding process. However, the decoder has little idea of whether or how well the attended vector and the given attention query are related.
This paper introduces the recent development of our research on transplanting the fully convolutional network technique to the detection tasks on 3D range scan data. We proposes to present the data in a 2D point map and use a single 2D end-to-end fully convolved network to predict the objectness confidence and the bounding boxes simultaneously.
We review some of the most seminal recent algorithms in the OOD detection field, we divide those methods into training and post-training and we experimentally show how the combination of the former with the latter can achieve state-of-the-art results.
This paper presents the IMS contribution to the PolEval 2018 Shared Task. We submitted systems for both of the Subtasks of Task 1. In Subtask (A), which was about dependency parsing, we used our ensemble system from the CoNLL 2017 UD Sharedtask. The system achieved the second place out of four participating teams.
We propose to fix almost all layers of a deep convolutional neural network, allowing only a small portion of the weights to be learned.
We introduce a novel approach for robust and selective STIP detection, by applying surround suppression combined with local and temporal constraints, resulting in improved performance and efficiency.
The paper presents architecture and properties of the ensemble of the classifiers operating in the tensor orthogonal spaces obtained with the Higher-Order Singular Value Decomposition of prototype tensors.
We propose a weakly supervised method for the phrase localization problem where neither training procedure nor paired, task-specific data is required.
A multiview representation framework based on transfer learning is proposed for micro-expression recognition. The proposed algorithm has better performance than other related methods.
We propose a new graph construction technique by fusing local and global structural similarity (FLGSS) and an extended label propagation algorithm (ELP) for graph-based semi-supervised learning.
This paper borrows the scaled Pearson correlation from the finance domain and builds a metric that can evaluate the performance of similarity methods over cross-sectional datasets over the benchmark dataset scores range.
We propose a scalable neural network framework to reconstruct the 3D mesh of a human body from multi-view images, in the subspace of the SMPL model.
This paper proposes a multi-task deep learning with dynamic programming approach for embryo early development stage classification from time-lapse videos.
In this paper we present a first version of the LifeSeeker interactive lifelog retrieval engine that is under development at Dublin City University.
We propose a pedestrian detection system based on deep learning, adapting a general-purpose convolutional network to the task at hand, achieving state-of-the-art performance.
We propose a Top-N-targets-balanced recommendation based on attentional sequence-to-sequence (Seq2Seq) learning to capture the users' transient interests.
We studied the capacity of the baker's yeast genome to compensate the complete loss of genes during evolution, and explored the long-term consequences of this process.
We develop a unified generative model that learns highly discriminative CNN features in both inductive and transductive learning settings, i.e. zero-shot and few-shot.
A comprehensive survey of recent advances in visual object detection with deep learning.
We tackle the problem of discovering novel classes in an image collection given labelled examples of other classes using self-supervised learning, improving both supervised classification of the labelled data, and the clustering of the unlabelled data.
This paper proposes an end-to-end DNN for piece-wise planar reconstruction from a single RGB image.
We provide a general framework for characterizing the trade-off between accuracy and robustness in supervised learning, define and study an influence function that captures the sensitivity, under adversarial attack, of the optima of a given loss function.
We propose Escort, an efficient sparse convolutional neural network on GPUs, which improves inference performance (speed) when running models on GPUs.
We propose a new tracking algorithm combining affine transformation with convolutional features to capture the geometric deformation of the target.
We introduce CLAMShell, a system that speeds up crowds in order to achieve consistently low-latency data labeling.
We propose a flexible deep CNN infrastructure, called Hypotheses-CNN-Pooling, where an arbitrary number of object segment hypotheses are taken as inputs, then a shared CNN is connected with each hypothesis, and finally the CNN output results from different hypotheses are aggregated with max pooling to produce the ultimate multi-label predictions.
The current state of the art for image annotation and image retrieval tasks is obtained through deep neural network multimodal pipelines, which combine an image representation and a text representation into a shared embedding space. In this paper we evaluate the impact of using the Full-Network embedding (FNE) in this setting, replacing the original image representation with a multi-scale discrete representation of images.
We have developed a systems biology approach to identify new factors controlling complex III biogenesis, which can compensate for defects in the biogenesis of the respiratory complexes.
In this paper, a hierarchical deep multi-task learning (HD-MTL) algorithm is developed for large-scale visual recognition.
We propose a new model, IoTNet, designed for resource-constrained environments which achieves state-of-the-art performance within the domain of small efficient models. IoTNet trades accuracy with computational cost differently from existing methods.
We present feature selective networks to reform the feature representations of RoIs by exploiting their disparities among sub-regions and aspect ratios.
In this paper, we propose a light dual-task Neural Network called LDTNet that restores the haze free image in one shot.
Experimental reproducibility and replicability are critical topics in machine learning. Authors have often raised concerns about their lack in scientific publications to improve the quality of the field. We provide an overview of common practices that should be avoided to fairly compare with the state of the art.
We present a weakly supervised approach to estimate 3D pose points, given only 2D pose landmarks, using random 2D projections.
We present a new method for generating adversarial examples that is fast to execute and provides exceptional diversity of output. We efficiently train feed-forward neural networks in a self-supervised manner to generate adversarial example against a target network or set of networks.
We propose a spectral regression kernel discriminant analysis algorithm which is 27 times faster than ordinary KDA.
We propose a novel neural network structure called CrossNets, which considers architectures on directed acyclic graphs, allowing for all forward cross-connections between both adjacent and non-adjacent layers.
We evaluate both supervised and unsupervised CLE models on a large number of language pairs in the BLI task and three downstream tasks, providing new insights concerning the ability of cutting-edge CLE models to support cross-lingual NLP.
We use learned representations from a large labeled modality as supervisory signal for training representations for a new unlabeled paired modality.
DropEasy2d searches discriminative feature areas in the feature maps by sliding and zeroing windows while reserving the indiscriminative features areas to constrain network learning.
This work presents a region-growing image segmentation approach based on superpixel decomposition and a global merging strategy to efficiently guide the region merging process.
We present a stable variational latent generative model for large inpainting of face images. It can not only synthesize novel image structures but also explicitly utilize the latent space with Eigenfaces.
Image classification requires the generation of features capable of detecting image patterns informative of group identity. The objective of this study was to classify images from the CIFAR-10 image dataset by leveraging combinations of disparate image feature sources from both manual and deep learning approaches.
We learn VQA models end-to-end, from pixels directly to answers, and show that strong performance is achievable without using region annotations in pre-training.
In this paper we present an approach to achieve high accuracy of optic disk segmentation using information on the location of blood vessels (vessel map) using robust initial approximation of OD boundary using circular Hough transform.
We present a novel auto-sampling method that is applicable to both 1D and 2D CNNs with significantperformance improvement over WSNet.
We propose U-PCR, a novel principal components approach for unsupervised ensemble regression, based on the assumption that the experts have uncorrelated deviations from the optimal predictor.
We propose a new texture descriptor, D-CNN, obtained by Fisher Vector pooling of a Convolutional Neural Network (CNN) filter bank, which improves the state-of-the-art in texture, mate- rial and scene recognition.
We propose a simple yet effective variant which improves the RC networks: the batch normalization layers of an RC module are learned independently (not shared) for different unrolling steps, which improves their performance.
This paper aims to unleash the potential of Reference-based super-resolution by leveraging more texture details from Ref images with stronger robustness even when irrelevant Ref images are provided.
We propose a novel two-stage method based on associative embedding, inspired by its recent success in instance segmentation, for planar 3D reconstruction.
We compare distance metrics (and divergences) to rank features generated from a neural network, for content-based image retrieval.
We create a co-regulation map of the cell that reflects functional associations between human proteins.
We propose a method for mapping and understanding the role of oncogenic viruses in the regulation of genes, and mapping their role in altering the cellular environment in cancer.
We present a method for disentangling the latent space into the label relevant and irrelevant dimensions, zs and zu, for a single input.
We propose Shooting Labels, the first 3D labeling tool for dense 3D semantic segmentation which exploits Virtual Reality to render the labeling task as easy and fun as playing a video-game.
We propose a GZSL method that directly synthesizes pseudo features of unseen classes contrary to current synthesis-based methods, which synthesize pseudo instances.
This paper aims at providing an introduction to Spiking Neural Networks by focusing on a probabilistic signal processing methodology that enables the direct derivation of learning rules leveraging the unique time encoding capabilities of SNNs.
We propose a novel video captioning framework, termed as \emph{Bidirectional Long-Short Term Memory} (BiLSTM), which captures bidirectional global temporal structure in video.
We propose Stacked Generative Adversarial Networks aiming at generating high-resolution photo-realistic images.
In this work, we move beyond the traditional complex-valued representations, introducing more expressive hypercomplex representations to model entities and relations for knowledge graph embeddings.
Generative models for deep learning are promising both to improve understanding of the model, and yield training methods requiring fewer labeled samples. However, there is no accompanying "proof of correctness" for the generative model.
We find that the variational distributions of deep Bayesian neural networks trained using Gaussian mean-field variational inference consistently exhibit strong low-rank structure after convergence. This means that by decomposing these variational parameters into a low-Rank factorization, we can make our variational approximation more compact without decreasing the models' performance.
This paper presents the Entity-Duet Neural Ranking Model (EDRM), which introduces knowledge graphs to neural search systems, improving generalization ability of neural ranking models.
We propose a multi-task architecture for 3D object recognition, in which the network is trained to predict the pose of the object in addition to the class label as a parallel task.
In this paper, we introduce the Outlier Confidence (OC) model which dynamically measures how likely one pixel is occluded.
We use dominant sets clustering to evaluate how accurate a kernel matrix is expected to be for a SVM classifier in feature combination.
We propose a deep learning basedapproach for facial action unit detection by enhancing andcropping the regions of interest.
We introduce a novel loss for boundary detection and propose an end-to-end network which adopts the bottom-up/top-down architecture to tackle the task.
We develop a method for tracing paths of diffusion and influence through networks and inferring the networks over which contagions propagate.
In multi-person pose estimation, the left/right joint type discrimination is always a hard problem because of the similar appearance. Traditionally, we solve this problem by stacking multiple refinement modules to increase network's receptive fields and capture more global context, which can also increase a great amount of computation. In this paper, we propose a Multi-level Network (MLN) that learns to aggregate features from lower-level (left/right information)
We propose a two-stage adversarial model for image inpainting that does a better job of reproducing filled regions exhibiting fine details.
We propose a cost-sensitive BLS framework for imbalanced learning from disproportionate size of categories instances, which aims to minimize the total misclassifying cost in classification learning.
Deep learning based models have surpassed classical machine learning based approaches in various text classification tasks, including sentiment analysis, news categorization, question answering, and natural language inference.
End-to-end view-aware attribute inference is able to learn better attribute predictions than state of the art.
We propose subspace networks for few-shot classification, where a classifier must generalize to new classes not seen in the training set, given only a small number of examples.
In this paper, we propose a novel efficient layer-wise training framework for graph convolution networks (L-GCN), that disentangles feature aggregation and feature transformation during training, hence greatly reducing time and memory complexities.
In this paper, we propose a novel method for modeling the prior shape knowledge in a probabilistic graphical model framework, where the inference is achieved through nonparametric belief propagation.
Learnable Gated Temporal Shift Module for video inpainting models that effectively tackle arbitrary video masks.
We propose a model (MxSalNet) that incorporates global scene semantic information in addition to local information gathered by a convolutional neural network for predictive capacity much greater than previous unsupervised methods.
We propose a hierarchical feature-aware tracking framework for efficient visual tracking. We propose a novel pre-known expert-adaptive selection strategy.
We propose a new robust subspace clustering method by using the correntropy induced metric, which is robust for handling the non-Gaussian and impulsive noises.
In this paper we present a new approach to creating a geometrically-correct user-perspective magic lens that displays the correct user perspective with a high-quality rendering.
We address the problem of learning vector representations for entities and relations in Knowledge Graphs (KGs) for Knowledge Base Completion (KBC).
StyleGAN2 is a state-of-the-art network in generating realistic images. Editing existing images requires embedding a given image into the latent space of StyleGAN2.
We propose a novel Hierarchical Scale Recalibration Network (HSRNet), which addresses the above issues by modeling rich contextual dependencies and recalibrating multiple scale-associated information.
We introduce a new Wikipedia based collection specific for answer passage retrieval containing thousands of questions with annotated answers and show benchmark results on a variety of state of the art neural architectures and retrieval models.
We present two contextual models (rescoring and re-labeling models) that leverage contextual information (16 contextual relationships are applied in this paper) to enhance the state-of-the-art RCNN-based object detection.
In addition, our work has text overlap with arXiv:1804.00938 by other authors. We want to rewrite this paper for avoiding this fact.
Comunicacio presentada al congres International Conference on Computer Vision Theory and Applications (VISSAP) celebrat a Porto (Portugal) del 27 de febrer a l'1 de marc de 2017.
This paper addresses the ability of generative adversarial networks (GANs) to model complex distributions of data in high-dimensional spaces in a flexible, permutation invariant manner.
We present an algorithm which provides the one-dimensional subspace where the Bayes error is minimized for the C class problem with homoscedastic Gaussian distributions.
This paper proposes a novel method for handling occluded pixels in stereo images based on a probabilistic voting framework that utilizes a novel support-and-decision process to propagate the information inside the Occluded pixel region.
We present Platypus, a production-ready multilingual question answering platform that targets Wiki-data, the largest general-purpose knowledge base on the Semantic Web.
This paper presents a method for learning an And-Or model to represent context and occlusion for car detection and viewpoint estimation.
We propose a contextual instance expansion module, which employs a relative attention module to search and filter useful context information in the scene for person search.
We pursue an early stopping technique that helps Gaussian Restricted Boltzmann Machines (GRBMs) gain good natural image representations in terms of overcompleteness and data fitting.
In this work, a probabilistic model is introduced for a generalized set-up in which the synaptic time series can take values in an arbitrary alphabet and are characterized by both causal and instantaneous statistical dependencies.
Hypotheses-CNN-Pooling (HCP) is a flexible deep CNN infrastructure for multi-label image classification.
This paper proposes a bilinear supervised discrete hashing (BSDH) method based on 2D image features which utilizes bil inear projections to binarize the image matrix features such that the intrinsic characteristics in the2D image space are preserved in the learned binary codes.
We introduce a numerically stable and differentiable approach to leveraging eigenvectors in deep networks. It can handle large matrices without requiring to split them.
We propose a novel debiasing technique to reduce the effects of a biased training dataset while retaining training set labels.
We propose a generic method for localising and localising human actions in video based solely on the distribution of interest points.
This paper finds that the recently widely used group convolution is not suitable for edge computing devices with low memory access speed and low computing resources. Therefore, the EdgeCNN of this paper is designed to reduce computation.
A detailed environment perception is a crucial component of automated vehicles. Based on a grid map environment representation, well-suited for sensor fusion, free-space estimation and machine learning, we detect and classify objects using deep convolutional neural networks using top-view grid maps from range sensor data.
We extend the space of probabilistic models using real NVP transformations, a set of powerful invertible and learnable transformations, resulting in an unsupervised learning algorithm with exact log-likelihood computation, exact sampling, exact inference of latent variables, and an interpretable latent space.
In this paper, we propose a complete video captioning system including both a novel model and an effective training strategy to take full advantage of the abundant linguistic knowledge.
Automatic synthesis of high quality 3D shapes is an ongoing and challenging area of research. In this work we present a method for a convolutional point cloud decoder/generator that makes use of recent advances in the domain of image synthesis.
We propose the use of Wasserstein autoencoders for probabilistic natural language sentence generation.
We use a single user-segmented demonstration to define the primitive actions that comprise a task, localizing additional examples of these actions in unsegmented auxiliary videos via a metalearning-based approach, and performing reinforcement learning on top of the inferred reward functions to learn action policies.
In this paper, we propose a novel feature learning framework for video person re-identification (re-ID) and tackle the poor spatial alignment in video re-ID data sets.
We present Dynamic Convolution, a new design that increases model complexity without increasing network depth or width.
We propose a Symmetric Network (SymmNet) to directly exploit information from an image pair, without estimating disparity or motion in advance, achieving state-of-the-art results on detecting stereo and motion occlusion.
We propose a stereo vision-based approach for tracking the camera ego-motion and 3D semantic objects in dynamic autonomous driving scenarios with instance accuracy and temporal consistency.
This paper presents a novel approach to learn additional proxies as means to side-step strong regularizations, as well as, leverages to promote detailed shape/albedo.
In this paper we identify a novel query type, the top-K assignment query (αTop-K), which computes the K best assignments, i.e., those achieving the K smallest total costs.
We propose a new pipeline for optical flow computation, based on Deep Learning techniques. We use a Siamese CNN to independently, and in parallel, compute the descriptors of both images.
Incremental Label Propagation algorithm for data samples observed sequentially .
This paper presents a novel multi-scale shape regression network (MSR) that is capable of locating text lines of different lengths, shapes and curvatures in scenes.
This paper proposed a novel HOME FAST (Histogram of Orientation, Magnitude, and Entropy with Fast Accelerated Segment Test) spatiotemporal feature extraction approach based on optical flow information to capture anomalies.
The goal of anomaly detection is to identify examples that deviate from normal or expected behavior. We propose a novel architectural choice when designing the CAE, an Inception-like CAE.
A novel concept called Teaching Style Semantic Space (TSSS) is developed based on the pleasure-arousal dimensional theory to describe teaching styles quantitatively and comprehensively.
We compare a number of methods from related fields such as calibration and epistemic uncertainty modeling for improving image confidence when faced with unexpected test samples.
We introduce Convolutional Sum-Product Networks (ConvSPNs) which exploit the inherent structure of images in a way similar to deep convolutional neural networks, optionally with weight sharing.
We exploit the spatial relations between objects in order to improve detection capacity, as well as analyze various properties of the contextual object detection problem.
We propose a novel method named progressive context refinement (PCR) for human keypoint detection from a single image that can efficiently integrate spatial and channel context information to aid feature learning.
This paper presents an approach to unsupervised object discovery in a given unlabeled image set, based on mining repetitive spatial configurations of image contours.
We propose an end-to-end RNN-based Hierarchical Attention-based classification model for vehicle re-identification.
We propose to address this issue by discriminative detection of OOD pixels in input data.
We propose to execute DNNs with dynamic and sparse graph (DSG) structure for compressive memory and accelerative execution during both training and inference.
In this paper, an action (skeleton sequence) is represented as a third-order nonnegative tensor time series to capture the original spatiotemporal information of the action.
We perform the first large scale content analysis of Instagram posts, addressing both the image and the associated hashtags, aiming to understand the content of partially-labelled images taken in-the-wild and the relationship with hashtags.
In this paper, we present a novel approach, called Deep MANTA (Deep Many-Tasks), for many-task vehicle analysis from a given image.
In this paper, a novel, low-complexity, method for action recognition from videos is presented.
We propose a novel sequential multi-camera re-identification approach which can accommodate human operator inputs and provides early gains via a monotonic improvement in target ranking.
This paper proposes a framework for recognizing objects in very low resolution images through the collaborative learning of two deep neural networks: image enhancement network and object recognition network.
A deeper look at how adaptive gradient methods interact with the learning rate schedule, a notoriously difficult-to-tune hyperparameter which has dramatic effects on the convergence and generalization of neural network training.
We introduce the problem of learning from weak labels for text to video moment retrieval.
We build extremely detailed Active Appearance Models (AAM), Constrained Local Models (CLM) and Supervised Descent Method (SDM) models of the human eye and propose two highly detailed shape annotation schemes.
A multi-objective neural architecture search method to find a family of CNN models with the best accuracy and computational resources tradeoffs, in a search space inspired by the state-of-the-art findings in neural search.
We propose a novel learning-based hashing method termed stable supervised discrete hashing with mutual linear regression, where only one stable projection is used to describe the linear correlation between hash codes and corresponding labels.
In this paper, we propose Attention and CL loss, which is a hybrid of center and Online Soft Mining (OSM) loss added to the attention loss on top of a temporal attention-based neural network.
In this paper, we introduce a new design to model a hierarchy from instance level (segmentation), region level (detection) to the whole image to delve into a thorough image understanding for captioning.
This paper presents a formal approach for the design of multisensor data fusion systems that support adaptive graceful degradation through the smart use of sensor modalities, for the purpose of deploying autonomous vehicles.
We present a way to rapidly bootstrap object detection on unseen videos using minimal human annotations using bounding box merging and data augmentation.
We propose an automatic system for organizing the content of a collection of unstructured videos of an articulated object class (e.g. tiger, horse) by exploiting recurring motion patterns of the class across videos.
We propose a method to automatically locate the optic nerve head in fundus images of the retina using the Hough transform.
Batch normalization (BN) has become a de facto standard for training deep convolutional networks. However, BN accounts for a significant fraction of training run-time and is difficult to accelerate, since it is a memory-bandwidth bounded operation. Such a drawback of BN motivates us to explore recently proposed weight normalization algorithms (WN algorithms), which can replace BN in practical, large-scale applications.
We present a conditional generative adversarial network-based model for underwater image enhancement in real-time.
We propose a knowledge representing (KR) framework mainly focusing on modeling the parameters distribution as prior knowledge for knowledge distillation.
Transferring Image Ensemble Representations using Deep Convolutional Neural Networks (TECNN) reuses pre-trained layers to generate a mid-level image representation.
A novel region-based active contour model based on two different local fitted images is proposed by constructing a novel local hybrid image fitting energy, which is minimized in a variational level set framework.
FireCaffe scales deep neural network training across a cluster of GPUs, achieving 47x and 39x speedup.
We propose a deep neural network that can estimate camera poses and reconstruct the full resolution depths of the environment simultaneously using only monocular consecutive images.
We introduce a new evaluation metric (mINP) for person Re-ID, indicating the cost for finding all the correct matches, which provides an additional criteria to evaluate the Re- ID system for real applications.
We propose a simple yet intuitive pixel-pair-based connectivity prediction task for semantic salient segmentation and achieve state-of-the-art performance.
We propose a deep learning pipeline, referred to as RSDNet, which automatically estimates the remaining surgery duration (RSD) intraoperatively by using only visual information from laparoscopic videos.
We propose a meta-learning method for few-shot learning, in which a model learns to adapt to novel tasks that it will encounter during test time.
We use a multimodal sentence encoder trained on a corpus of images with matching text captions to produce visually grounded sentence embeddings and achieve state-of-the-art results on MSCOCO and Flickr8k.
In this paper, we instigate how to exploit the semantic information encoded in a knowledge graph to build connections between units in a Neural Network, thus leading to a new method, SEM-AUTO, to extract and weight semantic features that can be used to build a recommender system.
We propose a method in which groups of regularly arranged objects are detected from an image, and the arrangement pattern of each group is identified.
We propose a new approach based on continual learning that uses feature-level predictions for self-supervision. The approach is inspired by cognitive models of visual event perception.
We propose a unified approach for bottom-up hierarchical image segmentation and object candidate generation for recognition by exploring efficiently their combinatorial space.
We propose a Latent Hinge Minimax (LHM) risk and a training algorithm that generalizes this paradigm to an ensemble of hyperplanes that can form arbitrary complex, piecewise linear boundaries.
A trojan backdoor is a hidden pattern typically implanted in a deep neural network. It could be activated and thus forces that infected model behaving abnormally only when an input data sample with a particular trigger present is fed to that model. In this work, we propose TABOR, a new trojan detection technique that formalizes a trojan Detection task as a non-convex optimization problem.
Selective Refinement Network (SRN) introduces novel two-step classification and regression operations selectively into an anchor-based face detector to reduce false positives and improve location accuracy simultaneously.
This paper builds the first tunnel crack dataset with semantic segmentation annotation and proposes an objective and fast tunnel crack identification algorithm using semantic segmentations in computer vision to construct a complete tunnel crack Identification and analysis system.
We apply the sketch-based approach or synthesizing way to solve the structural query language (SQL) queries from natural language.
We introduce hierarchical sequence embedding (HSE), a generic model for embedding sequential data of different modalities into hierarchically semantic spaces, with either explicit or implicit correspondence information.
Correlation filters based trackers rely on a periodic assumption of the search sample to efficiently distinguish the target from the background. To handle these issues, an end-to-end deep architecture is proposed to incorporate geometric transformations into a correlation filters based network.
We present a review of 3D point cloud processing and learning for autonomous driving.
In this paper we focus on the domain adaptation of deformable part-based models (DPMs) for object detection.
This paper introduces a novel orchestration framework, called CFO (COMPUTATION FLOW ORCHESTRATOR), for building, experimenting with, and deploying interactive NLP (Natural Language Processing) and IR (Information Retrieval) systems.
We propose SDIT: Scalable and Diverse image-to-image translation with attention mechanism and diversity.
We propose an efficient and accurate local stereo correspondence algorithm that can efficiently obtain results comparable to state of the art local approaches on GPUs with CUDA.
In this paper, we propose to benchmark action recognition methods in the absence of context and introduce a novel dataset, Mimetics, consisting of mimed actions for a subset of 50 classes from the Kinetics benchmark.
We propose S4ND, a new deep learning based method for lung nodule detection that uses a single feed forward pass of a single network for detection and provides better performance when compared to the current literature.
We describe our use of the system in the 2018 FEVER shared task. The system employed a frame-based information retrieval approach to select Wikipedia sentences providing evidence.
We demonstrate that Non-Maximum Suppression (NMS), which is commonly used in Object Detection (OD) tasks to filter redundant detection results, is no longer secure. We propose an adversarial example attack which triggers malfunctioning of NMS in end-to-end OD models.
We optimize a speaker embedding model with prototypical network loss, a state-of-the-art approach for the few-shot learning task, for both seen and unseen speakers.
Analytical queries are queries with numerical aggregators: computing the average number of objects per property, identifying the most frequent subjects, etc. In this paper, we show how to rewrite such queries into a set of queries that each satisfy the fair use policy.
We propose an efficient greedy neural architecture search approach (GNAS) to automatically discover optimal tree-like deep architecture for multi-attribute learning.
We propose a scalable neural network framework with quantification of decomposed uncertainty using a bootstrap ensemble.
Adaptive training quantization of binary embedding using cosine random mapping .
We describe a GPU-based system for Support Vector Machine training which achieves speedups of 9-35x over LIBSVM running on a traditional processor.
We use reinforcement learning (RL) to learn dexterous in-hand manipulation policies that can perform vision-based object reorientation on a physical Shadow Dexterous Hand.
In many scenarios of Person Re-identification (Re-ID), the gallery set consists of lots of surveillance videos and the query is just an image, thus Re-ID has to be conducted between image and videos.
In this paper, we propose a two-stage model which splits the inpainting task into two parts: structure reconstruction and texture generation.
Image captioning, a popular topic in computer vision, has achieved substantial progress in recent years. In this work, we propose a new learning method, Contrastive Learning, for image captioning.
In this paper, we introduce the exponential step sizes for stochastic optimization of smooth non-convex functions which satisfy the Polyak-Łojasiewicz (PL) condition.
We explored the relationship between the network roles of disease genes and their tolerance to deleterious germline variants in human populations leveraging on: the abundance of interactome resources, a comprehensive catalog of Disease genes and exome variation data.
We present a novel method for training a social robot to generate non-verbal backchannels during human-robot interaction.
We propose a novel loss function for pairwise ranking, which is smooth everywhere, and incorporate a label decision module into the model, estimating the optimal confidence thresholds for each visual concept.
We propose DropMax, a stochastic version of softmax classifier which at each iteration drops non-target classes according to dropout probabilities adaptively decided for each instance.
We propose simple but effective variants of pooling module, i.e., multi-kernel pooling and stacked pooling, to boost the scale invariance of convolutional neural networks (CNNs), benefiting much the crowd density estimation and counting.
In this work, we show that saturating output activation functions, such as the softmax, impede learning on a number of standard classification tasks.
The binary neural network, largely saving the storage and computation, serves as a promising technique for deploying deep models on resource-limited devices. However, binarization inevitably causes severe information loss, and even worse, its discontinuity brings difficulty to the optimization of the deep network. To address these issues, a variety of algorithms have been proposed, and achieved satisfying progress in recent years.
We propose a data-driven Point Cloud Completion Network ( P C C N e t ), which is an image-guided deep-learning-based object completion framework for 3D large-scale scene rapidly.
We propose a novel architecture for localizing facial landmarks from given images using fully convolutional DenseNets, skip-connections and dilated convolution architecture without further post-processing.
We investigate the application of adversarial autoencoders to the domain of emotion recognition.
In this paper we introduce ViSiL, a Video Similarity Learning architecture that considers fine-grained Spatio-Temporal relations between pairs of videos and captures the temporal similarity patterns between matching frame sequences.
We propose an end-to-end training strategy for video captioning that optimises both encoder and decoder simultaneously for state-of-the-art performance.
We propose a multi-layer approach to analyze saliency cues in complex images and improve detection quality on complex images.
We propose Viewpoint Discernibility Matrix (VDM) loss and Auxiliary Hierarchical Viewpoints Supervision (AHVS) method for viewpoints estimation.
In vehicular applications based on motion-stereo using monocular side-looking cameras, pairs of images must usually be rectified very well, to allow the application of dense stereo methods.
Data echoing reduces the total computation used by earlier pipeline stages and speeds up training whenever computation upstream from accelerators dominates the training time. We investigate the behavior of different data echoing algorithms on various workloads, for various amounts of echoing, and for various batch sizes.
We introduce a vector quantization method that aims at preserving the quality of the reconstruction of the network outputs rather than its weights.
We propose an end-to-end trainable model that directly predicts implicit surface representations of arbitrary topology by optimising a novel geometric loss function. We investigate the benefits of our approach on the task of 3D surface prediction.
Automatic extraction of anatomical features from retinal images to assist early diagnosis of the Glaucoma.
We propose an energy and computation efficient architecture called VoVNet comprised of One-Shot Aggregation (OSA) that overcomes the inefficiency of DenseNet.
In this paper, we propose a novel salient object detection algorithm which takes both background and foreground cues into consideration and integrate a bottom-up coarse salient regions extraction and a top-down background measure via boundary labels propagation into a unified optimization framework to acquire a refined saliency detection result.
This paper presents two approaches to broad-domain relation extraction and scoring in the DeepQA question-answering framework, i.e., one based on manual pattern specification and the other relying on statistical methods for pattern elicitation, which uses a novel transfer learning technique.
This paper tries to answer a question: can we predict the opinion holder in a heterogeneous social network without any labeled data?
We propose a learning rate free stochastic gradient algorithm for deep networks that does not require any learning rate setting.
We propose a visual feature encoding technique to generate semantically rich captions using Gated Recurrent Units (GRUs) and establish new state-of-the-art for video captioning.
We present GMC, grid-based motion clustering approach, a lightweight dynamic object filtering method that is free from high-power and expensive processors and is able to differentiate moving objects out of the surroundings.
We model the reconstruction process by using a conditional GAN with constraints on the stochastic component that introduce an explicit dependency between this component and the generated output.
We propose a fast deep architecture for object detection in JPEG images based on the blockwise DCT (discrete cosine transform) coefficients issued from JPEG compression algorithm.
We define and evaluate a system tailored to performing Time-ordered Online Training, capable of training an image classifier on a live video stream through minimal input from a human operator.
Semantic understanding of environments is an important problem in robotics in general and intelligent autonomous systems in particular. In this paper, we propose a semantic segmentation algorithm which effectively fuses information from images and point clouds.
Graph convolutional neural networks (Graph-CNNs) extend traditional CNNs to handle 3D point cloud data.
AttractioNet is a CNN-based category agnostic object location refinement module that is capable of yielding accurate and robust bounding box predictions regardless of the object category.
We propose a repulsive loss function to actively learn the difference among the real data by rearranging the terms in MMD.
In recent years, Deep Reinforcement Learning has made impressive advances in solving several important benchmark problems for sequential decision making. In this work, we propose a new neural network architecture for the policy network representation that is simple yet effective.
We leverage independently trained lo-cal visual cues to learn representations that can be trans-ferred from a source domain providing primitive action la-bels to a target domain with only a handful of examples.
We propose an efficient coupled bilinear model that generates virtual images under various illuminations using a single input image, and these images can be utilized to train the feature space for resolving SSPP problems.
The goal of Online Action Detection (OAD) is to detect action in a timely manner and to recognize its action category. In this paper, we propose new protocols and metrics to address challenges of OAD in untrimmed, streaming videos.
The goal of domain adaptation is to adapt models learned on a source domain to a particular target domain. Most methods for unsupervised domain adaptation proposed in the literature to date, assume that the set of classes present in the target domain is identical to the source domain. This is a restrictive assumption that limits the practical applicability of the method.
This paper introduces a new research problem of video domain generalization where most state-of-the-art action recognition networks degenerate due to the lack of exposure to the target domains of divergent distributions.
C-WSL uses a count-based region selection algorithm to select high quality regions, each of which covers a single object instance at training time, and improves WSL by training with the selected regions.
In this paper, we propose an unsupervised writer adaptation approach that is able to automatically adjust a generic handwritten word recognizer, fully trained with synthetic fonts, towards a new incoming writer.
The image ray transform is a method to highlight tubular features (such as blood vessels) based upon an analogy to light rays. The transform has been employed to enhance retinal images from the DRIVE database.
We propose a novel framework for simultaneously generating and manipulating the face images with desired attributes with GAN framework.
We present an end-to-end learning framework for detailed 3D face reconstruction from a single image, using a 3DMM-based coarse model and a displacement map in UV-space.
We explore the transferability of various layers and describe the effect of varying hyper-parameters on the transfer performance. We try to uncover thumb rules to ensure a successful positive transfer.
We present an elegant framework of fine-grained neural architecture search (FGNAS), which allows to employ multiple heterogeneous operations within a single layer and can even generate compositional feature maps using several different base operations.
We present a new method for uncertainty estimation and out-of-distribution detection in neural networks with softmax output.
We propose a hierarchical structure with novel skip-connections which allows for the use of low dimensional input and output layers for learning deep word-level representations efficiently.
We propose the Memory-Attended Recurrent Network for video captioning, in which a memory structure is designed to explore the full-spectrum correspondence between a word and its various similar visual contexts across videos in training data.
We propose to use pre-trained features from end-to-end ASR models to solve the speech sentiment analysis problem as a down-stream task.
We propose outlier channel splitting (OCS), which duplicates channels containing outliers, then halves the channel values. OCS requires no additional training.
We propose a hypothesis only baseline for diagnosing Natural Language Inference, which is able to significantly outperform a majority class baseline across ten NLI datasets.
Improving Markov clustering algorithm performance using GPU computing with CUDA-MCl .
We present ClusterVO, a stereo Visual Odometry which simultaneously clusters and estimates the motion of both ego and surrounding rigid clusters/objects, allowing for indoor scene understanding and autonomous driving.
We detect the presence of prominent concepts in images and use them to infer the target labels instead of using visual features, combining tools from vision and natural-language processing.
We explore gait recognition based on a matrix representation in this paper, which demonstrates better performance than state-of-the-art algorithms on the standard USF HumanID Gait database.
We propose a novel approach to integrate heterogeneous visual features to do semi-supervised classification on unlabeled as well as unsegmented images.
We present a general framework for geometric model fitting based on a set coverage formulation that caters for intersecting structures and outliers in a simple and principled manner.
We develop a new approach to DT analysis based on a CNN method applied on three orthogonal planes x y , xt and y t and combine their outputs to obtain competitive DT classifier.
We introduce a simple yet effective approach to improving cGANs by measuring the gap of log-densities (GOLD), a measure of discrepancy between the data distribution and the model distribution on given samples.
We propose a convolutional neural network to jointly solve clustering and representation learning in an iterative manner using stochastic gradient descent.
The ability to comprehend wishes or desires and their fulfillment is important to Natural Language Understanding. This paper introduces the task of identifying if a subject in a given short piece of text was fulfilled.
In this paper, we propose a sentiment-feature-enhanced deep neural network (SDNN) to address the problem by integrating sentiment linguistic knowledge into adeep neural network via a sentiment attention mechanism.
We propose to exploit a post-ranking approach and combine different feature representations through ranking aggregation to improve the state-of-the-art rank recognition rate.
Deconfounded Image Captioning (DIC), to find out the cause of the bias in image captioning, then retrospect modern neural image captioners, and finally propose a DIC framework.
A Hierarchical Attention Guided Network (HAGN) for crowd counting.
We propose MeliusNet, a new binary neural network architecture that can match MobileNet-v1 in terms of model size, number of operations and accuracy.
Academic homepages are rich sources of information on scientific research and researchers. Can we accurately discriminate between academic homepages and other webpages? What information can we extract about researchers from their homepages?
We solve the video stabilization problem using a convolutional neural network (ConvNet) for low-latency real-time camera path smoothing without explicitly representing the camera path.
This paper proposes a functional feature-based approach useful for real forensic caseworks, based on the shape, orientation and size of facial traits, which can be considered as a soft biometric approach.
This paper presents a model for head and body pose estimation (HBPE) when labelled samples are highly sparse. The proposed method tackles HBPE when manually annotated ground truth labels are temporally sparse.
We address this issue and first develop highly efficient video features using motion information in video compression and next explore feature encoding by Fisher vectors and demonstrate accurate action recognition using fast linear classifiers.
We present a novel method to reconstruct the 3D layout of a room -- walls,floors, ceilings -- from a single perspective view, even for general configurations.
A distance map captured using a time-of-flight (ToF) depth sensor using three ToF sensors, set to different integration times to address the ambiguity in depth information.
This paper compares different visual datasets and frameworks for machine learning. The comparison is both qualitative and quantitative and investigates object detection labels.
In this paper, we propose adaptive directional filters that fill the holes and suppress the noise in depth maps.
We propose an automatic BK selection approach that does not depend on an initial matching, can handle multilingualism and is domain independent.
We study the representation and encoding of phonemes in a recurrent neural network model of grounded speech, where low-level signals are processed at fine-grained level, although a large amount of phonological information is retain at the top recurrent layer.
We show for the first time that deep neural networks are capable of detecting loop closures, and we provide a method for generating large-scale datasets for use in evaluating and training loop closure detectors.
We propose an accurate and fast approximation method for Singular Value Thresholding (SVT), where we avoid direct computation of SVD.
In this paper, we propose a novel procedure for 3D layout recovery of indoor scenes from single 360 degrees panoramic images.
We present a pyramidal gradient matching approach that can provide dense matches for highly accurate and efficient optical flow estimation, which is efficient and robust.
We propose the Multi-view Intact Space Learning (MISL) algorithm, which integrates the encoded complementary information in multiple views to discover a latent intact representation of the data.
We first describe a CNN based approach for weakly supervised training of audio events. We then describe important characteristics, which naturally arise in weakly labeled learning of sound events.
We propose a new approach for tackling multi-span questions, based on sequence tagging, which improves on existing state-of-the-art results on DROP.
We propose an unsupervised approach for discovering characteristic motion patterns in videos of highly articulated objects performing natural, unscripted behaviors, such as tigers in the wild, in a bottom-up manner.
We present a novel dataset and a novel algorithm for recognizing activities of daily living (ADL) from a first-person wearable camera.
We propose a nonlocal cost-aggregation method joining object flow and minimum spanning tree-based support region rather than aggregating on fixed size windows.
Self-supervised learning (SlfSL), aiming at learning feature representations through ingeniously designed algorithms, can be combined with semi-super supervised learning to achieve state-of-the-art SemSL performance.
We embed temporal consistency into the segmentation network during the inference process and improve the temporal consistency with no extra computational cost and post-processing.
In this paper, rather than sampling from the pre-defined prior distribution, we propose a Local Coordinate Coding (LCC) based sampling method for GANs.
In this paper, following the recent success of part-based models, in order to generate a discriminative and robust feature representation, we first propose to learn global and weighted local body-part features from pedestrian images, which significantly improves the robustness of the resultant network against feature variance.
We propose a multi-task framework for jointly estimating 2D or 3D human poses from monocular color images and classifying human actions from video sequences, achieving state-of-the-art results.
We present a new structured dictionary learning method for collaborative filtering based recommender systems.
We address the problem of grounding distributional representations of lexical meaning. We introduce a new model which uses stacked autoencoders to learn higher-level representations from textual and visual input.
We describe the VKG structure that helps unify knowledge graphs and vector representation of entities, and enables powerful inference methods and search capabilities that combine their complementary strengths.
We propose to use Generative Adversarial Nets (GANs) for abnormal crowd behaviour detection.
We present an approach for watermarking Deep Neural Networks in a black-box way. The watermark has no noticeable impact on the primary task that the model is designed for.
In this paper, we propose a novel, resource-efficient method that is inspired by MGM's techniques for improving depth quality, but can be implemented to run in real time on a low-power FPGA.
We propose a controllable GAN (ControlGAN) structure for generative adversarial networks where the auxiliary classifier can hardly provide good guidance for training the generator, where the classifier suffers from overfitting.
We address the problem of fully automatic object localization and reconstruction from a single image. Our models capture top-down information about the main global modes of shape variation within a class providing a “low-frequency” shape.
We propose the quasi-hyperbolic momentum algorithm (QHM) as an extremely simple alteration of momentum SGD, averaging a plain SGD step with a momentum step. We propose a QH variant of Adam called QHAdam.
Conversational machine comprehension requires the understanding of the conversation history, such as previous question/answer pairs, the document context, and the current question, through an alternating parallel processing structure.
We propose an algorithm to learn the connections between branches in a multi-branch network and demonstrate its effectiveness on image classification.
We propose an end-to-end tracking framework for fusing the RGB and TIR modalities in RGB-T tracking that achieves state-of-the-art performance.
Incorporating Item Response Theory into NLP tasks can provide valuable information about model performance and behavior. Traditionally, IRT models are learned using human response pattern (RP) data, presenting a significant bottleneck for large data sets like those required for training deep neural networks.
We propose adaptive detrending (AD) for temporal normalization in order to accelerate the training of ConvRNNs, especially for convolutional gated recurrent unit.
We present an efficient 3D object detection framework based on a single RGB image in the scenario of autonomous driving using artful approach to efficiently obtain a coarse cuboid for each predicted 2D box.
We introduce a novel semi-supervised video segmentation approach based on an efficient video representation, called as "super-trajectory", which can handle occlusions and drifts in a robust and natural way.
This paper integrates the YOLO detection network, which is considered a state-of-the-art tool for real-Time object detection, with motion vectors and the Coyote Optimization Algorithm (COA) to construct a real-time human action localization and tracking system.
We aim to improve both the motion and observation models in visual object tracking by leveraging representation power of CNNs.
Graph-based semi-supervised classification uses a graph to capture the relationship between samples and exploits label propagation techniques on the graph to predict labels of unlabeled samples.
We present a parallelized navigation architecture that is capable of running in real-time and incorporating long-term loop closure constraints while producing the optimal Bayesian solution.
Inherent correlations between visual and semantic features in real-world scenes make it difficult to determine how different scene properties contribute to neural representations. Here, we partition the variance explained in human behavioral and brain measurements by three feature models whose inter-correlations were minimized a priori through stimulus preselection.
In this paper, we propose a combination of multiple classifiers based on Convolutional models that complement each other and thus, achieve an improvement in performance.
We explore a novel spatialtemporal network (StNet) architecture for both local and global modeling in videos.
Binarization is an attractive strategy for implementing lightweight Deep Convolutional Neural Networks (CNNs). Despite the unquestionable savings offered, memory footprint above all, it may induce an excessive accuracy loss that prevents a widespread use. This work elaborates on this aspect introducing TentacleNet, a new template for improving the predictive performance of binarized CNNs via parallelization.
This paper investigates generative modeling of CNNs. We propose a generative gradient for pre-training CNNs by a non-parametric importance sampling scheme, which helps improve their performance.
The interference of the complex background and less information of the small targets are two major problems in vehicle attribute recognition. In this paper, two cascaded networks are established to solve the two problems.
We propose a novel method that jointly extracts reliable low- and high-level facial features namely, 3D facial geometry, skin reflectance, expression, head pose, and scene illumination in a video sequence for deception detection.
We propose a novel and efficient residual dense network for image restoration, by making a better tradeoff between efficiency and effectiveness in exploiting the hierarchical features from all the convolutional layers.
We identify and address three research gaps in the field of vessel segmentation for funduscopy for which only a limited set of ground truth data is publicly available.
In this paper, we propose to learn an adversarial pattern to effectively attack all instances belonging to the same object category (e.g., person, car) in the wild.
In this paper, we propose a compact and low-complexity binary feature descriptor for video analytics. The descriptor is based on a binning strategy and a construction that binarizes separately the horizontal and vertical motion components of the spatio-temporal support region.
In this paper an FPGA stereo matching unit based on fuzzy logic is described.
We propose a novel and efficient person re-identification network that combines two tasks: the classification task and the metric learning task.
Biometric recognition on partial captured targets is challenging, where only several partial observations of objects are available for matching. We propose a robust general framework for arbitrary biometric matching scenarios without the limitations of alignment and size of inputs.
We use real-valued non-volume preserving transformations (real NVP) to exactly compute the conditional likelihood of the data given the latent distribution, on image modeling tasks.
We propose two novel techniques in the generative adversarial networks to produce photo-realistic images for image super-resolution.
Predictive coding for speech emotion recognition, followed with transfer learning approaches to share knowledge of the pre-trained predictive model.
We propose an efficient and interpretable scene graph generator that provides a semantic, structured comprehension of an image that is beyond pixels and objects.
We explore: 1) multichannel demodulation schemes for multi-microphone setups; 2) richer descriptors of frequency modulations; and 3) feature transformation and combination via hierarchical deep networks for distant speech recognition.
We propose a dynamic memory network to adapt the template to the target's appearance variations during tracking while retaining real-time speed.
We propose an automatic method to infer high dynamic range illumination from a limited field-of-view, low dynamic range photograph of an indoor scene, without strong assumptions on scene geometry, material properties, or lighting.
This paper proposes a new face recognition method which captures the neighborhood gradient orientation information which is not considered in the conventional local binary patterns to give more discriminant power.
We propose a novel approach to activity recognition from visual data based on qualitative and quantitative spatio-temporal features which encode the interactions between human subjects and objects in an efficient manner.
In this paper, we introduce a novel regularization method called Adversarial Noise Layer (ANL), which are able to significantly improve CNN’s generalization ability by adding carefully crafted noise into the intermediate layer activations.
We extend Fast Deep Evolutionary Network Structured Representation (Fast-DENSER) to incremental development to accelerate evolution.
We propose a Combined Attention Model (CAM) for NLI. CAM combines the two attention mechanisms: intra-attention and inter-att attention.
We propose a re-weighted TGV regularized nuclear norm minimization model for local structure preserving image denoising.
We propose sparse variants of ResNet18 and VGG16 that use up to 82% fewer model parameters with negligible loss in accuracy for both training and inference.
We propose Residual-Squeeze-VGG16, a very deep neural network comprised of 16 Convolutional layers compressed with the Fire Module adapted from the SQUEEZENET model.
Network pruning reduces the computation costs of an over-parameterized network without performance damage. To break the structure limitation of the pruned networks, we propose to apply neural architecture search to search directly for a network with flexible channel and layer sizes.
We propose a simple and effective method for imputing missing features and estimating the distribution of target assignments given incomplete data, under missingness rates and structures.
We propose a parallax-attention stereo superresolution network to integrate the information from a stereo image pair for SR with small computational and memory cost.
This paper presents a stereo matching approach for a novel multi-perspective panoramic stereo vision system, making use of asynchronous and non-simultaneous stereo imaging towards real-time 3D 360° vision.
We propose to estimate 3D scene flow from unstructured point clouds using a deep neural network and augment real scans from KITTI with virtual objects.
We propose a novel few-shot learning framework for semantic segmentation, where unlabeled surrogate tasks in the episodic training leads to more powerful feature representations, which ultimately results in better generability.
We present a novel learning-based approach to estimate the direction-of-arrival (DOA) of a sound source using a convolutional recurrent neural network (CRNN) trained via regression on synthetic data and Cartesian labels.
We introduce intent detection methods backed by pretrained dual sentence encoders such as USE and ConveRT that can be trained in a matter of minutes on a single CPU.
This paper seeks to model human language by the mathematical framework of quantum physics. A complex-valued network is built to implement this framework for semantic matching.
In this paper, we propose to recognize facial expressions by extracting independent expressive representation through a novel learning procedure, called Inter-class Relational Learning (IcRL), which is capable of learning the mutual relations between different classes of expression.
This paper introduces a generic method which enables to use conventional deep neural networks as end-to-end one-class classifiers.
This paper proposes learning disentangled but complementary face features with minimal supervision by face identification.
A novel pose estimation method that exploits a quad-tree-based representation of facial features, providing accurate yaw, pitch and roll axis estimates almost in real-time, without any training or previous knowledge about the subject.
The Mahalanobis distance-based confidence score, a recently proposed anomaly detection method for pre-trained neural classifiers, achieves state-of-the-art performance while imposing an implausible assumption that class conditional distributions of intermediate features have tied covariance.
In recent years, deep neural networks have achieved great success in the field of computer vision. However, it is still a big challenge to deploy these deep models on resource-constrained embedded devices such as mobile robots, smart phones and so on. In this paper, a novel channel pruning method based on genetic algorithm is proposed.
A review of the state-of-the-art in handling label noise in deep learning for medical image analysis, where we investigated several existing strategies and developed new methods to combat the negative effect of label noise.
Raven's Progressive Matrices are a benchmark originally designed to test the cognitive abilities of humans. Here we show that deep neural networks are capable of solving this benchmark, reaching an accuracy of 98.0 percent over the previous state-of-the-art.
We introduce a novel framework that learns to modify existing captions from a given framework by modeling the residual information, where at each timestep the model learns what to keep, remove or add to the existing caption.
In the field of natural language processing, combining multiple pre-trained word embeddings has become a viable approach to improve word representations. However, there is a lack of understanding of why common and individual information contributes to different tasks.
In this paper, we present a novel approach for stereo visual odometry with robust motion estimation that is faster and more accurate than standard RANSAC.
This paper presents an efficient algorithm for face recognition using the local binary pattern (LBP) and random forest (RF) for improved facial texture classification performance.
In this paper, we propose Convolutional Aggregation of Local Evidence (CALE), a convolutional Neural Network (CNN) architecture particularly designed for addressing both of them.
Learning object templates composed of local sketches and local textures, and investigates the relative importance of the sketches and textures for different object categories.
We propose a novel self-supervised approach which uses both left and right images equally during training, but can still be used with a single input image at test time, for monocular depth estimation.
A core part of linguistic typology is the classification of languages according to linguistic properties, such as those detailed in the World Atlas of Language Structure.
We propose a molecular generative model based on the conditional variational autoencoder for de novo molecular design.
In this paper, we propose a deep end-to-end neu- ral network to simultaneously learn high-level features and a corresponding similarity metric for person re-identification.
We present a novel Content Based Video Retrieval (CBVR) system, driven by free-hand sketch queries depicting both objects and their movement (via dynamic cues; streak-lines and arrows).
We study the problem of answering questions about images in the harder setting, where the test questions and corresponding images contain novel objects, which were not queried about in the training data.
In this paper, a new DR framework that can directly model the target distribution using the notion of similarity instead of distance is introduced.
We propose a novel and elegantly simple Min-Max normalization scheme, which scales inputs to nonlinear functions in DNN into ranges with low approximation error.
Adversarial training (AT) as a regularization method has proved its effectiveness in various tasks, such as image classification and text classification. In this paper, we aim to apply AT on machine reading comprehension and study its effects from multiple perspectives.
We propose a new robust federated optimization algorithm, with provable convergence and robustness under non-IID settings.
We propose the ambiguity problem for the foreground object segmentation task and motivate the importance of estimating and accounting for this ambiguity when designing vision systems.
We combine continuous reinforcement learning and deep content embedding into a novel semi-supervised joint learning framework to model node similarity in content-rich heterogeneous networks.
We propose a novel end-to-end weakly-supervised attention and relation learning framework for AU detection, which has not been explored before.
We extend the latest HTM work on augmented spatial pooling, to produce a fixed frame temporal pooler (FFTP), which is evaluated on the KTH action recognition data set.
Data augmentation is a ubiquitous technique for increasing the size of labeled training sets by leveraging task-specific data transformations that preserve class labels. We propose a method for automating this process by learning a generative sequence model over user-specified transformation functions using an adversarial approach.
A new head pose estimation technique based on Random Forest (RF) and texture features for facial image analysis using a monocular camera is proposed in this paper.
We propose a new generative model based on an adversarially regularized autoencoder (ARAE), which uses latent variables like VAE, but the distribution of the latent variables is obtained by adversarial training.
In this paper, we propose a model, called "bi-directional block self-attention network (Bi-BloSAN)", for RNN/CNN-free sequence encoding. It requires as little memory as RNN but with all the merits of SAN.
An effective approach to transcribe handwritten text documents is to follow a sequential interactive approach. In the case of multilingual documents with a high percentage of out-of-vocabulary words, two principal issues arise.
We propose a new method that uses deep learning techniques to accelerate the popular alternating direction method of multipliers (ADMM) solution for inverse problems.
This paper presents a new method of pixel based stereo matching algorithm using illumination control to enhance the image quality of absolute difference (AD) matching.
In this paper, we propose a Progressive Domain-independent Feature Decomposition (PDFD) network for zero-shot sketch-based image retrieval.
This paper introduces a novel contour-based approach named deep snake for real-time instance segmentation, which implements the classic idea of snake algorithms with a learning- based approach.
In this paper, a proposed lane detection system is developed from our previous work where the estimation of the dense vanishing point is further improved using the disparity information.
This work targets the automated minimum-energy optimization of Quantized Neural Networks (QNNs) - networks using low precision weights and activations.
We introduce a novel unsupervised domain adaptation approach for object detection. We aim to alleviate the imperfect translation problem of pixel-level adaptation, and the source-biased discriminativity problem of feature-level adaptations simultaneously.
In this paper, we focus on training and evaluating effective word embeddings with both text and visual information. We introduce a large-scale dataset with 300 million sentences describing over 40 million images crawled and downloaded from publicly available Pins.
We propose transfer learning in DNNs for lensless imaging through scattering media, which alleviates the problem of costly data acquisition.
We propose a flexible method for training deep latent variable models of discrete structures. We first extend this framework to model discrete sequences, and then explore different learned priors targeting a controllable representation.
We propose Node-wise Graph Neural Networks (NGNN) which can better model node interactions and learn better node representations for fashion recommendation.
We propose a novel online action detection framework that considers actions as a set of temporally ordered subclasses and leverages a future frame generation network to cope with the limited information issue associated with the problem outlined above.
This paper presents a modular system for both abnormal event detection and categorization in videos.
In this paper, a computational approach is proposed and put into practice to assess the capability of children having had diagnosed Autism Spectrum Disorders (ASD) to produce facial expressions.
We show that a sparse coding model particularly designed for super-resolution can be incarnated as a neural network, and trained in a cascaded structure from end to end.
Cross-corpus speech emotion recognition using Deep Belief Networks using generalization power.
Exploiting multi-scale representations is critical to improve edge detection for objects at different scales. To extract edges at dramatically different scales, we propose a Bi-Directional Cascade Network (BDCN), where an individual layer is supervised by labeled edges at its specific scale, rather than directly applying the same supervision to all CNN outputs.
We propose a generative adversarial network that can generate samples conditioned on the properties of a latent distribution engineered in accordance with a certain data prior.
In this paper, we propose a mechanism to mimic the process of priming in the context of object detection and segmentation.
We propose a unified framework to compress the convolutional neural networks by combining these two strategies, while taking the nonlinear activation into consideration.
We propose Interrogative-Word-Aware Question Generation (IWAQG), a pipelined system composed of two modules: an interrogative word classifier and a QG model.
We propose SeaReader, a modular end-to-end reading comprehension model based on LSTM networks and dual-path attention architecture for answering questions in clinical medicine.
We propose to extend the scale of the dataset using parameterized synthetic images which effectively boost the diversity of samples.
Ensemble learning is a method of combining multiple trained models to improve model accuracy. We propose the usage of such methods, specifically ensemble average, inside Convolutional Neural Network (CNN) architectures by replacing the single convolutional layers with Inner Average Ensembles (IEA), which boosts the model performance.
We propose a novel model based on a structure-appearance joint embedding learned from both images and wireframes for structured indoor image generation for design applications.
We introduce the bidirectional Scene Text Transformer (Bi-STET), a novel Bidirectional STR method with a single decoder for bidirectionAL text decoding.
This paper presents an extended dynamic programming approach for energy minimization (EDP) to solve the correspondence problem for stereo and motion.
This paper presents a hand-written character recognition comparison and performance evaluation for robust and precise classification of differentHand-written characters.
We present an end-to-end model for following gaze across views by predicting where a particular person is looking throughout a scene.
We present an approach to neural machine translation (NMT) that supports multiple domains in a single model and allows switching between the domains when translating.
We propose NovoGrad, an adaptive stochastic gradient descent method with layer-wise gradient normalization and decoupled weight decay that performs on par or better than momentum and Adam or AdamW.
We propose a statistical mechanical theory that connects geometric properties of network representations and the separability of classes to probe how information is untangled within neural networks trained to recognize speech.
In this paper, we present MultiPoseNet, a novel bottom-up multi-person pose estimation architecture that combines a multi-task model with a novel assignment method.
CNN-aided diagnosis of Helicobacter pylori infection during health check-ups.
This paper presents a new, realistic and challenging human interaction dataset for multiplayer gaming, containing synchronised colour, depth and skeleton data, and proposes an evaluation metric for real time applications.
We propose to use sketch as weak constraint for image-to-sketch generation, where the output edges do not necessarily follow the input edges.
In this paper, we propose six new reputation-based algorithms, where the users' reputation is determined by the aggregated difference between the users’ ratings and the corresponding objects’ rankings.
We propose a new multi-stage method for pose estimation, which establishes the new state-of-the-art on both MS COCO and MPII Human Pose dataset, justifying the effectiveness of a multi-Stage architecture.
We introduce a novel approach that extends the scope of extreme relative pose estimation to extreme relative poses, with little or even no overlap between the input scans.
We propose SenTion: A framework for sensing facial expressions, which achieves state of the art recognition accuracy.
We propose a novel multi-attribute tensor correlation neural network (MTCN), which learns multiple face attributes simultaneously to achieve shared or mutually related representations.
We introduce a sentence embedding method that is based on knowledge distillation from cross-attentive models, focusing on sentence-pair tasks.
In this paper, we propose a novel class shared dictionary learning method named label embedded dictionary learning (LEDL) by introducing the L1-norm sparse constraint to replace the conventional L0-norm regularization term.
A novel multi-task recurrent convolutional network with correlation loss to exploit their relatedness to simultaneously boost the performance of both tasks.
This paper presents an end-to-end text detection strategy combining a segmentation algorithm and an ensemble of multiple text detectors of different types to detect text in every individual image segments independently.
We propose an active action detection model that learns to search actions through continuously adjusting the bounds of temporal attended window in a self-adaptive way.
We characterize the problem of pose estimation for rigid objects in terms of determining viewpoint to explain coarse pose and keypoint prediction to capture the finer details. We present Convolutional Neural Network based architectures for these.
We propose an efficient end-to-end convolutional neural network architecture for audio classification with state-of-the-art accuracy and efficiency.
We propose a new process for training and evaluation in the GZSL setting that addresses the gap in performance between samples from unseen and seen classes by penalizing the latter, and enables to select hyper-parameters well-suited to the G ZSL task.
We introduce a fast method for extracting examples of real-world events in low-level data, given only a rough estimate of when these events have taken place, and use this data to identify examples of such diverse events as human actions, power consumption patterns, and spoken words.
We propose Convolutional Tensor-Train Decomposition, a novel tensor decomposition with convolutional operations to capture higher-order space-time correlations in videos.
We propose a novel 3D object detection method, named SMOKE, in this paper that predicts a 3D bounding box for each detected object by combining a single keypoint estimate with regressed 3D variables.
We propose self-adaptive training---a new training algorithm that dynamically corrects problematic training labels by model predictions without incurring extra computational cost---to improve generalization of deep learning for potentially corrupted data.
We find that both Kronecker-Factored Approximate Curvature (K-FAC) and Stochastic Gradient Descent don't have ideal scalability behavior beyond a certain batch size, as compared to SGD.
We present a novel end-to-end framework for facial performance capture given a monocular video of an actor’s face.
In this work we propose a simple unsupervised approach for next frame prediction in video. Instead of directly predicting pixels in a frame given past frames, we predict the transformations needed for generating the next frame in a sequence.
In model-based reinforcement learning, generative and temporal models can be leveraged to boost agent performance, either by tuning the agent's representations during training or via use as part of an explicit planning mechanism.
We develop new algorithmic techniques for learning neural networks with non-convex objectives, under a modest privacy budget, and at a manageable cost.
Descriptors are decomposed in primitive extraction, coding and aggregation. We propose a new framework for the design of local descriptors and their evaluation.
We address the open question: "What do adversarially robust models look at?"
We propose a novel end-to-end deep saliency network which could effectively utilize multi-scale feature maps according to their characteristics.
We propose a novel supervised learning method to optimize the kernel in maximum mean discrepancy generative adversarial networks (MMD GANs) using a particle stochastic gradient descent method.
This paper shows that inference with triple cliques can be effectively performed. The strategy is to repeatedly merge proposal depth maps using a novel extension of QPBO.
The familiarity of faces is one of the key factors that come into play during human face analysis. In this paper, two methods are proposed to quantitatively measure the degree of familiarity of a face with respect to a known set.
We show that it is more beneficial to employ fine-tuning from a closer domain to detect tables in document images, where there is a close relation between source and target task.
We introduce Complex-YOLO, a state of the art real-time 3D object detection network on point clouds only.
This study proposes a deep neural network model for effective video captioning.
In the context of music production, distortion effects are mainly used for aesthetic reasons and are usually applied to electric musical instruments. Most existing methods for nonlinear modeling are often either simplified or optimized to a very specific circuit. In this work, we aim to find a general purpose end-to-end deep neural network to perform modeling of nonlinear audio effects.
We present efficient and optimisable multi-class learned object descriptors together with a novel probabilistic and differential rendering engine, for principled full object shape inference from RGB-D images.
This paper presents three Targeted Adversarial Objectness Gradient attacks, coined as TOG, which can cause the state-of-the-art deep object detection networks to suffer from object-vanishing, object-fabrication, and object-mislabeling attacks.
We investigate the role of motifs in scene graphs and introduce Stacked Motif Networks, a new architecture for encoding global context that is crucial for capturing higher order motifs.
We propose cascaded inference that wraps around the α-expansion algorithm for semantic image segmentation.
We propose a novel hierarchical generative model with a simple Markovian structure and a corresponding inference model. Both the generative and inference model are trained using the adversarial learning paradigm.
In this paper we show how an imbalanced dataset affects the performance of a standard learning algorithm, and propose a distribution-sensitive prior to deal with the imbalanced data problem.
In this paper, we introduce hybrid video classification architectures based on carefully designed unsupervised representations of hand-crafted spatio-temporal features classified by supervised deep networks.
We propose a sub-categorization model for texture classification, which achieves state-of-the-art performance on challenging datasets.
We propose an integrated framework for social and emotional game agents to enhance their believability and quality of interaction, in particular by allowing an agent to forge social relations and make appropriate use of social signals.
We propose a method to create a video descriptor composed of three main steps: Computation of displacement vectors between frames with VSBMA, histogram representation of these vectors, and orientation tensor generation from the histogram.
We propose a new framework for action localization that tracks people in videos and extracts full-body human tubes, even in the case of occlusions or truncations.
This paper makes explicit the variety of preprocessing and evaluation protocols to test the robustness of a dataset (or lack of flexibility) and proposes a method to select a preprocessing protocol and share results more transparently.
Neural networks have proven effective at solving difficult problems but designing their architectures can be challenging, even for image classification problems alone. Our goal is to minimize human participation, so we employ evolutionary algorithms to discover such networks automatically.
In this paper, we propose a novel deep filter based on Generative Adversarial Network (GAN) architecture integrated with global skip connection and dense architecture in order to tackle this problem.
We propose Multi-lingual language model Fine-Tuning to enable practitioners to train and fine-tune language models efficiently in their own language.
In this paper, we report on a benchmark in which we have evaluated the performance of IPU processors on deep neural networks for inference.
EvoNorms are a set of new normalization-activation layers that go beyond existing design patterns that are independent from batch statistics.
We propose a method for instance-level segmentation that uses RGB-D data as input and provides detailed information about the location, geometry and number of individual objects in the scene.
In this paper, we propose a recurrent attention mechanism for VQA which utilizes dual (textual and visual) Recurrent Attention Units (RAUs).
Neural network architectures found by sophistic search algorithms achieve strikingly good test performance, surpassing most human-crafted network models by significant margins. We implement undiscoverable expert knowledge into the economic search algorithm Efficient Neural Architecture Search (ENAS), guided by the design principles and architecture of ShuffleNet V2.
We study the extent to which blackbox models can be stolen based solely on blackbox interactions, and propose a two-step approach to steal functionality of such models.
Loop-closure detection for monocular vSLAM and its application to real-time control .
In this paper, we propose two solutions to cope with limited datasets. Firstly, we incorporate a pose estimation network into an end-to-end human-image parsing network, in order to transfer common features across the domains. Secondly, we increase the variation in image backgrounds automatically.
A global fingerprint orientation field model, represented in terms of ordinary differential equations, which does not require any prior information such as singular points or orientation of a fingerprint.
We investigate the transferability of knowledge learned from a source QA dataset to a target dataset using two QA models using a transfer learning technique.
We propose a generative adversarial network based on cyclic consistency over multiple concepts, represented individually by Generative Adversarial Networks (GANs), for data augmentation.
We propose a novel CNN-based global descriptor, called REMAP, which learns and aggregates a hierarchy of deep features from multiple CNN layers, and is trained end-to-end with a triplet loss.
We propose a novel approach that utilises continuous streams of joint motion data for recognising and predicting actions in linear latent spaces operating online and in real time.
We propose a novel end-to-end differentiable architecture for joint denoising, deblurring, and classification that makes classification robust to realistic noise and blur.
Inference of causal disease/gene associations for disease classification, analysis of clinical disorder associations and prediction of disease genes.
We introduce a novel feature extraction approach based on clinical observations for the screening of diabetic retinopathy and propose an enhanced detection procedure that consists of two steps.
We propose a gated factor graph framework to use semantic information associated with visual features to make decisions on outlier/ inlier computation from three perspectives.
We introduce an intermediate state, HEMlets, to address the uncertainty of lifting the detected 2D joints to the 3D space, which shortens the gap between the 2D observation and the3D interpretation.
We extend the cycleGAN to ${\it Conditional}$ cycleGAN such that the mapping from $X$ to $Y$ is subjected to attribute condition $Z$ and use the resulting face image image super-resolution.
Blockwise adaptive gradient descent converges faster and improves generalization performance over Nesterov's accelerated gradient and Adam.
We propose a generative model which discovers temporal dependencies on the shared/individual latent spaces in probabilistic CCA and use it to solve temporal alignment and fusion of multiple expert annotations in time.
We propose a novel method to evaluate the naturalness of images by building a variant of Recurrent Neural Network Language Models on pre-trained CNN representations.
Face-SSD uses a Fully Convolutional Neural Network (FCNN) to detect multiple faces of different sizes and for performing various face-related task analysis tasks including smile recognition, face attribute prediction and valence-arousal estimation in the wild.
We propose a probabilistic model that learns and infers all layers of the hierarchy jointly, outperforming existing hierarchical approaches and demonstrating performance on par with current single-feature state-of-the-art models.
In this preliminary report, we present a simple but very effective technique to stabilize the training of CNN based GANs.
This paper contributes a new, real-world web image dataset for cross-media retrieval called FB5K. We propose a semantic-based cross- media retrieval method.
We propose COCO-GAN of which the generator generates images by parts based on their spatial coordinates as the condition, and the discriminator learns to justify realism across multiple assembled patches.
A series of competitive analysis studies on image recognition and text analysis tasks, for which convolutional networks are known to provide state-of-the-art results.
We propose and evaluate a novel architecture that generates an egocentric, grid-based, predictive, and semantically-interpretable ER that can make accurate predictions in complex sensor fusion scenarios.
This paper proposes an approach based on a state-space model for learning the user concepts in image retrieval.
In this paper, a dual online subspace-based learning method called dual-generalized discriminative common vectors (Dual-GDCV) is presented.
We propose a three-state Markov Random Field method that utilizes known biological pathways and interaction to improve sensitivity and specificity and therefore reducing false discovery rates (FDRs) when detecting differentially expressed genes from RNA-seq data.
This paper introduces EXMOVES, learned exemplar-based features for efficient recognition of actions in videos. The entries in our descriptor are produced by evaluating a set of movement classifiers trained on low-level features.
We develop a procedure for setting mini-batch size and choosing computation algorithms and derive lemmas for determining the quantity of key components.
We extend a conventional visual question answering dataset, which contains image-question-answerg triplets, through additional image- question-answer-supporting fact tuples.
We propose a Bayesian regression approach for integrating multiple protein-protein interaction networks to explain similarities between disease phenotypes using diffusion kernels of PPI networks.
We formulate the problem of loop-closure detection as a sparse, convex ::: l 1 -minimization problem. By leveraging fast convex optimization techniques, we are able to efficiently find loop closures.
We introduce the Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion, improving on the state-of-the-art on object recognition benchmarks.
We propose fast-SWA, a semi-supervised method which accelerates convergence by averaging multiple points within each cycle of a cyclical learning rate schedule. We show that consistency regularization leads to flatter optima.
We try to evaluate the traffic between the two planes based on allowing a minimum level of acceptable distortion in the network state representation in the control plane.
We propose a depth-adaptive convolutional Siamese network that performs video tracking adaptively at multiple neural network depths and achieves state-of-the-art accuracy.
An analysis of gene regulatory networks reveals multiple genes and biological processes in response to nitrogen fertilizer usage.
A popular approach to selling online advertising is by a waterfall, where a publisher makes sequential price offers to ad networks for an inventory, and chooses the winner in that order.
This paper analyzes the perturbation on the input of the generator and its influence on the generated images. We further integrate this smooth generator with a gradient penalized discriminator, and design smooth GAN that generates stable and high-quality images.
We address these issues by introducingtheStack-augmentedParser-Interpreter NeuralNetwork(SPINN),whichcombines parsing and interpretation within a single tree-sequence hybrid model by integrating tree-structured sentence interpretation into a shiftreduceparser.
We propose an architecture that leverages both sources of information - surface-form and context - and show that it results in large increases in embedding quality.
This paper introduces a novel approach for generating videos called Synchronized Deep Recurrent Attentive Writer (Sync-DRAW), which combines a Variational Autoencoder with a Recurrent Attention Mechanism in a novel manner to create a temporally dependent sequence of frames that are gradually formed over time.
In this paper, we propose a generic diversity-promoting joint network, called Holistic Semantic Constraint Joint Network (HSCJN), enhancing the global sentence information, and then regularizing the objective function with penalizing the low entropy output.
We introduce sidekick policy learning to capitalize on this imbalance of observability, where an agent must intelligently select its camera motions to efficiently reconstruct the full environment from only a limited set of narrow field-of-view glimpses.
A convolutional neural network is leveraged to uniquely determine the translation and rotation of an object of interest relative to the camera. The model performs comparable to the current feature-selection methods and can therefore be used in conjunction with them to provide more reliable estimates.
Large datasets have been crucial to the success of deep learning models in the recent years, which keep performing better as they are trained with more labelled data. While there have sustained efforts to make these models more data-efficient, the potential benefit of understanding the data itself, is largely untapped.
This paper proposes an efficient image retrieval system based on semantic segmentation using fully convolutional networks (FCN) and a quantization technique (PQ)
Multi-object tracking using only mono-camera images as input using a Poisson multi-Bernoulli mixture tracking filter.
Isoxsuprine binds with high affinity to endothelial NO synthase (eNOS) and cystathionine gamma-lyase (CSE) and has a vasodilator effect.
We present a simple, efficient model for learning boundary detection based on a random forest classifier that speeds up training time by a factor of 10.
This paper proposed a Progressive Soft Filter Pruning method (PSFP) to prune the filters of deep Neural Networks which can thus be accelerated in the inference.
We propose an information-theoretic framework for knowledge transfer which formulates knowledge transfer as maximizing the mutual information between the teacher and the student networks.
This paper proposes Deep Bi-Dense Networks (DBDN) for single image super-resolution.
We proposed a novel 3D deep learning model for object localization and object bounding boxes estimation.
We propose Switchable Whitening (SW), a general form unifying different whitening methods as well as standardization methods. SW learns to switch among these operations in an end-to-end manner.
We propose a novel framework to solve the cross-domain sentiment classification problem, by modelling the emotion across domains.
We propose a new method for automatically deriving NLI datasets from the growing abundance of large-scale question answering datasets. Our approach hinges on learning a sentence transformation model which converts question-answer pairs into declarative forms.
The attention mechanisms in deep neural networks are inspired by human's attention that sequentially focuses on the most relevant parts of the information over time to generate prediction output.
In this paper, we propose a novel end-to-end deep neural network model for omnidirectional depth estimation from a wide-baseline multi-view stereo setup.
This paper introduces a neural network to solve the structure-from-motion (SfM) problem via feature bundle adjustment (BA), which explicitly enforces multi-view geometry constraints in the form of feature reprojection error.
We devise a cascade GAN approach to generate talking face video, which is robust to different face shapes, view angles, facial characteristics, and noisy audio conditions.
We deepen the representation learned by the model by fusing the hidden representation in terms of an explicit HIdden Representation Extractor (HIRE), which automatically absorbs the complementary representation with respect to the final layer.
We introduce a novel abductive reasoning approach based on Grenander's Pattern Theory framework to provide self-supervised domain adaptation cues or "pseudo-labels," which can be used instead of expensive human annotations.
This paper presents an end-to-end radar odometry system which delivers robust, real-time pose estimates based on a learned embedding space free of sensing artefacts and distractor objects.
We propose a dual perspective similarity metric called Forward Backward Similarity (FBS) that efficiently computes topological similarity from both the query node and the perspective of candidate nodes.
We propose a counter-factual reasoning method to counter the bias in hindsight experience replay and extend HER with a trade-off to make rewards calculated for hindsight experiences numerically greater than real rewards.
We propose a shallow CNN (SHCNN) architecture with only three layers to classify static expressions and micro-expressions simultaneously without big training datasets.
An Anchor-to-Joint Regression Network for 3D Hand and Body Pose Estimation in Depth Image .
We propose EHSOD, an end-to-end hybrid-supervised object detection system which can train a high quality detector with only a limited amount of fullyannotated data and fully exploiting cheap data with imagelevel labels.
In this paper, we propose a novel face alignment method using single deep network (SDN) on existing limited training data.
We present empirical evidence that the activations of convolutional neural networks trained for object categorization are not robust to identity-preserving image transformations commonly used in data augmentation. As a solution, we propose a simple, yet effective and efficient (10 % increase in training time) way of increasing the invariance of the models.
We introduce an architecture for image categorization that enables the end-to-end learning of separate visual features for the different classes to distinguish.
We propose a reconstruction network (RecNet) with a novel encoder-decoder-reconstructor architecture, which leverages both the forward (video to sentence) and backward (sentence to video) flows for video captioning.
We propose a self-supervision method for semantic image segmentation without any labels. The proposed approach is readily pluggable to many self-Supervision methods and does not use more annotated samples than the original process.
In this paper, we propose a residual non-local attention network for high-quality image restoration.
We propose convolutional neural network (CNN)-based down-scale methods for multi-scale deep-learning-based non-uniform single image deblurring.
We propose an Auto-Encoder Matching (AEM) model to learn utterance-level semantic dependency and generate semantically coherent responses in dialogue generation.
Drug-drug interaction (DDI) is an important topic for public health and thus attracts attention from both academia and industry. Here we hypothesize that clinical side effects (SEs) provide a human phenotypic profile and can be translated into the development of computational models for predicting adverse DDIs.
We study the similarities of easy and hard examples respectively for different Convolutional Neural Network (CNN) architectures, assessing how those examples contribute to generalization.
We address the novel, highly challenging problem of estimating the layout of a complex urban driving scenario, which involves "hallucinating" scene layout for even parts that are occluded in the image.
We propose a method to learn an Action Concept Tree (ACT) and an Action Semantic Alignment (ASA) model for action classification from image-description data via a two-stage learning process.
CyCADA adapts representations at both the pixel-level and feature-level, enforces cycle-consistency while leveraging a task loss, and does not require aligned pairs.
We present a novel deep-learning-based approach for one-class transfer learning in which labeled data from an unrelated task is used for feature learning in one- class classification.
In this paper, a new keypoint matching method is proposed based on the local multi-layer convolutional neural network (CNN) features, termed Local Convolutional Features (LCFs)
We propose a new loss function that amplifies the impact of errors from the interval (-w, w) by switching from L1 loss to a modified logarithm function.
We propose an improved joint optimization framework, which mixed the mix-up entropy and Kullback-Leibler entropy as the loss function. The new loss function can give better fine-tuning after the framework updates both the label annotations.
This paper introduces a novel global patch matching method that focuses on how to remove fronto-parallel bias and obtain continuous smooth surfaces with assuming that the scenes covered by stereos are piecewise continuous.
We present a method to separate a single image captured under two illuminants, with different spectra, into the two images corresponding to the appearance of the scene under each individual illuminant.
We present two novel solutions for multi-view 3D human pose estimation based on new learnable triangulation methods that combine 3D information from multiple 2D views.
We introduce a new data augmentation algorithm, Population Based Augmentation (PBA), which generates nonstationary augmentation policy schedules instead of a fixed augmentationpolicy. We show that PBA can match the performance of AutoAugment on CIFAR-10.
This paper studies the object transfiguration problem in wild images. The generative network in classical GANs for object transfigureduration often undertakes a dual responsibility: to detect the objects of interests and to convert the object from source domain to target domain.
This paper first shows that the evaluation protocols used in the literature for supervised hashing are not satisfactory: we show that a trivial solution that encodes output of a classifier significantly outperforms existing supervised or semi-supervised methods, while using much shorter codes.
A Comprehensive study on the BoVW pipeline for action recognition task.A generic analysis on 13 encoding methods.An evaluation on three fusion methods.Intra-normalization for supervector based encoding method.Several good practices.
The paper introduces the disparity assumption into the stereo matching using dynamic programming, proposes a new global energy function, which not only resolves the problem of traditional dynamic programming stereo matching algorthm that the energy function is short of intensity and disparity constraints between scan lines but also can be computed more exactly because the adopted dissimillarity function propsed by Birchfield is extended from 2-connect neighborhood to 8-connect Neighborhood.
We propose a convnet designed to perform NMS of a given set of detections, obtaining better recall and precision.
The task of Face Recognition is often cited as being complicated by the presence of lighting and expression variation. In this article a novel combination of facial expression categorisation and 3D face recognition is used to provide enhanced recognition performance.
This paper considers the problem of single image depth estimation with a focus on depth maps with higher spatial resolution, for which we propose two improvements to existing approaches.
We propose a novel Random Quad-Tree based ensemble algorithm (R-QT) to address the small sample size (SSS) problem.
In this paper, a novel approach for human gesture classification on skeletal data is proposed for the application of exergaming in physiotherapy. Unlike existing methods, we propose to use a general classifier like Random Forests to recognize dynamic gestures.
We present a human-in-the-optimization method that allows users to directly explore and search the latent vector space of generative image modeling.
We propose a fully neural-based model called IODA (Input Output Deep Architecture) that learns both input and output dependencies.
We demonstrate that many detection methods are designed to identify only a sufficently accurate bounding box, rather than the best available one. To address this issue we propose a simple and fast modification to the existing methods called Fitness NMS, which obtains a significantly improved MAP at greater localization accuracies without a loss in evaluation rate.
We propose a method that explores semantic segmentation results as self-attention cues to significantly improve the pedestrian detection performance.
We insert a second layer of privacy protection by using non-invertible motion features based on phase correlation and log-polar transformation, which are mask-invariant.
We introduce MetaOD, the first metamorphic testing system for object detectors to effectively reveal erroneous detection results by commercial object detectors.
We model the video forecasting problem at a higher level of abstraction and use the structured space of pose as an intermediate representation to solve the problem.
We present a performance-based facial animation system capable of running on mobile devices at real-time frame rates.
We present a novel approach to recognize hand-object interactions by extracting both local motion features representing the subtle movements of the hands and global hand shape features to capture grasp types.
Ritanserin and compound AMB639752 are druggable diacylglycerol kinase alpha inhibitors that restore restimulation induced cell death in X-linked lymphoproliferative disease 1.
In this paper, we propose a low-rank and sparse learning framework that trains the compressed network from scratch.
In this paper, we propose bilinear attention networks (BAN), an efficient way to utilize given vision-language information seamlessly.
We propose an adversarial method generating perturbations based onroot mean square gradient which formulates adversarial perturbation size in root mean square level and update gradient in direction, due to updating gradients with adaptive and root meansquare stride, our method map origin, and corresponding adversarial image directly which shows good transferability in adversarial examples generation.
We trained a deep convolutional neural network (CNN) to recognize affordances from images and to learn the underlying features or the dimensionality of affordances.
A self-attention mechanism based on analyzing a person's food habits from daily recorded egocentric photo-streams of the food places can provide valuable means for people to improve their eating habits.
We propose to learn a deep fitting degree scoring network for monocular 3D object detection, which aims to score fitting degree between proposals and object conclusively.
In this paper, we propose a more fine-grained model named TransD, which is an improvement of TransR/CTransR.
We extend the generative adversarial network (GAN) framework with a low-dimensional approximate semantic space, and shape that space to capture semantics such as merging and turning.
Integrating Faster R-CNN and a stacked hourglass for improved face detection precision and accurate landmark localisation.
An attention-guided coarse-to-fine network based on an attention mechanism for robust face alignment.
We propose a new automatic approach for the classification of food-related environments, that is able to classify up to 15 such scenes.
We address the problem of synthesizing new video frames in an existing video, either in-between existing frames (interpolation), or subsequent to them (extrapolation), using a deep network that learns to synthesize video frames by flowing pixel values from existing ones.
We present Multitask Network Cascades for instance-aware semantic segmentation and demonstrate state-of-the-art results on PASCAL VOC.
In this paper, we propose a novel activation function called flexible rectified linear unit (FReLU) to further explore the effects of negative values.
We propose "Neural Illumination" a new approach that decomposes illumination prediction into several simpler differentiable sub-tasks: 1) geometry estimation, 2) scene completion, and 3) LDR-to-HDR estimation.
Neural networks are known to be vulnerable to adversarial examples: inputs that are close to natural inputs but classified incorrectly. In order to better understand the space of Adversarial examples, we survey ten recent proposals for detection and compare their efficacy.
This paper presents a nonparametric approach to semantic parsing using small patches and simple gradient, color and location features.
We propose an end-to-end comparative attention-based model for person re-identification that learns to selectively focus on parts of pairs of person images after taking a few glimpses and adaptively comparing their appearance.
In this research, we focus on the 6D pose estimation of known objects from the RGB image. We use separate deep neural networks to: detect the object on the image, estimate the center of the object, and estimate the translation and ”in-place” rotation of theobject.
A common object detector can be learnt by making its detection confidence scores distributed like those of a strongly supervised detector, which improves state-of-the-arts.
The skeleton based gesture recognition is gaining more popularity due to its wide possible applications. In this paper, we first leverage a robust feature descriptor, path signature (PS), and propose three PS features to explicitly represent the spatial and temporal motion characteristics.
In this paper, we propose a computationally efficient transfer learning approach using the output vector of final fully-connected layer of deep convolutional neural networks for classification.
We propose a simple yet effective method for unsupervised domain adaptation that minimizes domain shift by aligning the second-order statistics of source and target distributions.
In this paper we propose a new augmentation technique, called patch augmentation, that improves model accuracy and makes networks more robust to adversarial attacks.
In this paper, we propose to exploit machine-generated labels to learn better acoustic representations, based on the synchronization between vision and audio.
A divide-and-conquer method classifying sentence types before sentiment analysis, then performing sentiment analysis separately.
We introduce a method for training GANs with discrete data that use the estimated difference measure from the discriminator to compute importance weights for generated samples, thus providing a policy gradient for training the generator.
We augment the self-attention layers with persistent memory vectors that play a similar role as the feed-forward layer without degrading the performance of a transformer.
In this paper we propose a simple way to modify any conventional deep architecture to automatically provide more transparent explanations for classification decisions, as well as an intuitive notion of the credibility of each prediction.
We propose a simple yet effective visual tracking framework (named Siamese Box Adaptive Network, SiamBAN) by exploiting the expressive power of the fully convolutional network (FCN) for efficient visual tracking.
We develop an approximate Bayesian method for decoding natural images from the spiking activity of populations of retinal ganglion cells, enabling fast nonlinear decoding that incorporates natural scene statistics implicitly.
In this paper, we developed a family of novel features, called summation invariant that are invariant to Euclidean transformation in both 2D and 3D, for 3D face recognition.
This paper presents an approach for answering fill-in-the-blank multiple choice questions from the Visual Madlibs dataset using a combination of networks trained for specialized tasks.
In this paper, we introduce a new real-time MDP framework, in which states and actions evolve simultaneously and show how it is related to the classical MDP formulation. We then use those insights to create a new algorithm Real-Time Actor-Critic (RTAC) that outperforms the existing state-of-the-art continuous control algorithm Soft actor-critic.
In this study, we profiled disorder in Mediator subunits of 146 eukaryotes belonging to three kingdoms viz., metazoans, plants and fungi, and attempted to find correlation between the evolution of Mediator complex and its disorder.
We propose a general framework for unsupervised domain adaptation, which allows deep neural networks trained on a source domain to be tested on a different target domain without any training annotations in the target domain.
We investigate a mixture graph and propose a semi-supervised classification based on mixture graph.
In this paper, we propose a four stream Siamese deep convolutional neural network for person redetection that jointly optimises verification and identification losses over a four image input group.
In this paper, we propose Differentiable Automatic Data Augmentation (DADA), an efficient and effective one-pass optimization strategy for discrete data augmentation.
We investigate the problem of stroke-level sketch segmentation, which is to automatically assign strokes of a given sketch with semantic labels. In this paper, we propose an approach for multi-class sketch semantic segmentation by considering it as a sequence-to-sequence generation problem.
We propose a framework for face image analysis, addressing three challenging problems of race, age, and gender recognition through face parsing.
We investigate and build upon the recent success of Conditional Generative Adversarial Networks (cGANs) for Image-to-Image translations.
The Distilled Dropout Network makes standard (non-Bayesian) neural networks more introspective by adding a new training loss which prevents them from being overconfident.
Semantic segmentation of 3D point clouds is a challenging problem with numerous real-world applications. Recent attempts, based on 3D deep learning approaches, have achieved below-expected results.
We propose a compact and robust method for encoding the relative position of visual words using sliding coordinates coding.
In this paper, we introduce a network architecture (https://github.com/mzolfaghari/ECO-efficient-video-understanding) that enables fast per-video processing at the same time.
A search of the ZINC database for GPR91 agonists of unique structures and synthetic non-metabolite succinate analogs that activate GPR 91.
In this paper, we propose a novel general framework that incorporates arbitrary single content feature with user-video interactions, named as collaborative embedding regression (CER) model, to make effective video recommendation in both in-matrix and out-of-Matrix scenarios.
This paper presents a state-of-the-art model for visual question answering (VQA), which won the first place in the 2017 VQA Challenge.
We study probabilistic models of natural images and extend the autoregressive family of PixelCNN models by incorporating latent variables.
We propose a framework for disentangling the appearance and geometry representations in the face recognition task and integrate it into state-of-the-art models.
We propose Intra-Ensemble, an end-to-end strategy with stochastic training operations to train several sub-networks simultaneously within one neural network.
Our Knowledge-Augmented Language Model (KALM) learns to recognize named entities in an entirely unsupervised way by using latent information latent in the model.
We propose a framework for compressing state-of-the-art Single Shot MultiBox Detector (SSD) using Sparsity Induction, Filter Selection, and Filter Pruning.
In this paper, we propose a saliency detection model for RGB-D images based on the deep features of RGB images and depth images within a Bayesian framework.
Automated plant species identification using computer vision approaches .
This paper presents a system for the recognition of online whiteboard notes. For the recognition we use an offline HMM-recognizer, which is supplemented with methods for processing online data and generating offline images.
We present the first all-in-one end-to-end trainable model for semantic amodal segmentation that predicts theAmodal instance masks as well as their visible and invisible region in a single forward pass.
We propose a novel robust norm that exploits the information from both the local error term and the global image registration information, achieving unprecedented convergence range.
We propose a self-supervised approach to deep surface deformation that uses cycle-consistency to define a notion of good correspondences in groups of objects and use it as a supervisory signal to train our network.
We propose a novel model-based deep convolutional autoencoder that addresses the highly challenging problem of reconstructing a 3D human face from a single in-the-wild color image.
We propose a strategy based on decreasing the number of features in order to improve accuracy in the human action classification task.
An application of the generalized hidden Markov models to handwritten word recognition.
We address the personalization problem, which involves adapting to the user's domain incrementally using a very limited number of samples. We propose a simple yet effective personalization framework based on deep features.
In this paper, we introduce a generalization of the minimum cost lifted multicut problem to hypergraphs for motion segmentation, and propose a simple primal feasible heuristic that allows for a reasonably efficient inference in instances of higher-order lifted mult Connecticut problem instances defined on point trajectory hypergraph.
This paper presents a convolutional layer that is able to process sparse input features. The presented algorithm makes use of the permutohedral lattice data structure.
A novel and model-based approach for automatic recognition of buildings’ roof models based on deep structures for hierarchical learning of features that are extracted from both LiDAR and aerial ortho-photos.
Batch Normalization (BN) is essential to effectively train state-of-the-art deep Convolutional Neural Networks (CNN). It normalizes the layer outputs during training using the statistics of each mini-batch. In this work, we study BN from the viewpoint of Fisher kernels that arise from generative probability models. We propose mixture normalization, a soft piecewise version of batch normalization.
We introduce a novel task, Image-Grounded Conversations (IGC), in which natural-sounding conversations are generated about a shared image.
We propose Adaptive Federated Averaging, a novel algorithm for robust federated learning that detects failures, attacks, and bad updates provided by participants in a collaborative model.
We propose a practical approach to the problem of facial landmark detection under the rich shape deformation.
Two studies on multilingual multimodal image description provide empirical evidence towards two hypotheses at the core of the task: (i) whether target language speakers prefer ::: descriptions generated directly in their native language, as compared to descriptions translated from a different language, and (ii) the role of the image in human translation of descriptions.
We use denoising auto-encoder (DAE) and language model (LM) based reinforcement learning to enhance the training of encoder and decoder with unlabeled data.
This paper investigates a new task named Conversational Question Generation (CQG) which is to generate a question based on a passage and a conversation history (i.e., previous turns of question-answer pairs) using a reinforcement learning mechanism.
A localization-aware auxiliary network to find out the channels with key information for classification and regression so that we can conduct channel pruning directly for object detection, which saves lots of time and computing resources.
We propose a two-stage detector that can not only detect and localize hands, but also provide fine-detailed information in the bounding box of hand in an efficient fashion.
We propose an evaluation methodology consisting of automatically constructed"stress tests"that allow us to examine whether systems have the ability to make real inferential decisions.
Policy Prediction Network introduces implicit model-based learning to Policy Gradient algorithms for continuous action space and is made possible via the empirically justified clipping scheme.
We propose an entropy-based approach for link-prediction in bipartite graphs, which can be used for network analysis.
We study a simple generic framework to address the issue of bad training data; both bad labels in supervised problems, and bad samples in unsupervised ones. We show the merit of this approach in both theory and practice.
We propose the double attention block'', a novel component that aggregates and propagates informative global features from the entire spatio-temporal space of input images/videos, enabling subsequent convolution layers to access features of the entire space efficiently and achieve state-of-the-art results.
In this work, we introduce the novel problem of identifying dense canonical 3D coordinate frames from a single RGB image, where a canonical frame can be identified as represented by three orthogonal axes.
In this paper we show that GP hybrid deep networks, GPDNNs, inherit the nice properties of both GPs and DNNs and are much more robust to adversarial examples.
A survey on recent advances of image super-resolution techniques using deep learning approaches in a systematic way.
We propose a strategy that exploits the unpaired image style transfer capabilities of CycleGAN in semi-supervised segmentation, which may significantly reduce human annotation efforts.
We propose a new method named soft Gaussian mapping (SGM) to address the discrepancies between color names and pixels using a Gaussian and utilize the inverse of covariance matrix to bridge the gap between them.
We propose a classification adversarial model(Cls-GAN) that can balance between attribute transfer and generated photo-realistic images.
In recent years, convolutional neural networks (CNNs) took over the field of document analysis and they became the predominant model for word spotting. The drawback of this approach is the overconfidence of neural networks when used out of their training distribution. In this paper, we explore different metrics for quantifying the confidence of a CNN in its predictions.
We develop a first approach that works directly on input point clouds, does not require paired training data, and hence can directly be applied to real scans for scan completion.
Multi-domain translation seeks to learn a probabilistic coupling between marginal distributions that reflects the correspondence between different domains. We propose a new framework and algorithm based on learning the shared latent distribution and training autoencoders under distributional constraints.
Answer selection is an important task in question answering (QA) from the Web. To address the intrinsic difficulty in encoding sentences with semantic meanings, we introduce a general framework with several optimization strategies.
We propose a simple yet effective unsupervised hashing framework, which exploits the powerful visual representation capabilities of deep architectures and combines this within a tree structure involving a multi-path scheme.
We present a data-driven method for building dense 3D reconstructions using a combination of recognition and multi-view cues.
This paper introduces a novel multi-layer Hebbian network trained by a rule derived from a non-negative classical multidimensional scaling cost-function. The performance is compared to that of other fully unsupervised learning algorithms.
We propose an effective defence against the above misclassification attacks in transfer learning.
We propose a multitask reinforcement learning approach to training an E2E video captioning model that is trained end-to-end from raw video input to the caption output.
This paper presents the first comprehensive empirical study demonstrating the efficacy of the Brain Floating Point (BFLOAT16) half-precision format for Deep Learning training across image classification, speech recognition, language modeling, generative networks and industrial recommendation systems.
We propose a constrained multi-stage Convolutional Neural Network to jointly pursue locally consistent density map from two aspects for object counting in surveillance scenes.
We analyze the effect of curriculum learning, which involves the non-uniform sampling of mini-batches, on the training of deep networks, and specifically CNNs trained for image recognition.
We present a deep hierarchical multi-patch network inspired by Spatial Pyramid Matching to deal with blurry images via a fine-to-coarse hierarchical representation.
This study explores the necessity of performing cross-corpora evaluation for grammatical error correction (GEC) models.
This paper describes a channel-selection approach for simplifying deep neural networks. We also develop a cost-aware mechanism to prevent the compression from sacrificing the expected network performance.
We propose to use cosine similarity instead of dot product for normalization in neural networks, which we call cosine normalization.
This paper identifies the strengths and limitations of available deep learning methods through comparative analysis and discusses the research challenges in terms of computation, architecture selection, goal specification, generalisation, verification and validation.
In this paper, we discuss the required skills to build recommender systems, and why the literature provides little help in identifying promising recommendation approaches.
We investigate the integration of GNSS and monocular camera measurements in a simultaneous localization and mapping system.
A principled batch active learning method using Determinantal Point Processes, a repulsive point process that enables generating diverse batches of samples at a time.
We use deep transfer learning for face swapping detection, showing true positive rates with very few false alarms.
We explore object discovery and detector adaptation based on unlabeled video sequences captured from a mobile platform. We propose a novel approach for unsupervised object discovery by appearance-based clustering.
 SmileNet uses a Fully Convolutional Neural Network (FCNN) to detect multiple smiling faces in a given image of varying resolution.
In this paper, we propose a new approach for depth estimation based on alternating gradient descent algorithm that jointly estimates a continuous depth map and light distribution of the unknown scene from its lensless measurements.
In natural language the intended meaning of a word or phrase is often implicit and depends on the context. We propose a simple yet effective method for sentiment analysis using contextual embeddings and a self-attention mechanism.
In this paper, we propose a novel Decision Propagation Module (DPM) to make an intermediate decision that could act as category-coherent guidance extracted from early layers, and then propagate it to the latter layers.
We consider the two related problems of detecting if an example is misclassified or out-of-distribution. We present a simple baseline that utilizes probabilities from softmax distributions, and assess performance by defining several tasks.
End-to-end neural network based approaches to audio modelling are generally outperformed by models trained on high-level data representations. In this paper we present preliminary work that shows the feasibility of training the first layers of a CNN model to learn the commonly-used log-scaled mel-spectrogram transformation.
The fine-tuning method achieves higher accuracy than common few-shot learning algorithms in the low-resolution mini-ImageNet dataset and nearly the same accuracy as the state-of-the-art algorithm in the 5-shot task.
We used computational modeling to measure the contributions of target, nontarget, and coarse scene features towards object detection in humans, showing systematic variations in object detection.
We propose a new channel pruning technique based on attention that can evaluate the importance of channels. We improved the method with the criterion to allow the automatic channel selection using a single compression rate.
We describe a novel method for searching 3D model collections using free-form sketches within a virtual environment as queries. Using immersive virtual reality the user can express their query through a sketch that demonstrates the desired structure, color and texture.
We propose a way to combine the best attributes of 2D- and 3D-CNN -- we propose to hallucinate spatiotemporal representations as computed by 3D convolutional neural networks, using a 2DCNN.
We propose a novel dual-stream framework for modeling the interweaved spatiotemporal dependency, and develop a deep neural network within this framework that aims to achieve high adaptability and flexibility in STS configurations from various diagonals.
In this paper we propose a novel efficient learning scheme that tightens a sparsity constraint by gradually removing variables based on a criterion and a schedule, with theoretical guarantees of convergence and selection consistency.
We propose a new method to generate multi-resolution word embeddings that represent documents at multiple resolutions in terms of context-scopes.
We propose a novel architecture, called the TL-embedding network, to learn an embedding space with generative in 3D and predictable in 2D.
We investigate and determine the most cost-effective way of obtaining high-quality multi-label annotations for temporal data such as videos. We conclude that the optimal strategy is to ask as many questions as possible in a HIT.
We propose a novel region based ensemble learning network for fine-grained classification.
In this paper, we introduce the problem of predicting why a person has performed an action in images, and propose a new dataset of people performing actions annotated with likely motivations.
We propose Adversarially-Trained Autoencoder Augmentation, the first transferable adversarial defense that is robust to certain adaptive adversaries.
We propose a fingerprinting method for deep neural networks that extracts a set of inputs from a source model so that only surrogates agree with the source model on the classification of such inputs.
We propose an algorithm for vessel extraction in retinal images using multiscale line-tracking procedure.
Privacy-Preserving Representation-Learning Variational Generative Adversarial Network (PPRL-VGAN) to learn an image representation that is explicitly disentangled from the identity information.
A robust multiscale stereo matching algorithm is proposed to find reliable correspondences between low contrast and weakly textured retinal image pairs with radiometric differences.
We propose a progressive data adapted pruning strategy for efficient architecture search while allowing a large candidate set in a more efficient manner.
We proposed an Exigent Features Preservative Network (EXPERTNet), to describe the features of the facial expressions.
We propose a novel approach called Latent Space Encoding (LSE) for ZSL based on an encoder-decoder framework, which learns a highly effective latent space to well reconstruct both the visual space and the semantic embedding space to achieve zero-shot learning.
We address action temporal localization in untrimmed long videos via multi-stage segment-based 3D ConvNets and propose a novel loss function for the localization stage to explicitly consider temporal overlap and therefore achieve high temporal localization accuracy.
We have developed a computational, knowledge-based approach to infer gene functions from phenotypic manifestations and applied this approach to yeast (Saccharomyces cerevisiae), nematode worm (Caenorhabditis elegans), zebrafish (Danio rerio) and mouse (Mus musculus) phenotypes.
We formalize the problem of adversarial images given a pretrained classifier, showing that even in the linear case the resulting optimization problem is nonconvex.
This work presents a new and simple approach for fine-tuning pretrained word embeddings for text classification tasks such as sentiment analysis and emotion detection.
Pruning is a popular technique for compressing a neural network: a large pre-trained network is fine-tuned while connections are successively removed. In this extended abstract, we examine residual networks obtained through Fisher-pruning and make two interesting observations.
We propose an image captioning approach in which a generative recurrent neural network can focus on different parts of the input image during the generation of the caption, by exploiting the conditioning given by a saliency prediction model on which parts of an image are salient and which are contextual.
We propose a hierarchical trinity search framework to simultaneously discover efficient architectures for all components (i.e. backbone, neck, and head) of object detector in an end-to-end manner.
We study the problem of learning to collaborate directly from pixels in AI2-THOR and demonstrate the benefits of explicit and implicit modes of communication to perform visual tasks.
We introduce ScanComplete, a novel data-driven approach for taking an incomplete 3D scan of a scene as input and predicting a complete 3D model along with per-voxel semantic labels.
In this paper, we present a stereo matching algorithm using arbitrarily-shaped windows and a local optimization method called Go-light.
Robustness to label noise up to severe strengths can be achieved by using a set of trusted data with clean labels, and propose a loss correction that utilizes trusted examples in a data-efficient manner to mitigate the effects of label noise on deep neural network classifiers.
We introduce the first benchmark for a new problem --- recognizing human action adverbs (HAA), a semantically complete set of adverbs describing human actions.
We formulate AU recognition under incomplete data as a multi-label learning with missing labels (MLML) problem.
This paper studies large-scale image classification, in a setting where new classes and training images could continuously be added at (near) zero cost. We cast this problem into one of learning a low-rank metric, which is shared across all classes and explore k-nearest neighbor and nearest class mean classifiers.
In this paper we propose a new method to get the specified network parameters through one time feed-forward propagation of meta networks and explore the application to neural style transfer.
We propose a self-adaptation approach for CNN training, utilizing both synthetic training data (with ground-truth disparities) and stereo pairs in the new domain (without ground- Truths), utilizing an iterative optimization problem with graph Laplacian regularization.
We propose f-BRS (feature backpropagating refinement scheme) that solves an optimization problem with respect to auxiliary variables instead of the network inputs, and requires running forward and backward pass just for a small part of a network.
A completely unsupervised mechanism for textual grounding using hypothesis testing as a mechanism to link words to detected image concepts.
In this paper, we propose a low-rank sparse coding (LRSC) method that exploits local structure information among features in an image for the purpose of image-level classification.
We explored the extent of mutational robustness in the budding yeast by genome wide dosage suppressor analysis of 53 conditional lethal mutations, revealing 660 suppressor interactions of which 642 are novel.
Inferring new facts from existing knowledge graphs (KG) with explainable reasoning processes is a significant problem and has received much attention recently. We propose CogKR for one-shot KG reasoning.
We propose a novel expression transfer method based on an analysis of the frequency of multi-expression facial images. The subtle expression changes are important visual clues to distinguish different expressions.
We present deep networks for context-aware emotion recognition, called CAER-Net, that exploit not only human facial expression but also context information in a joint and boosting manner.
We propose a simple multi-task learning scheme to achieve quantitatively better common sense reasoning in language models by leveraging auxiliary training signals from datasets designed to provide common sense grounding.
We propose a two-stage encoder-decoder network coupled with Semantic Prediction Guidance module which learns to re-weight the local features through the guidance from pixel-wise semantic prediction.
We propose a modular extension of the backpropagation algorithm for computation of the block diagonal of the training objective's Hessian to various levels of refinement.
In this paper, we propose a biologically inspired contour detection model inspired by the biological characteristics of multiple visual channels and multi-hierarchical visual information.
We propose Deep Multi-Modal Sets: a scalable, multi-modal framework that reasons over different modalities to learn various types of tasks.
In this paper, the drift error in an odometry is modeled and a Drift Covariance Estimation algorithm is introduced.
We propose a sparsity-invariant autoencoder able to process the output of conventional visual odometry algorithms working in synergy with depth-from-mono networks.
We use a bilinear convolutional neural network with pairwise ranking loss function for fine-grained attribute recognition task by focusing on each category separately.
This philosophical paper proposes a modified version of the scientific method, in which large databases are used instead of experimental observations as the necessary empirical ingredient, and proposes to reformulate computer vision as an empirical science of visual reality.
We show that multimodal ASR models can recover words which are masked in the input acoustic signal, by grounding its transcriptions using the visual representations, by leveraging the visual context.
We propose a novel approach, which takes both advantages of good generalization of generative models and excellent discrimination of discriminative models, for visual tracking, in which deep features could usually be redundant, noisy and less discrim in certain instances, and the tracking performance might thus be affected.
We propose an Attentive but Diverse Network (ABD-Net), which seamlessly integrates attention modules and diversity regularization throughout the entire network, to learn features that are representative, robust, and more discriminative.
A style representation learning model based on the deep neural networks called StyleNet is proposed in this paper.
In this paper, the multi-branch architectures are extended by convolutional LSTM layers at different positions and evaluated on two different datasets in order to find the best one.
Affective human-robot interaction requires lightweight software and cheap wearable devices that could further this field. The challenge of filtering artifacts and extracting features, while reducing processing time and maintaining high accuracy results, is attempted in this work.
A survey of the Markov-model-based offline handwriting recognition approaches.
In distributed machine learning, data is dispatched to multiple machines for processing. Motivated by the fact that similar data points are often belonging to the same or similar classes, and more generally, classification rules of high accuracy tend to be "locally simple but globally complex", we propose data dependent dispatching that takes advantage of such structures.
HyperNOMAD is an extension of the NOMAD software that applies the MADS algorithm to simultaneously tune the hyperparameters responsible for both the architecture and the learning process of a DNN, and that allows for an important flexibility in the exploration of the search space by taking advantage of categorical variables.
We propose an end-to-end pipeline for solving the instance-level human analysis, named Parsing R-CNN, which is applicable to many issues in human instance analysis.
We analyze the trade-off between the error in the trained model and the actual training runtime(wallclock time) in asynchronous SGD and propose a method of gradually varying synchronicity in distributed SGD.
We introduce a hypothesis testing approach based on memory augmented neural networks for language comprehension task.
We propose to model object composition in a GAN framework as a self-consistent composition-decomposition network by explicitly learning the possible interactions between multiple entities that could be present in a scene.
Clustering Embedded Network Inference with Projection-based CENI .
We propose a novel efficient and lightweight model for human pose estimation from a single image that incorporates part-based structural and geometric priors in a hierarchical prediction framework.
We provide an overview of network analysis including a step-by-step guide on how to perform and use this approach to investigate a biological question, including the software packages that we and others employ for each of the steps of a network analysis workflow.
We design a novel Slim Convolution (SlimConv) module to boost the performance of CNNs by reducing channel redundancies and improving the feature diversities.
In this work, we propose an efficient and accurate monocular 3D detection framework in single shot, which achieves state-of-the-art performance on the KITTI benchmark.
We study the performance of neural tangent kernels on CIFAR-10 and compare them to finite nets.
We propose a novel approach for sketch-based 3D model retrieval by constructing a deep common semantic space embedding using triplet network.
We propose a novel face alignment algorithm that estimates both 2D and 3D landmarks and their 2D visibilities for a face image with an arbitrary pose.
We propose a novel differentiable NAS method which can search for the width and the spatial resolution of each block simultaneously.
We address the task of cross-domain feature disentanglement with generative adversarial networks. We advance the idea of unsupervised domain adaptation and propose a novel deep generative model for the task.
The viewpoint variability across a network of non-overlapping cameras is a challenging problem affecting person re-identification performance. In this paper, we investigate how to mitigate the cross-view ambiguity by learning highly discriminative deep features under the supervision of a novel loss function.
We propose an optimized cross-scale cost aggregation scheme with coarse-to-fine strategy for stereo matching and introduce an adaptive scheme in each region.
We propose an algorithm that automatically discovers groups of arbitrary numbers of participating objects that demonstrate consistent spatial, scale, and viewpoint interactions with each other. These groups of objects are likely to correspond to a specific layout of the scene.
We propose the use of large set of unlabeled images as a source of regularization data for learning robust visual representation which alleviates the need to rely on large labeled datasets.
Esters of arylacetic acids, including those substituted on the methylene group, are prepared by rearrangement of the corresponding alpha-halo-alkylarylketones with Ag compounds in lower alcohols and in an acid medium.
We investigate the possibility of improving skin lesion classification using the additional context information provided by body location using the state-of-the-art ImageNet pretrained model.
The aim of multi-task reinforcement learning is two-fold: efficiently learn by training against multiple tasks and quickly adapt, using limited samples, to new tasks at test time.
A dynamic descriptor facilitates robust recognition of facial expressions in video sequences. The current two main approaches to the recognition are basic emotion recognition and recognition based on facial action coding system.
We present an adaptation of the recently proposed graph-shifts algorithm for labeling MRF problems from low-level vision with large label sets.
This survey paper presents a taxonomy of contemporary IDS, a comprehensive review of notable recent works, and an overview of the datasets commonly used for evaluation purposes. It also presents evasion techniques used by attackers to avoid detection.
We introduce ExplaiNE, an approach to offer counterfactual explanations for NE-based LP methods, by identifying existing links in the network that explain the predicted links.
In this paper, we apply structural sparsification on time-delay neural networks (TDNN) to remove redundant structures and accelerate the execution.
We propose a novel deep neural multi-task learning framework with explicit feedback strategies to jointly model recognition and normalization.
Action Machine extends the Inflated 3D ConvNet by adding a branch for human pose estimation and a 2D CNN for pose-based action recognition, being fast to train and test.
We focus on this problem and find that the devil of top-down pose estimator is in the biased data processing. We propose a principled way to tackle this dilemma.
We aim to automate the process of selecting an appropriate DNN topology that fulfills both functional and non-functional requirements of the application.
A novel adversarial perturbation based algorithm for anonymizing selective attributes which an individual does not want to share without affecting the visual quality of images.
We present a new cnn architecture directed specifically toimage compression, which generates a map that highlights semantically-salient regions sothat they can be encoded at higher quality as compared to background regions.
This paper attempts to address this problem with a new framework for evaluating story understanding and script learning.
We propose a novel feature selection method, which takes advantage of these redundancies to reduce the size of the pre-trained features, while maintaining 97% of the performance.
We present NetLoc, a novel diffusion Kernel-based Logistic Regression KLR algorithm for predicting protein subcellular localisation using four types of protein networks including physical PPI networks, genetic Protein-Protein Interaction networks, mixed P PI networks and co-expression networks. The results showed that protein networks can provide rich information for protein localisation prediction.
We propose a coarse-to-fine learning framework for real-time detailed 3D face reconstruction from monocular video.
We propose a real-time dynamic object detection algorithm which leverages previously mapped Lidar point clouds to reduce processing and online execution pipeline.
The highest accuracy object detectors to date are based on a two-stage approach popularized by R-CNN, where a classifier is applied to a sparse set of candidate object locations. We propose to address this class imbalance by reshaping the standard cross entropy loss such that it down-weights the loss assigned to well-classified examples.
We present INFaaS, an inference-as-a-service system that abstracts resource management and model selection. The system automatically selects and serves inference queries using a specific model that satisfies these requirements.
We propose Parameterized Structured Pruning (PSP), a novel method to dynamically learn the shape of DNNs through structured sparsity.
We present a novel approach to reconstructing lightweight, CAD-based representations of scanned 3D environments from commodity RGB-D sensors, explicitly modeling inter-relationships between objects and layout, guiding generation of a globally object alignment in a scene.
In this paper, we propose an incremental learning framework that can work in the online learning scenario and handle both new classes data and new observations of old classes.
In this paper, we propose Path Aggregation Network (PANet) aiming at boosting information flow in proposal-based instance segmentation framework.
We propose a multi-view-based 3D convolutional neural network that takes only part of contiguous multi- view images as input and can still maintain high accuracy.
We introduce a novel network architecture, Multi-Adversarial Variational Variational autoEncoder Networks (MAVENs), which incorporate an ensemble of discriminators in a combined VAE-GAN network, with simultaneous adversarial learning and variational inference.
We analyze and compare Western and Chinese classical music based on soundscape models with transfer learning.
An efficient and powerful deep neural network for fast-and-accurate semantic segmentation and a novel loss function Object Weighted Focal Loss are proposed.
This paper proposes Co-Stack Residual Affinity Networks (CSRAN), a new and universal neural architecture for text sequence matching, involving stacked recurrent encoders.
We propose a novel method to learn a deep convolutional neural network that both classifies an object and estimates the rotation path to its best view under the predicted object category.
This paper proposes a novel Optimized Filter Size CNN (OFS-CNN), where the filter sizes and weights of all convolutional layers are learned simultaneously from the training data along with learning convolution filters.
We present Pyramid, a limited-exposure data management system that builds upon count featurization to enhance data protection.
We investigate and introduce a new type of adversarial attack to evade FR systems by manipulating facial content, called adversarial morphing attack (a.k.a Amora).
We redesign four efficient algorithms for HPC systems to improve EASGD's poor scaling on clusters, which is higher than state-of-the-art implementation.
From a single view of an urban environment, we propose a method to effectively exploit the global structural regularities for obtaining a compact, accurate, and intuitive 3D wireframe representation.
Uncertainty quantification for deep learning is a challenging open problem. We propose a family of algorithms which split the classification task into two stages: representation learning and uncertainty estimation. We evaluate their performance in terms of selective classification (risk-coverage), and their ability to detect out-of-distribution samples.
We introduce Dual-Domain LSTM, an architecture that is able to learn temporal dependencies from two domains concurrently, and achieve domain alignment.
We propose LatticeNet, a novel approach for 3D semantic segmentation, which takes as input raw point clouds and embeds them into a sparse permutohedral lattice.
We introduce a parameter sharing scheme, in which different layers of a convolutional neural network (CNN) are defined by a learned linear combination of parameter tensors from a global bank of templates. Training these networks thus implicitly involves discovery of suitable recurrent architectures.
We show how to predict boundaries by exploiting object-level features from a pretrained object-classification network. We can view this process as a "Low-for-High" scheme, where low-level boundaries aid high-level vision tasks.
We present a novel approach that combines Reinforcement Learning and Generative Adversarial Networks (GANs) to generate more human-like responses to questions.
In this paper, we show for the first time, to the best of our knowledge, that it is possible to construct SDMs with dense correspondence.
Multi-hierarchical independent correlation filters (MHIT) for visual tracking.
In this paper, we introduce XGLUE, a new benchmark dataset to train large-scale cross-lingual pre-trained models using multilingual and bilingual corpora, and evaluate their performance across a diverse set of cross-Lingual tasks.
We present three similarity measures for predicting disease associations. The strong correlation between our similarity measures and known disease associations demonstrates the ability of our measures to provide novel insights into disease relationships.
Scene graph inference by solving a neural variant of an ODE by end-to-end learning.
We propose to encode mesh connectivity using Laplacian spectral analysis, along with Mesh Pooling Blocks (MPBs) that can split the surface domain into local pooling patches and aggregate global information among them.
We introduce mutual posterior-divergence regularization, a novel regularization that is able to control the geometry of the latent space to accomplish meaningful representation learning, while achieving comparable or superior capability of density estimation.
We present an approach that learns to synthesize high-quality, novel views of 3D objects or scenes, while providing fine-grained and precise control over the 6-DOF viewpoint.
We propose a fully decoupled training scheme using delayed gradients (FDG) to break all the lockings of the BP.
We explore the dependencies between speaker recognition and emotion recognition. We show that knowledge learned for speaker recognition can be reused for emotion recognition through transfer learning. Then, we improve emotion recognition performance by fine-tuning. Finally, we show the effect of emotion on speaker recognition.
We propose a quantitative evaluation procedure for style transfer, and use these statistics to investigate the relative performance of a number of Neural Style Transfer methods, revealing several intriguing properties.
We propose local Gabor XOR patterns (LGXP), which encodes the Gabor phase by using the local XOR pattern (LXP) operator. Then, we introduce block-based Fisher's linear discriminant (BFLD) to reduce the dimensionality of the proposed descriptor and enhance its discriminative power.
The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images, attracting participation from more than fifty institutions.
We propose an effective approach to generate images with higher quality and better diversity of generated images using BEGANs.
In this paper, we propose to employ identification loss with center loss to train a deep model for person re-identification.
We address the problem of data description using a Bayesian framework to precisely compute the class boundary and therefore utilize domain information in form of prior knowledge in the framework.
We propose a novel convolutional neural network that mines mid-level image patches that are sufficiently dedicated to resolve the corresponding subtleties. We validate our method for action clas- sification.
We develop a few-shot object detector that can learn to detect novel objects from only a few annotated examples.
We study the task of video-to-video translation in the context of visual speech generation and propose a novel character-based GANs architecture for video domain translation.
We propose to explore a broader semantic contextual information in the text domain to enrich the word vector representation of action classes for zero shot learning.
In this paper, we introduce a programmable system for model compression called Condensa. Given a strategy and a user-provided objective, such as minimization of running time, the system uses a novel sample-efficient constrained Bayesian optimization algorithm to automatically infer desirable sparsity ratios.
We propose the normalized direction-preserving Adam (ND-Adam) algorithm, which bridges the generalization gap between Adam and SGD, when used for training DNNs.
We present a novel multi-view dataset for evaluating model-free action recognition systems, covering 56 distinct action classes.
Sketch-based 3D shape retrieval has become an important research topic in content-based3D object retrieval. To foster this research area, two Shape Retrieval Contest (SHREC) tracks on this topic have been organized by us in 2012 and 2013.
In neural image captioning systems, a recurrent neural network (RNN) is typically viewed as the primary `generation' component. This view suggests that the image features should be `injected' into the RNN.
Knowledge distillation is a potential solution for model compression. To solve the problem, we propose model distillation with knowledge transfer from face classification to alignment and verification.
We introduce a novel stochastic regularization technique for deep neural networks, which decomposes a layer into multiple branches with different parameters and merges stochastically sampled combinations of the outputs from the branches during training.
In this work, we overcome brightness constancy by incorporating feature descriptors into a direct visual odometry framework that combines the strength of both feature-based algorithms and direct methods.
Parsing inconsistency, referring to the scatters and speckles in the parsing results as well as imprecise contours, is a long-standing problem in human parsing. To address the inconsistency issue, we propose in this paper an end-to-end trainable, highly flexible and generic module called feature context module (FCM)
We propose a novel fully-convolutional approach where HOI detection is posed as a keypoint detection and grouping problem that directly detects the interactions between human-object pairs.
We propose the first Remote Embodied Referring Expression dataset of natural language references to remote objects in real images. A Navigator-Pointer model for the task.
Stereo matching is an ill-posed problem for at least two principal reasons: (1) because of the random nature of match similarity measure and (2)because of structural ambiguity due to repetitive patterns. Both ambiguities require the problem to be posed in the regularization framework.
Deep-Q-Learning bypasses the need for estimation of the hand-crafted states, and directly determine the best action base on the present retrieval status.
An end-to-end foreground-aware network to discriminate foreground from background by learning a soft mask for person re-identification.
We propose a novel lightweight deep learning module by low-rank pointwise residual (LPR) convolution that achieves competitive performance but with significant reduction of Flops and memory cost compared to the state-of-the-art deep models focusing on model compression.
We present PerceptNet, a convolutional neural network where the architecture has been chosen to reflect the structure and various stages in the human visual system in order to replicate to what extent it determines our ability to judge image quality.
A multilingual BERT is able to solve the complex Question Answering task defined in the English SQuAD dataset in Japanese and French.
This paper proposes a novel dialogue coherence model trained in a hierarchical multi-task learning scenario where coherence assessment is the primary and the high- level task, and dialogue act prediction is the auxiliary and the low-level task.
We present semi-supervised splitting to overcome this limitation by splitting nodes with the guidance of both labeled and unlabeled data.
We present BOFFIN TTS (Bayesian Optimization For FIne-tuning Neural Text To Speech), a novel approach for few-shot speaker adaptation, using Bayesian optimization to efficiently optimize hyper-parameter values for a target speaker.
In this paper, we address a novel problem of cloning a patch of the source spherical panorama image to the target spherical panoramic image to achieve real time cloning performance.
We present FoveaBox, an accurate, flexible and completely anchor-free framework for object detection.
We propose GAN based EM learning framework that can maximize the likelihood of images and estimate the latent variables with only the constraint of L-Lipschitz continuity.
We propose a novel Spatial Context Recurrent ConvNet (SCRC) model as scoring function for natural language object retrieval, integrating spatial configurations and global scene-level contextual information into the network.
We introduce a novel autoencoder model that deviates from traditional autoencoders by using the full latent vector to independently modulate each layer in the decoder.
We propose a new equilibrium enforcing method paired with a loss derived from the Wasserstein distance for training auto-encoder based Generative Adversarial Networks.
We propose a new type of attack for finding adversarial examples for image classifiers. The key idea in our attack is to search over latent code pairs to find ones that generate nearby classifier outputs.
This paper introduces a novel cumulative attribute concept for learning a regression model when only sparse and imbalanced data are available.
We propose two algorithms with arm-wise randomization to overcome the shortcoming in the clustered case, in which the feature vectors form several large clusters, and propose a new algorithm with the Thompson sampling to overcome it.
We introduce a simple procedure built upon decoder-transformers to obtain competitive ROUGE scores for summarization performance using a language modeling loss alone, with no beam-search or other decoding-time optimization, and instead relying on efficient nucleus sampling and greedy decoding.
This paper introduces a rotation-based framework for arbitrary-oriented text detection in natural scene images.
We use knowledge of linguistic statistics to regularize visual model learning, improving upon state-of-the-art methods.
We report a learning rule for neural networks that computes how much each neuron should contribute to minimize a giving cost function via the estimation of its target value. We also give a general technique for weights initialization.
We explore the use of deep learning for pulmonary lobe segmentation and propose pre-processing CT image by cropping region that is covered by convex hull of lungs in order to mitigate the influence of noise from outside the lungs.
We propose a multi-kernel LSTM extension that supports accommodation of multiple convolutional kernels and layers, and propose an attention-based mechanism for the extension.
We propose a novel and efficient training algorithm inspired by alternating direction method of multipliers (ADMM) for supervised learning of hash codes.
We propose an efficient approach to perform adversarial training by perturbing intermediate layer activations and use these perturbations as a regularizer during training.
We introduce a new serial crystallography dataset that is both scalable and accurate. We explore several computer vision approaches for classification on DiffraNet.
This paper presents a brief study of the various approaches and the techniques of emotion recognition. The survey covers a succinct review of the databases that are considered as data sets for algorithms detecting the emotions by facial expressions.
We revisit two widely used approaches in computer vision, namely filtered channel features and Convolutional Neural Networks (CNN), and absorb merits from both by proposing an integrated method called convolutional Channel Features (CCF), which achieves state-of-the-art performances.
We propose ELFISH, a resource-aware federated learning framework to tackle computation stragglers in Federated learning.
A weakly supervised learning approach to reduce the domain-shift between synthetic and real data for scene text segmentation task.
We first propose a strong pointer-copy mechanism based sequence-to-sequence sentence simplification model, and then improve its entailment and paraphrasing capabilities via multi-task learning. We also introduce a novel multi-armed bandit based training approach.
We propose the first model-parallel algorithm that speeds the training of Transformer-based language models with over a billion parameters.
We propose Pose Neural Fabrics Search (PNFS), introducing prior knowledge of body structure into NAS for human pose estimation, using differentiable search strategy.
Humans are able to master a variety of knowledge and skills with ongoing learning. When new tasks are added to an existing neural network, performance degradation is observed.
In this paper, we propose a framework for leaf instance segmentation by augmenting real plant datasets with generated synthetic images of plants inspired by domain randomisation.
Inspired by recent work in machine translation and object detection, we introduce an attention based model that automatically learns to describe the content of images.
We propose to compress deep CNNs by using channel-wise convolutions, which replace dense connections among feature maps with sparse ones in CNNs. We investigate the behavior of our proposed convolutional classification layer and conduct detailed analysis.
We compare several dictionary learning methods and feature encoding schemes through extensive experiments on KTH and HMDB51 datasets for video-based action classification.
We propose a novel active learning method that is simple but task-agnostic, and works efficiently with the deep networks.
We propose Redundancy-Disentangled Networks (RDNets), which decouples intra- and inter-redundancy such that all redundancy can be suppressed via previous network pruning schemes.
We present a lightweight strategy that only requires sparse inputs or even a single image to recover high-fidelity face shapes with images captured under near-field lights.
In this paper, we tackle the more realistic scenario where unexpected objects of unknown classes can appear at test time. We introduce a drastically different strategy: It relies on the intuition that the network will produce spurious labels in regions depicting unexpected objects.
In this paper, we tackle the problem of co-localization in real-world images, which are typically characterized by large amounts of intra-class variation, inter-class diversity, and annotation noise.
In this paper we present a novel framework for cross-age face verification (FV by seeking help from its “competitor” named cross-face age verification (AV), i.e., deciding whether two face photos are taken at similar ages.
A framework that takes the dynamics of runtime resources into account to enable resource-aware multi-tenant on-device deep learning for mobile vision systems.
The Low-Power Image Recognition Challenge (LPIRC, this https URL) is an annual competition that identifies the best technologies that can classify and detect objects in images efficiently (short execution time and low energy consumption) and accurately (high precision).
We propose a novel generative adversarial network utilizing weak supervision for image attribute editing.
This paper proposes a novel edge detection algorithm based on gray entropy theory and local texture features for adaptive edge detection.
This work introduces the Deep Hebbian Network (DHN), which combines the advantages of sparse coding, dimensionality reduction, and convolutional neural networks for learning features from images.
In this paper, we build an outfit evaluation system which provides feedbacks consisting of a judgment with a convincing explanation.
We prove the expressive power theorem for recurrent recurrent neural networks that correspond to the Hierarchical Tucker tensor decompositions.
We address interactive full image annotation, where the goal is to accurately segment all object and stuff regions in an image. We propose an interactive, scribble-based annotation framework which operates on the whole image to produce segmentations for all regions.
We investigate the performance of the landmark general CNN classifiers, which presented top-notch results on large scale classification datasets, on the fine-grained datasets, and compare it against state-of-the-art fine-Grained classifiers.
We propose a feature for action recognition called Trajectory-Set (TS) that encodes only trajectories around densely sampled interest points, without any appearance features.
We propose a method able to learn to jointly label objects and parts without requiring exhaustively labeled data.
The highest accuracy object detectors to date are based on a two-stage approach popularized by R-CNN, where a classifier is applied to a sparse set of candidate object locations. In contrast, one-stage detectors that are applied over a regular, dense sampling of possible object locations have the potential to be faster and simpler.
Search engines are the prevalently used tools to collect information about individuals on the Internet. The European Court of Justice recently ruled that EU citizens have a right to be forgotten in the sense that indexing systems, such as Google, must offer them technical means to request removal of links from search results that point to sources violating their data protection rights.
We investigate the effect of randomized smoothing on feasible hypotheses space, and show that for some noise levels the set of hypotheses which are feasible shrinks due to smoothing, giving one reason why the natural accuracy drops after smoothing.
In this paper, we study the problem of transfer learning with the attribute data. In the transfer learning problem, we want to leverage the data of the auxiliary and the target domains to build an effective model for the classification in the target domain.
We propose a novel pre-training strategy for learning object-agnostic visual features for more generalizable relationship models that capture shared but not object-specific visual patterns.
We propose a unified model SegVoxelNet to address the above two problems. A semantic context encoder is proposed to leverage the free-of-charge semantic segmentation masks in LiDAR.
We propose a novel end-to-end network that disentangles the task of facial editing into two steps: a "motion-editing" step and a "texture-edited" step, for a photo-realistic result.
We propose an efficient yet robust technique for on-the-fly dense reconstruction and semantic segmentation of 3D indoor scenes.
We propose a new algorithm, termed Low-Rank Sparse Subspace Clustering (LRSSC), by combining SSC and LRR, and develop theoretical guarantees of when the algorithm succeeds.
A pose invariant deeply learned multiview 3D face recognition approach for face alignment and face identification and verification.
A psychophysical experiment to record human fixations on line drawings of natural scenes with an eye-tracking system in this work.
We propose leveraging these data to improve deep anomaly detection by training anomaly detectors against an auxiliary dataset of outliers, an approach we call Outlier Exposure (OE), which improves detection performance.
We propose a novel 3D shape signature to explore the shape information from point clouds, which serves as soft constraint to improve the feature capability of multi-class discrimination.
A theoretical basis for the design of MRC based on psychology and psychometrics and summarizes it in terms of the requirements for explainable MRC.
TimeGate reduces the computation of existing CNNs on three benchmarks for long-range activities: Charades, Breakfast and MultiThumos.
We introduce a simple and effective network architecture for monocular 3D hand pose estimation consisting of an image encoder followed by a mesh convolutional decoder that is trained through a direct3D hand mesh reconstruction loss.
In this paper we convert the dense weight matrices of the fully-connected layers to the Tensor Train format such that the number of parameters is reduced by a huge factor and at the same time the expressive power of the layer is preserved.
We propose a more powerful trojaning attack method for both outsourced training attack and transfer learning attack, which outperforms existing studies in the capability, generality, and stealthiness.
We address the problem of robust identity recognition in the framework of multilinear models, in which bilinear separation outperforms other common approaches, allowing robust viewand action-invariant identity recognition.
We draw upon a previously largely untapped literature on human collective intelligence as a source of inspiration for improving deep learning.
In this paper, we propose a new method called ProfWeight for transferring information from a pre-trained deep neural network that has a high test accuracy to a simpler interpretable model or a shallow network of low complexity and a priori low test accuracy.
We propose a unified framework to compress the convolutional neural networks (CNNs) by combining low-rankness and sparsity, while taking the nonlinear activation into consideration.
We extend our preliminary work PointRCNN to a novel and strong point-cloud-based 3D object detection framework, the part-aware and aggregation neural network (Part-$A^2$ net)
We introduce switched linear projections for expressing the activity of a neuron in a deep neural network in terms of a single linear projection in the input space. With these projections we can decompose activity in any hidden layer into patterns detected in a given input instance.
We propose a novel technique for adversarial-image detection, RAID, that trains a secondary classifier to identify differences in neuron activation values between benign and adversarial inputs, which improves the state of the art when evaluated against six popular attacks.
Visible and infrared image fusion is one of the most important areas in image processing due to its numerous applications. While much progress has been made in recent years with efforts on developing fusion algorithms, there is a lack of code library and benchmark which can gauge the state-of-the-art.
We propose a self-supervised block that uses a pretext motion segmentation task to intertwine motion and appearance knowledge to capture spatio-temporal correlations between the two in a better way.
We provide a theoretical and empirical overview of interpretability and explanation methods for nonlinear Machine Learning and demonstrate successful usage of explainable AI in a sample of application scenarios.
We explore the ability of sparse coding to improve reconstructed image quality for the same degree of compression.
We present LEAR (Lexical Entailment Attract-Repel), a novel post-processing method that transforms any input word vector space to emphasise the asymmetric relation of lexical entailment, also known as the is-a or hyponymy-hypernymy relation.
In this paper, we propose a novel hashing method based on orthogonal projection of both image and semantic attribute, which constrains the generated binary codes in Orthogonal space should be orthogonomous with each other when they belong to different classes, otherwise be same.
We propose an Extreme Channel Prior embedded Network (ECPeNet) to plug the extreme channel priors into a network architecture for effective dynamic scene deblurring.
We propose an octree guided neural network architecture and spherical convolutional kernel for machine learning from arbitrary 3D point clouds.
In this technical report, we introduce FastFusionNet, an efficient variant of FusionNet, which achieves state-of-the-art results on DAWNBench and SQuAD.
We propose and study a general framework for regularized Markov decision processes (MDPs) where the goal is to find an optimal policy that maximizes the expected discounted total reward plus a policy regularization term.
We introduce the concept of multi-hop assortativity, that captures the similarity of the nodes situated at the extremities of a randomly selected path of a given length, and offer a versatile family of 'fingerprints' to characterize networks.
We investigate two crucial and closely related aspects of CNNs for optical flow estimation: models and training. We design a compact but effective CNN model, called PWC-Net, according to simple and well-established principles: pyramidal processing, warping, and cost volume processing.
We propose a Texture Deformation Based GAN to disentangle texture from original image and transfers domains based on the extracted texture.
We propose a Learning based Facial Image Compression (LFIC) framework with a novel Regionally Adaptive Pooling (RAP) module whose parameters can be automatically optimized according to gradient feedback from an integrated hybrid semantic fidelity metric.
We propose to represent image and text with two kinds of scene graphs, each of which is exploited to jointly characterize objects and relationships in the corresponding modality in a cross-modal way.
We propose a novel CNN architecture, wavelet CNNs, which combines a multiresolution analysis and CNNs into one model for image classification and object recognition.
We present PARIS, an approach for the automatic alignment of ontologies that is probabilistic.
In this work we aim to solve a large collection of tasks using a single reinforcement learning agent with a single set of parameters. We have developed a new distributed agent IMPALA that can scale to thousands of machines and achieve a throughput rate of 250,000 frames per second.
In this paper we address a classification problem that has not been considered before, namely motion segmentation given pairwise matches only.
The soaring demand for intelligent mobile applications calls for deploying powerful deep neural networks (DNNs) on mobile devices. However, the outstanding performance of DNNs notoriously relies on increasingly complex models, which in turn is associated with an increase in computational expense far surpassing mobile devices’ capacity.
We propose a fast and accurate approximation method for Singular Value Thresholding, that we call fast randomized SVT, with which we avoid direct computation of SVD at each iteration.
We quantify the generalization of a convolutional neural network (CNN) trained to identify cars. First, we perform a series of experiments to train the network using one image dataset and then test on a different image dataset.
We propose a unified deep neural network that exploits both semantic and spatial relations between labels with only image-level supervisions for improving multi-label image classification.
We propose a new semi-supervised learning method on face-related tasks based on Multi-Task Learning (MTL) and data distillation which exploits multiple datasets with different labels.
We show that the strategy of warping the multichannel dense feature image at each iteration is more beneficial than extracting features after Warping the intensity image.
We propose several novel optimization solutions for training a specific-structured (repetitively triple modules of Conv-BNReLU) extremely deep convolutional neural network (CNN) WITHOUT any shortcuts/ identity mappings.
We systematically explore zero-shot cross-lingual transfer learning on reading comprehension tasks with a language representation model pre-trained on multilingual corpus.
This paper proposes a simple yet effective self-supervised correction mechanism to learn all intrinsic structures of human poses from abundant images.
We present an alternative framework for comparing image classifiers, which we name the MAximum Discrepancy (MAD) competition, and we report the MAD competition results of eleven ImageNet classifiers.
We propose a novel loss function for learning image features which are both visually representative and geometrically relatable for image-retrieval-based localization.
We present a highly accurate single-image superresolution (SR) method using a very deep convolutional network inspired by VGG-net.
The goal of Sketch-Based Image Retrieval (SBIR) is using free-hand sketches to retrieve images of the same category from a natural image gallery. However, SBIR requires all categories to be seen during training, which cannot be guaranteed in real-world applications. So we investigate more challenging Zero-Shot SBIr, in which test categories do not appear in the training stage.
We propose Quantization-aware Knowledge Distillation (QKD) wherein quantization and KD are care-fully coordinated in three phases to achieve state-of-the-art performance.
We propose an embedding learning method called Delta Embedding Learning, to learn semantic information from high-level supervised tasks like reading comprehension, and combine it with an unsupervised word embedding.
ADL enlarges the distillation loss for hard-to-learn and hard- to-mimic samples and reduces distillation Loss for the dominant easy samples, enabling distillation to work on single-stage detector first time, even if the student and the teacher are identical.
We propose to understand the vulnerabilities of DRL from various perspectives and provide a thorough taxonomy of potential attacks. We conduct the first set of experiments on the unexplored parts within the taxonomy.
In this paper, we characterize long-range dependence with attentive normalization (AN), which is an extension to traditional instance normalization.
We propose a novel pooling scheme, dubbed SVM pooling, based on the notion that among the bag of features generated by a CNN on all temporal windows, there is at least one feature that characterizes the action.
We investigate the effects of initialization and architecture on the start of training in deep ReLU nets. We identify two failure modes for early training in which the mean and variance of activations are poorly behaved. We give a rigorous proof of when it occurs at initialization and how to avoid it.
We propose Deep Self-Semi-Supervised learning (D$S^3$L), a flexible multi-task framework with shared parameters that integrates the rotation task in Self-SL with the consistency-based methods in deep Semi-SL.
We propose a neural architecture search (NAS) algorithm, Petridish, to iteratively add shortcut connections to existing network layers.
Unsupervised domain adaptation aims to address the problem of classifying unlabeled samples from the target domain whilst labeled samples are only available from the source domain.
We present a novel technique to assess the confidence levels of interactions in PPI networks obtained from experimental studies. We use it for predicting new interactions and thus for guiding future biological experiments.
This paper combines recent deep convolutional neural network methods with image-into-image steganography to safely embed hidden information into cover images with payload capacity.
We propose a novel reasoning network called Adversarial Composition Modular Network (ACMN), capable of building an interpretable Visual Question Answering system that gradually dives the image cues following a question-driven reasoning route.
The problem of generalizing deep neural networks from multiple source domains to a target one is studied under two settings: When unlabeled target data is available, it is a multi-source unsupervised domain adaptation problem, otherwise a domain generalization (DG) problem. We propose a unified framework termed domain adaptive ensemble learning (DAEL) to address both problems.
We present PoliBox, a decentralized, edge-based framework for policy-based personal data analytics.
We propose a paradigm shifting CAD system that unifies eye-tracking data and a CAD system in realistic radiology room settings.
We propose a reinforcement learning framework, ReCo-RL, which captures the essence of these quality criteria and achieves better performance than state-of-the-art baselines.
We introduce TransF, a novel translation-based method which mitigates the burden of relation projection by explicitly modeling the basis subspaces of projection matrices, and is robust when facing a high number of relations.
This paper presents a robust face recognition method using color information with the following three-fold contributions.
In this work, we present a novel local descriptor for video sequences. The proposed descriptor is based on histograms of oriented 3D spatio-temporal gradients.
We use a well-known deep neural network framework, called Mask R-CNN, for identification of solar filaments in full-disk H-$\alpha$ images from Big Bear Solar Observatory (BBSO).
StyleGAN is a state-of-art generative adversarial network architecture that generates random 2D high-quality synthetic facial data samples. In this paper, we recap the StyleGAN architecture and training methodology and present our experiences of retraining it on alternative public datasets.
Renal angiomyolipoma is a kidney tumor in the perivascular epithelioid (PEComa) family that is common in patients with Tuberous Sclerosis Complex (TSC) and Lymphangioleiomyomatosis (LAM) but occurs rarely sporadically. We performed whole exome sequencing in 32 resected tumor samples from 15 subjects, including three with TSC.
An algorithm for modeling a set of unordered two-dimensional points by line segments by highly eccentric ellipses is presented.
We propose an approach that considers the internal color and saliency properties of the image. It changes the saliency map via an optimization framework that relies on patch-based manipulation.
We propose a new random pruning method (called"submodular sparsification (SS)") to reduce the cost of submodular maximization, while maintaining the quality of the original greedy algorithm.
This paper reports an exhaustive analysis of the discriminative power of the different regions of the human face on various forensic scenarios.
In this work, we propose a novel approach for generating videos of the six basic facial expressions given a neutral face image using manifold-valued Wasserstein generative adversarial networks.
We propose a feature-aware correlation filter for efficient visual tracking. We propose a novel pre-known expert-adaptive selection strategy.
We propose a novel data augmentation for labeled sentences called contextual augmentation. Words predicted according to a context are numerous but appropriate for the augmentation of the original words.
This study considers the 3D human pose estimation problem in a single RGB image by proposing a conditional random field (CRF) model over 2D poses, in which the3D pose is obtained as a byproduct of the inference process.
The problem of generating a diverse paraphrase sentences while (1) not compromising the original meaning of the original sentence, and (2) imposing diversity in various semantic aspects, such as a lexical or syntactic structure, is examined.
A translation domain segmentation (TDS) model based on improved cosine similarity is proposed to segment moving crowds with different crowding levels and complex motion modes.
In this paper, we propose a model for the Environment Sound Classification Task that consists of multiple feature channels given as input to a Deep Convolutional Neural Network (CNN) with Attention mechanism.
We propose an object detection system that depends on position-sensitive grid feature maps that activate the object’s specific locations in the feature maps in the form of grids.
This paper explores the use of extreme points in an object as input to obtain precise object segmentation for images and videos, also with less user input.
We propose an end-to-end learning framework for fully automatic segmentation of generic objects in both images and videos using a deep fully convolutional network.
Spatial-temporal relations among facial muscles carry crucial information about facial expressions yet have not been thoroughly exploited. We propose the Interval Temporal Bayesian Network to capture complex temporal relations among primitive facial events for facial expression modeling and recognition.
This work proposes a Fast Fourier Transform-based DNN training and inference model suitable for embedded platforms with reduced asymptotic complexity.
We investigate an alternative approach of synthesizing image classifiers: almost directly from a user's imagination, via freehand sketch.
We discuss the problem of echographic transcription in autoregressive sequence-to-sequence attentional architectures for automatic speech recognition, where a model produces very long sequences of repetitive outputs when presented with out-of-domain utterances.
In this paper, we propose a high performance image retrieval scheme based on descriptor fusion, which reduces information redundancy and boost image retrieval performance.
In this paper, we propose a novel cross-trees structure to perform the nonlocal cost aggregation strategy, and the cross-Trees structure consists of a horizontal-tree and a vertical-tree.
We propose classifier-agnostic saliency map extraction, which finds all parts of the image that any classifier could use, not just one given in advance.
We propose an approach for articulated tracking of multiple people in unconstrained videos that achieves state-of-the-art results while using only a fraction of time.
We present a generative framework for generalized zero-shot learning where the training and test classes are not necessarily disjoint.
We introduce a novel algorithm for the detection of possible sample corruption such as mislabeled samples in a training dataset given a small clean validation set via gradient descent based learning.
We propose a novel probabilistic model for visual question answering (Visual QA) that takes the semantic relationships (as characterized by the embeddings) among answers into consideration, instead of viewing them as independent ordinal numbers. We validate our approach on several Visual QA datasets.
We propose Deep Plastic Surgery, a novel, robust and controllable image editing framework that allows users to interactively edit images using hand-drawn sketch inputs without the need for real sketch training data.
We propose a region-partition based attraction field dual representation for line segment maps, and thus poses the problem of line segment detection (LSD) as the region coloring problem.
We propose a novel method to extract accurate masks from networks pre-trained for the task of object recognition from activations of higher-level convolutional layers of a network.
We develop Seatbelt-VAE, a new hierarchical disentangled VAE that is designed to be significantly more robust to adversarial attacks than existing approaches.
We compared the performances of different image feature sets on digital mammograms for characterizing the calcification mammography.
Convolutional neural networks are top-performers on image classification tasks. Understanding how they make use of color information in images may be useful for various tasks.
We propose a context encoder network to capture more high-level information and preserve spatial information for 2D medical image segmentation.
Fully Convolutional Network and Generative Adversarial Network for biometric recognition based on sclera.
We define layer-level training speed as the rotation rate of the layer's weight vector (denoted by layer rotation rate hereafter), and develop Layca, an optimization algorithm that enables direct control over it through each layer's learning rate parameter, without being affected by gradient propagation phenomena.
We focus on the problem of training a deep neural network in generations. The flowchart is that, in order to optimize the target network (student), another network (teacher) with the same architecture is first trained, and used to provide part of supervision signals.
We propose a temporal-action detection framework that can detect multiple actions in an end-to-end manner, based on a Bag of Discriminant Snippets.
Compressing the convolutional layers via randomly-shuffled tensor decomposition (RsTD) for standard classification task using CIFAR-10.
We propose a Deep Multi-task Transfer Network for cross domain person re-identification, which conduct classification, attribute attention and identification task between source and target domains.
We propose a principled deep Bayesian learning framework that combines these cues to produce natural questions. We observe that with the addition of more cues and by minimizing uncertainty among the cues, the Bayesian framework becomes more confident.
We introduce a new approach to generative data-driven dialogue systems (e.g. chatbots) called TransferTransfo which is a combination of a Transfer learning based training scheme and a high-capacity Transformer model for fine-tuning.
We present a method to generate a key for a protein interaction record and akey for each participant protein. We define records with identical keys as a redundant group.
OctDPSNet is a novel learning-based plane-sweeping stereo, which drastically reduces the required GPU memory and computation time while achieving a state-of-the-art depth estimation accuracy.
Generative models have achieved state-of-the-art performance for the zero-shot learning problem, but they require re-training the classifier every time a new object category is encountered. The traditional semantic embedding approaches, though very elegant, usually do not perform at par with their generative counterparts. In this work, we propose an unified framework termed GenClass, which combines the representative power of the generative approaches and the elegance of
Information bottleneck (IB) is a method for extracting information from one random variable $X$ that is relevant for predicting another random variable$Y$, and IB identifies an intermediate"bottleneck"variable $T$ that has low mutual information$I(X;T)$ and high mutual information $I(Y;T), and uses the IB Lagrangian to recover the IB curve.
We extend a previously developed `repulsion Laplacean' technique based on adding terms to the objective function with the goal or creation a repulsion energy between such images in the projected space in a supervised setting, using an image-as-matrix representation.
In this paper, we propose double sparse local Fisher discriminant analysis for face recognition.
A theoretical study on the role of Batch Normalization in binary training, backed up by numerical experiments.
We propose to inject corpus-level constraints for calibrating existing structured prediction models and design an algorithm based on Lagrangian relaxation for collective inference that decreases the magnitude of bias amplification.
This article used Convolutional Neural Networks (CNN) to classify scenes in the CIFAR-10 database, and detect emotions in the KDEF database.
Multi-view learning can provide self-supervision from adjacent sentences which are plentiful in large unlabelled corpora in an unsupervised fashion.
We study object recognition under the constraint that each object class is only represented by very few observations. We propose a generic framework that utilize unlabeled data to aid generalization for all three tasks.
We propose a multi-layer CRF framework that inherits the simplicity from pairwise CRFs by formulating both the higher-order and pairwise cues into the same pairwise potentials in the first layer.
We attempt to uncover what has made recent advances possible through a thorough analysis of how the objective function, the optimization method, and modern implementation practices influence accuracy.
We devise a learning algorithm for possibly nonsmooth deep neural networks featuring inertia and Newtonian directional intelligence only by means of a back-propagation-based oracle.
We propose a unified learning framework that leverages and aggregates the cross-modality contextual information, including (i) visual context from high-level image representation, and (ii) geometric context from 2D keypoint distribution.
We use a deformable vehicle shape prior learned from CAD vehicle data to fully reconstruct the vehicles in 3D and to recover their 3D pose and shape.
From an image of a person in action, we can guess the 3D motion of the person in the immediate past and future. We present a framework that can similarly learn a representation of 3D dynamics of humans from video via a simple but effective temporal encoding of image features.
In this paper, we introduce Random Path Generative Adversarial Network (RPGAN), an alternative design of GANs that can serve as a tool for generative model analysis.
We induce structure and geometric constraints by leveraging three core observations: (1) the surface of most everyday objects is often almost entirely exposed from pairs of typical opposite views; (2) everyday objects often exhibit global reflective symmetries which can be accurately predicted from single views; and (3) opposite orthographic views of a 3D shape share consistent silhouettes.
Recommender systems often rely on models which are trained to maximize accuracy in predicting user preferences. When the systems are deployed, these models determine the availability of content and information.
In this paper, an independent scale filter is proposed to estimate the scale of an object, and a local search strategy is used to expand the searching area of the tracker, which can effectively solve the problem caused by fast motion and occlusion.
We propose precision gating (PG), an end-to-end trainable dynamic dual-precision quantization technique for deep neural networks, which significantly reduces the computational cost of DNN execution.
This work was supported by King Abdullah University of Science and Technology as part of VCC center baseline funding.
We propose a large-scale, publicly available benchmark for object DetectIon in Optical Remote sensing images, which we name as DIOR.
We build and apply graphs to graph convolution networks with convolutional neural networks for visual hierarchical context-based reasoning.
We explore the impacts of annotation artifacts in cross-dataset testing. We propose a training framework to mitigate the impacts.
We propose a robust and generalizable CNN-based system for detecting and counting whales from space based on open data and tools.
We present an unsupervised method for learning a hierarchy of sparse feature detectors that are invariant to small shifts and distortions.
This paper aims to address these challenges by offering and leveraging the insight that a vector dot-product (the basic operation in DNNs) can be bit-partitioned into groups of spatially parallel low-bitwidth operations, and interleaved across multiple elements of the vectors.
We propose a novel Universal Non-volume Preserving approach to the problem of domain generalization in the context of deep learning.
In this paper, we propose an innovated contextualized attention-based deep neural network, SDNet, to fuse context into traditional MRC models.
We investigate the effectiveness of two-stage detectors in real-time generic detection and propose a lightweight two-Stage detector named ThunderNet.
We introduce a deep structured network for co-generating object proposals in multiple images, thus leveraging the collective power of multiple object candidates.
We revise the attention distribution to focus on the local and contextual semantic information by incorporating the relative position information between utterances. We introduce a hierarchical model based on self-attention to capture intra-sentence and inter-sentENCE information.
Quantum scheme based on quantum K Nearest-Neighbor algorithm for image classification.
In this paper, we propose TransCF to discover latent user-item relationships embodied in implicit feedback-based recommendations. Inspired by the translation mechanism popularized by knowledge graph embedding.
We introduce a pose refinement network (PoseRefiner) which takes as input both the image and a given pose estimate and learns to directly predict a refined pose by jointly reasoning about the input-output space.
We propose the MotionGAN which transforms an input face image into a new one according to a heatmap of target landmarks and use it to edit a facial image with arbitrary motions according to landmarks.
We propose a black-box optimization method with orthogonal directions (Ortho-MADS) for the selection of hyperparameters of Support Vector Machines with a Gaussian kernel that provides competitive convergence rate and a mechanism to escape from undesired local minima.
We propose an active learning approach for active adversarial domain adaptation and transfer learning when the source domain has many labeled examples while the target domain does.
The complex multi-stage architecture of cortical visual pathways provides the neural basis for efficient visual object recognition in humans. Here, we compared temporal (magnetoencephalography) and spatial (functional MRI) visual brain representations with representations in an artificial deep neural network tuned to the statistics of real-world visual recognition.
In the past decade, deep learning based visual object detection has received a significant amount of attention, but cases when heavy intra-class occlusions occur are not studied thoroughly. In this work, we propose a novel Non-MaximumSuppression (NMS) algorithm that dramatically improves the detection recall while maintaining high precision in scenes with heavy Occlusions.
We propose novel stochastic gradient algorithms for problems on Riemannian manifolds by adapting the row and column subspaces of gradients.
We propose a layered garment representation on top of SMPL and novelly make the skinning weight of garment to be independent with the body mesh, which significantly improves the expression ability of our garment model.
We study representations of sentences in one such artificial system for natural language processing. Our results reveal parallels to the analogous representations in people.
We use influence functions to measure the impact of every training sample on the validation set data. A k-nearest neighbor (k-NN) model fitted on the DNN activation layers is employed to search for the ranking of these supporting training samples.
We propose a novel gradient-guided network to exploit the discriminative information in gradients and update the template in the siamese network through feed-forward and backward operations.
We propose a novel method for building coherent 3D reconstructions of orchard rows using global features and semantic information to obtain an initial solution aligning the two side-views.
We propose a CNN-based unsupervised hashing method for image retrieval task in large scale.
Fast image search with efficient additive kernels and kernel locality-sensitive hashing with explicit feature maps .
We propose a Spatial Group-wise Enhance (SGE) module that can adjust the importance of each sub-feature by generating an attention factor for each spatial location in each semantic group, so that every individual group can autonomously enhance its learnt expression and suppress possible noise.
We propose a new convolutional neural network architecture to first estimate dense symmetric correspondences in a product image and then propose an optimization which utilizes this information explicitly to significantly improve the quality of single-view depth estimations.
This paper presents a comprehensive survey of the free-hand sketch oriented deep learning techniques.
In this paper, we extend the Maximum uncertainty Linear Discriminant Analysis (MLDA), proposed recently for limited sample size problems, to its kernel version, which performs as well as GDA and RKDA on face recognition.
We propose a policy gradient estimator that exploits the knowledge of actions being clipped to reduce the variance in estimation.
We propose a lightweight multi-task CNN for age and gender classification.
Reading Comprehension with Multiple Choice Questions task,required a human (or machine) to read a given passage, question pair and select the best one option from n given options using the given passage and question.
Dropout and other feature noising schemes have shown promise in controlling over-fitting by artificially corrupting the training data. This paper presents dropout training for both linear SVMs and the nonlinear extension with latent representation learning.
Type 2 diabetes: Different mitochondrial protein profile in skeletal muscleDiabetes alters the mitochondrial proteins in insulin-responsive tissues. A comparison of the mitochondrial proteomes identified 335 differentially expressed proteins (DEPs) between T2DM and nondiabetic samples.
We collect the subset of sentences that an (oracle) ensemble of state-of-the-art sentiment classifiers misclassify and then annotate them for 18 linguistic and paralinguistic phenomena, such as negation, sarcasm, modality, etc.
We propose an End-to-End BoWs (E$^2$BoWs) model based on Deep Convolutional Neural Network, which achieves promising accuracy and efficiency compared with recent deep learning based retrieval works.
We formulate an optimization problem to minimize the training time in pipelining communications and computations. We derive an optimal solution that can be solved efficiently without affecting the training performance.
In this paper, we propose to factorize the convolutional layer to reduce its computation.
We introduce the pedestrian alignment network (PAN) which improves the discriminative ability of the feature embeddings and yields competitive accuracy with state-of-the-art methods.
We investigate filter level sparsity that emerges in convolutional neural networks (CNNs) which employ Batch Normalization and ReLU activation, and are trained with adaptive gradient descent techniques.
We propose a symmetric cross entropy learning approach that addresses both under learning and overfitting problem of CE in the presence of noisy labels.
We use prior knowledge about the visual world as guidance to discover novel attributes from unlabeled faces and perform high-quality translation.
We propose a simple and flexible one-stage instance segmentation framework that can compete with Mask R-CNN in mask AP with single-model detectors.
We propose a novel algorithm for visual question answering based on a recurrent deep neural network, where every module in the network corresponds to a complete answering unit with attention mechanism by itself.
We use demonstrations to overcome the exploration problem and successfully learn to perform long-horizon robotics tasks with continuous control such as stacking blocks with a robot arm.
Learning your first language is an incredible feat and not easily duplicated. As an alternative we propose to use situated interactions between agents as a driving force for communication, and the framework of Deep Recurrent ::: Q-Networks for learning a common language grounded in the provided environment.
We propose a robust sparse reconstruction method for the face alignment problems that achieves better robustness over state-of-the-art methods.
We propose a novel deep convolutional neural network carefully designed for robustness and efficiency at both learning and testing. By trading runtime and using internal priors we achieve 0.1 up to 0.3dB PSNR improvements over standard datasets.
We make theoretical contributions to disentanglement learning by (a) defining precise semantics of disentangled representations, and (b) establishing robust metrics for evaluation.
In this paper, we present a Cross-media Body-part Attention Network (CBAN) for image-to-video person re-id, which can extract the cross-media body part attention features from images/videos (by CNN/LSTM), and simultaneously ignore the useless information in the background by using a part attention mechanism.
We propose to effectively generate test cases that activate parameters as many as possible and propagate their perturbations to outputs for functional validation.
We propose a new deep detection network that can simultaneously detect the size and location of human heads and count them in crowds.
We propose an extractive question answering (QA) formulation of pronoun resolution task that overcomes this limitation and shows much lower gender bias (0.99) on their dataset.
We propose a novel method, named Curriculum Model Adaptation (CMAda), which gradually adapts a semantic segmentation model from light synthetic fog to dense real fog in multiple steps, using both synthetic and real foggy data.
We propose a graph-based evidence aggregating and reasoning (GEAR) framework which enables information to transfer on a fully-connected evidence graph and then utilizes different aggregators to collect multi-evidence information.
We present a novel retinal image denoising approach which is able to preserve the details of retinal vessels while effectively eliminating image noise.
We present a variational denoising recursive autoencoder that generates and iteratively refines a hierarchical representation of 3D object layouts, interleaving bottom-up encoding for context aggregation and top-down decoding for propagation.
We explore the benefits of using a man- ifold network structure for covariance pooling to improve facial expression recognition.
We develop a theoretical model for camera pose regression and use it to predict failure cases for pose regression techniques and verify our predictions through experiments.
We introduce Title-Guided Network (TG-Net) for automatic keyphrase generation task based on the encoderdecoder architecture with two new features: (i) the title is additionally employed as a query-like input, and (ii) a titleguided encoder gathers the relevant information from the title to each word in the document.
We propose a novel online motion Auto-Encoder (online motion-AE) framework that functions on the super-segmented object motion clips.
The growing amount of data available in modern-day datasets makes the need to efficiently search and retrieve information. We investigate whether binary or n-ary coding works better under different retrieval strategies.
We propose a driver behavior recognition method based on human parsing which can quickly and accurately recognize the driver’s unsafe behavior.
We propose Scale-Clip, a Distribution Reshaping Quantization technique that can reshape weights or activations into a uniform-like distribution in a dynamic manner. Furthermore, to increase the model capability for a low-bit model, a novel Group-based Quantization algorithm is proposed.
We propose a novel pedestrian scanning method based on orientation aware pedestrian likelihood estimation using the orientation-wise pedestrian’s shape models with local distribution of measured points.
We propose a new approach, PhaseNet, that is designed to robustly handle challenging scenarios while also coping with larger motion.
A complete scheme for the ego-motion estimation in monocular vision systems using sparse SURF flow with multilayer bucketing screener.
We introduce a novel strategy for learning semantically meaningful features from aerial imagery. Instead of manually labeling the aerial imagery, we propose to predict (noisy) semantic features automatically extracted from co-located ground imagery.
This paper addresses the construction of a short-vector (128D) image representation for large-scale image and particular object retrieval using multiple vocabularies.
We present a sampling approach for estimating the statistics of larger graph pattern occurrences in a graph database.
We propose a novel semantic neural tree for human parsing, which uses a tree architecture to encode physiological structure of human body, and designs a coarse to fine process in a cascade manner to generate accurate results.
We propose a network for extracting semantic information of video sequences based on the deep fusion feature of local spatial–temporal information for action recognition.
We propose a novel 1D Convolutional Neural Network (CNN) for speech, music and noise classification/segmentation which is fast and lightweight.
We propose an adversarial defense method that achieves state-of-the-art performance while also maintaining robustness to input resolution, scale of adversarial perturbation, and scale of dataset size in various adversarial settings.
We propose a novel instance-merging based method to extract influence aspects and learn aspect-level influence strength.
We propose an extension to the Sitemaps protocol which provides a simple and effective solution for efficient discovery and high-performance retrieval by clients and search engines.
We revisit the paradigm of pre-training on large supervised datasets and fine-tuning the weights on the target task and achieve strong performance on over 20 datasets.
We present a novel approach for video parsing and simultaneous online learning of dominant and anomalous behaviors in surveillance videos in Surveillance videos.
We compare two popular methods for dense alignment-subject-dependent active appearance models versus subject-independent CLMs-on the task of action-unit detection.
In this paper, we consider the role of convolution filters in detecting energy modulation patterns of environmental sounds and propose a channel attention mechanism to focus on the semantically relevant channels generated by corresponding filters.
This notebook paper presents an overview and comparative analysis of our systems designed for the following five tasks in ActivityNet Challenge 2018: temporal action proposals, temporal action localization, dense-captioning events in videos, trimmed action recognition, and spatio-temporal action localization.
Residual Network (ResNet) is the state-of-the-art architecture that realizes successful training of really deep neural network. In this paper, simplified models of ResNets are analyzed.
We present a novel method for accurate and efficient upsampling of sparse depth data, guided by high-resolution imagery, using structured edge detection and semantic scene labeling.
SpiderCNN extends convolutional operations from regular grids to irregular point sets that can be embedded in \(\mathbb {R}^n\) point clouds.
We propose an adaptive convolutional filter generation framework for natural language understanding.
We propose a novel approach for image segmentation that combines Neural Ordinary Differential Equations (NODEs) and the Level Set method for improved initial contour embedding functions.
We propose a new analytical approximation to the $\chi^2$ kernel that converges geometrically.
We address the problem of text-based activity retrieval in video using a multilevel model that integrates vision and language features earlier and more tightly than prior work.
In this paper, an efficient stereo matching algorithm is implemented on a state-of-the-art GPU to achieve highly accurate disparity maps in real time for autonomous vehicle applications.
Exploring spatial-temporal information in video sequences for video-based person re-identification .
We present a unified framework for learning continuous control policies using backpropagation. We use learned models but only require observations from the environment in- stead of observations from model-predicted trajectories.
We evaluate its impact on the recognition rate using a shallow modular architecture, adopting both standard filter banks and filter banks learned in an unsupervised way.
We propose a novel label distribution approach named part-based gradation regularization (PGR) for pedestrian retrieval in sensor networks.
In this paper, we demonstrate a novel algorithm that uses ellipse fitting to estimate the bounding box rotation angle and size with the segmentation(mask) on the target for online and real-time visual object tracking.
We study the state-of-the-art of RGB-D SLAM for indoor robot navigation.
In this paper, we propose a unified panoptic segmentation network (UPSNet) which solves these two subtasks simultaneously and achieves state-of-the-art performance.
We introduce full-Jacobians, which describe the normal to affine planes, and use them for distillation, generalization, and saliency maps.
We propose a global filter pruning algorithm called Gate Decorator, which transforms a vanilla CNN module by multiplying its output by the channel-wise scaling factors (i.e. gate).
Social exclusion is a painful experience that is felt as a threat to the human need to belong and can lead to increased aggressive and anti-social behaviours, and results in emotional and cognitive numbness.
PISA aggregates multiple saliency cues in a global context, such as complementary color and structure contrast measures, with their spatial priors in the image domain in a unified framework.
We propose MagnifierNet, a novel network which accurately mines details for each semantic region and selectively fuse all semantic feature representations for person re-identification.
We propose a progressive unsupervised learning (PUL) method to transfer pretrained deep representations to unseen domains to improve the re-identification accuracy.
In this paper, we propose a multi-task network base on an improved Res2Net model that simultaneously computes identification loss and verification loss of two pedestrian images.
We explore the benefits of generalizing one step further into the hyper-complex numbers, quaternions specifically, and provide the architecture components needed to build deep quaternion networks.The field of deep learning has seen significant advancement in recent years.
This paper tackles the problem of video object segmentation, given some user annotation which indicates the object of interest. The problem is formulated as pixel-wise retrieval in a learned embedding space.
We present some updates to YOLO! We made a bunch of little design changes to make it better. We also trained this new network that's pretty swell.
This paper proposes a probabilistic ordinal link function model for ordinal regression, which improves the results of a nominal model and outperforms other proposals in the literature.
A novel cross-network deep network embedding (CDNE) model that learns label-discriminative and network-invariant node vector representations.
We propose a weakly-supervised regularization for few-shot learning models with compositionality, which provides substantial improvements over state-of-the-art methods.
We propose a method which leverages the existing labeled data for events by simulating events from a pair of temporal image frames, using a convolutional neural network, using an adversarial discriminator loss, and a cycle consistency loss.
In this paper, we propose a novel approach for enforcing the Lipschitz continuity in the training procedure of WGANs, a generative adversarial net.
Deep learning (DL), a subset of machine learning approaches, has emerged as a versatile tool to assimilate large amounts of heterogeneous data and provide reliable predictions of complex and uncertain phenomena.
We show state-of-the-art word representation learning methods maximize an objective function that is a lower bound on the mutual information between different parts of a word sequence (i.e., a sentence) and introduce a principled framework that can be used to construct new self-supervised tasks.
We propose replacing the fully-connected CRF with domain transform (DT), a modern edge-preserving filtering method in which the amount of smoothing is controlled by a reference edge map.
We propose a new method to estimate piecewise affine motion fields directly without intermediate segmentation and derive a specific proximal splitting optimization scheme.
We propose a video prediction network based on multi-level wavelet analysis to deal with spatial and temporal information in a unified manner, which improves fidelity and temporal consistency.
Star-census transform, a stereo matching algorithm, which compares the brightness of pixels separated by a certain distance along a symmetrical pattern within the matching window.
CNN-WTADP is a deep-learning-based stereo matching algorithm based on convolutional neural network WTADP for stereo matching.
 Probabilistic deep learning models combine the expressive power of deep learning with uncertainty quantification to achieve robustness against challenging imaging conditions.
We propose a novel regularizer to improve the training of Generative Adversarial Networks (GANs), by encouraging the binary activation patterns on selected internal layers of D to have a high joint entropy.
In this paper, we demonstrate how automatic grasp selection can be achieved by placing a camera in the palm of a prosthetic hand and training a convolutional neural network on images with corresponding grasp labels.
In this paper, we propose a novel methodcalled STD-Net to reconstruct the 3D models utilizing the mesh representationthat is well suitable for characterizing complex structure and geometry details.
We present a novel, end-to-end learnable, multiview 3D point cloud registration algorithm for joint learning of both parts of this two-stage problem.
Random Forest (RF) is a successful paradigm for learning classifiers due to its ability to learn from large feature spaces and seamlessly integrate multi-class classification, as well as the achieved accuracy and processing efficiency. However, as many other classifiers, RF requires domain adaptation (DA) provided that there is a mismatch between the training (source) and testing (target) domains which provokes classification degradation.
This paper describes an effective and efficient image classification framework based on a hierarchical distributed deep representation learning model (DDRL).
This paper reports a novel deep architecture referred to as Maxout network In Network (MIN), which can enhance model discriminability and facilitate the process of information abstraction within the receptive field.
This notebook paper presents our model in the VATEX video captioning challenge.
We introduce a novel Supervised Spatial Divide-and-Conquer Network (SS-DCNet) that transforms open-set counting into a closed-set problem.
Robust and accurate visual tracking is one of the most challenging computer vision problems. In order to reduce the computational complexity by creating a novel method to enhance tracking ability, we first introduce an adaptive dimensionality reduction technique to extract the features from the image, based on pre-trained VGG-Net.
We consider the image retrieval problem of finding the images in a dataset that are most similar to a query image. We adopt a group testing formulation and design the decoding architecture using either dictionary learning or eigendecomposition.
We introduce the graph convolutional networks (GCN) into the object detection, and propose a new framework called OD-GCN (object detection with graph convolutionsal network). It utilizes the category relationship to improve the detection precision.
The task of a neural associative memory is to retrieve a set of previously memorized patterns from their noisy versions using a network of neurons. In this paper, we show that if we target memorizing only those patterns that have inherent redundancy, we can obtain all the aforementioned properties.
We propose a loss function that can be used in any fully convolutional network (FCN) to estimate object locations without bounding boxes.
We address this conflict with a general and novel training scheme called model slicing, which enables deep learning models to provide predictions within prescribed computational resource budget dynamically.
Audio-visual learning, aimed at exploiting the relationship between audio and visual modalities, has drawn considerable attention since deep learning started to be used successfully.
We propose a Gaussian-based softmax function that can effectively improve intraclass compactness and interclass separability of features learned by convolutional networks and improve state-of-the-art models across all evaluated data sets.
We formulate our weakly supervised tracklets Re-ID model based on Weakly Supervised Tracklets(WST) data from various camera views, which can be inexpensively acquired by combining the fragmented tracklets of the same person in the same camera view over a period of time.
We present a fully-automatic statistical 3D shape modeling approach and apply it to a large dataset of 3D images, the Headspace dataset, thus generating the first public shape-and-texture 3D morphable model of the full human head.
We propose an effective method for query-based object localization, which uses artificial intelligence techniques to automatically locate queried object in complex backgrounds.
We present ConvLab-2, an open-source toolkit that enables researchers to build task-oriented dialogue systems with state-of-the-art models, perform an end-to-end evaluation, and diagnose the weakness of systems.
A novel top-push constrained feature learning (TFL) method for face identification.
We identified a novel VCP mutation segregating in an autosomal dominant Charcot-Marie-Tooth disease type 2 family that impaired autophagic function leading to the accumulation of immature autophagosomes.
In this paper we propose to jointly optimize the scene depth and camera motion via incorporating differentiable Bundle Adjustment layer by minimizing the feature-metric error, and then form the photometric consistency loss with view synthesis as the final supervisory signal.
In this paper we investigate the performance of different types of rectified activation functions in convolutional neural network: standard rectified linear unit (ReLU), leaky rectifiedlinear unit (Leaky ReLU), parametric rectified Linear unit (PReLU) and a new randomized leaky Rectified linear units (RReLU).
A challenge in creating a dataset for machine reading comprehension (MRC) is to collect questions that require a sophisticated understanding of language to answer beyond using superficial cues. In this work, we investigate what makes questions easier across recent 12 MRC datasets with three question styles (answer extraction, description, and multiple choice) and investigate the difference between easy and hard subsets.
In this paper, we make adaptations on the metrics to better correlate n-gram overlap with the human judgment for answers to questions inquiring yes-no opinions and entity lists.
In this paper, we address the problem of applying the updated optimal control in real-time on the physical robot.
We propose a novel discriminative sparse neighbor approximation (DSNA) method to ameliorate the effect of class-imbalance during prediction.
We use the stacked hourglass design and inception-resnet module to construct a fractal network to regress human pose images into heatmaps with no explicit graphical modeling. We encode external knowledge with visual features.
This paper addresses this issue using a bi-directional pixel long-short time memory (LSTM) network, which can simultaneously scan the input image row by row or column by column.
We present a general framework for distilling both regression and classification ensembles in a way that preserves the decomposition of the ensemble, improving their predictive performance.
This paper proposes a self-supervised low light image enhancement method based on deep learning.
We propose Adversarial Inverse Graphics networks (AIGNs), weakly supervised neural network models that combine feedback from rendering their predictions, with distribution matching between their predictions and a collection of ground-truth factors.
We present a unified learning framework for recovering both 3D mesh and camera pose of the object from a single image.
We explore a method for reconstructing visual stimuli from brain activity. Using large databases of natural images we trained a deep convolutional generative adversarial network capable of generating gray scale photos.
auDeep is a Python toolkit for deep unsupervised representation learning from acoustic data.
We propose a Decentralized MF (DMF) framework for POI recommendation, which significantly improves the recommendation performance in terms of precision and recall.
GCN-LSTM integrates Graph Convolutional Networks plus Long Short-Term Memory for image captioning.
In this paper, we provide a modern synthesis of the classic inverse compositional algorithm and replace multiple components of this algorithm using more expressive models whose parameters we train in an end-to-end fashion from data.
We propose a minimum spanning tree based stereo matching method by using the image edge and segmentation optimization to preserve the image boundary, which is able to significantly improve the accuracy of MST aggregating.
In this paper we consider the task of recognizing human actions in realistic video where human actions are dominated by irrelevant factors. We then learn a non-action classifier and use it to down-weight irrelevant video segments.
This paper proposes a pairwise-coupled reformulation of LBP-type classificatio n which involves selecting single-point features for each pair of classes ac ross multiple scales to form compact, contextually-relevant multiscale predicates known as Multiscale Selected Local Binary Features.
We investigate the use of Approximate Convex Decompositions (ACD) as a self-supervisory signal for label-efficient learning of point cloud representations.
In this paper, we introduce Channel-wise recurrent convolutional neural networks (RecNets), a family of novel, compact neural network architectures for computer vision tasks inspired by recurrent neural networks.
A fusion algorithm based on improved emotional profiles (IEPs) and maximum confidence is proposed to recognize emotions with these real-time facial expression features.
Neural networks with tree-based sentence encoders have shown better results on many downstream tasks. To study the effectiveness of different tree structures, we replace the parsing trees with trivial trees that contain no syntactic information.
In this paper, we propose the point projection feature, which is invariant to the rotation of the input point cloud, for point cloud recognition and segmentation.
We present an unsupervised algorithm to generate optical flow ground truth from real-world videos, using either ground truth or predicted segmentation.
We introduce type 2 fuzzy rough sets to develop a Type 2 Fuzzy Rough Convolutional Neural Network, as type 2 fuzzy rough sets form a suitable mathematical tool to characterize uncertainty of classifification.
Circular statistics-based Inter-Microphone Phase difference estimation Localizer for binaural hearing aid systems with microphone arrays in each unit.
Logical connectives and their implications on the meaning of a natural language sentence are a fundamental aspect of understanding. In this paper, we investigate visual question answering through the lens of logical transformation and posit that systems that seek to answer questions about images must be robust to these transformations of the question.
A Bayesian approach to source separation that uses generative models as priors over the components of a mixture of sources, and Langevin dynamics to sample from the posterior distribution of sources given a mixture.
In this paper, we propose D eeply S upervised O bject D etectors (DSOD), an object detection framework that can be trained from scratch.
Dynamic Stale Synchronous Parallel (DSSP) adaptively adjusts the staleness threshold per iteration at running time to reduce the waiting time of faster workers for synchronization of the globally shared parameters, and consequently increases the frequency of parameters updates.
We study the robustness of a given in-painting neural network against variations in hole geometry distributions, even if the underlying image dataset used (in training and testing) does not alter.
We propose a superpixel-based hierarchical approach for image segmentation that works by iteratively merging nodes of a weighted undirected graph initialized with the superpixels regions.
We employ a polarised LWIR camera to acquire data from a mobile vehicle, to compare and contrast four different convolutional neural network configurations to detect other vehicles in video sequences.
In this paper, a novel island loss is proposed to enhance the discriminative power of the deeply learned features for facial expression recognition.
We propose a novel sample mining method, called Online Soft Mining (OSM), which assigns one continuous score to each sample to make use of all samples in a mini-batch.
We propose a new learning criterion for the reading comprehension task which combines the merits of both MLE and RL-based methods and achieves consistently improved results.
Using vanilla domain adaptation strategies to fine-tune a face recognition CNN on domain-specific doc-selfie data improves the performance of the model on such data, but, in the presence of imbalanced training data, also significantly increases the demographic bias.
The EMNLP 2018 workshop BlackboxNLP was dedicated to resources and techniques specifically developed for analyzing and understanding the inner-workings and representations acquired by neural models of language.
Facial actions are spatio-temporal signals by nature, and therefore their modeling is crucially dependent on the availability of temporal information. We present a novel approach to capture multiple scales of temporal dynamics, with an application to facial Action Unit intensity estimation and dimensional affect estimation.
CMAT is a multi-agent policy gradient method that frames objects into cooperative agents, and then directly maximizes a graph-level metric as the reward by fixing the predictions of other agents.
This paper presents an object detection method that can simultaneously estimate the positions and depth of the objects from multiplexed images from a CNN-based detector.
We propose a deep learning architecture that achieves discrete $\mathbf{SO}(2)$/$\mathbf(3)$ rotation equivariance for point cloud recognition with state-of-the-art results.
We present a novel intrinsically motivated agent that learns how to control the environment in a sample efficient manner, that is with as few environment interactions as possible, by optimizing learning progress.
We propose SpineNet, a backbone with scale-permuted intermediate features and cross-scale connections that is learned on an object detection task by Neural Architecture Search, achieving state-of-the-art performance of one-stage object detector.
We propose the use of discrete cosine transform (DCT) to compress word sequences in an order-preserving manner, which results in suitable embeddings for syntactic features.
We propose a novel video database, the “Action Similarity LAbeliNg” (ASLAN) database, along with benchmark protocols for action recognition.
In this paper, we present a technique for unsupervised learning of visual representations, in the process of which it learns visual representations.
We introduce a novel relative entropy reinforcement learning algorithm that gives the agent the freedom to control the intermediate task distribution, allowing for its gradual progression towards the target context distribution, improving sample efficiency and generalization.
FABIR achieves competitive results in the Stanford Question Answering Dataset while having fewer parameters and being faster at both learning and inference than rival methods.
A collection of computer vision applications reuse pre-learned features to analyse video frame-by-frame. Those features are classically learned by Convolutional Neural Networks trained on high quality images. However, available video content is almost always subject to compression which is nearly never considered during the analysis process. In this paper, we present an empirical study to measure how the visual discrepancy of compressed data limit the learning performance of the CNN model.
We present a densely annotated dataset ADE20K, which spans diverse annotations of scenes, objects, parts of objects, and in some cases even parts of parts. We provide baseline performances on both of benchmarks and re-implement state-of-the-art models for open source.
We proposed a novel trust-based method called AgreeRelTrust. Unlike accuracy-based methods, this method does not require the calculation of initial prediction and the trust relationship is more meaningful.
In this work, we define and address"Boundless Unsupervised Domain Adaptation"(BUDA), a novel problem in semantic segmentation.
We improve upon the previous state of the art on LAMBADA on hard entity tracking cases with two extensions: (1) additional features, and (2) training with a multi-task tracking objective.
Comparing first and higher-order optimization functions, in this paper, our experiments reveal that Levemberg-Marquardt (LM) significantly supersedes optimal convergence but suffers from very large processing time increasing the training complexity of both, classification and reinforcement learning problems.
Sentence representations can capture a wide range of information that cannot be captured by local features based on character or word N-grams. This paper examines the usefulness of universal sentence representations for evaluating the quality of machine translation.
We propose an adversarialNAS method specially tailored for Generative Adversarial Networks to search for a superior generative model on the task of unconditional image generation.
In this work we contribute a novel pipeline to automatically generate training data, and to improve over state-of-the-art multi-object tracking and segmentation (MOTS) methods.
We used the spectrogram images of environmental sounds to train the convolutional neural network (CNN) and the tensor deep stacking network (TDSN) for sound classification systems.
We present novel data-driven adversarial attacks against 3D point cloud networks. These attacks lead to perturbations that are resilient against current defenses while remaining highly transferable compared to state-of-the-art attacks.
A computational approach to the prediction of potential drug interactions through similarity-based in-silico computational DDI prediction.
We propose to detect abnormal events via a sparse reconstruction over the normal bases and extend it to online abnormal event detection.
We present region-based, fully convolutional networks for accurate and efficient object detection.
We propose a multi-scale multi-channel deep neural network framework that, for the first time, yields sketch recognition performance surpassing that of humans.
We produce a large number of potential spatial features using two combinations of facial landmarks. Among these, we search for a descriptive subset of features using sequential forward selection. The chosen feature subset is used to classify facial expressions.
We propose an intuitive workflow for the integrative analysis of expression, mutation and copy number data taken from the METABRIC study on breast cancer.
We develop an Identity-preserving Face Recovery from Portraits method that utilizes a Style Removal network (SRN) and a Discriminative Network (DN) and achieve state-of-the-art results.
We propose a generalized large-margin softmax (L-Softmax) loss which explicitly encourages discriminative learning of features.
We present a simple yet effective method that tackles these limitations without training on any pre-defined styles and generate high-quality stylized images.
We view the faces and the latent classes as the latent Dirichlet allocation model for robust cascaded pose regression, which can significantly reduce time cost on landmark localization without dropping accuracy.
We present a task-aware approach to synthetic data generation. The synthesizer and target networks are trained in an adversarial manner wherein each network is updated with a goal to outdo the other.
We use CCA (canonical correlation analysis) to study the learned representations of the different models, finding that pretrained models are surprisingly similar to random initialization at higher layers.
Multiregion Bilinear CNN for person re-identification problem .
In this paper, we introduce an auxiliary natural language processing system for the text modality, and incorporate co-training to reduce noise and augment signal in distant supervision.
We explore the role of supervoxels in unsupervised video object segmentation and devise a method called supervoxel gerrymandering that links masks of foregroundness and backgroundness.
This paper presents a novel method to manipulate the visual appearance (pose and attribute) of a person image according to natural language descriptions.
We explore learning-based approaches for feedback control of a dexterous five-finger hand performing non-prehensile manipulation.
In this paper we propose a technique for obtaining coarse pose estimation of humans in an image that does not require any manual supervision.
We propose an approach based on Convolutional Neural Networks (CNNs) supplemented with the most recent techniques adopted from the deep learning community.
We improve video captioning by sharing knowledge with two related directed-generation tasks: a temporally-directed unsupervised video predictiontask to learn richer context-aware video encoder representations, and a logically-directed language entailment generation task to learn better video-entailed caption decoder representations.
We propose a neural network architecture to solve both object detection in and semantic segmentation of camera images.
We focus on the time-consuming training process of large-scale CNNs and propose a Bi-layered Parallel Training (BPT-CNN) architecture that effectively improves the training performance of CNNs while maintaining the accuracy.
We present a simple and effective image super-resolution algorithm that imposes an image formation constraint on the deep neural networks via pixel substitution.
In this paper, we analyze object detection from videos and point out that AP alone is not sufficient to capture the temporal nature of video object detection. We propose a comprehensive metric, average delay (AD), to measure and compare detection delay.
We propose a weakly-supervised approach for conditional image generation of complex scenes where a user has fine control over objects appearing in the scene.
We propose a bidirectional trajectory computation method, by which the poses before the first turning are refined in the backward computation thread, and the real-time trajectory is adjusted accordingly.
We propose a deep Variation-structured Reinforcement Learning (VRL) framework to sequentially discover object relationships and attributes in the whole image.
The neural architecture search (NAS) algorithm with reinforcement learning can be a powerful and novel framework for the automatic discovering process of neural architectures. To resolve these problems, we proposed NAS in embedding space (NASES), which is a novel framework.
A novel detection method that uses Shapley Additive Explanations (SHAP) values computed for the internal layers of a DNN classifier to discriminate between normal and adversarial inputs.
We propose an improved language representation model, Semantics-aware BERT (SemBERT), capable of explicitly absorbing contextual semantics over a BERT backbone.
We explore the application of graph neural networks for music genre classification on spectrograms.
We develop a robust multi-scale structure-aware neural network for human pose estimation that can effectively localize occluded keypoints.
In this paper we propose to model uncertainty using intervals, further leading to the generation of so-called interval-valued images.
We propose a mixed objective that combines cross entropy loss with self-critical policy learning to improve model performance across question types and input lengths.
We propose an instance-based method to find similar questions of a new question, in the sense of their relations, to predict its mentioned relation.
In this work, we propose a novel decoding algorithm -- InDIGO -- which supports flexible sequence generation in arbitrary orders through insertion operations.
This paper attempts at finding the relationship between Fully Connected (FC) layers with some of the characteristics of the datasets.
We propose a smart-food logging system, FoodAI, which offers state-of-the-art deep learning based image recognition capabilities. FoodAI has made food logging convenient, aiding smart consumption and a healthy lifestyle.
We present a ranking based approach, and implement both carefully designed features and neural network architectures to measure the relevance between a query and the content of a table.
We propose a fusion network for static and continuous facial expression recognition in the wild and evaluate the recognition results.
We present RE$^3$QA, a unified question answering model that combines context retrieving, reading comprehension, and answer reranking to predict the final answer.
In this paper, we introduce the problem of estimating the real world depth of elements in a scene captured by two cameras with different field of views, while leveraging the stereo information in the overlapping FOV, as Tele-Wide Stereo Matching (TW-SM)
We present an approach to accurately estimate high fidelity markerless 3D pose and volumetric reconstruction of human performance using only a small set of camera views ($\sim 2$)
The advancement of visual sensing has introduced better capturing of the discrete information from a complex, crowded scene for assisting in the analysis. The proposed system contributes to developing a novel region-wise repository to extract contextual information about the discrete-event for a given scene.
We address the problem of 3D object detection from 2D monocular images in autonomous driving scenarios. We propose to lift the 2D images to 3D representations using learned neural networks and leverage existing networks working directly on 3D data.
We propose a new feature-based, model-free, object-aware dynamic SLAM algorithm that exploits semantic segmentation to allow estimation of motion of rigid objects in a scene without the need to estimate the object poses or have any prior knowledge of their 3D models.
We propose the angular softmax (A-Softmax) loss that enables convolutional neural networks (CNNs) to learn angularly discriminative features under open-set protocol.
In this paper, we develop a new training framework for learning a smooth policy that behaves smoothly with respect to states in reinforcement learning algorithms.
We present an evaluation server, ORB, that reports performance on seven diverse reading comprehension datasets, encouraging and facilitating testing a single model's capability in understanding a wide variety of reading phenomena.
This paper introduces a new simple reputation model that aggregates ratings based on the concept of moving window. The window size can be defined by either number of ratings or duration.
We propose a novel self-paced knowledge distillation framework, termed Learning From Multiple Experts (LFME), which aggregates the knowledge from multiple `Experts' to learn a unified student model.
We observe that most existing proxies exhibit different behaviors in maintaining the rank consistency among network candidates. Inspired by these observations, we present a reliable proxy and further formulate a hierarchical proxy strategy.
In this paper, we develop and present a system, called Rafiki, to provide the training and inference service of machine learning models, and facilitate complex analytics on top of cloud platforms.
This paper proposes an approach for rapid bounding box annotation for object detection datasets collected from indoor scenes.
We'd like to share a tweak of Single Shot Multibox Detector (SSD) family of detectors, which is effective in reducing model size while maintaining the same quality.
Our cascaded classification framework accurately models 3D scenes by iteratively refining semantic segmentation masks, stereo correspondences, 3D rigid motion estimates, and optical flow fields for state-of-the-art performance.
We propose a novel cascaded regression-based method for automatic facial landmark localization in 3D face data designed specifically to address appearance variability caused by significant pose variations.
In this paper, we propose a novel adaptive label regularization method, which enables the neural network to learn the erroneous experience and update the optimal label representation online.
We study multi-turn response generation for open-domain dialogues using auxiliary tasks that leverage conversation contexts for response generation.
We develop a new class of models that can predict human brain activity in high-level visual areas, directly from pixels and without the need for any semantic tags or hand annotation of images.
We propose a unified approach for bottom-up hierarchical image segmentation and object proposal generation for recognition, called Multiscale Combinatorial Grouping.
We propose a novel read-then-verify system, which not only utilizes a neural reader to extract candidate answers and produce no-answer probabilities, but also leverages an answer verifier to decide whether the predicted answer is entailed by the input snippets.
We propose several text generative neural networks for constructing Natural Language Inference datasets suitable for training classifiers. The model learns a mapping embedding for each training example.
We propose a unified framework for referring expression comprehension and generation that achieves state-of-the-art results on three referring expression datasets.
We present SCGAN, an architecture to generate images with a desired shape specified by an input normal map. The network is trained using unpaired training samples of real images.
We propose a novel Siamese network based visual tracking method, which enhances decision-making ability by Spatially Constrained Correlation Filter (SCCF) and Saliency Prior Context (SPC) model.
We propose a hierarchical Gaussian process framework for age estimation from facial images.
Learning predictive models from interaction with the world allows an agent, such as a robot, to learn about how the world works, and then use this learned model to plan coordinated sequences of actions.
This article introduces the solutions of the two champion teams, `MMfruit' for the detection track and 'MMfruitSeg', for the segmentation track, in OpenImage Challenge 2019.
We propose to enforce semantic consistency at all stages of (generalized) zero-shot learning: training, feature synthesis and classification.
We study the scientific problem of identifying and preserving the most informative image structures while constraining the color space to just a few bits, such that the resulting image can be recognized with possibly high accuracy.
Unsupervised learning with denoising autoencoder, where the noisy input data is generated by corrupting latent clean data in the gradient domain.
An approach to image retrieval using spatial configurations is presented. The goal is to search the database for similar objects (image-patches) with a given configuration, size and position.
A novel approach to deal with the stereo correspondence problem induced by the implicit assumptions made by cost aggregation strategies by gathering multiple assumptions that locally would be made by a hypothetical variable CA strategy.
We propose a novel multi-stage network for robustness to scale transformation.
This paper addresses the task of joint object category and 3D pose estimation given a 2D bounding box. We design a residual network based architecture to solve these two seemingly orthogonal tasks with new category-dependent pose outputs.
We propose a 3D object detection method for autonomous driving by fully exploiting the sparse and dense, semantic and geometry information in stereo imagery by extending Faster R-CNN for stereo inputs.
We make the first attempt towards multi-pose guided virtual try-on system which enables transfer clothes on a person image under diverse poses.
We propose a context-dependent diffusion network (CDDN) framework for visual relationship detection.
We proposed a container-based edge offloading framework for autonomous driving service offloading on edge.
We present BART, a denoising autoencoder for pretraining sequence-to-sequence models. BART is trained by corrupting text with an arbitrary noising function, and learning a model to reconstruct the original text.
We look into the use of the domain adversarial neural network (DANN) to extract a common representation between different speakers.
We propose DecaProp (Densely Connected Attention Propagation), a new densely connected neural architecture for reading comprehension (RC), achieving state-of-the-art results on four challenging RC benchmarks.
In this paper, we study deep transfer learning as a way of overcoming object recognition challenges encountered in the field of digital pathology.
In recent studies on model-based reinforcement learning (MBRL), incorporating uncertainty in forward dynamics is a state-of-the-art strategy to enhance learning performance, making MBRLs competitive to cutting-edge model free methods, especially in simulated robotics tasks.
In this paper, we propose a novel approach for efficient training of deep neural networks in a bottom-up fashion using a layered structure using a cascade correlation approach of Fahlman and Lebiere.
We propose a novel technique to segment a telegraphic query and assign a coarse-grained purpose to each segment: a base entity e1, a relation type r, a target entity type t2, and contextual words s.
The rapid development of information era has influenced to realize the notion of Smart Bank via approaches like paperless services and interactive self-service systems.
This paper introduces a regression method called Privileged Information (PI)-based Conditional Structured Output Regression Forest for facial point detection.
We introduce a new, large-scale EV-Action dataset, which consists of RGB, depth, electromyography (EMG) modality, and two skeleton modalities.
We propose a simple change to the current neural network structure for defending against gradient-based adversarial attacks. Instead of using popular activation functions (such as ReLU), we advocate the use of $k$-Winners-Take-All ($k$)-WTA activation, a $C^0$ discontinuous function that purposely invalidates the neural network model's gradient at densely distributed input data points.
We investigate the collection of solutions reached by the same network architecture, with different random initialization of weights and random mini-batches. Surprisingly, all network instances seem to share the same learning dynamics, whereby initially the same train and test examples are correctly recognized by the learned model, followed by other examples which are learned in roughly the same order.
We proposed a new two-stream based deep framework for video classification to discover spatial and temporal information only from RGB frames, moreover, the multi-scale pyramid attention (MPA) layer and the semantic adversarial learning (SAL) module is introduced and integrated in our framework.
We develop a practical test for detecting adversarial attacks, achieving unprecedented accuracy under the white-box setting where the adversary is given full knowledge of our detection mechanism.
We present a state-aware anti-drift tracker (SAT) in this paper, which jointly models the discrimination and reliability information in filter learning in order to resist the model drift caused by challenging distractions.
We propose SASE-FE, the first dataset of genuine and deceptive facial expressions of emotions for automatic recognition.
We propose an improved (IKMSEC) by using the $L_{2,1}$ -norm regularization, which can obtain a sparse representation of nonlinear features to guarantee an efficient classification performance.
We propose a novel approach for performing directional convolution of signals on curved surfaces and show its utility in a variety of geometric deep learning applications.
We present RenderNet, a differentiable rendering convolutional network with a novel projection unit that can render 2D images from 3D shapes.
In this paper, we propose two novel regularization models in patch-wise and pixel-wise respectively, which are efficient to reconstruct high-resolution (HR) face image from low- resolution (LR) input.
Analyzing human actions in videos has gained increased attention recently. In this paper, we propose two methods to predict a considerably large amount of future actions and their duration.
In this paper we present a novel method for proposal free instance segmentation that can handle sophisticated object shapes that span large parts of an image and form dense object clusters with crossovers.
We develop a deep learning framework for amino acid determination in a 3D Cryo-EM density volume and formulate this problem as a vision-inspired 3D detection and pose estimation task.
We introduce Parseval networks, a form of deep neural networks in which the Lipschitz constant of linear, convolutional and aggregation layers is constrained to be smaller than 1.
We analyze how committee size and makeup of models trained with different preprocessing methods impact final performance. We point out some guidelines to predict committee behavior and good approaches to analyze them.
The past 20 years has seen a progressive evolution of computer vision algorithms for unsupervised 2D image segmentation. Of these 2D segmentation efforts, one that comes close to being a state of the art method is the ultrametric contour map (UCM).
We present a novel theory to explain why this unpleasant phenomenon exists in deep neural networks. Based on that theory, we introduce a simple, efficient, and effective training approach, Batch Adjusted Network Gradients (BANG), which significantly improves the robustness of machine learning models.
We propose DeFeat-Net (Depth&Feature network), an approach to simultaneously learn a cross-domain dense feature representation, alongside a robust depth-estimation framework based on warped feature consistency.
This paper presents a framework for the analysis of changes in visual streams: ordered sequences of images, possibly separated by significant time gaps. We use learned representations for change evidence and consistency of perceived change.
We address the problem of multi-label video classification and propose to incorporate external knowledge graphs in a novel end-to-end framework that improves mean average precision by up to 2.9%.
We propose an exposure-aware framework to address the night-time semantic segmentation problem through augmenting the segmentation process with explicitly learned exposure features.
We introduce first-order preconditioning (FOP), a fast, scalable approach that generalizes previous work on hypergradient descent (Almeida et al., 1998) to learn a preconditionsing matrix that only makes use of first- order information.
We propose an assemble-on-demand pre-training toolkit, which contains pre-trained models based on different corpora, encoders, and targets.
In this paper, we introduce a novel hybrid temporal convolutional and recurrent network (TricorNet), which has an encoder-decoder architecture: the encoder consists of a hierarchy of temporal Convolutional kernels that capture the local motion changes of different actions.
We propose an end-to-end learning algorithm capable of using sparse, noisy input depth for refinement and depth completion.
We propose a generic and interpretable learning framework for building robust text classification model that achieves accuracy comparable to full models under test-time budget constraints.
We present a method to extract a video sequence from a single motion-blurred image that generalizes well on synthetic and real datasets.
We propose a novel recurrent ConvNet architecture called recurrent residual networks to address the task of action recognition.
We suggest using an estimator for both rewards and value functions in model-free RL, which improves performance under corrupted stochastic rewards.
In response to the growing importance of geospatial data, its analysis including semantic segmentation becomes an increasingly popular task in computer vision today. When performing remote sensing image segmentation, multiple instances of one class with precisely defined boundaries are often the case, and it is crucial to extract those boundaries accurately. In this paper, we propose a novel loss function for binary segmentation.
We propose theoretical and empirical improvements for two-stage hashing methods. We first provide a theoretical analysis on the quality of binary codes and show that, under mild assumptions, a residual learning scheme can construct binary codes that fit any neighborhood structure with arbitrary accuracy.
We develop a robust pose estimation method based on the recent deep conv-deconv modules with two improvements: (1) multi-scale supervision of body keypoints, and (2) global regression to improve structural consistency of keypoints.
We perform a thorough analysis and find an interesting fact that the two head structures have opposite preferences towards the two tasks. We propose a Double-Head method, which has a fully connected head focusing on classification and a convolution head for bounding box regression.
 DOOR-SLAM produces more inter-robot loop closures, successfully rejects outliers, and results in accurate trajectory estimates, while requiring low communication bandwidth.
We study the problem of ambiguous reprojections in depth prediction from stereo-based self-supervision, and introduce Depth Hints to alleviate their effects.
Discriminative Correlation Filters have demonstrated excellent performance for visual object tracking.
We report experiments on food/non-food classification and food recognition using a GoogLeNet model based on deep convolutional neural network.
This paper addresses the problem of transparent object matting as a refractive flow estimation problem, and proposes a deep learning framework, called TOM-Net, for learning the refractive Flow.
We extend BERT to a new model, StructBERT, by incorporating language structures into pre-training. As a result, the new model is adapted to different levels of language understanding required by downstream tasks.
We propose a new algorithm, DART (Disturbances for Augmenting Robot Trajectories), that collects demonstrations with injected noise, and optimizes the noise level to approximate the error of the robot's trained policy.
We investigate how knowledge can be transferred between three paralinguistic tasks: speaker, emotion, and gender recognition, using progressive neural networks.
We propose a new adversarial modeling method by substituting the classification loss of discriminator with triplet loss. Theoretical proof based on IPM.
We propose a solution to make object detection for UAVs both fast and super accurate. We apply optimization steps such that we achieve minimal latency on embedded on-board hardware.
In this paper, a novel method is proposed to restore de-occluded face images based on inverse use of 3DMM and generative adversarial network.
We present a novel dataset captured from a VW station wagon for use in mobile robotics and autonomous driving research, capturing real-world traffic situations.
We propose to exploit proprioceptive motor signals to provide unsupervised regularization in convolutional neural networks to learn visual representations from egocentric video. We enforce that our learned features exhibit equivariance.
We propose to improve both the model expressiveness of GMMN and its computational efficiency by introducing adversarial kernel learning techniques, as the replacement of a fixed Gaussian kernel in the original GMMN.
We propose a novel neural network architecture called $MeteorNet$ for learning representations for dynamic 3D point cloud sequences.
We use an HMM grounded on a Gated Recurrent Unit for frame labeling in training, where we have access to a temporal ordering of actions, but their start and end frames in training videos are unknown.
We propose the maximum squares loss method to balance the gradient of well-classified target samples in the unlabeled target domain.
We propose DeepGUM: a deep regression model that is robust to outliers thanks to the use of a Gaussian-uniform mixture model.
We present Multimodal Residual Networks for the multimodal residual learning of visual question-answering, which extends the idea of the deep residual learning.
We propose a novel Reversible Recursive Instance-level Object Segmentation (R2-IOS) framework to address the challenging instance-level object segmentation task.
This paper focuses on the transferability of both instances and parameters across natural language understanding tasks by proposing an ensemble-based transfer learning method for few-shot learning.
A two-step process where we first build a multi-entity-label image recognition model to predict abstract concepts as image labels and then leverage them in the second step as an external semantic attention and constrained inference in the caption generation model for describing images that depict unseen/novel objects.
In this paper, we explore a form of hierarchical memory network, which can be considered as a hybrid between hard and soft attention memory networks.
This paper investigates when users create profiles in different social networks, whether they are redundant expressions of the same persona, or they are adapted to each platform in an identifiable and learnable manner.
In this paper a new method for providing insensitivity to expression variation in range images based on Log-Gabor Templates is presented.
We construct scale equivariant cross-correlations based on a principled extension of convolutions, grounded in the theory of scale-spaces and semigroups.
We introduce Label Universal Targeted Attack (LUTA) that makes a deep model predict a label of attacker's choice for `any' sample of a given source class with high probability.
We build on the recent convolutional DGP models which effectively capture image level features through the use of convolution kernels, therefore opening up the way for applying DGPs to computer vision tasks.
We propose a novel multi-scale convolutional neural network (MSCNN) for single image crowd counting.
A strengthened region-based convolutional network (SRPN) for object detection .
We propose a directional deep embedding and appearance learning method, which is free of the online fine-tuning process for fast VOS.
We propose a novel semi-supervised framework, which models shared information between domains and domain-specific information separately, allowing us to learn diverse many-to-many mappings between the two domains.
We revisit the geometric approach to this problem, and provide a theoretical proof that explicitly shows the ambiguity between radial distortion and scene depth when two-view geometry is used to self-calibrate the radial distortion.
We propose DecomposeMe, a simple but effective technique to learn features using 1D convolutions that improves performance while reducing the number of parameters required.
We augment standard architectures with deeper aggregation structures iteratively and hierarchically merge the feature hierarchy to better fuse information across layers.
Automated scene analysis has been a topic of great interest in computer vision and cognitive science. Recently, with the growth of crowd phenomena in the real world, crowded scene Analysis has attracted much attention.
We propose a simple yet powerful pipeline that yields fast and accurate text detection in natural scenes in full images.
We propose the Triplet Representation for Body (TRB), a compact 2D human body representation, with skeleton keypoints capturing human pose information and contour keypoints containing human shape information. We further introduce the challenging problem of TRB estimation.
In this paper, we propose Gumbel Tree-LSTM, a novel tree-structured long short-term memory architecture that learns how to compose task-specific tree structures only from plain text data efficiently.
We introduce a novel risk control framework for risk-aware Web QA and introduce risk-related metrics for evaluation.
We present a method for compressing large, complex trained ensembles into a single network, where the knowledge from a variety of trained deep neural networks (DNNs) is distilled and transferred to a single DNN.
We compare the image compression standards JPEG, JPEG2000, and WebP to a modern encoder/decoder image compression approach based on generative adversarial networks (GANs) based on semantic segmentation, and we show that the GAN autoencoder method is a promising candidate.
In this paper, we propose an end-to-end learning strategy to generate textures of human bodies under the supervision of person re-identification. We render the synthetic images with textures extracted from the inputs.
We provide a comprehensive overview about various 3D data representations highlighting the difference between Euclidean and non-Euclidean ones. We also discuss how Deep Learning methods are applied on each representation, analyzing the challenges to overcome.
The aim of this study is to assess the performance of two machine-learning technologies, namely, deep learning (DL) and support vector machine (SVM), for detecting central retinal vein occlusion (CRVO) in ultrawide-field fundus images.
We propose a Siamese Edge-Enhancement Network (SE2Net) to preserve the edge structure for salient object detection.
We proposed a motion-guided filter that exploits spatial and temporal information between consecutive frames of the video to recover missed detections.
We propose a new unsupervised automatic method to segment the retinal vessels from retinal fundus images.
We propose a general method to perform saliency-like pre-selection on overlapped region features by the interrelation of bidirectional LSTM (BiLSTM), and use a novel element-wise multiplication based attention method to capture more competent correlation information between visual and textual features.
We propose a hierarchical LSTM with adaptive attention approach for image and video captioning.
We describe a precision assignment methodology for neural network training in which all network parameters, i.e., activations and weights in the feedforward path, gradients and weight accumulators in the feedback path, are assigned close to minimal precision.
We propose a novel method for clustering data points that lie in nonlinear subspaces by solving a graph Laplacian problem.
The performance of speech emotion recognition is affected by the differences in data distributions between train (source domain) and test (target domain) sets used to build and evaluate the models. This study looks into the use of adversarial training to extract a common representation between train and test domains.
In this paper, a simple but effective method is proposed for detecting salient objects by utilizing texture and local cues.
In this paper, we propose a novel and effective abnormality detector implementing the attention mechanism and group convolution on 3D single shot detector (SSD) called group-attention SSD (GA-SSD).
We introduce a hybrid deep learning framework that integrates useful clues from multiple modalities, including static spatial appearance information, motion patterns within a short time window, audio information as well as long-range temporal dynamics.
In this paper, we propose to bridge the domain gap with an intermediate domain and progressively solve easier adaptation subtasks.
We propose the Wasserstein Auto-Encoder (WAE)---a new auto-encoder for building a generative model of the data distribution, which shares many of the properties of VAE while generating samples of better quality, as measured by the FID score.
This paper proposes a novel framework for HRRS images scene classification, which utilizes CNN as feature extractor and XGBoost as classifier.
Vessel segmentation in retinal fundus images is a preliminary step to clinical diagnosis for some systemic diseases and some eye diseases. In this paper, we present a method for both main and peripheral vessel segmentation.
We propose a method based on generative adversarial networks that learns to discover cross-domain relations between different domains (DiscoGAN)
This paper is concerned with improving the empirical convergence speed of block-coordinate descent algorithms for approximate nonnegative tensor factorization (NTF) using heuristic extrapolation with restarts.
We investigate the learning dynamics of neural networks as they train on single classification tasks and find that certain examples are forgotten with high frequency, and some not at all.
We propose a method to generate labeled pedestrian data and adapt them to support the training of pedestrian detectors.
We present the results from the third shared task on multimodal machine translation. This year the task was extended with a third target language (Czech) and a new test set.
Recurrent Neural Networks can be effectively used in order to encode sequences and provide effective representations.
We extend recurrent neural networks for temporal data to include nonlinear mappings and propose a novel recurrent neural network that can make predictions about the future and then correct those predictions with bottom-up observations.
We combine state-of-the-art cross-lingual methods with recently proposed methods for weakly supervised learning to close both the language gap and the domain gap in XLU.
We present an image similarity learning method that can scale well in both the number of images and the dimensionality of image descriptors.
We present a hybrid stereo matching algorithm, which decomposes the stereo matching process into a number of subtasks and deals with them using different methods.
We improve the state of the art on enwik8 from 0.99 to 0.94 bits/char, text8 from 1.08 to 1.04 bits/ char, and WikiText-103 from 18.3 to 16.4 perplexity points.
We present Wasserstein introspective neural networks (WINN) that are both a generator and a discriminator within a single model, achieving compelling results even with a single classifier.
This paper introduces the Attribute-Decomposed GAN, a novel generative model for controllable person image synthesis, which can produce realistic person images with desired human attributes in various source inputs.
A novel adaptive Multi-scale Convolution Aggregation module and regularization method for DenseNets.
In this paper we propose a new regularizer built upon the Laplacian of similarity graphs obtained from the representation of training data at each layer of the DNN architecture that penalizes large changes (across consecutive layers in the architecture) in the distance between examples of different classes.
We study the problem of object recognition, where the training samples are missing during the classifier learning stage, a task also known as zero-shot learning.
We propose an ID-aware Embedding for set-based person re-identification that measures the perceptual and semantic quality of images guided by their ID information.
We propose and analyze a series of architectural modifications for LSTM networks resulting in improved performance for text classification datasets.
We propose a data augmentation technique by automatically generating relevant unanswerable questions according to an answerable question paired with its corresponding paragraph that contains the answer.
We provide substantial advances to the pseudo-LiDAR framework through improvements in stereo depth estimation, and explore the idea to leverage cheaper but extremely sparse LiDAR sensors for stereo-based 3D detection.
NeoCPU optimizes the operations as templates without relying on third-parties libraries, which enables further improvement of the performance via operation- and graph-level joint optimization.
We propose query2box, an embedding-based framework for reasoning over arbitrary logical queries with $\wedge$, $\vee$, and $\exists$ operators in massive and incomplete KGs.
We present a generalization of the person-image generation task, in which a human image is generated conditioned on a target pose and a set X of source appearance images.
We propose the Low-rank Multimodal Fusion method, which performs multimodal fusion using low-rank tensors to improve efficiency.
We demonstrate that hand-crafted low level features can provide complementary information to enhance performance of saliency detection that utilizes only high level features.
We present a novel end-to-end single-shot method that segments countable object instances (things) as well as background regions (stuff) into a non-overlapping panoptic segmentation at almost video frame rate.
We explore the potential of using GANs to improve a domain adaptation task carried out by the MUNIT architecture, aiming to use the resulting images to raise awareness of the potential future impacts of climate change.
We propose a Fairness-Aware Re-ranking algorithm to balance the ranking quality and provider-side fairness while being attentive to individual user differences.
We propose the Shape Transformation-based Dataset Augmentation (STDA) framework to augment pedestrian detection datasets by transforming real pedestrians from the same dataset into different shapes.
In this paper, we propose a new saliency method by introducing short connections to the skip-layer structures within the HED architecture.
This paper investigates how to rapidly and accurately localize facial landmarks in unconstrained, cluttered environments rather than in the well segmented face images without relying on pre-process or sliding window approaches.
We present a novel and easy-to-implement training framework for visual tracking based on online discriminatively trained ridge regression model that achieves state-of-the-art performance.
We propose an efficient and unified framework to generate temporal action proposals named Dense Boundary Generator (DBG), which draws inspiration from boundary-sensitive methods and implements boundary classification and action completeness regression for densely distributed proposals.
This paper presents a complete novel pipeline for Helmholtz Stereopsis. The pipeline is validated quantitatively and qualitatively against alternative formulations and coping with complex geometry and reflectance.
Visual question answering (or VQA) is a new and exciting problem that combines natural language processing and computer vision techniques. We present a survey of the various datasets and models that have been used to tackle this task.
This paper proposes a lightweight CNN-based network for estimating crowd counting and generating density maps under resource constraints.
We propose a method for single-shot segmentation in a feature residual pyramid network (RPNet), which learns the coarse results and residuals of segmentations by decomposing the label at different levels of residual blocks.
We develop a weak foreground-background segmentation approach in order to robustly extract not only foreground features that are focused on the actors, but also global camera motion and contextual scene information.
This paper attempts to compare and combine different approaches for de-tecting errors in Knowledge Graphs and proposes a novel hybrid and modularmethodology for the task.
We propose a domain adaptation method for pixel-level crowd understanding, which eliminates the need for synthetic data.
We propose a compressed CNN model termed CS-CNN for image classification by incorporating the theory of compressive sensing at the input layer of the CNN models to both reduce the resources consumption (evaluated as computation time in this paper) and a required number of training samples.
We propose a novel, conceptually simple and general framework for instance segmentation on 3D point clouds. The framework directly regresses 3D bounding boxes for all instances in a point cloud, while simultaneously predicting a point-level mask.
A cascaded, deep-to-shallow, fashion, along the deep feature hierarchy, for unpaired image to image translation.
Transfer learning is aimed to make use of valuable knowledge in a source domain to help model performance in a target domain. It is particularly important to neural networks which are very likely to be overfitting.
We show that handcrafted features can be as good as deep features, that the attributes themselves are powerful enough to predict other attributes and that clustering the samples according to their attributes can mitigate the training complexity for deep learning.
We propose a self-supervised deep learning approach for part segmentation, where we devise several loss functions that aids in predicting part segments that are geometrically concentrated, robust to object variations and are also semantically consistent across different object instances.
Deep Neural Networks (DNNs) are becoming an important tool in modern computing applications. Accelerating their training is a major challenge and techniques range from distributed algorithms to low-level circuit design. In this survey, we describe the problem from a theoretical perspective, followed by approaches for its parallelization.
We present a novel method to calibrate knowledge graph embedding models when ground truth negatives are not available, which is the usual case in knowledge graphs.
We develop a bundle adjustment algorithm which incorporates the planar motion constraint, and devise a scheme that utilises the sparse structure of the problem. Experiments are carried out on real data.
In this paper, we propose a network model selection methodology that focuses on evaluating a network's utility for varying tasks, together with an efficiency measure which selects the most parsimonious model.
In this paper, we use the recently introduced entmax transformation to train and sample from a natively sparse language model, avoiding this mismatch.
We propose a novel and principled hybrid CNN+CRF model for stereo estimation and train it end-to-end.
We propose a new semi-supervised object detection formulation, in which a few seed box level annotations and a large scale of image level annotations are used to train the detector.
We propose a lightweight monocular depth model obtained from a large trained model that achieves 5x compression rate with small drop in accuracy on the KITTI driving dataset.
In the feature maps of CNNs, there commonly exists considerable spatial redundancy that leads to much repetitive processing. Towards reducing this superfluous computation, we propose to compute features only at sparsely sampled locations, which are probabilistically chosen according to activation responses, and then densely reconstruct the feature map with an efficient interpolation procedure.
We introduce the Particle Filter Networks (PF-nets) that encode both a learned probabilistic system model and the particle filter algorithm in a single neural network architecture, circumventing the difficulties of conventional model-based methods.
In this paper, we introduce a novel decision-making framework for image captioning. We utilize a policy network and a value network to collaboratively generate captions.
We identified moexipril, a well tolerated and safe angiotensin-converting enzyme inhibitor, as a bona fide PDE4 inhibitor that may provide the starting point for development of novel Pde4 inhibitors with improved therapeutic window.
Pedestrian tracking and detection of crowd abnormal activity under dynamic and complex background us ing I ntelligent V ideo S urveillance (IVS) system.
This paper presents an approach for recognising activities using video from an egocentric (first-person view) setup based on global spatio-temporal relationships.
The DBpedia project extracts structured information from Wikipedia and makes it available on the web. In this paper we focus on the extraction of historical events from Wikipedia articles.
This paper presents a novel framework for simultaneously implementing localization and segmentation, which are two of the most important vision-based tasks for robotics.
A novel two-stream framework for action recognition for hockey using three main components for pose estimation, flow estimation and transfer learning.
We propose metric learning with background noise class for the few-shot detection of rare sound events.
We propose a modified matched filter with the first derivative of Gaussian for the early detection of diabetic retinopathy.
This paper explores the use of relative labels to train machine learning algorithms that can rank expressive behaviors that occur during human interactions.
This paper presents a novel learning-based framework that combines the robustness of parametric model with the flexibility of free-form 3D deformation.
We develop an end-to-end deep learning framework capable of avoiding the dominant effect of majority classes by discovering sparsely sampled boundaries of minority classes.
A suite of ligand annotation, purchasability, target, and biology association tools, incorporated into ZINC and meant for investigators who are not computer specialists.
We consider the task of learning visual connections between object categories using the ImageNet dataset, which is a large-scale dataset ontology.
The QUIS-CAMPI data feed, comprising samples automatically acquired by an outdoor visual surveillance system, with subjects on-the-move and at-a-distance (up to 50 m), provides a high-quality set of enrolment data for biometric recognition in unconstrained scenarios.
In human-object interactions (HOI) recognition, conventional methods consider the human body as a whole and pay a uniform attention to the entire body region. They ignore the fact that normally, human interacts with an object by using some parts of the body.
This paper addresses the problem of learning binary hash codes for large scale image search by proposing a novel hashing method based on deep neural network.
We proposed an approach for building summary graph structures automatically from RDF graph data based on instance similarities using locality-sensitive hashing technique.
We develop a state-of-the-art simulator for evaluating end-to-end Bayesian controllers for autonomous driving, and provide a method for computing pointwise uncertainty measures that can be used in collision avoidance.
We propose a novel feature learning method named local embedding deep features (LEDF) for person re-identification.
We propose a more sample-efficient pre-training task that corrupts the input by replacing some tokens with plausible alternatives sampled from a small generator network and train a discriminative model that predicts whether each token in the corrupted input was replaced by a generator sample or not.
The RepEval 2017 Shared Task aims to evaluate natural language understanding models for sentence representation, in which a sentence is represented as a fixed-length vector with neural networks and the quality of the representation is tested with a natural language inference task.
This paper addresses the problem of semantic scene understanding under foggy road conditions, using purely synthetic data to improve the performance on unseen real-world foggy scenes captured in Zurich and its surroundings.
We propose an end-toend trainable framework, called View Confusion Feature Learning (VCFL), for person re-identification across cameras.
This paper explores a brand new research direction, which aims at bridging dialogue generation and facial expression synthesis for better multimodal interaction.
Neural networks have recently become good at engaging in dialog. However, current approaches are based solely on verbal text, lacking the richness of a real face-to-face conversation.
Robust Initialization for Cascaded Pose Regression by providing texture and pose correlated initial shapes for the testing face.
We used a data-driven method to learn the "potential regularization term" rather than design a penalty term manually.
We show that by maximizing the entropy of predictions about the body---touch sensors, proprioception and vestibular information---we are able to learn dynamic models of the body that can be used for control.
In this paper, we propose the conditional difference adversarial autoencoder, CDAAE, for facial expression synthesis.
We propose a multi-scale aggregation R-CNN which performs human detection and keypoint localization in a single model, which results in reduced computation.
This paper aims to provide a comprehensive study on temporal modeling for OAD including four meta types of temporal modeling methods.
Drug-drug interaction (DDI) is a change in the effect of a drug when patient takes another drug.
We present an approach for weakly supervised learning of human actions. Given a set of videos and an ordered list of the occurring actions, the goal is to infer start and end frames of the related action classes within the video and to train the respective action classifiers without any need for hand labeled frame boundaries.
We focus our attention on the problem of generating adversarial perturbations based on the gradient in image classification domain, which can fool deep neural models into making incorrect predictions.
We present a novel neural network architecture for retinal vessel segmentation that improves over the state of the art on two benchmark datasets, is the first to run in real time on high resolution images, and its small memory and processing requirements make it deployable in mobile and embedded systems.
We introduce a novel continual architecture search (CAS) approach, so as to continually evolve the model parameters during the sequential training of several tasks, without losing performance on previously learned tasks, thus enabling life-long learning.
We introduce spectral cluster regularization to reduce the error margin in long-term prediction (3-5 seconds) and improve the accuracy of the predicted trajectories.
We propose a deep face super-resolution method with iterative collaboration between two recurrent networks which focus on facial image recovery and landmark estimation respectively.
OneShot is a global localization algorithm that uses only a single 3D LiDAR scan at a time, while outperforming approaches based on integrating a sequence of point clouds.
We introduce a real-time stereo matching technique based on a reformulation of Yoon and Kweon's adaptive support weights algorithm using the bilateral grid to achieve a speedup of 200× compared to a straightforward full-kernel GPU implementation.
We solve the personalized paper recommendation problem in the setting of heterogeneous information networks. A heterogeneous graph representation based recommendation method is proposed.
In this paper, we introduce a new low-level purely rotation-invariant representation to replace common 3D Cartesian coordinates as the network inputs, and introduce a network architecture to embed these representations into features, encoding local relations between points and their neighbors, and the global shape structure.
This paper presents our submissions for the CoNLL 2017 UD Shared Task. Our parser, called UParse, is based on a graph-based dependency parser.
We propose a data-driven regularization model for stereo or flow through transferring the shape information of the disparity or flow from semantically matched patches in the training database.
We propose Morphed Learning, a privacy-preserving technique for deep learning based on data morphing that, allows data owners to share their data without leaking sensitive privacy information.
Working in the frequency domain can yield good recognition features for commonly used optical flow and articulated pose features, which are highly sensitive to small differences in motion, viewpoint, dynamic backgrounds, occlusion and other sources of variability.
We propose an efficient framework for real-time object tracking which is end-to-end trained offline-Fully Conventional Anchor-Free Siamese network (FCAF)
We present a method to address this challenge, developing tasks that directly target compositional meaning information in sentence vector representations with a high degree of precision and control.
In this paper, we propose the Ordered Memory architecture. Inspired by Ordered Neurons, we introduce a new attention-based mechanism and use its cumulative probability to control the writing and erasing operation of the memory.
We investigate whether state-of-the-art multi-hop QA models understand the underlying sub-questions like humans, and propose a new model for answering them.
We propose a multi-stage Siamese Cascaded RPN framework for real-time tracking, which achieves state-of-the-art results.
We introduce an end-to-end trainable deep architecture that combines features obtained using multiple receptive field sizes and learns the importance of each such feature at each image location.
We address the problem of learning a single model for person re-identification, attribute classification, body part segmentation, and pose estimation without creating significant computational overhead.
In this paper, we introduce an image"inner space"preserving generative pose machine (ISP-GPM) that assigns an interpretable low-dimensional pose descriptor (LDPD) to an articulated figure in the image and generate a conditional GAN structure that preserves the rest of the image.
We present a unified max-margin framework that learns to find these hidden structures (given a corpus of question-answer pairs), and uses what it learns to answer machine comprehension questions on novel texts.
We propose a recommendation method that improves collaborative filtering by using multiple levels of Pearson Correlation Similarity.
We propose a class imbalanced deep learning model based on batch-wise incremental minority (sparsely sampled) class rectification by hard sample mining.
A novel neural network model for conversational reading comprehension, which captures topic transfer features using temporal convolutional network in the dialog.
We exploit a multi-channel attention mechanism in feature space to obtain an attention mask for each feature while existing CNN visualization methods provide only a common attention mask.
We study and compare the discriminative capabilities of 15 facial regions considered in forensic practice for face recognition applications.
We propose to learn a dialogue system that independently parameterizes different dialogue skills, and learns to select and combine each of them through Attention over Parameters (AoP).
Feature-fusion guidelines, proposed in our recent work, are extended by adding a new face segmentation method and the support vector machine classifier.
We propose Drop to Adapt (DTA), which leverages adversarial dropout to learn strongly discriminative features by enforcing the cluster assumption.
We use camera motion to improve motion-based descriptors, such as HOF and MBH, which are shown to be complementary.
We propose a hierarchical segmentation algorithm that starts with a very fine over segmentation and gradually merges regions using a cascade of boundary classifiers using asymetric loss to maximize boundary recall.
We propose an energy minimization based formulation to simultaneously complete the depth maps, estimate the scene flow and deblur the color images.
We propose an unsupervised framework to align the entity and relation embddings of different knowledge graphs with an adversarial learning framework with limited number of aligned triples.
The goal of this paper is to determine the spatio-temporal location of actions in video. Rather than asking users to provide point supervision, we propose fully automatic visual cues that replace manual point annotations.
In this paper, we mine threat intelligence about open source projects and libraries from bugs and issues reported on public code repositories. We represent and store this threat intelligence, along with the software dependencies in a security knowledge graph.
We propose to alleviate the dataset bias by adapting detectors from category to instances, and back.
We investigate a variety of data augmentation techniques commonly used in Light Detection and Ranging (LiDAR) based 3D Object Detection.
In this paper, we propose a novel Temporal Bilinear model to capture the temporal pairwise feature interactions between adjacent frames.
We present the Deep Canonical Time Warping (DCTW), a method which automatically learns complex non-linear representations of multiple time-series, generated such that (i) they are highly correlated, and (ii) temporally in alignment.
We introduce a new benchmark named “Look into Person (LIP)” that provides a significant advancement in terms of scalability, diversity, and difficulty, which are crucial for future developments in human-centric analysis.
We propose a novel Disentangled Expression learning-Generative Adversarial Network (DE-GAN) to explicitly disentangle facial expression representation from identity information.
We introduce a simple and efficient procedure for the segmentation of rigidly moving objects, imaged under an affine camera model, using the theory of “linear combination of views”.
TUPA is a general neural transition-based DAG parser, which we use to present the first experiments on recovering enhanced dependencies as part of the general parsing task.
Adaptive neural language model improves predictions of human reading times compared to a non-adaptive model.
We propose a pose-based two-stream relational network for action recognition by combining 2D human pose extracted from raw video and image appearance.
We investigate entity linking in the context of a question answering task and present a jointly optimized neural architecture for entity mention detection and entity disambiguation that models the surrounding context on different levels of granularity.
SQuAD 2.0 combines existing SQuAD data with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones.
In this work, we propose a novel framework named Region-Aware Network (RANet), which learns the ability of anti-confusing in case of heavy occlusion, nearby person and symmetric appearance, for human pose estimation.
We propose a variational method for training probabilistic latent variable models using any f-divergence, when combined with Spread Divergence.
In this work, we focus on the problem of tracking objects under significant viewpoint variations, which poses a big challenge to traditional object tracking methods. We propose a novel method to track an object and estimate its continuous pose and part locations under severe viewpoint change.
This paper presents a new, computationally simple, and automatic method to extract the retinal blood vessel from the fundus image using several image processing techniques.
In this paper, we investigate whether graph structure is necessary for multi-hop reasoning tasks and what role it plays.
We proposed a method that exploits finer-classes than the most specific ones existing, leading to significantly better results on 10 target-tasks from multiple domains.
We propose to compose dynamic tree structures that place the objects in an image into a visual context, helping visual reasoning tasks such as scene graph generation and visual QA.
We propose to use boosted decision trees as the hash functions, which are nonlinear, highly descriptive, and are very fast to train and evaluate.
The recent COCO object detection dataset presents several new challenges for object detection. To address these challenges, we test three modifications to the standard Fast R-CNN object detector: (1) skip connections that give the detector access to features at multiple network layers, (2) an integral loss function and corresponding network adjustment that improve localization.
We propose a multi-task learning framework to jointly train a Machine Reading Comprehension (MRC) model on multiple datasets across different domains.
We propose a local feature descriptor for 3D LiDAR scans and propose a method for estimating local surface patches and obtaining ground truth correspondences.
We formulate lifelong relation extraction and investigate memory-efficient incremental learning methods without catastrophically forgetting knowledge learned from previous tasks.
We propose a generative adversarial network which synthesizes additional examples for novel categories by conditioning a conditional generative adversarial network with class prototype vectors.
We analyze the advantages and shortcomings of recent adversarial examples generation methods and provide a research direction of this aspect.
We propose semi-supervised generative models for human body analysis in which the body pose and visual appearance are disentangled.
We propose a new Group Feature Selection method for Discriminative Correlation Filters (GFS-DCF) based visual object tracking.
We quantitatively investigate how machine learning models leak information about the individual data records on which they were trained. We investigate the factors that influence this leakage and evaluate mitigation strategies.
The proposed method using a geodesic-division-based discrete spherical image as the CNN input obtains the best performance—better than that of the cubemap and far superior to the equirectangular image.
We propose an anti-drift background-aware correlation filter via introducing the temporal consistency constraint into BACF, which can mitigate the drifting problem.
In this work, a siamese network is integrated into the pipeline of a well-known 3D object detector approach to suppress duplicate proposals coming from different cameras via re-identification.
We present a novel approach for synthesizing photo-realistic images of people in arbitrary poses using generative adversarial learning. We tackle this challenging scenario by splitting the problem into two principal subtasks.
We introduce a formal setting for studying training under the non-asymptotic, resource-constrained regime, i.e., budgeted training. Under such a setting, we show that the key to a good schedule is budgeted convergence, a phenomenon whereby the gradient vanishes at the end of each allowed budget.
We propose a Transferred Single and Couple Representation Learning Network (TSCN) for group re-identification.
We propose a novel fully supervised local descriptor learning algorithm based on the image-to-class distance to learn compact but highly discriminative local feature descriptors for action recognition.
We propose to automatically create capsule wardrobes. We pose the task as a subset selection problem. Given an inventory of candidate garments and accessories, the algorithm must assemble a minimal set of items that provides maximal mix and match outfits.
We present a novel clustering objective that learns a neural network classifier from scratch, given only unlabelled data samples, achieving state-of-the-art results in eight unsupervised clustering benchmarks spanning image classification and segmentation.
This paper introduces a novel Convolutional Neural Network (CNN) architecture which automatically discovers latent domains in visual datasets and exploits this information to learn robust classifiers.
Attention in machine learning is largely bottom-up, whereas people also deploy top-down, goal-directed attention. Motivated by neuroscience research, we evaluated a plug-and-play, top- down attention layer that is easily added to existing deep convolutional neural networks.
We have created a computational prediction method that allows us to obtain a first model of the Human-Microbial oral interactome.
We study the hypothesis that these visible facial colors allow observers to successfully transmit and visually interpret emotion even in the absence of facial muscle activation.
We introduce fast segmentation convolutional neural network (Fast-SCNN), an above real-time semantic segmentation model suited to efficient computation on embedded devices with low memory.
We propose a novel strategy for fast candidate detection from volumetric chest CT scans, which can minimize false negatives (FNs) and false positives (FPs), and simplify the design of the FP reduction.
We propose a nonparallel data-driven emotional speech conversion method that enables the transfer of emotion-related characteristics of a speech signal while preserving the speaker's identity and linguistic content.
In this paper, we propose an algorithm named, Relative Pairwise Relationship constrained Non-negative Matrix Factorisation (RPR-NMF), which places constraints over relative pairwise distances amongst features by imposing penalties in a triplet form, achieving superior performance compared with other algorithms.
We propose a new effective MM approach that learns implicit generative models by performing mean and covariance matching of features extracted from pretrained ConvNets and achieve state-of-the-art results.
We propose to generalize slow feature analysis to "steady" feature analysis, which captures *how* the visual content changes over time.
We give a comprehensive survey on adversarial attacks in reinforcement learning under AI security.
This work presents the Video Platform for PyTorch (ViP), a deep learning-based framework designed to handle and extend to any problem domain based on videos.
We study the commonsense ability of GPT, BERT, XLNet, and RoBERTa by testing them on seven challenging benchmarks, finding that language modeling and its variants are effective objectives for promoting models' commonsENSE ability while bi-directional context and larger training set are bonuses.
Feature or interest points typically use information aggregation in 2D patches which does not remain stable at object boundaries when there is object motion against a significantly varying background.
This paper is concerned with the problem of learning a distance metric by considering meaningful and discriminative distance constraints in some contexts where rich information between data is provided.
We tackle two of them related to the loss of gradients during parameter update and backpropagation through a softmax nonlinearity layer in low precision training.
We present a simple method of domain adaptation between synthetic images and real images - by high quality rendering of the 3D models and correlation alignment.
We introduce 3D-SIS, a novel neural network architecture for 3D semantic instance segmentation in RGB-D scans. The core idea of our method to jointly learn from both geometric and color signal, thus enabling accurate instance predictions.
A matching algo- rithm that combines illumination normal similarity, gradient similarity, color similarity, and Euclidean distance similarity to compute the corresponding support weights and dissimilarity measurements.
A general network architecture to concatenate CNN features of different layers in a simple and effective way, called Selective Feature Connection Mechanism (SFCM).
This paper proposes to leverage the resulting structured covariance matrix to obtain detectors with identical performance in orders of magnitude less time and memory.
We propose a novel neural network architecture, namely MoBiNet - Mobile Binary Network in which skip connections are manipulated to prevent information loss and vanishing gradient, thus facilitate the training process.
We focus on the one-shot learning for video-based person re-Identification (re-ID) by gradually improving the discriminative capability of the Convolutional Neural Network (CNN) feature representation via stepwise learning.
This work investigates a novel deep structured model, which adaptively decomposes an activity instance into temporal parts using the convolutional neural networks using the latent variables.
Finding novel and effective inhibitors against uridine diphosphogalactofuranose mutase from reported natural phytochemicals and ZINC database using virtual screening approach.
We propose a method for generating images from scene graphs, enabling explicitly reasoning about objects and their relationships, enabling realistic images with multiple objects.
Answering questions using multi-modal context is a challenging problem, as it requires a deep integration of diverse data sources. Our HMMN framework effectively integrates information from the multi- modal context, question, and answer choices, enabling more informative context to be retrieved for question answering.
We first study the gradient distributions of TopK-SGD during the training process through extensive experiments. We then theoretically derive a tighter bound for the Top-$k$ operator. Finally, we exploit the property of gradient distribution to propose an approximate top-$ k$ selection algorithm.
In this paper, we propose a novel rigid motion segmentation algorithm called randomized voting (RV) based on epipolar geometry, and computes a score using the distance between the feature point and the corresponding epipolar line.
We provide the definition of the human predictability of the model, as a part of the interpretability of DNNs. In addition, we introduce one example of high human-predictable Dnns.
We propose a new framework for finding biologically significant signaling pathways in protein-protein interaction networks by integrating microarray expression profiles, protein subcellular localization and sequence information.
We propose to use variable mini-batch shapes with different spatial-temporal resolutions that are varied according to a schedule to accelerate video model training.
This article studies the domain adaptation problem in person re-identification (re-ID) under a"learning via translation"framework, consisting of two components, 1) translating the labeled images from the source to the target domain in an unsupervised manner, 2) learning a re-ID model using the translated images.
We propose a new CNN-based face recognition approach that incorporates such attributes into the training process, improving the accuracy and robustness of face recognition.
We introduce a novel way of representing heterogeneous relations in knowledge graphs (KGs) in statistical relational learning, in which relation and entity embeddings are learned simultaneously.
In this paper, we present exemplar-based graph matching (EGM), a robust framework for facial landmark localization.
In this paper, we propose the structured discriminative and difference constraints to learn visual-semantic embeddings that capture the intra- and inter-class relationships of image Embeddings.
Instance segmentation is the problem of detecting and delineating each distinct object of interest appearing in an image. We propose an end-to-end method that learns how to segment instances sequentially.
We propose to use a surrogate of the mutual information of the input representation space to build a set of binary masks that fit the current weights configuration for unsupervised learning.
Lateral connections between encoder and decoder allow higher layers of a denoising autoencoder to focus on invariant representations.
We introduce an adversarial training scheme that operates directly on the time-frequency representations and makes the output distribution closer to the ground-truth, improving the model estimations.
We analyze the regularization properties of additive gradient noise in the training of deep networks by posing it as finding the ground state of the Hamiltonian of a spherical spin glass in an external magnetic field.
An efficient sparse modeling pipeline for the classification of human actions from video is here developed, which outperforms previously reported results for virtually all standard datasets.
We propose Optimal Thresholding, a simple yet effective method to prune channels with layer dependent thresholds that optimally separate important from negligible channels while minimizing performance degradation.
A unified network that localizes and recognizes text with a single forward pass, avoiding intermediate processes such as image cropping and feature re-calculation.
We introduce a natural generalization flex-convolution of the conventional convolution layer along with an efficient GPU implementation which can efficiently process 7 million points concurrently.
In many computer vision tasks, for example saliency prediction or semantic segmentation, the desired output is a foreground map that predicts pixels where some criteria is satisfied. Despite the inherently spatial nature of this task commonly used learning objectives do not incorporate the spatial relationships between misclassified pixels and the underlying ground truth. The Weighted F-measure, a recently proposed evaluation metric, does reweight errors spatially.
We develop a superpixel-wise neural network for tracking-by-segmentation, called TBSNet, which extracts multi-level convolutional features of each superpixel.
We propose to use genetic algorithms to find the optimal setting of all the diffusion parameters with respect to retrieval performance for each different dataset.
We show that the search for a partition of a given graph where each member of the partition has only pairwise distant vertices is NP-hard. We present a modification of this approach, where similarly we group together vertices of identical properties.
We propose a new method for fusing a LIDAR point cloud and camera-captured images in the deep convolutional neural network (CNN), which produces 3D bounding boxes from the bird view map.
We evaluate the multilingual BERT model on Finnish and compare it with a new Finnish BERTmodel trained from scratch. The new language-specific model is shown to systematically and clearly outperform the mult bilingual.
Pre-training a neural network with a small number of examples of images that are drawn from the same distribution as interest can improve reconstruction results in compressed sensing and semantic image recovery.
We address the problems of identifying phrase alignment of flexible granularity and pooling alignments of different intensities for sentence pair classification tasks, and propose an architecture based on Gated Recurrent Unit that supports both.
We propose a Multi-Task Learning (MTL) paradigm based deep neural network architecture, called MTCNet (Multi-Task Crowd Network) for crowd density and count estimation.
We introduce a differentiable, end-to-end trainable framework for solving pixel-level grouping problems such as instance segmentation consisting of a recurrent neural network parameterized by kernel bandwidth.
We use Long Short Term Memory units in conjunction with object proposals to incorporate object-object relationship and object-scene relationship in an end-to-end trainable manner.
In the recent years, there has been a significant improvement in the quality of samples produced by generative models such as variational auto-encoders and generative adversarial networks.
This paper proposes a speech emotion recognition method based on speech features and speech transcriptions (text) based on Deep Neural Network architectures.
We introduce a novel Progressive LiDAR adaptation-aided road detection ( PLARD) approach to adapt LiDar information into visual image-based road detection and improve detection performance.
We propose a new variational method that recovers the fundamental matrix and the optical flow simultaneously as the minimisers of a single energy functional in a natural way.
We show that it is possible to predict output quality without generating the captions, based on the probability assigned by the neural model to the reference captions.
An improved ShuffleNetV2 network based on mixed attention mechanism for face age estimation .
We develop an end-to-end tracking architecture, capable of fully exploiting both target and background appearance information for target model prediction, achieving state-of-the-art performance.
We explore the use of a decision network to adaptively assign different frame regions to different networks based on a metric called expected confidence score.
We investigate the extent to which neural networks exhibit convergent learning, which is when the representations learned by multiple nets converge to a set of features which are either individually similar between networks or where subsets of features span similar low-dimensional spaces.
In this paper, several variants of two-stream architectures for temporal action proposal generation in long, untrimmed videos are presented.
This paper exploits the OpenFace open-source system to generate a deep convolutional neural network model using publicly available data and software.
This paper describes UALing’s approach to the CoNLL 2017 UD Shared Task using corpus selection techniques to reduce training data size.
Variations on GLU are possible, using different nonlinear (or even linear) functions in place of sigmoid.
This paper starts from the observation that multiple top performing pedestrian detectors can be modelled by using an intermediate layer filtering low-level features in combination with a boosted decision forest.
This paper proposes to perform unsupervised detection of bioacoustic events by pooling the magnitudes of spectrogram frames after per-channel energy normalization.
In this paper, we propose an effective tracking algorithm to alleviate the time-consuming problem. We design a deep flow collaborative network, which executes the expensive feature network only on sparse keyframes and transfers the feature maps to other frames via optical flow.
We improve Google's CNN-LSTM model by introducing concept-based sentence reranking, a data-driven approach which exploits the large amounts of concept-level annotations on Flickr.
We study approaches to recover a dense outlier map alongside the primary task with a single forward pass, by relying on shared convolutional features.
In this paper, we propose a new task and solution for vision and language: generation of grounded visual questions.
We consider reinforcement learning in input-driven environments, where an exogenous, stochastic input process affects the dynamics of the system. We derive a bias-free, input-dependent baseline to reduce this variance.
A novel unsupervised audiovisual learning model that synchronously performs sets of clustering with multimodal vectors of convolutional maps in different shared spaces in an end-to-end fashion.
We present a self-organizing neural network for the recognition of human-object interactions from RGB-D videos.
We propose a post-detection stage during which we explore the image with the objective of recovering missed detections.
We introduce hyperbolic attention networks to endow neural networks with enough capacity to match the complexity of data with hierarchical and power-law structure.
We show that log-linear training can be a highly ill-conditioned optimization problem, resulting in extremely slow convergence.
We examine learning in DNNs through analysis of their outputs. We investigate how training size and the incorporation of noise affect a DNN's ability to generalize and learn.
In this paper, we propose a novel unsupervised feature selection algorithm for image classification and clustering using ordinal preserving self-representation.
Dense RepPoints adaptively distributes a dense set of points to semantically and geometrically significant positions on an object, providing informative cues for object analysis.
Hyper-SAGNN is a self-attention based graph neural network applicable to homogeneous and heterogeneous hypergraphs with variable hyperedge sizes.
Video activity recognition, although being an emerging task, has been the subject of important research efforts due to the importance of its everyday applications.
This paper presents a self-supervised approach which learns visual representations from input images without human annotations.
We study the problem of grounding distributional representations of texts on the visual domain, namely visual-semantic embeddings (VSE for short), using textual contrastive adversarial samples to enforce the model to concrete concepts within the image.
In this paper, depth estimation and semantic segmentation are jointly addressed using a unified convolutional neural network under a unified framework under the assumption that integrating two highly correlated tasks may benefit each other to improve the estimation accuracy.
In this paper, we propose ShapeHD, pushing the limit of single-view shape completion and reconstruction by integrating deep generative models with adversarially learned shape priors.
We propose a new collaborative filtering recommendation method based on users' interest sequences (IS) that rank users’ ratings or other online behaviors according to the timestamps when they occurred.
We propose a knowledge-guided pose grammar network to tackle the problem of 3D human pose estimation.
A Bayesian method with spatial constraint is proposed for vessel segmentation in retinal images.
In this paper, we introduce a novel RGB-D based relative pose estimation approach that is suitable for small- overlapping or non-overlapping scans and can output multiple relative poses.
We propose a light-weight CNN architecture for mobile devices for real-time facial affective computing tasks.
In this work, doubly stochastic Poisson processes and convolutional neural net (CNN) classifiers are used to estimate the number of instances of an object in an image.
A novel algorithmic solution for efficient multi-query evaluation against a stream of graph updates and its applicability to a number of use cases.
We propose a controllable stylish image description generation model that learns to generate stylish image descriptions that are more related to image content.
A simple unsupervised method based on Gabor wavelet and Multiscale Line Detector for retinal vessel segmentation.
We introduce a novel machine learning framework to classify apathetic and non-apathetic patients based on analysis of facial dynamics, entailing both emotion and facial movement.
An improved random walk algorithm for OD segmentation to tackle complex challenges.
We propose User-Resizable Residual Networks (URNet), which allows users to adjust the scale of the network as needed during evaluation.
A large number of proteins in the nucleus and cytoplasm are exported by an exportin called CRM1 from either yeast, human or frog cell nuclei. Kirli, Karaca et al. propose that the export of such accidentally displaced proteins is a crucial measure to protect the nucleus.
We propose a black-box adversarial attack algorithm that can defeat both vanilla DNNs and those generated by various defense techniques developed recently.
An end-to-end processing pipeline for Glaucoma detection from retinal images includes the detection of optic disc (OD), neuroretinal rim (NRR), and optic cup (OC) segmentation, feature computation from the segmented OD and OC, and estimation of Glauca from these features.
We propose a statistical adaptive procedure called SALSA for automatically scheduling the learning rate (step size) in stochastic gradient methods using a statistical test for detecting stationarity.
In this paper, we propose a new augmentation method that leverages the first and second moments extracted and re-injected by feature normalization, and also interpolate the target labels.
A new convolutional neural network architecture for 2D driver/passenger pose estimation and seat belt detection is proposed in this paper.
In this paper, we introduce the tree-structured group sparsity regularization into the DCF-based formula for robust visual tracking.
In this paper, we propose a novel Deep Adversarial Disentangled Autoencoder capable of disentangling domain-specific features from class identity.
We propose a novel approach to generate natural-looking semantic adversarial examples by optimizing a particular adversarial loss over the range-space of a parametric conditional generative model.
We proposed a method based on learning to rank and multiple loss to achieve state-of-the-art image retrieval.
This article proposes a solution based on evidential grids and a particle filter to map the static environment and simultaneously estimate the position in a global reference at a high rate.
We introduce a HoG (Histogram of Oriented Gradients) tracker for Gesture Recognition.
We propose a 3D environment modelling method using multiple pairs of high-resolution spherical images. Reconstruction is based on stereo image pairs with a vertical displacement between camera views.
We develop a differentiable model for superpixel sampling that leverages deep networks for end-to-end trainable superpixel segmentation.
We present an approach to answer structured queries over text data without storing results in a database.
We systematically study the trade-off between the model complexity and the performance on the VQA task. Our thorough experimental evaluation leads us to two proposals, one optimized for minimal complexity and another optimized for state-of-the-art performance.
Target-specific scoring methods such as SVMSP may hold promise for the identification of small-molecule kinase inhibitors that exhibit some level of specificity toward the target of interest across a large number of proteins.
We propose a compact framework with guided attention for multi-label classification in the fashion domain, even without using any landmark annotations.
This paper describes the cascaded multimodal speech translation systems developed by Imperial College London for the IWSLT 2019 evaluation campaign.
We propose an algorithm to over-segment an image through the propagation of reflection symmetry evident at the pixel level to superpixel boundaries through an iterative algorithm.
In this paper, we focus on the problem of answer triggering ad-dressed by Yang et al. (2015), which is a critical component for a real-world question answering system.
In this paper, we design an adversarial backdoor embedding algorithm that can bypass the existing detection algorithms including the state-of-the-art techniques (published in IEEE S\&P 2019 and NeurIPS 2018).
In this paper, we focus on the camera localization problem using visual semantic information. We propose a coarse to a fine mechanism to localize the camera position.
In this paper, we propose a novel model for the TextVQA task based on a multimodal transformer architecture accompanied by a rich representation for text in images to answer a question.
In this paper, we prove that the weight decay term $\frac{1}{2}\lambda||{\boldsymbol{W}}||^2$ merely modulates the effective learning rate for improving objective optimization, and has no influence on generalization when the weight normalization family is compositely employed.
We present an alternative method to increase the depth by introducing computation orderings to the convolutional layers or blocks, based on which we gradually compute the outputs in a channel-wise manner.
We conducted a subjective comparison of nine state-of-the-art inpainting algorithms and propose objective quality metrics that exhibit high correlation with the results of our comparison.
In this work, we present a Multi-Channel deep convolutional Pyramid Person Matching Network based on the combination of the semantic-components and the color-texture distributions for person re-identification.
We perform an extensive analysis of fine-tuned BERT models using second order Hessian information, and we use a Hessian based mix-precision method to compress the model further.
In this paper, we introduce a novel form of value function, $Q(s, s')$, that expresses the utility of transitioning from a state $s$ to a neighboring state $ s'$ and then acting optimally thereafter.
We augment a hierarchical LSTM language model that generates sequences of word tokens character by character with a caching mechanism that learns to reuse previously generated words.
We present a CNN-based technique to estimate high-dynamic range outdoor illumination from a single low dynamic range image.
In this study, the influence of objects is investigated in the scenario of human action recognition with large number of classes. Trained Deep network models are used as object detectors.
We propose a variational inference approach to deep probabilistic video compression that combines advances in variational autoencoders for sequential data and combines it with recent work on neural image compression.
We design a framework for training deformable classifiers, where latent transformation variables are introduced, and a transformation of the object image to a reference instantiation is computed in terms of the classifier output, separately for each class.
We explore the properties of byte-level recurrent language models. When given sufficient amounts of capacity, training data, and compute time, the representations learned by these models include disentangled features corresponding to high-level concepts.
We propose an asymmetrical transfer learning framework, wherein three classifiers are trained using the RGB and depth images in the source domain and RGB images inthe target domain with a structural risk minimization criterion and regularization theory.
We make a thorough investigation on the attention mechanisms in a CNN-based SR model and shed light on how simple and effective improvements on these ideas improve the state-of-the-arts.
We propose large margin cosine loss, a novel loss function for face recognition, which achieves state-of-the-art performance on face recognition datasets.
We propose the Neuron Importance Score Propagation (NISP) algorithm to prune neurons in the entire neuron network jointly based on a unified goal of minimizing the reconstruction error of important responses in the FRL.
We propose a two-stream part-based deep representation for human attribute classification, leading to state-of-the-art results.
We propose a multilinear subspace learning technique suitable for applications requiring class-specific tensor models.
An image feature extraction method based on the two- dimensional 2-D mel cepstrum, which is extended to speech recognition, is introduced.
The recent success of deep network in visual trackers learning largely relies on human labeled data, which are however expensive to annotate. To address this problem, we propose a novel unsupervised learning pipeline based on the discriminative correlation filter network.
This paper presents a hardware implementation of a full high-definition depth estimation system that is capable of processing full HD resolution images with a maximum processing speed of 125 fps and a disparity search range of 240 pixels.
This paper address the problem of novel view synthesis by means of neural rendering, where we are interested in predicting the novel view at an arbitrary camera pose based on a given set of input images from other viewpoints.
We apply state-of-the-art deep learning models on a large-scale, geo-tagged and image-based dataset to efficiently estimate urban tree cover using Google Street View images.
We develop an Artificial Intelligence-based test for COVID-19 preliminary diagnosis. The test is deployable at scale through a mobile app named AI4COVID19.
A computational method that provides prospective predictions of potential DDI-induced ADRs will help to identify and mitigate these adverse health effects.
We propose an effective region proposal extraction method for YOLO network to constitute an entire detection structure named ACF-PR-YOLO, and take the cyclist detection problem to show our methods.
We developed a model for multilabel abnormality classification of chest CT volumes that uses a deep convolutional neural network (CNN) and developed a rule-based method for automatic label extraction.
We propose an Attention-based Multi-scale Attention Guided Module for saliency detection.
We propose a new layer called Separable Convolutional Eigen-Filters (SCEF) for reducing the complexity of a 2D convolutional network without sacrificing its accuracy.
Spectral pooling and complex-coefficient spectral parameterization of convolutional filters improve CNN design.
This paper presents a novel approach to estimating the continuous six degree of freedom (6-DoF) pose (3D translation and rotation) of an object from a single RGB image.
This paper provides an empirical analysis of the dependencies between data-sets, lexical resources and algorithms that are commonly used in text-to-text inference tasks.
We propose a multimodal convolutional neural network-based audio-visual video captioning framework for interpretable sentence generation and introduce a modality-aware module for exploring modality selection during sentence generation.
HF-PIM frontalizes the profiles through a novel texture warping procedure and leverages a dense correspondence field to bind the 2D and 3D surface spaces in a high-resolution manner.
We propose a novel rank aggregation method based on converting permutations into their corresponding Lehmer codes or other subdiagonal images and performing aggregation via simple median or mode computations.
We study deep learning approaches to inferring numerical coordinates for points of interest in an input image. Existing convolutional neural network-based solutions to this problem either take a heatmap matching approach or regress to coordinates with a fully connected output layer.
We propose a siamese architecture that learns a rotation equivariant hidden representation to reduce the need for data augmentation and achieves state-of-the-art cross-camera error rate.
We present a novel segmentation algorithm based on a hierarchical representation of images. The main contribution of this work is to explore the capabilities of the A Contrario reasoning when applied to the segmentation problem, and to overcome the limitations of current algorithms.
We investigated using ultrawide-field fundus images with a deep convolutional neural network (DCNN), which is a machine learning technology, to detect treatment-naive proliferative diabetic retinopathy (PDR)
In this paper, a novel approach for automatic anomaly detection is proposed. Our approach is highly efficient; thus it can perform real-time detection. Furthermore, it can also handle multiscale detection and can cope with spatial and temporal anomalies.
This paper describes a pipeline to integrate various sensor data and prior information, such as a Geospatial Information System (GIS) map, to segment and track moving objects in a scene.
We introduce probabilistic pixel-adaptive convolutions (PPACs), which not only depend on image guidance data for filtering, but also respect the network's confidence in its own predictions.
We propose a superpixel-based fast fast fuzzy c-means clustering algorithm for color image segmentation.
We propose PeelNet, an end-to-end generative adversarial framework for textured 3D reconstruction of the human body from a single RGB image.
We present PyTorch-BigGraph (PBG), an embedding system that incorporates several modifications to traditional multi-relation embedding systems that allow it to scale to graphs with billions of nodes and trillions of edges.
We present Group Normalization (GN), a simple alternative to batch normalization that can effectively replace the powerful BN in a variety of computer vision tasks.
We propose an approach based on a convolutional neural network pre-trained on a large-scale image classification task to estimate human fixations across complex natural scenes.
GLUT1 is an oligomer of allosteric, alternating access transporters in which cis-allostery is mediated by intrasubunit interactions and trans- allostery requires intersubunit interactions, and these findings reconcile contradictory conclusions from structural and transport studies.
The topic of object detection has been largely improved recently, especially with the development of convolutional neural network. However, there still exist a lot of challenging cases, such as small object, compact and dense or highly overlapping object. Existing methods can detect multiple objects wonderfully, but because of the slight changes between frames, the detection effect of the model will become unstable.
We propose a deep convolutional Laplacian Pyramid Compressed Sensing Network (LapCSNet) for CS that integrates multi-scale information to achieve better performance.
We introduce Skip-Clip, a method that utilizes temporal coherence in videos, by training a deep model for future clip order ranking conditioned on a context clip as a surrogate objective for video future prediction.
We formulate a generative latent tree (LT) model, its inference, and novel algorithms for efficient learning of both LT parameters and structure.
We present a novel framework for iterative visual reasoning. The framework consists of two core modules: a local module that uses spatial memory to store previous beliefs with parallel updates; and a global graph-reasoning module that combines the best of both modules with an attention mechanism.
This paper addresses the problem of 3D human pose and shape estimation from a single image. Previous approaches consider a parametric model of the human body, SMPL, and attempt to regress the model parameters that give rise to a mesh consistent with image evidence. In our work, we propose to relax this heavy reliance on the model's parameter space.
We propose a hierarchical deep cosegmentation approach that repeatedly divides a video into two sub-videos formed by the odd and even frames, respectively.
We present a novel unsupervised feature representation learning method, Visual Commonsense Region-based Convolutional Neural Network (VC R-CNN), to serve as an improved visual region encoder for high-level tasks such as captioning and VQA.
We propose a novel neighbor embedding method which learns an embedding simplex where the similarities between the mapped words are optimal in terms of minimal discrepancy to the input neighborhoods.
Convolution neural networks were implemented to detect the lowest 21 unique HG modes with an accuracy greater than 99%.
An instance segmentation neural network can be trained purely by a synthetically generated dataset for precision phenotyping of barley seeds.
In this paper, we report the results of our recent research into the understanding of the exact distribution of a smile across the face, especially the distinction between a genuine and a posed smile.
We propose a universal adversarial attack that reduces the top-1 accuracy of various network architectures on ImageNet to less than 20%, while learning the universal perturbation 13X faster than standard method.
In this paper, we propose a novel Hybrid-RL method that builds on MVE, namely the Risk Averse Value Expansion (RAVE). With imaginative rollouts generated by an ensemble of probabilistic dynamics models, we further introduce the aversion of risks by seeking the lower confidence bound.
We focus on the problem of class-agnostic instance segmentation of LiDAR point clouds. We propose an approach that combines graph-theoretic search with data-driven learning: it searches over a set of candidate segmentations and returns one where individual segments score well according to aData-driven point-based model of "objectness".
Improving monocular depth estimation using 2D planar observation from the remaining laser range finder without extra cost.
We propose a novel inter-color image registration algorithm for DCA-based range finding and color image enhancement.
This paper studies panoptic segmentation, a recently proposed task which segments foreground (FG) objects at the instance level as well as background (BG) contents at the semantic level.
In this paper, we propose a novel framework that simplifies face manipulation with extreme pose and expression into two correlated stages: a boundary prediction stage and a disentangled face synthesis stage.
We present an end-to-end trainable architecture to incorporate the information from these elements and the image to segment/identify the part of the image a natural language expression is referring to.
We propose a new adversarial robustness training paradigm called Guided Complement Entropy that improves model robustness without compromising performance.
We study the efficacy of transfer learning by examining how the choice of data impacts performance. We propose domain adaptive transfer learning, a simple and effective pre-training method using importance weights.
We investigate image-to-image translation using Generative Adversarial Networks (GANs for generating new data, taking as a case study the morphing of giraffes images into bird images.
Generative adversarial networks (GANs)successfully generate high quality data by learning amapping from a latent vector to the data. This paper proposes an effective algorithm to accurately infer the latent vector by utilizing GAN discriminator features.
We propose a method for cheap annotation based on chroma-keying, thereby bypassing weeks of human effort required to label such data.
We present DeepPerimeter, a deep learning based pipeline for inferring a full indoor perimeter (i.e. exterior boundary map) from a sequence of posed RGB images.
We propose a novel unsupervised hashing framework in which feature aggregating and hashing are designed simultaneously and optimized jointly. This leads to more discriminative binary hash codes.
The rising challenges in the field of iris recognition, concerning the development of accurate recognition algorithms using images acquired under an unconstrained set of conditions, is leading to a renewed interest in the area. The proposed work focused on mutual context information from iris centre and iris limbic contour to perform robust and accurate Iris segmentation in noisy images.
We propose Sparsely Grouped Generative Adversarial Networks (SG-GAN), a novel approach that can translate images in sparsely grouped datasets where only a few train samples are labelled.
We introduce a novel training scheme for multi-task models that automatically generates synthetic training triplets by inferring the missing element on the fly, thus enabling end-to-end training.
We study the problem of how to defend classifiers against adversarial attacks that fool the classifiers using subtly modified input data. We propose RIDE, an efficient and provably convergent self-supervised learning algorithm for individual data estimation to protect the predictions.
We propose an activation function based on the conditioning of the RGB and ICP point-to-plane error terms, which strengthens the geometric error influence in the first coarse iterations, while the intensity data term dominates in the finer increments.
In this work, we explore the impact of visual modality in addition to speech and text for improving the accuracy of the emotion detection system.
We introduce a new saliency map model which formulates a map as a generalized Bernoulli distribution and use novel loss functions which pair the softmax activation function with measures designed to compute distances between probability distributions.
In this paper, we propose a novel example-based face hallucination method through nonparametric Bayesian learning based on the assumption that human faces have similar local pixel structure.
We propose a siamese training scheme for a deep convolutional neural network that decomposes a captured scene into its albedo and shading images, discarding the need for any ground truth annotations.
QGMRN can fuse the visual and textual modalities in multiple semantic levels which makes the fusion occur in a fine-grained way.
The biologically inspired hierarchical model for object recognition, Hierarchical Model and X (HMAX), has attracted considerable attention in recent years. To address this issue, the authors propose a novel patch selection method for HMAX called saliency and keypoint-based patch selection (SKPS), which is based on a saliency (attention) mechanism and multi-scale keypoints.
We propose a novel method which trains a student to match the predictions of its teacher without using any data or metadata.
We have developed a Linked Data framework which can automate the extraction of know-how from existing Web resources and generate links to related knowledge on the Linked data Cloud.
We present a probabilistic deep latent variable model that can represent both discrete labels and continuous observations as well as latent dynamics over time. This allows us to solve several tasks at once without explicit fine-tuning.
In this paper, we introduce a cascade semantic fusion architecture (CSF) to mine the representative features to encode image content through attention mechanism without bells and whistles.
We build a large-scale Human Activity Knowledge Engine (HAKE) based on the human body part states for activity understanding.
Training a deep neural network is a non-trivial task. Not only the tuning of hyperparameters, but also the gathering and selection of training data, the design of the loss function, and the construction of training schedules is important to get the most out of a model.
We propose a gating function to selectively emphasize such fine common local patterns by comparing the mid-level features across pairs of images.
The 2.0 release of the Universal Dependency treebanks demonstrates the effectiveness of the UD scheme to cope with very diverse languages. In this work we propose to go further and enrich the enhanced dependency scheme along two axis: extending the cases of recovered arguments of non-finite verbs, and neutralizing syntactic alternations.
The neuropeptide oxytocin modulates gazing behavior during emotional perception in domestic dogs through a mechanism that may facilitate communication between humans and dogs.
We propose a novel attribute-guided cross-resolution (low-resolution to high-resolution) face recognition framework that leverages a coupled generative adversarial network (GAN) structure with adversarial training to find the hidden relationship between the low-resolution and high- resolution images in a latent common embedding subspace.
We consider the problem of selective prediction (also known as reject option) in deep neural networks, and introduce SelectiveNet, a deep neural architecture with an integrated reject option.
This paper investigates community detection by modularity maximisation on bipartite networks, where each algorithm maximises a different modularity function and sees different aspects of the bipartisan structure.
Hierarchy-Aware Knowledge Graph Embedding can effectively model semantic hierarchies in knowledge graphs, and significantly outperforms state-of-the-art methods on benchmark datasets for the link prediction task.
We propose OpeN-ended Centre nEt (ONCE), a detector designed for incrementally learning to detect novel class objects with few examples.
In this paper we present the results of an investigation of the importance of verbs in a deep learning QA system trained on SQuAD dataset.
Joint distribution matching (JDM) problem, which aims to learn bidirectional mappings to match joint distributions of two domains, occurs in many machine learning and computer vision applications. However, the resultant optimization problem is still intractable. In this paper, relying on optimal transport theory, we propose to address JDM problem by minimizing the Wasserstein distance of the joint distributions in two domains.
We propose a method of stacking multiple long short-term memory (LSTM) layers for modeling sentences using the soft gating mechanism of LSTMs.
We propose a method based on the Bayes' rule, that can naturally incorporate class imbalance into the Active Learning framework, significantly improving the state of the art.
We consider the problem of dense depth prediction from a sparse set of depth measurements and a single RGB image. We propose the use of a regression network to learn directly from the RGB-D raw data, and explore the impact of number of depth samples on prediction accuracy.
We explore an efficient variant of convolutional sparse coding with unit norm code vectors and reconstructions are evaluated using an inner product (cosine distance).
We investigate a contrastive coding scheme, in which a self-supervsied representation is learned that maximizes mutual information between different views but is otherwise compact. The resulting learned representations perform above the state of the art for downstream tasks such as object classification.
The main goal of this paper is to illustrate a geometric analysis of 3D facial shapes in the presence of varying facial expressions.
We introduce a probabilistic model that explicitly recognizes a variety of nuclear localization signals, and integrates relevant amino acid sequence and interaction data for any candidate nuclear protein.
In this paper we present a bottom up procedure for segmentation of text lines written or printed in the Latin script.
A large scale integration of bio-entity relationship information from both databases containing manually annotated, structured information and automatic information extraction of unstructured text in scientific literature.
We propose a weakly supervised adversarial domain adaptation to improve the segmentation performance from synthetic data to real scenes, which consists of three deep neural networks.
We used a structural model of human P-gp that we obtained from molecular dynamics experiments as the protein target for ligand docking. We employed a novel approach of subtractive docking experiments that identified ligands that bound predominantly to the nucleotide binding domains but not the drug-binding domains of P- gp.
I present a new way to parallelize the training of convolutional neural networks across multiple GPUs.
We propose to automate the response measurement through video recording of the scene following the use of Deep Neural models for human action recognition from videos, improving state-of-the-art multi-class humanaction recognition models in-spite of supervision with scarce data.
We show that optimal performance results from discarding some context in a greedy manner, while maintaining the simplicity of the algorithm.We highlight the relation between context and data variance context.We analyse the value of context in the Supervised Descent Method.
We propose the first end-to-end algorithm for Zero-shot learning in video classification.
We propose to overcome the SSS problem in re-identification distance metric learning by matching people in a discriminative null space of the training data.
We propose a novel approach to learning the joint distribution between the data and a latent code which uses an adversarially learned iterative procedure to gradually refine the Joint distribution, $p(x, z)$, to better match with the data distribution on each step.
We propose a novel network architecture that combines deep deconvolutional neural networks with CNNs for multi-patch training for scene parsing.
We propose a simple yet effective convolutional spatial propagation network (CSPN) to learn the affinity matrix for depth prediction.
We investigate whether domain knowledge for emoji can improve the accuracy of emoji recommendation task in case of multimedia posts composed of image and text.
We reduce the problem of generating adversarial examples that violate First-Order Logic constraints to a combinatorial optimisation problem, by maximising a quantity measuring the degree of violation of such constraints and by using a language model for generating linguistically-plausible examples.
We present a temporal 6-DOF tracking method which leverages deep learning to achieve state-of-the-art performance on challenging datasets of real world capture while maintaining real-time performance.
We propose ConsSent, a simple yet surprisingly powerful unsupervised method to learn universal distributed representations of sentences by enforcing consistency constraints.
We demonstrate that modern image recognition methods based on artificial neural networks can recover hidden information from images protected by various forms of obfuscation.
We train a convolutional neural network to predict a statistical summary of the sound associated with a video frame. The network learns a representation that conveys information about objects and scenes.
This paper addresses statistical tricks found in deep convolutive neural networks, where each cell yields scores instead of class labels. The same kind of marginalization is implemented in an ensemble of K-nearest neighbours cells.
In this paper we provide an evaluation of 4 state-of-the-art deep neural network models for object detection under various levels of video compression.
We propose a novel top-down refinement approach to augment feedforward nets for object segmentation with a novel bottom-up/top-down architecture.
In this work, we aim at building a simple, direct, and fast instance segmentation framework with strong performance. We follow the principle of the SOLO method of Wang et al.
We study this Dual Policy Iteration (DPI) strategy in an alternating optimization framework and provide a convergence analysis that extends existing API theory.
 eXpression2Kinases (X2K) computationally predicts involvement of upstream cell signaling pathways, given a signature of differentially expressed genes.
We propose a category-agnostic keypoint representation, which combines a multi-peak heatmap (StarMap) for all the keypoints and their corresponding features as 3D locations in the canonical viewpoint (CanViewFeature) defined for each instance.
We propose Fault-Tolerant Neural Architecture Search (FT-NAS) to automatically discover convolutional neural network (CNN) architectures that are reliable to various faults in nowadays edge devices.
We propose a new task of generat-ing commonsense rationales for Visual QuestionAnswering that injects com-monsense understanding in the VQA model.
A survey of existing metric learning approaches for object re-identification.
We show that the residual network and its variants with noise injection can be regarded as weak approximations of stochastic differential equations and propose a novel perspective on the effects of regularization from the loss landscape viewpoint.
This paper presents a salient object extraction method based on fusing textural and structural information, which achieves state-of-the-art performance.
We present KG-AUTOENCODER, an autoencoder that bases the structure of its neural network on the semanticsaware topology of a knowledge graph thus providing a label for neurons in the hidden layer that are eventually used to build a user profile and then compute recommendations.
We propose a recurrent neural model that generates natural-language questions from documents, conditioned on answers, and use the model to improve the performance of question answering systems.
Learning to simultaneously handle face alignment of arbitrary views, e.g. frontal and profile views, appears to be more challenging than we thought. In this study, we address this shortcoming through learning an Ensemble of Model Recommendation Trees (EMRT), which is capable of selecting optimal model configuration without prior head pose estimation.
We develop AntMan, combining structured sparsity with low-rank decomposition synergistically, to reduce model computation, size and execution time of RNNs while attaining desired accuracy.
We study robust algorithms for the Influence Maximization problem, in which the goal is to identify a set of k nodes in a social network whose joint influence on the network is maximized.
In this paper, we propose a new channel pruning method by explicitly using both intermediate outputs of the baseline model and the classification loss of the pruned model to supervise layer-wise channel selection.
We propose a way of transferring domain knowledge on depth estimation to a separate image classification task over a disjoint set of train, and test data.
We consider the task of learning to estimate human pose in still images. In order to avoid the high cost of full supervision, we propose to use a diverse data set, which consists of two types of annotations: (i) a small number of images are labeled using the expensive ground-truth pose; and (ii) other images are labelled using the inexpensive action label.
FastMask uses hierarchical features in deep convolutional neural networks to segment multi-scale objects in one shot in near real time.
We investigate the multi-label AU detection problem by embedding the data on low dimensional manifolds which preserve multi-Label correlation.
In this paper we present minimal solutions for two-view relative motion estimation based on a homography formulation. We demonstrate that rotation and translation estimation can be decoupled.
We propose a novel formulation of the low-rank tensor completion problem that is based on the duality theory and a particular choice of low-Rank regularizer.
We propose a novel method to analyze and understand a classifier's errors, allowing the user to focus their attention on relevant areas of the data space.
We propose a pseudo-multimodal object detector trained on natural image domain data to help improve the performance of object detection in thermal images.
We propose a novel method to corrupt object detectors by adding small perturbations to patches in the background outside the object.
This paper presents a method of learning deep AND-OR Grammar (AOG) networks for visual recognition, which we term AOGNets.
We propose a deep inverse rendering framework for indoor scenes. From a single RGB image of an arbitrary indoor scene, we create a complete scene reconstruction, estimating shape, spatially-varying lighting, and spatially varying, non-Lambertian surface reflectance.
We introduce Sliced-Wasserstein Autoencoders (SWAE), generative models that enable one to shape the distribution of the latent space into any samplable probability distribution without the need for training an adversarial network or defining a closed-form.
In this letter, we introduce iBoW-LCD, a novel appearance-based loop-closure detection method that uses an incremental bag-of-words scheme based on binary descriptors to retrieve previously seen similar images.
A novel face recognition method is proposed, in which face images are represented by a set of local labeled graphs, each containing information about the appearance and geometry of a 3-tuple of face feature points, extracted using Local Feature Analysis technique.
We propose a numerical MRC model named as NumNet, which utilizes a numerically-aware graph neural network to consider the comparing information and performs numerical reasoning over numbers in the question and passage.
In this paper, we propose a new geometric-temporal representation for visual action recognition based on local spatio-Temporal features.
Fine-tuning language models to predict brain activity of people reading text will lead to representations that encode more brain-activity-relevant language information, improving the model's ability to perform downstream NLP tasks.
This paper proposes a method to ease the unsupervised learning of object landmark detectors. The method uses the pre-trained network as a core which remains frozen and does not get updated during training.
We propose a novel pseudo-Bayesian algorithm that explicitly compensates for design weaknesses in many existing non-convex approaches leading to state-of-the-art performance with a sound analytical foundation.
In this paper, we propose a new approach to sequence pair matching with Transformer, by learning head-wise matching representations on multiple levels.
This article presents a feature-based framework to automatically track 18 facial landmarks for emotion recognition and emotional dynamic analysis.
In this paper, we introduce a new DCNN model called the Inception Recurrent Residual Convolutional Neural Network (IRRCNN), which utilizes the power of the Recurrent convolutional neural network (RCNN) and Inception-residual network (IRCNN) for improved recognition accuracy.
We present Deep Matching LiDAR Odometry (DMLO), a novel learning-based framework which makes the feature matching method applicable toLiDAR odometry task. Unlike many recent learning- based methods, DMLO explicitly enforces geometry constraints in the framework.
In this paper, we propose a virtual label called Multi-pseudo Regularized Label (MpRL) and assign it to the generated data to train a deep neural network in a semi-supervised learning fashion.
We propose an algorithm for recovering depth using less than two images using only a fraction of the pixels.
This paper concerns the validation of automatic retinal image analysis algorithms processing color fundus camera images, currently the largest section of the ARIA literature.
This paper proposes to solve the SSL problem by building a novel density-aware graph, based on which the neighborhood information can be easily leveraged and the feature learning and label propagation can also be trained in an end-to-end way.
Convolutional Neural Network (CNN) models can be forced to learn successively coarse to fine concepts in the internal layers at the output stage in decreasing order of class abstraction.
Protein-protein interactions for model organisms based solely on sequence-based prediction.
In this paper, we propose to create multiple and independent random binary codes per input class and train ensemble of homogeneous CNN classifiers with these codes to improve the adversarial robustness of the networks.
We proposed a new temporal convolution network called Multipath Temporal ConvNet (MTN), which consists of two parts i.e.multipath DenseNet and SE-ConvNet, for temporal action proposal generation.
We explore the use of a knowledge graphs, that capture general or commonsense knowledge, to augment the information extracted from images by the state-of-the-art methods for image captioning.
We incorporate the gray-level co-occurrence matrix (GLCM) to extract patterns that our prior knowledge suggests are superficial: they are sensitive to the texture but unable to capture the gestalt of an image. We introduce two techniques for improving our networks' out-of-sample performance.
We propose a convolutional neural network based method for recovering homography from hand-held camera captured document images.
In this paper, we present a novel parallel image segmentation algorithm which segments images in real-time in a non-parametric way in the superparamagnetic phase of the system.
We propose a novel framework of Error-Correcting Networks (ECN) to address the challenge of learning in the presence structured error in fine-grained annotations.
We introduce a cascade architecture for a multi-stage, coarse-to-fine HOI understanding, which can be used for relation detection and segmentation.
A semi-automatic method for cleaning the noisy large face datasets with the use of face recognition.
We propose an efficient DNN testing method based on the conditioning on the representation learned by the DNN model under testing, leveraging cross entropy minimization.
We provide a comprehensive review of the literature at the time of this writing, covering a broad spectrum of pioneering works for semantic and instance-level segmentation using deep learning models.
Parameterized Principal Component Analysis (PPCA) is a novel manifold approximation method that models data with linear subspaces that change continuously according to the extra parameter of contextual information.
We propose the locally constrained mixed-diffusion method, which partly fuses the given measures into one and propagates on the resulted locally dense data space.
In this article, a system is proposed for the identification of casting defects in X-ray images using the Mask Region-based CNN architecture.
We present a principled approach for detecting out-of-distribution (OOD) and adversarial samples in deep neural networks using parametric probability distributions.
We propose a new algorithm for learning kernels for variants of the Normalized Cuts (NCuts) objective which permits a nice SDP relaxation, which improves on the state-of-the-art.
In this paper, we propose MiXing-LSTM to capture the interplay between positions and head orientations (vislets) thanks to a joint unconstrained optimization of full covariance matrices during the LSTM backpropagation. The proposed approach also allows for accurate predictions on a longer time horizon.
We describe a very simple bag-of-words baseline for visual question answering. This baseline concatenates the word features from question and CNN features from the image to predict the answer.
We propose "Scene-Net", a new deep convolutional neural network (CNN) structure, based on which we build a novel scene sketch recognition system. Our system has been tested on the collected scene sketch dataset.
We use bioinformatics-based integrative approach to identify and prioritize putative p53-regulated miRNAs, and unravel the miRNA-based microregulation of the p53 master regulatory network.
We propose a recurrent generative model that can be trained using adversarial training.
This paper summarizes recent developments in this field and makes a plea for more interpretability in artificial intelligence. Furthermore, it presents two approaches to explaining predictions of deep learning models.
We propose a generative adversarial network (GAN) based model for synthesizing realistic person images conditional on pose and using it to learn discriminative identity-sensitive and view-invariant features.
We augment the high-resolution representation by aggregating the (upsampled) representations from all the parallel convolutions. This simple modification leads to stronger representations, evidenced by superior results.
We present an action anticipation model that enables the prediction of plausible future actions by forecasting both the visual and temporal future, and then performing action anticipation using these predictions.
We give an overview over 24 recently developed NLIs for databases. We categorize the NLIs into four groups based on the methodology they are using.
We first propose a fully learning-based, camera distance-aware top-down approach for 3D multi-person pose estimation from a single RGB image.
We propose a different "proximal" approach to optimize image analysis networks against quantitative perceptual models, in which a proxy network mimics the perceptual model while serving as a loss layer.
We propose contextual decomposition explanation penalization (CDEP), a method which enables practitioners to leverage existing explanation methods in order to increase the predictive accuracy of deep learning models.
An efficient Re-Id approach based on a highly discriminative hybrid person representation which combines the low-level hand-crafted appearance based features together with the mid-level attributes and semantic based deep features for robust person matching.
We introduce a neuron-level Selective Context Aggregation module for scene segmentation.
We propose a new optimization algorithm, Lookahead, that is orthogonal to these previous approaches and iteratively updates two sets of weights. The algorithm chooses a search direction by looking ahead at the sequence of ``fast weights" generated by another optimizer.
Our goal is to decorrelate feature representations of a category from its co-occurring context to improve the robustness of the learnt feature representations without compromising on performance.
We replace continuous absolute condition with relative condition, specifically, relative action units, for high-quality expression editing.
We propose a new norm Basis-path Norm based on a group of linearly independent paths to measure the capacity of neural networks with Rectified Linear Unit activation function.
A domain adaptation method for urban scene segmentation that learns target-specific discriminative representations.
We propose DualDis, a new auto-encoder-based framework that disentangles and linearizes class and attribute information in computer vision.
Our proposed framework attempts to bridge the gap between sentence selection and fusion to support summarizing by both compressing single sentences and fusing pairs.
We present Optimal Transport GAN (OT-GAN), a variant of generative adversarial nets minimizing a new metric measuring the distance between the generator distribution and the data distribution.
We propose a novel continuous-level learning framework using a Filter Transition Network (FTN) which is a non-linear module that easily adapt to new levels, and is regularized to prevent undesirable side-effects.
In this paper, we introduce the attentioned distillation module in our previous work Occlusion-adaptive Deep Network (ODN) model to improve performance.
We exploit the spatio-temporal proximity distribution of local features in 3D space to characterize geometric context of action class.
The seemingly infinite diversity of the natural world arises from a relatively small set of coherent rules, such as the laws of physics or chemistry. We conjecture that these rules give rise to regularities that can be discovered through primarily unsupervised experiences and represented as abstract concepts. This paper describes a new framework for learning such abstractions in the visual domain.
We describe a method for 3D human pose estimation from transient images (i.e., a 3D spatio-temporal histogram of photons) acquired by an optical non-line-of-sight imaging system.
We present a deep layered architecture that generalizes convolutional neural networks (ConvNets), showing a gain in accuracy over ConvNets when computational resources at run-time are limited.
We develop an efficient tensor transformation scheme to protect the private information carried by elements' values of a tensor. Then we design a privacy-preserving outsourcing algorithm for CP tensor decompositions.
We propose an integrated multiple deep learning models reuse and prediction strategy, which greatly increases the feasibility of the digital retina in processing and analyzing the large-scale visual data in smart cities.
We present a proposal learning approach to boost accuracies of proposal-based object detectors (a.k.a. two-stage object detectors) by training on both labeled and unlabeled data.
Segmentation of Fundus images using convolution 8 directions without initialization .
We use a combination of convolutional-neural-network-generated static features and motion features in the form of motion tubes for activity recognition.
Building on crucial insights into the determining factors of the visual integrity of an image and the property of deep convolutional neural network, we have developed the Deep Feature Consistent Deep Image Transformation (DFC-DIT) framework which unifies challenging one-to-many mapping image processing problems such as image downscaling, decolorization (colour to grayscale conversion) and high dynamic range (HDR) image tone mapping.
We propose a novel and effective optical flow conditioned method for video prediction with an application to complex urban scenes.
We propose a novel loss function to impose a large margin on any chosen set of layers of a deep network (including input and hidden layers).
We combined ResNet, DenseNet, ShuffleNet and Highly Efficient Networks(HENet) to improve the efficiency of convolutional neural networks.
In this paper, we detail our submission to the 2019, 7th year, BioASQ competition. We present our approach for Task-7b, Phase B, Exact Answering Task using BioBERT.
In this paper, we present an approach based on convolutional neural networks (CNNs) for facial expression recognition in a difficult setting with severe occlusions.
We introduce masked convolutional generative flow (MaCow), a simple yet effective architecture of generativeFlow that achieves significant improvements over Glow for density estimation on standard image benchmarks.
We achieve 3D semantic scene labeling by exploring semantic relation between each point and its contextual neighbors through edges in a hierarchical graph framework.
We propose a two-stage multi-task learning framework for dimensional emotion recognition on static images.
We propose a gated bi-directional CNN (GBD-Net) to pass messages among features from different support regions during both feature learning and feature extraction.
A novel multi-layer MemNet-based memory decoder for video captioning.
We introduce a learning-based forensic detector which adapts well to new domains, i.e., novel manipulation methods and can handle scenarios where only a handful of fake examples are available during training.
In this paper we propose a novel extension of the MF approach, namely the MF-FDOG, to detect retinal blood vessels and achieve competitive vessel detection results.
We combine the strengths of both architectures and propose a novel and unified model called C-LSTM for sentence representation and text classification.
We present a rotation-and-scale invariant airplane proposal generator for automatic airplane detection in aerial imagery.
We introduce Adversarial Discriminative Domain Generalization and Multiclass ADDoG, which improve upon baseline state-of-the-art methods for cross-corpus speech emotion recognition.
We propose a single end-to-end trainable deep neural network, convolutional gated recurrent Mask-RCNN, for tackling the semi-supervised VOS task.
A real-time algorithm for accurate localization of facial landmarks in a single monocular image is proposed.
We propose a new architecture for combining RL with recommendation systems which obviates the need for hand-tuned features, thus automating the state-space representation construction process.
We propose a data augmentation algorithm that learns to optimize augmentation strategies by narrowing down search space and adopting the best parameters discovered in previous iterations.
We propose DualConvMesh-Nets (DCM-Net) a family of deep hierarchical convolutional networks over 3D geometric data that combines two types of convolutions.
A robust edge detection algorithm using multiple threshold approaches (B-Edge) is proposed to cover both the limitations.
Hierarchical Multi-scale Attention Network for Action Recognition .
Heat Conduction is a non-progressive influence model with real-world interpretations. We present a scalable and provably near-optimal greedy algorithm for influence maximization.
We extend the success of deep convolutional neural network to depth super-resolution. We propose to exploit the depth field statistics and the local correlation between depth image and color image.
We investigate omni-supervised learning in which the learner exploits all available labeled data plus internet-scale sources of unlabeled data, offering the potential to surpass state-of-the-art fully supervised methods.
We present a new deep point cloud rendering pipeline through multi-plane projections. The input to the network is the raw point cloud of a scene and the output are image or image sequences from a novel view.
We propose an automatic threshold optimization method for sound event detection using convolutional recurrent neural networks.
In this paper we propose a supervised object recognition method using new global descriptors which are invariant to geometric transformations.
We have proposed a system with the objective to help the visually impaired by providing audio aid guiding them to avoid obstacles in their daily routines.
We present a novel regularization approach to train neural networks that enjoys better generalization and test error than standard stochastic gradient descent, using cross-validation principles.
We propose a new, hybrid approach that combines manual selection of features of potential interest with existing automated classification methods to improve accuracy and interpretability of the network classification results.
We propose Locality-aware AutoEncoder (LAE), which combines fine-grained representation learning and enforcing locality in a unified framework.
We leverage the large-scale unlabeled yet naturally paired data for visual representation learning in the driving scenario. We postulate that success on this task requires the network to learn semantic and geometric knowledge.
An increase in the number of convolutional filters on traditional activation functions performs equal-to or better-than maxout networks for different entity recognition tasks.
We introduce a ring parallel architecture based on Message Passing Interface, which is a reliable communication protocol and supported by multiple programming languages.
We propose a novel approach to complete the partial point cloud in two stages using a joint loss function to guide the distribution of the points.
HybridNet is a two-branch encoder-decoder architecture for leveraging unlabeled data to improve generalization performances of image classifiers.
We present an algorithm for constructing 3D panoramas from a sequence of aligned color-and-depth image pairs using dual lens cell phone cameras that reconstruct depth maps.
We propose an approach based on disentangled representation for generating diverse outputs without paired training images.
We introduce a Deep Learning regression architecture for structured prediction of 3D human pose from monocular images or 2D joint location heatmaps that relies on an overcomplete autoencoder to learn a high-dimensional latent pose representation and accounts for joint dependencies.
We question the generalization performance of the state-of-the-art convolutional neural network (CNN) models on the classification of two most common neurodegenerative diseases, namely Alzheimer's Disease (AD) and Parkinson's disease (PD) using MRI.
We first propose two novel approaches that not only penalize the prediction on confusing answers but also guide the training with alignment information distilled from the ensemble.
The comprehension of environmental traffic situation largely ensures the driving safety of autonomous vehicles. More intuitively, we transform the problem into calculating the interaction-aware drivable spaces.
We improve both volumetric CNNs and multi-view CNNs according to extensive analysis of existing approaches, and introduce multi-resolution filtering in 3D.
We show that the representation of an image in a deep neural network (DNN) can be manipulated to mimic those of other natural images, with only minor, imperceptible perturbations to the original image.
In real-time display advertising, ad slots are sold per impression via an auction mechanism. For an advertiser, the campaign information is incomplete --- the user responses (e.g, clicks or conversions) and the market price of each ad impression are observed only if the advertiser's bid had won the corresponding ad auction. A common solution for learning over such censored data is to reweight data instances to correct the discrepancy between training and prediction.
In this paper, we aim at discovering genetic factors of psoriasis through searching for statistically significant SNP-SNP interactions exhaustively from two real Psoriasis genome-wide association study datasets (phs000019.v1 and phs000982.p1) downloaded from the database of Genotypes and Phenotypes.
We propose new taxonomies to categorize and summarize the state-of-the-art network representation learning techniques according to the underlying learning mechanisms, the network information intended to preserve, and the algorithmic designs and methodologies.
We propose a novel weakly-supervised framework by adversarial learning of two modules for minimizing the video-level classification loss and eliminating demerits.
We propose a novel two-pronged pedestrian detection network that localizes the head-shoulder and full body regions based on a feasible object detection backbone. We validate the effectiveness of the proposed method using the CUHK-SYSU and CityPersons datasets.
We propose an Eulerian motion representation for action recognition, based on complex Gabor filters.
We present an end-to-end joint training framework that explicitly models 6-DoF motion of multiple dynamic objects, ego-motion and depth in a monocular camera setup without supervision.
We propose an efficient and extendible SR framework based on local classification instead of traditional dictionary learning.
We present a novel Heterogeneous Traffic Motion and Interaction model (HTMI) to predict the motion of agents by modeling collision avoidance and interactions between agents.
We propose Answer-Clue-Style-Aware Question Generation (ACS-QG), which aims at automatically generating high-quality and diverse question-answer pairs from unlabeled text corpus at scale by imitating the way a human asks questions.
Knowledge graph (KG) completion aims at filling the missing facts in a KG, where a fact is typically represented as a triple in the form of (head, relation, tail)
This paper presents a new metric called TIGEr for the automatic evaluation of image captioning systems. Building upon a machine-learned text-image grounding model, TIG er allows to evaluate caption quality not only based on how well a caption represents image content, but also onHow well machine-generated captions match human- generated captions.
We propose the first generic attack model for GANs that can be instantiated in various settings according to adversary's knowledge about the victim model.
We propose a novel Angular Deep Supervised Hashing method for image retrieval to optimize the deep features structure in the hash space from a perspective of angular view.
We propose a deep learning framework that combines a local strategy, to propagate colors frame-by-frame ensuring temporal stability, and a global strategy, using semantics for color propagation within a longer range.
We propose a novel approach that uses a single forward pass to adapt a general-purpose segmentation model to the appearance of a specific object.
We propose novel 3D-CNN using 3D architecture to model actions and motion representation in an efficient way to be accurate and also as fast as real-time.
We provide an extensive evaluation of triplet loss applied to vehicle re-identification and demonstrate that using the recently proposed sampling approaches for mining informative data points outperform most of the existing state-of-the-art approaches for vehicle re -identification.
We develop a novel framework that uses the PointNet representation to align point clouds and perform registration for applications such as tracking, 3D reconstruction and pose estimation.
We describe an approach to reducing the computational cost of identifying coreferent instances in heterogeneous semantic graphs where the underlying ontologies may not be informative or even known.
This paper proposes the first end-to-end DNN training framework that provides quantitative energy guarantees.
We propose a novel Deep Pyramid Feature Learning (DPFL) CNN architecture for multi-scale appearance feature fusion optimised simultaneously by concurrent per-scale re-id losses and interactive cross-scale consensus regularisation in a closed-loop design.
We analyze the pros and cons of two widely adopted optimization objectives for training VSE and propose a novel hubness-aware loss function (HAL) that addresses previous methods' defects.
This paper presents a complete system for automatic recognition and the diagnosis of electrical insulator strings which efficiently combines different deep learning-based components to build a versatile solution to the automation problem of the power line inspection process.
We identified pyrazolidine-3,5-diones as a new small molecule with inhibitory potential down to the submicromolar range against C4 PEPC and a selectivity factor of up to 16 over C3 PEPC.
We explore the use of synthetic data for training CNN-based intrinsic image decomposition models, then applying these learned models to real-world images.
This paper presents a LIDAR-based framework, which provides fast detection of 3-D urban objects from point cloud sequences of a Velodyne HDL-64E terrestrial LIDar scanner installed on a moving platform.
We propose a new segmentation model combining common regularization energies, e.g. Markov Random Field (MRF) potentials, and standard pairwise clustering criteria like Normalized Cut (NC), average association (AA), etc.
We propose a dissimilarity-based approach for action recognition in video where classification is performed in terms of minimum distance from templates, which achieves state-of-the-art results.
We propose an attention-based end-to-end neural network that learns multi-sensory association for the task of person verification.
We propose methods to reduce the latent space dimension of flow models to achieve exact log-likelihood with reduced dimensionality.
We propose Deep Alignment Network (DAN), a robust face alignment method based on a deep neural network architecture that uses entire face images at all stages.
This paper considers the task of matching images and sentences. The challenge consists in discriminatively embedding the two modalities onto a shared visual-textual space.
We propose a new encoder-decoder approach to learn distributed sentence representations that are applicable to multiple purposes, including sentence reconstruction and future sentence prediction.
We propose a sensor fusion scheme which integrates camera videos, motion sensors (GPS/IMU), and a 3D semantic map in order to achieve robustness and efficiency of the system.
We introduce OpenSketch, a dataset of product design sketches aimed at offering a rich source of information for a variety of computer-aided design tasks.
We implemented and simulated CNNs on resistive crossbar circuits with consideration of parasitic resistances and proposed a new mapping scheme for high utilization of crossbar arrays on convolution, and a mitigation algorithm to mitigate parasitic resistures in CNN applications.
A hierarchical image matting model is proposed to extract blood vessels from fundus images.
In many personalized recommendation problems available data consists only of positive interactions (implicit feedback) between users and items. This problem is also known as One-Class Collaborative Filtering (OC-CF). Linear models usually achieves state-of-the-art performances on OC-CF problems and many efforts have been devoted to build more expressive and complex representations able to improve the recommendations.
We present a representation learning method for denoising autoencoders that learns features at multiple different scale.
We present a Temporal Context Network (TCN) for precise temporal localization of human activities.
We introduce a novel Recurrent Neural Network-based algorithm for future video feature generation and action anticipation using only some of the earliest frames of a video.
We augment the raw image input to a Deep Q-Learning Network (DQN), by adding details of objects and structural elements encountered, along with the agent's localisation into its policy-learning framework.
We propose a novel B-COSFIRE filter for the automatic segmentation of vessel trees in retinal fundus images. It achieves rotation invariance efficiently by simple shifting operations.
We propose three high-quality matching systems and a Coarse-to-Fine RANSAC estimator. The experiments are conducted in four large-scale datasets using strictly defined evaluation metrics.
A novel framework for semi-supervised domain adaptation by unifying the learning of opposite structures (UODA)
This paper focuses on addressing a practical problem in fashion style transfer, person-to-person clothing swapping, which aims to visualize what the person would look like with the target clothes worn on another person instead of dressing them physically.
We propose a position-sensitive axial-attention layer that is parameter-efficient and 27x computation-efficient, a novel building block that one could stack to form a fully attentional network.
We develop hierarchical Bayesian neural networks to capture subject-specific variations and share statistical strength across subjects.
An end-to-end metal artifact reduction algorithm that is computationally efficient textcolorredand therefore practical and fits well into existing CT workflows allowing easy adoption in existing scanners.
We propose a new trellis encoder-decoder network for crowd counting, which can handle large variations of objects.
Binding sites of human RBPs are highly conserved across primates with weak conservation profiles in lower vertebrates. Expression level and number of targets of an RBP are important factors contributing to the differences in the extent of conservation of binding sites across species.
We propose a novel and systematic method that autonomously and simultaneously optimizes multiple parameters of any deep neural network by using a GAN aided by a bi-generative adversarial network (Bi-GAN)
We investigate whether recurrent neural networks learn to track abstract hierarchical syntactic structure in four languages.
We propose to estimate the head-pose angles (pitch, yaw, and roll) by simultaneously predicting the pose parameters from observed high-dimensional feature vectors, and tracking these parameters over time.
Chemical-genomic and genetic interaction profiling approaches are widely used to study mechanisms of drug action and resistance.
Convolutional neural networks learn shape-sensitive representations of objects that can explain human shape judgments for several benchmark behavioral and neural stimulus sets.
We explore how information from other objects in the scene can be exploited for viewpoint estimation. In particular, we look at object configurations by following a relational neighbor based approach for reasoning about object relations.
We propose a new method to enhance and extract the retinal vessels. The experimental results show that our method is quite effective.
We introduce a self-supervised, predictive learning framework that draws inspiration from cognitive psychology to segment long, visually complex videos into constituent events. Learning involves only a single pass through the training data.
We develop Expectation-Maximization (EM) methods for semantic image segmentation model training under weakly supervised and semi-supervised settings.
We introduce a neural reading comprehension model that integrates external commonsense knowledge, encoded as a key-value memory, in a cloze-style setting, for improved results over a hard Common Nouns dataset.
In this work, we put into question the effectiveness of the evaluation methods currently used to measure the performance of latent factor models for the task of knowledge base completion.
In this paper, we model the salient object detection problem under a probabilistic framework encoding the boundary connectivity saliency cue and smoothness constraints in an optimization problem. We show that this problem has a closed form global optimum which estimates the salientobject.
The paper presents a thorough analysis of the influence of the number of negative training examples on the performance of machine learning methods in simulated virtual screening experiments.
This work proposes a novel attentive graph neural network for zero-shot video object segmentation.
We propose a set of methods, which we collectively call VisionISP, to re-purpose the ISP for machine consumption while preserving the relevant information.
We propose a new loss function, Minimum Margin Loss (MML), which is aimed at enlarging the margin of those overclose class centre pairs so as to enhance the discriminative ability of the deep features.
We address the problem of obstacle detection, having as input multiple point clouds from a set of laser-based distance sensors; the latter generate high-rate data and can rapidly exhaust baseline analysis methods, that gather and cluster all the data.
ResUNet++ is an improved ResUNet architecture for pixel-wise polyp segmentation during colonoscopy examinations.
We propose a novel strategy making regularization-based Deep Transfer learning Never Hurt that can improve state-of-the-art regularizers in all cases with 0.1%--7% higher accuracy.
The objective of this paper is to evaluate whether a background sequence alone can classify human actions in current large-scale action datasets.
The problem of minimizing the Potts energy function frequently occurs in computer vision applications. One way to tackle this NP-hard problem was proposed by Kovtun [19, 20]. It identifies a part of an optimal solution by running k maxflow computations.
We present a simple yet effective end-to-end trainable deep network with geometry-inspired convolutional operators for detecting vanishing points in images. The code and dataset have been made publicly available.
In this paper, we propose a new representation learning method, named Structure Transfer Machine (STM), which enables feature learning process to converge at the representation expectation in a probabilistic way.
In the area of computer vision, deep learning has produced a variety of state-of-the-art models that rely on massive labeled data.
We introduce a simple and effective method for regularizing large convolutional neural networks using a stochastic pooling procedure.
In this paper, we introduce a video prediction model that discovers the keyframe structure of image sequences in an unsupervised fashion and use these keyframes as subgoals for planning.
We propose a novel tree-like curvilinear structure reconstruction algorithm based on supervised learning and graph theory.
We propose a novel Face Destylization Neural Network (FDNN) to restore the latent photo-realistic faces from the stylized ones.
This paper presents a new training mechanism called Batch Feature Erasing for person re-identification.
We applied Bayesian model to the proposals generated by MCG [1, 2] to re-rank the candidate bounding boxes using several geometrical features for better object detection.
In this paper, we propose a novel learning method for image classification called Between-Class learning (BC learning) by mixing two images belonging to different classes with a random ratio.
We attempt to employ different Algorithmic methodologies including local features and deep neural networks along with multiple clustering methods to find an effective way of summarizing a video by interesting keyframe extraction.
We propose a new method that uses semantically related questions, dubbed basic questions, acting as noise to evaluate the robustness of VQA models under increasing levels of noisiness.
In this paper, we analyze several neural network designs for sentence pair modeling and compare their performance extensively across eight datasets, including paraphrase identification, semantic textual similarity, natural language inference, and question answering tasks.
We generalize orthogonal rectangular matrix to optimization over Multiple Dependent Stiefel Manifolds, which improves the performance of state-of-the-art networks, including Inception and residual networks.
Graph processors such as Graphcore's Intelligence Processing Unit (IPU) are part of the major new wave of novel computer architecture for AI, and have a general design with massively parallel computation, distributed on-chip memory and very high inter-core communication bandwidth.
We show an equivalence between the submodular extensions of an energy function and the objective functions of linear programming (LP) relaxations for the corresponding MAP estimation problem.
We propose a new architecture denoted as Transformer with BLSTM (TRANS-BLSTM) which has a BLSTm layer integrated to each transformer block, leading to a joint modeling framework for transformer and BLSTMs.
This paper studies the estimation of Dirichlet process mixtures over discrete incomplete rankings. The generative model for each mixture component is the generalized Mallows (GM) model, an exponential family model for permutations which extends seamlessly to top- t rankings.
A survey of the recent developments in image-based 3D reconstruction using convolutional neural networks.
We present a deep learning approach based on Iizuka et al. for adversarially training a network to hallucinate past image boundaries.
In this paper, a novel gait representation termed as Gait Entropy Image (GEnI) is proposed. It captures mostly motion information and is robust to covariate condition changes.
We show that this approach can effectively solve complex RL tasks without access to the reward function, including Atari games and simulated robot locomotion, while providing only one percent of our agent's interactions with the environment.
We propose the multi-kernel depthwise convolution(MD-Conv) which can be used for chest X-rays diagnosis.
We propose a capsule network model with BiLSTM for sentiment analysis and introduce experimental results on different datasets.
In this paper, we present an efficient method for single image super-resolution based on the dense network, which addresses degeneracy problem caused by the loss of input information.
We present a review of brain imaging-based neurolinguistic studies with a focus on the natural language representations, such as word embeddings and pre-trained language models.
This paper proposes a robust probabilistic model for projection errors, based on real world data, which improves both precision and accuracy.
A trivial generalization from single-path to multi-path incurs severe feature inconsistency, which deteriorates both supernet training stability and model ranking ability. To remedy this degradation, we employ what we term as shadow batch normalizations (SBN) to catch changing statistics when activating different sets of paths.
We introduce a new Generative Adversarial Neural Network (GAN) based on multiple fake class and oversampling to generate more samples from minority class instances and rebalance dataset.
We generalize the concept of maximum-margin classifiers (MMCs) to arbitrary norms and non-linear functions.
We propose UniPose, a unified framework for human pose estimation, based on our "Waterfall" Atrous Spatial Pooling architecture, that achieves state-of-art-results on several pose estimation metrics.
We address the limitations of the current state-of-the-art model for isolated word recognition in the wild and propose changes which further improve its performance.
We provide a new benchmark and thorough empirical evaluation of generalisation challenges for state of the art Deep RL methods and evaluate several techniques for improving generalisation.
We define a more comprehensive search space of parallelization strategies for DNNs called SOAP, which includes strategies to parallelize a DNN in the Sample, Operation, Attribute, and Parameter dimensions. We propose FlexFlow, a deep learning framework that uses guided randomized search of the SOAP space to find a fast parallelization strategy for a specific parallel machine.
We analyze the quantitative relation of quantization errors to the neural network loss function and identify that the Hessian-weighted distortion measure is locally the right objective function for the optimization of network quantization.
A major component of a generic image retrieval pipeline is producing concise and effective descriptors for each image. When planning to globally pool such feature maps from a ConvNet, some options to consider are (1) the depth of the network, (2) choice of layer to pool, and (3) level of dimension reduction.
We show that it is possible to tag images with attribute-denoting adjectives even when no training data containing the relevant annotation are available.
We propose a novel memory network model named Read-Write Memory Network (RWMN) for large-scale, multimodal movie story understanding.
We propose QAInfomax as a regularizer in reading comprehension systems by maximizing mutual information among passages, a question, and its answer.
In this paper, we propose a novel binary local representation for RGB-D video data fusion with a structure-preserving projection.
We propose a pipeline to create diagnostic datasets for IR, each engineered to fulfill one axiom. We empirically validate to what extent well-known deep IR models are able to realize the axiomatic pattern underlying the datasets.
A survey of recent commonsense QA methods and a systematic analysis of popular knowledge resources and knowledge-integration methods, across benchmarks from multiple commonsense datasets.
A learnable unified framework for propagating a variety of visual properties of video images, including but not limited to color, high dynamic range (HDR), and segmentation information, where the properties are available for only a few key-frames.
We propose a novel generative adversarial network based on inter-frame difference for future video prediction on UCF-101, KITTI.
We automatically learn spatio-temporal motion feature descriptors for action recognition and accelerate the convergence of optimal solutions.
Transferring the knowledge learned from large scale datasets (e.g., ImageNet) via fine-tuning offers an effective solution for domain-specific fine-grained visual categorization tasks (FGVC) tasks that require specialized domain knowledge.
We propose a novel convolutional neural network for real-time Semantic Segmentation and explore three ways to achieve high recall rate.
We present a deep learning approach for pedestrian trajectory forecasting using a single vehicle-mounted camera and propose a model for forecasting pedestrian trajectory up to one second into the future.
Deep Matching (DM) is a popular high-quality method for quasi-dense image matching. Despite its name, however, the original DM formulation does not yield a deep neural network that can be trained end-to-end. In this paper, we remove this limitation by rewriting the complete DM algorithm as a convolutional neural network.
We propose a computationally inexpensive detection network for real-time vehicle detection in UAV imagery which we call ShuffleDet.
We introduce the Hidden Tree Markov Network (HTN), a neuro-probabilistic hybrid fusing the representation power of generative models for trees with the incremental and discriminative learning capabilities of neural networks.
We propose DeBayes: a conceptually elegant Bayesian method that is capable of learning debiased embeddings by using a biased prior, which can then be used to perform link prediction that is significantly more fair in terms of popular metrics such as demographic parity and equalized opportunity.
A systematic approach to establishing a large baseline source domain and target domain for cross-domain person ReID, which promotes variety in both source and target domains.
Long non-coding RNAs (lncRNAs) play an important role in the regulation of key cellular processes in early development and in cancer.
This paper presents a new loss function, namely Rectified Wing (RWing) loss, for regression-based facial landmark localisation with Convolutional Neural Networks (CNN)
In this paper, we integrate spiking convolutional neural network (SCNN) with temporal coding into YOLOv2 architecture for real-time object detection.
We reconcile both expressiveness and complexity through the use of Complex-valued embeddings and explore the link between such complex-valued Embeddings and unitary diagonalization.
In this paper, we propose a kinship generator network that can synthesize a possible child face by analyzing his/her parent's photo.
Pooling is an essential component of a wide variety of sentence representation and embedding models. We propose vector-based multi-head attention that achieves state-of-the-art performances on four datasets.
We introduce a fine-to-coarse global registration algorithm that detects planar structures spanning multiple RGB-D frames and establishes geometric constraints between them as they become aligned.
We introduce a novel differentiable relaxation for point cloud sampling that approximates sampled points as a mixture of points in the primary input cloud. Our approximation scheme leads to consistently good results.
In this paper, a multi-task deep learning framework is proposed to map damaged and intact buildings from large-scale very high spatial resolution images.
We implement a residual neural network for 3D object classification of the 3D Princeton ModelNet dataset, and we show that widening network layers improves classification accuracy.
This paper explores the integration of features originating from multiple languages into a machine learning approach to subjectivity analysis, and aims to show that this enriched feature set provides for more effective modeling for the source as well as the target languages.
This paper introduces Associative Compression Networks (ACNs), a new framework for variational autoencoding with neural networks, in which the prior distribution used to model each code is conditioned on a similar code from the dataset, leading to rich, informative codes.
A large-scale traffic near-miss incident database that provides automated systems with a performance level that is comparable to a human-level understanding of near- miss incidents.
In this paper, we attempt to study through the lens of information measures how a particular architecture behaves when the true probability law of samples is potentially different at training and testing times.
We propose AID++, a large-scale dataset for aerial scene classification based on the AID dataset, which can be used as a promising benchmark for scene classification.
In this paper, we propose a new methodology for segmenting non-rigid visual objects, where the search procedure is onducted directly on a sparse low-dimensional manifold, guided by the classification results computed from a deep belief network.
We propose new NAS baselines that build off the following observations: (i) NAS is a specialized hyperparameter optimization problem; and (ii) random search is a competitive baseline for hyperparameters optimization. We explore the existing reproducibility issues of published NAS results.
We provide a comprehensive overview of different models proposed for the QA task, including both traditional information retrieval perspective, and more recent deep neural network perspective.
Our goal is to condense the multi-modal, extremely high dimensional information from videos into a single, compact video representation for the task of video retrieval using free-form text queries, where the degree of specificity is open-ended.
This paper presents a methodology to map building and to efficient pose computation which is specially adapted for cases of large displacements in a multi-resolution framework.
A publicly-accessible web platform for large-scale protein-ligand docking using idock and RF-Score .
We present a method that"meta"classifies whether segments (objects) predicted by a semantic segmentation neural network intersect with the ground truth.
We study the temporal evolution of facial landmarks as parametrized trajectories on the Riemannian manifold of positive semidefinite matrices of fixed-rank, and propose a novel space-time geometric representation.
We develop dual refinement networks for fast and accurate object detection in images and videos.
We explore topics of the dialog as an important contextual feature into the architecture along with explorations around multimodal Attention. We also incorporate an end-to-end audio classification ConvNet, AclNet, into our models.
We propose Deep Closed-Form Subspace Clustering (DCFSC), a new embarrassingly simple model for subspace clustering with learning non-linear mapping.
This paper presents a method for detecting salient objects in videos, where temporal information in addition to spatial information is fully taken into account. We propose a new set of spatiotemporal deep features that utilize local and global contexts over frames.
We propose an advanced LSTM based weighted pooling RNN for emotion recognition.
A patch-based estimation technique is used to estimate for noise level and applies it to the proposed blind image denoising algorithm.
We investigate a hybrid strategy that begins training with an adaptive method and switches to SGD when a triggering condition is satisfied.
We present a logarithmic-scale efficient convolutional neural network architecture for edge devices, named WaveletNet.
We propose a novel deep learning model of Cross-Domain Representation Disentangler (CDRD) that bridges the information across data domains and transfers the attribute information accordingly.
We propose BridgeNet for age estimation, which aims to mine the continuous relation between age labels effectively.
Image matting is a fundamental computer vision problem and has many applications. In this paper, we propose a novel deep learning based algorithm that can tackle both these problems.
Generative Adversarial Self-Imitation Learning improves the performance of proximal policy optimization on 2D Point Mass and MuJoCo environments with delayed reward and stochastic dynamics.
This work focuses on representing very high-dimensional global image descriptors using very compact 64-1024 bit binary hashes for instance retrieval.
A faster, simpler single-stage detector based on YOLOv3 for detecting multiple concrete damages of highway bridges.
To achieve parsimonious inference in per-pixel labeling tasks with a limited computational budget, we propose aPixel-wise Attentional Gating unit (\emph{PAG}) that learns to selectively process a subset of spatial locations at each layer of a deep convolutional network.
This paper focuses on learning from easy-to-acquire web data and utilizes the learned model to reduce the built-in gap between the web and standard datasets for fine-grained image classification.
We show that using ASR tokens for time-stamped, subtask annotations improves performance significantly over constant prediction.
A region based deep learning approach is proposed for image description generation. It employs a regional object detector, recurrent neural network (RNN)-based attribute prediction, and an encoderdecoder language generator.
In this paper, we study the task of image retrieval, where the input query is specified in the form of an image plus some text that describes desired modifications to the input image, and propose a new way to combine image and text through residual connection.
We introduce a new dual simulation graph pattern matching process for SPARQL queries and achieve running times competing with state-of-the-art database systems.
We analyze the deficiencies of several widely-used objective functions handling image resolution discrepancies and propose a new framework called deep antithetical learning that directly learns from the natural image space rather than creating an arbitrary one.
We focus on generative autoencoders, which jointly learn a generative model alongside an inference model. We formulate a Markov chain Monte Carlo sampling process, equivalent to iteratively decoding and encoding, which allows us to sample from the learned latent distribution.
In this paper, we consider a class of sparse regression problems, whose objective function is the summation of a convex loss function and a cardinality penalty, and propose a projected neural network and a correction method for solving this problem.
The goal of this study was to validate AFFDEX and FACET, two algorithms classifying emotions from facial expressions, in iMotions’s software suite.
In this paper, an improved scheme is proposed to keep the salient regions of the transferred image the same with that of content image in the semantic level.
We propose to pre-train a unified language model for both autoencoding and partially autoregressive language modeling tasks using a novel training procedure, referred to as a pseudo-masked language model.
A novel framework that optimizes the prediction accuracy and energy cost simultaneously, thus enabling effective cost-accuracy trade-off at test time.
In this paper, we introduce a Bag of Expression (BoE) framework for human action recognition in simple and realistic scenarios. The proposed approach includes space time neighborhood information in addition to visual words.
Efficient Spatio-Channel dilated convolution based on split-transform-merge for real-time semantic segmentation.
We show that augmentation of weakly annotated training dataset with synthetic images minimizes both the annotation efforts and also the cost of capturing images with sufficient variety.
This paper presents a novel approach, named bag-of-bags of words (BBoW), to address the problem of Content-Based Image Retrieval (CBIR) from image databases.
We propose a novel approach for aligning CAD models to 3D scans, based on deep reinforcement learning.
This paper proposes a novel 3D super resolution approach to reconstruct surface of the objects in the scene using anisotropic diffusion equation.
We propose a content-aware text super-resolution network to generate the information desired for text recognition, which improves text recognition performance.
We use the kinematic structure directly as the hardware encoding and show great zero-shot transfer to completely novel robots.
A simple framework Probabilistic Multi-view Graph Embedding (PMvGE) is proposed for multi-view feature learning with many-to-many associations.
We propose method to encode spatial-layout of features inside bounding box. We also introduce descriptor which encodes static information for low amount of motion.
Facial landmark localization is a very crucial step in numerous face related applications, such as face recognition, facial pose estimation, face image synthesis, etc. However, previous competitions on facial landmark localization (i.e., the 300-W, 300-VW and Menpo challenges) aim to predict 68-point landmarks, which are incompetent to depict the structure of facial components.
We propose a caveat for the use of partial-input baselines for dataset verification and creation.
This paper presents a comprehensive survey on vision-based robotic grasping. We concluded four key tasks during robotic grasping are object localization, pose estimation, grasp detection and motion planning.
The recent advent of automated neural network architecture search led to several methods that outperform state-of-the-art human-designed architectures. We propose two novel methods which aim to accelerate this optimization problem by transferring knowledge acquired from previous tasks to new ones.
This paper describes AllenNLP, a platform for research on deep learning methods in natural language understanding, built on top of PyTorch.
We propose a straightforward method that simultaneously reconstructs the 3D facial structure and provides dense alignment and achieves state-of-the-art performance.
A generalization of deformable part models from 2D images to 3D spatiotemporal volumes to better study their effectiveness for action detection in video.
We present a learning model that makes full use of boundary information for salient object segmentation, which achieves superior performance over state-of-the-art ones.
We propose a novel adversarial-consistency loss for image-to-image translation and achieve state-of-the-art results on three challenging tasks.
We explore the idea of using high-level semantic concepts, also called attributes, to represent human actions from videos and argue that attributes enable the construction of more descriptive models for human action recognition.
We describe a novel way of representing a symbolic knowledge base (KB) called a sparse-matrix reified KB. This representation enables neural modules that are fully differentiable, faithful to the original semantics of the KB, and scalable enough to use with realistically large KBs.
We present an enhanced hidden Markov model capable of dealing with the noisy, high-dimensional and sparse measurements typical of action feature sets.
In this paper, we propose a dynamic part-attention (DPA) method based on masks, which aims to improve the use of variable attention parts.
Pose prediction is to predict future poses given a window of previous poses. In this paper, we propose a new problem that predicts poses using 3D joint coordinate sequences.
In this paper, we propose a novel neural architecture featuring a shared decision module followed by several network branches, one for each action dimension, for continuous action tasks.
We propose a Lifelong 3D Object Recognition (i.e., L3DOR) framework, which can consecutively learn new 3D object recognition tasks via imitating "human learning".
We present Vispedia, a Web-based visualization system that reduces the cost of data integration into structured tables before visualization can begin.
This paper presents a novel line-aware rectification network to address the problem of fisheye distortion rectification based on the classical observation that straight lines in 3D space should be still straight in image planes.
An increasing number of simultaneous localization and mapping (SLAM) systems are using appearance-based localization to improve the quality of pose estimates.
We provide the first real-time solution that is guaranteed to minimize the delay, i.e., the time between when the object comes in view and the declared detection time, subject to acceptable levels of detection accuracy.
We propose a multi-level bottom-top and top-bottom fusion method for crowd counting in congested scenes, which is able to outperform several recent methods in all datasets.
Multi-scale spatially-asymmetric recalibration, which extracts visual cues from surrounding regions at multiple scales, and designs a weighting scheme which is asymmetric in the spatial domain.
We propose an ensemble deep neural network with an underlying U-Net framework consisting of bi-directional convolutional LSTMs and dense connections that outperforms recent state-of-the-art networks in several evaluation metrics.
ActiveLink extends uncertainty sampling by exploiting the underlying structure of the knowledge graph, i.e., links between entities, to improve sampling effectiveness.
We explore methods to flexibly guide a trained convolutional neural network through user input to improve its performance during inference.
Learning-based Text To Speech systems have the potential to generalize from one speaker to the next and thus require a relatively short sample of any new voice. We present a method that captures a new speaker from a short untranscribed audio sample.
An unsupervised learning classification model is described. It achieves classification error probability competitive with that of popular supervised learning classifiers such as SVM or kNN.
Y-Net: a CNN architecture to reconstruct the PA image by optimizing both raw data and beamformed images once.
We propose a fully convolutional AlignDet architecture which combines the flexibility of learned anchors and the preciseness of aligned features in a principled way.
In this paper, we study the importance of pretraining for the generalization capability in the color constancy problem. We propose two novel approaches based on convolutional autoencoders.
In this paper, we propose an advanced multilateral filter (AMF), which refers spatial, range, depth, and credibility information to achieve their enhancements.
We propose a new stereo matching algorithm which is insensitive to change in radiometric conditions between stereo pairs i.e. left image as well as right image.
We propose a guided convolutional layer to recover dense depth from sparse and irregular depth map when an aligned high-resolution color image is given as guidance.
We propose CERENKOV3, a machine learning pipeline that leverages clustering-derived and molecular network-derived features to improve prediction accuracy of regulatory SNPs (rSNPs) in the context of post-GWAS analysis.
We exploit coarse linguistic structure in keyword queries, and combine it with rich structured query representations of information needs to answer keyword queries.
We propose an automatic method for recovering the atmospheric light vector in hazy scenes given a single input image.
Cascade of Tasks combines three complementary detection tasks to detect AU events rather than frames.Performed best in four datasets that differ in complexity.
We propose a novel method to evaluate the support for protein-protein interaction data based on gene ontology information.
We study whether five scaling properties (given by Zipf’s law, Heaps’ law, Ebeling’ method, Taylor's law, and long-range correlation analysis) can serve for evaluation of computational models that reproduce the long memory behavior of natural language.
We introduce deep canonical correlation analysis (DCCA) to multimodal emotion recognition and demonstrate state-of-the-art performance on all five datasets.
In many systems privacy of users depends on the number of participants applying collectively some method to protect their security. This may be particularly problematic in the presence of a strong adversary that can additionally corrupt some users.
We propose a method named Dimensional reweighting Graph Convolution Network (DrGCN) that can guarantee to improve the stability of GCNs via mean field theory.
We introduce Lipizzaner, an open source software system that allows machine learning engineers to train GANs in a distributed and robust way.
In this paper, we present a novel method to detect salient object based on multi-level cues.
We propose a new metric learning loss with hard sample mining called margin smaple mining loss (MSML) which achieves better accuracy compared with other metric learning losses, such as triplet loss.
In this paper, we propose a novel tracklet processing method to cleave and re-connect tracklets on crowd or long-term occlusion by Siamese Bi-Gated Recurrent Unit (GRU).
Delaunay-based stereo matching method improves both running speed and disparity accuracy.
This paper presents a scalable big data benchmarking methodology that captures the common requirements of each class of unit of computation while being reasonably divorced from individual implementations.
We study end-to-end learning strategies for 3D shape inference from images, in particular from a single image, using probabilistic inference-based reconstruction.
We propose RelGAN, a new method for multi-domain image-to-image translation. The key idea is to use relative attributes, which describes the desired change on selected attributes.
We propose a single-stage Human-Object Interaction (HOI) detection method that has outperformed all existing methods on HICO-DET dataset at 37 fps on a single Titan XP GPU.
The majority of existing models of person re-identification(re-id) that matches pedestrian images across different camera views are largely dependent on color appearance. We perform cross-clothes person Re-id based on a contour sketch of person image to take advantage of shape of human body instead of color information.
We propose a Sparse Subspace Clustering-based Motion Segmentation method that categories the static scene parts and the multiple moving objects using their 3D motion trajectories using the minimal 3-point Random Sample Consensus algorithm.
We propose to use dice loss in replacement of the standard cross-entropy objective for data-imbalanced NLP tasks, and we observe significant performance boost on a wide range of data imbalancedNLP tasks.
Deep learning methods have greatly increased the accuracy of face recognition, but an old problem still persists: accuracy is usually higher for men than women on test data.
We propose a novel method for local attribute transfer, where only parts of a face have to be altered in order to achieve semantic changes (e.g. removing a mustache).
We can transfer most of the generalization ability of the teacher to the student, often producing a much better small model than directly training the student on the training data.
We propose an effective motion-excited sampler to obtain motion-aware noise prior, which underlines frame correlations and utilizes video dynamics via relative motion among video frames.
We present a method for explaining the image classification predictions of deep convolution neural networks, by highlighting the pixels in the image which influence the final class prediction.
We propose to use simple Markov models that only model observed quantities and retain a highly expressive dynamic model for human motion.
In frequency space, GAN-generated images exhibit severe artifacts that can be easily identified. We perform a comprehensive analysis, showing that these artifacts are consistent across different neural network architectures, data sets, and resolutions.
We propose a new knowledge distillation method (named Collaborative Distillation) for encoder-decoder based neural style transfer to reduce the convolutional filters.
We study the recursive composition of this subtree-level entailment relation, which can be viewed as a soft version of the Natural Logic framework and bring significant improvements in accuracy.
We use deep learning to model interactions across two or more sets of objects, such as user-movie ratings, protein-drug bindings, or ternary user-item-tag interactions. We argue that models should hence be Permutation Equivariant (PE), constrained to make the same predictions across such permutations.
We propose a new ranking algorithm that learns the data affinity matrix and the ranking scores. We develop a novel and efficient algorithm to solve the optimization problem.
We propose leveraging the manifold structure to constrain the deep action feature learning, thereby minimizing the intra-class variations in the feature space and alleviating the over-fitting problem.
We present a novel learning-based framework for face reenactment, capable of transferring facial movements and expressions from monocular video input of an arbitrary person to a target person.
We propose DASNet, a semi-supervised method for pixel-level supervised learning. The basic idea is exploring detection models to simplify the pixel- level supervised learning task.
We introduce an unsupervised feature learning approach that embeds 3D shape information into a single-view image representation that learns to perform "mental rotation" even for objects unseen during training.
We have re-implemented the main four word2vec inspired graph embedding techniques under the same framework and analyzed how different sampling distributions affects embeddings performance when tested in node classification problems.
We introduce phrase-based statistical machine translation for grammatical error correction (GEC) trained on a pseudo learner corpus created by Google Translation.
We propose a CNN implementation inspired by dense networks to reduce the number of parameters and train end-to-end.
UAIL applies Monte Carlo Dropout to estimate uncertainty in the control output of end-to-end systems using states where it is uncertain to selectively acquire new training data.
3D Dense Face Alignment using Cascaded Convolutional Neural Networks.
We propose a video frame interpolation method which explicitly detects the occlusion by exploring the depth information. The proposed model then warps the input frames, depth maps, and contextual features based on the optical flow and local interpolation kernels.
This paper is concerned with a new approach to the development of plant disease recognition model, based on leaf image classification, by the use of deep convolutional networks. Novel way of training and the methodology used facilitate a quick and easy system implementation in practice.
Adversarial examples are the inputs to machine learning models that result in erroneous outputs, which are usually generated from normal inputs via subtle modification and seem to remain unchanged to human observers. Based on statistical feature of Markov chain, an effective defense method is proposed in this paper.
We propose Dugong, the first framework to model multi-resolution weak supervision sources with complex correlations to assign probabilistic labels to training data.
A novel transductive zero-shot hashing method for multi-label unseen image retrieval.
In this paper, we address the problem of road segmentation and free space detection in the context of autonomous driving.
We propose that phase-disparity neurons in visual cortex help to work out which feature in the left eye corresponds to a given feature in a given right eye.
Facial attribute editing aims to manipulate single or multiple attributes on a given face image, i.e., to change what you want. Some existing methods attempt to establish an attribute-independent latent representation for further attribute editing.
We propose a flexible CAE by eliminating the constraints on the numbers of convolutional layers and pooling layers from the traditional CAE. We also design an architecture discovery method by exploiting particle swarm optimization.
A fish-eye lens achieves a large field of view at the cost of image distortion, and underwater imaging by a fish-eyes lens introduces refraction when light passes through the different medium.
We propose a new CNN based method for age group and gender estimation leveraging Residual Networks of ResidUAL Networks (RoR), which exhibits better optimization ability for age and gender classification than other CNN architectures.
We propose a scalable benchmarking methodology that uses the combination of one or more data motifs---to represent diversity of big data and AI workloads. Following this methodology, we present a unified big Data and AI benchmark suite.
We improve the standard Euclidean distance with dynamic weights, which are selected based on the standard deviation of features across the batch, and exploit channel attention via a squeeze and excitation unit in the backbone model.
We use both labeled and unlabeled data during model training across active learning cycles, and we find that the latter brings a surprising accuracy improvement in image classification, compared to the former.
In this paper, we introduce a novel recurrent U-Net architecture that preserves the compactness of the original U-net, while substantially increasing its performance to the point where it outperforms the state of the art on several benchmarks.
Region proposal network (RPN) based object detection, such as Faster Regions with CNN (Faster R-CNN), has gained considerable attention due to its high accuracy and fast speed. However, it has room for improvements when used in special application situations, like on-board vehicle detection.
We propose a unified model for Knowledge Embedding and Pre-trained LanguagE Representation (KEPLER), which not only better integrates factual knowledge into PLMs but also effectively learns knowledge graph embeddings.
In unsupervised domain adaptation, rich domain-specific characteristics bring great challenge to learn domain-invariant representations. In this paper, we equip adversarial domain adaptation with Gradually Vanishing Bridge (GVB) mechanism on both generator and discriminator. GVB could not only reduce the overall transfer difficulty, but also reduce the influence of the residual domain-Specific characteristics in domain-Invariant representation.
In this paper, we propose an extension of the Extreme Learning Machine algorithm for Single-hidden Layer Feedforward Neural network training that incorporates Dropout and DropConnect regularization in its optimization process, which is adopted by the proposed DropELM network.
We explore and identify a DP model that is suitable for Thai social network data.
PAGAN, an accessible, general-purpose, online platform for crowdsourcing affect labels in videos, overcomes accessibility limitations of existing annotation tools.
We propose the ACtion Tubelet detector (ACT-detector) that takes as input a sequence of frames and outputs tubelets, i.e., sequences of bounding boxes.
We address the problem of venue recommendation from a novel perspective: applying cross-domain recommenda- tion techniques considering each city as a different domain.
We propose to use an attention mechanism to learn the alignment between speech frames and text words, aiming to produce more accurate multimodal feature representations for emotion recognition.
This study focuses on the creation of Artificial Neural Network (ANN) and Recurrent Neural Networks (RNN) based models to classify sound sources from manually collected sound clips in local streets.
This paper introduces new surface descriptors, which are derived from either unstructured face data, or a radial basis function (RBF) model of the facial surface, and use them to localise facial landmarks from 3D images.
We introduce SceneNet RGB-D, expanding the previous work of SceneNet to enable large scale photorealistic rendering of indoor scene trajectories in synthetic layouts with random but simulated object poses.
We uncover inconsistencies in ground truth temporal bounds within and across annotators and datasets, and propose an approach based on the Rubicon Boundaries for consistent temporal bounds of object interactions.
We propose a novel adversarial training algorithm that promotes higher robustness and invariance in the embedding space, by adding adversarial perturbations to word embeddings and minimizing the resultant adversarial risk inside different regions around input samples.
We propose a lightweight information multi-distillation network to super-resolve block-wise image patches using the same well-trained model using adaptive cropping strategy.
We present Residual Policy Learning (RPL), a simple method for improving nondifferentiable policies using model-free deep reinforcement learning. RPL thrives in complex robotic manipulation tasks where good but imperfect controllers are available.
We propose a novel distributional ranking (DR) loss to address the imbalance issue in one-stage detectors and improve the efficiency for the ranking algorithm.
We propose a robust deep features-based structured group local sparse tracker (DF-SGLST), which exploits the deep features of local patches inside target candidates and represents them by a set of templates in the particle filter framework.
We propose to use deep video features that encode various levels of content semantics, including objects, actions, and scenes for video summarization.
Zero-shot learning (ZSL) enables solving a task without the need to see its examples. In this paper, we propose two ZSL frameworks that learn to synthesize parameters for novel unseen classes.
We show that a character-level encoder-decoder framework can be successfully applied to question answering with a structured knowledge base.
We propose an artificial intelligence-assisted deep stride convolutional neural network (DSCNN) architecture using the plain nets strategy to learn salient and discriminative features from spectrogram.
We explore the approach for tuning regularization hyperparameters and find that in experiments on MNIST, SVHN and CIFAR-10, the resulting regularization levels are within the optimal regions.
Learning robust value functions given raw observations and rewards is now possible with model-free and model-based deep reinforcement learning algorithms. In this paper, we present DSR, which generalizes SR within an end-to-endDeep reinforcement learning framework.
We propose a novel model called Dual BERT, which takes advantage of the large-scale training data provided by rich-resource language and learn the semantic relations between the passage and question in a bilingual context.
This paper presents a new approach to employ active contour-based model that exhibits robustness to illumination and clothing changes in activity recognition.
We present a method to learn the 3D surface of objects directly from a collection of images, for the first time that fully unsupervised 3D learning is possible.
We propose R-STAN, a feed-forward convolutional neural network using residual learning and spatial-temporal attention mechanism for video action recognition, which focuses more on discriminative temporal and spatial features.
We propose structured models for image labeling that take into account the dependencies among the image labels explicitly. These models are more expressive than independent label predictors.
We propose a novel Localization Guided Network which assigns attribute-specific weights to local features based on the affinity between pre-extracted proposals and attribute locations.
We propose an image captioning framework with a self-retrieval module as training guidance, which encourages generating discriminative captions.
We propose a novel tasks-constrained deep model for multi-task facial landmark detection, with task-wise early stopping to facilitate learning convergence.
For the first time, we study complex rare categories with both task and view heterogeneity, and propose a novel optimization framework that integrates them in a way of mutual benefit.
Critical periods are phases in the early development of humans and animals during which experience can affect the structure of neuronal networks irreversibly. In this work, we study the effects of visual stimulus deficits on the training of artificial neural networks.
We consider seq2seq problems from the RL point of view and provide a formulation combining the power of RL methods in decision-making withseq2seq models that enable remembering long-term memories. We also provide the source code for implementing most of the RL models.
In this paper, we propose an approach for locating anomalies in crowded scene for surveillance videos. The proposed approach does not rely on traditional tracking techniques which tend to fail in crowed scenes.
We propose and analyse network distillation as a learning strategy to reduce the computational cost at inference time while even increasing the accuracy performance.
We propose a Direction Concentration Learning (DCL) method to improve Congruency in the learning process, where enhancing congruency influences the convergence path to be less circuitous.
This work proposes a novel local approach aimed at maximizing the speed-accuracy trade-off by means of an efficient segmentation-based cost aggregation strategy.
In this work, we propose "Residual Attention Network", a convolutional neural network using attention mechanism which can incorporate with state-of-art feed forward network architecture in an end-to-end training fashion.
Stereo matching techniques aim at reconstructing depth information from a pair of images. The use of stereo matching algorithms in embedded systems is challenging due to the complexity of state-of-the-art algorithms.
This paper describes a novel stereo matching algorithm for epipolar rectified images, capable of handling large untextured regions, estimating precise depth boundaries and propagating disparity information.
We propose an alternative probabilistic interpretation of the Huber loss to minimize an upper bound on the Kullback-Leibler divergence between Laplace distributions, which provides an intuitive way to select well-suited hyper-parameters.
Three CNNs are trained on 275 UAS-derived and freely available online images for object detection of 3m2 segments of railway track.
We propose a new benchmark for zero-shot learning and analyze the state-of-the-art methods in depth.
Nonnegative Matrix Factorization (NMF) is a popular tool to estimate the missing entries of a dataset under the assumption that the true data has a low-dimensional factorization.
We propose an alternative that utilizes the most powerful generative models as decoders, whilst optimising the variational lower bound all while ensuring that the latent variables preserve and encode useful information.
We use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called EfficientNets, which achieve much better accuracy and efficiency than previous ConvNets.
We introduce a simple yet surprisingly powerful model to incorporate attention in action recognition and human object interaction tasks, and give a sizable boost in accuracy while keeping the network size and computational cost nearly the same.
We design a new multi-task leaning (MTL) ConvNet for object recognition, which explicitly enforces the disentangled representations of object identity and pose, and is trained to predict object categories and pose transformations.
We study how to design a genetic programming approach for optimizing the structure of a CNN for a given task under limited computational resources yet without imposing strong restrictions on the search space.
We propose a novel unified model for multi-modal and multi-domain image translation, which bridges these two objectives.
This paper considers an alternative stochastic stress minimization framework that is amenable to incremental and distributed solutions.
We extend the information bottleneck method to the unsupervised setting, by taking advantage of multi-view data, which provides two views of the same underlying entity.
In this paper, we propose to generate visual features based on an auto-encoder framework paired with multi-modality adversarial networks to reinforce the visual-semantic interactions with a bidirectional alignment, which ensures the generated visual features to fit the real visual distribution and to be highly related to the semantics.
We consider the design of nonlinear activation functions that take into consideration the structure of the graph and propose modifications to the backpropagation algorithm necessary to train local activation functions.
We propose Saliency-guided Attention Network (SAN) that asymmetrically employs visual and textual attention modules to learn the fine-grained correlation intertwined between vision and language to improve discrimination of visual representations.
We introduce a scheme for optimally allocating a variable number of bits per LSH hyperplane for non-uniform quantisation.
We propose a novel, graph-theoretic framework for distinguishing arteries from veins in a fundus image. We make use of the underlying vessel topology to better classify small and midsized vessels.
We propose a new DNN-based communication scheme that directly maps the feature vectors to channel inputs for image retrieval.
Partially annotated clips contain rich temporal contexts that can complement the sparse key frame annotations in providing supervision for model training. We present a novel paradigm called Temporally-Adaptive Features (TAF) learning that can utilize such data to learn better single frame models.
We propose the first implementation of Green’s function convolution inside a neural network, which allows the network, via very minor architectural changes and no additional parameters, to operate in the feature and in the gradient domain at the same time, thus improving the regional representation via edge filling.
We present a method to automatically extract question-article pairs from Q&A web forums, which can be used for document retrieval and QA tasks.
We cast this problem into one of learning a metric which is shared across all classes and explore k-nearest neighbor (k-NN) and nearest class mean (NCM) classifiers.
We consider data-driven generative models for the 3D face, and focus in particular on factorized representations that can decouple sources of variation, typically identity and expression with faces.
In this paper, we present an in-depth study on the interestingness of GIFs. We create and annotate a dataset with a set of affective labels, which allows us to investigate the sources of interest.
We propose a new two-stage detector, Light-Head R-CNN, to address the shortcoming in current two-Stage approaches, which is not as fast as single-stage, fast detectors like YOLO and SSD.
We propose a simple and effective improvement that learns the boundary handling itself, leading to improved boundary handling.
This paper presents a logistic discriminant metric learning method which exploits both original data and auxiliary data during training, which is motivated by the new machine learning paradigm - Learning Using Privileged Information.
We present a new method to learn video representations from large-scale unlabeled video data using an evolutionary search algorithm.
We develop a general definition of representation vulnerability that captures the maximum change of mutual information between the input and output distributions, under the worst-case input distribution perturbation. We then propose an unsupervised learning method for obtaining intrinsically robust representations by maximizing the Worst-case mutual information.
We show that a variety of modern deep learning tasks exhibit a "double-descent" phenomenon where, as we increase model size, performance first gets worse and then gets better.
We present a unified, end-to-end trainable spatiotemporal CNN model for VOS, which consists of two branches, i.e., the temporal coherence branch and the spatial segmentation branch.
We treat shape co-segmentation as a representation learning problem and introduce BAE-NET, a branched autoencoder network, for the task.
We explore a new dimension of the design space: quantizing different layers with different bit-widths and propose a novel differentiable neural architecture search (DNAS) framework to efficiently explore its exponential search space with gradient-based optimization.
We propose a new regularization method called ShakeDrop regularization, which is an unusual use of an existing regularizer. ShakeDrop is more effective than Shake-Shake and can be applied not only to ResNeXt but also ResNet, Wide ResNet and PyramidNet.
In this paper, we introduce a variant of the max-flow algorithm that requires much less storage. Consequently, our algorithm makes it possible to optimally solve multi-label submodular problems involving large numbers of variables and labels on a standard computer.
We propose to learn a spherical convolutional network that translates a planar CNN to process 360° imagery directly in its equirectangular projection.
The goal of this work is to generate better features for transfer learning from multiple publicly available pre-trained neural networks. To this end, we propose a novel architecture called Stacked Neural Networks which leverages the fast training time of transfer learning while simultaneously being more accurate.
We introduce an adversarial strategy for controlling bias in person re-identification, with two complementary branches to reduce or to enhance bias-related features.
In this paper, we present mdNet (the Optimal Margin Distribution Network), a network which embeds a loss function in regard to the optimal margin distribution for classification within the framework of deep networks.
In this paper, we propose to directly add constraints to the cost volume by filtering cost volume with unimodal distribution peaked at true disparities for state-of-the-art performance.
This work proposes to integrate the power of deep learning-based detection with the prior maps used by our car platform IARA (acronym for Intelligent Autonomous Robotic Automobile) to recognize the relevant traffic lights of predefined routes.
We propose a real-time stereo vision system on GPU for the high-resolution images when the maximum disparity is 760.
Convolutional neural networks excel in image recognition tasks, but this comes at the cost of high computational and memory complexity. To tackle this problem, [1] developed a tensor factorization framework to compress fully-connected layers.
We propose a two-stream Faster R-CNN network and train it endto- end to detect the tampered regions given a manipulated image.
Adversarial perturbations of normal images are usually imperceptible to humans, but they can seriously confuse state-of-the-art machine learning models. In this paper, we show empirically that adversarial examples mainly lie in the low probability regions of the training distribution, regardless of attack types and targeted models.
We propose a hybrid approach that employs dense block floating-point arithmetic on dot product computations and FP arithmetic elsewhere, leading to more compact models and denser arithmetic in computing platforms.
We study two procedures (reverse-mode and forward-mode) for computing the gradient of the validation error with respect to the hyperparameters of any iterative learning algorithm such as stochastic gradient descent.
STRIP-ViTA is a run-time Trojan detection method exploiting STRong Intentional Perturbation of inputs, is a multi-domain Trojan defence across Vision, Text and Audio domains.
We study the influence of context on sentence acceptability, showing that context induces a cognitive load for humans, which compresses the distribution of ratings.
Dropout introduces two distinct but entangled regularization effects: an explicit effect (also studied in prior work) which occurs since dropout modifies the expected training objective, and an additional implicit effect from the stochasticity in the dropout training update. We disentangle these two effects through controlled experiments.
We study the influence of backward skip connections which are in the opposite direction to forward shortcuts, i.e. skip connections from low to high layers. We propose a new fully convolutional model that consists of a pair of networks.
We propose a new family of convolutional descriptors for patch representation, based on the recently introduced Convolutional kernel networks, which perform better than SIFT for un-supervised tasks such as image retrieval.
In this paper, we describe an encoding implementation based on the asynchronous ::: partitioned global address space (APGAS) parallel programming model for efficient dictionary encoding.
ProphetNet is a sequence-to-sequence pre-training model with future n-gram prediction and n-stream self-attention mechanism.
In this paper, it is found that small-scale pedestrian detection and occluded pedestrian detection actually have a common problem, i.e., an inaccurate location problem. Therefore, solving this problem enables to improve the performance of both tasks, where two modules ( location bootstrap and semantic transition) are proposed.
We propose a novel entropy-based method for building effective datasets for training classifiers by automatically assembling data from social media, and propose a framework to incorporate an information-theoretic principle to guide it.
In this paper, a novel residual deep network, called CompNet, is proposed for the single image super resolution problem without an excessive increase in network complexity.
This study uses the asymmetric bilinear factorization model to perform the decoupling of linguistic and affective information when they are not given.
We address fundamental flaws in previously used metrics and show how Dynamic Time Warping (DTW), a long known method of measuring similarity between two time series, can be used for evaluation of navigation agents.
In this paper, we propose a novel representation model for bibliographic data, which combines co-authorship and content similarity information, and allows for the formation of scientific networks.
We developed CORnet-S, a shallow ANN with four anatomically mapped areas and recurrent connectivity, guided by Brain-Score, a new large-scale composite of neural and behavioral benchmarks for quantifying the functional fidelity of models of the primate ventral visual stream.
Part-Guided Attention Network (PGAN) combines part-guided bottom-up and top-down attention, global and part visual features in an end-to-end framework.
We propose a Graph-guided Architecture Search (GAS) pipeline to automatically search real-time semantic segmentation networks.
We perform an extensive resilience analysis of CapsNets inference subjected to the approximation errors, and analyze their impact on the classification accuracy.
We present a filter correlation based model compression approach for deep convolutional neural networks. Our approach iteratively identifies pairs of filters with the largest pairwise correlations and drops one of the filters from each such pair.
We address the boundary detection task motivated by the ambiguities in current definition of edge detection and propose a novel multi-scale semantic boundary detector.
An automated system that recognizes facial gestures by capturing local changes and encoding the motion into a histogram of frequencies.
We propose a novel image dataset construction framework by employing multiple textual queries, which improves the accuracy and diversity of the selected images.
A survey of optic disc detection and segmentation methodologies for retinal fundus region.
We provide new insights into the Inception Score, a recently proposed and widely used evaluation metric for generative models, and demonstrate that it fails to provide useful guidance when comparing models.
We analyze the problem of regression when both input covariates and output responses are functions from a nonparametric function class, and develop a scalable non-parametric estimator capable of operating over many instances.
We propose a more practical adversarial attack that manipulates the semantic attributes of images via the disentangled latent codes.
We propose to use a neural network to learn the weights of the input relative transformations for transformation synchronization and use them to prune incorrect relative transformations by detecting inconsistent cycles.
We address the problem of action recognition by describing actions as time series of frames and introduce a new kernel to compare their dynamical aspects and propose a kernel specifically tailored for action recognition.
The challenge of person re-identification (re-id) is to match individual images of the same person captured by different non-overlapping camera views against significant and unknown cross-view feature distortion. Learning view-specific feature transformations for re-id, an under-studied approach, becomes an alternative resort for this problem.
We propose an attention-based sequence-to-sequence model for handwritten text recognition and achieve competitive results on IAM and ICFHR2016 READ data sets compared to state-of-the-art without the use of a language model.
This paper introduces a state-of-the-art video representation and applies it to efficient action recognition and detection, using explicit camera motion estimation.
We propose an OOD detection algorithm which comprises of an ensemble of classifiers. We train each classifier in a self-supervised manner by leaving out a random subset of training data as OOD data and the rest as ID.
We propose a Hierarchical Graph Reasoning (HGR) model, which decomposes video-text matching into global-to-local levels for fine-grained retrieval.
We describe a weakly-supervised approach that learns to detect actions in long sequences given training videos with only whole-video class labels using attentional processing.
In this paper, we propose a novel framework by learning high-order relation and topology information for Occluded person re-identification and robust alignment.
We propose a unified margin view to revisit eleven performance measures in multi-label classification and prove that through maximizing these margins, different corresponding performance measures are optimized.
We propose a Densely Connected NAS (DCNAS) framework, which directly searches the optimal network structures for the multi-scale representations of visual information, over a large-scale target dataset.
We propose the first dedicated end-to-end deep learning approach for motion boundary detection, which we term as MoBoNet. We introduce a refinement network structure which takes source input images, initial forward and backward optical flows and produces high-resolution motion boundaries.
In this paper, we present a modular approach which can easily be incorporated into existing vision-language methods in order to support many languages.
This paper addresses the problem of scale estimation in monocular SLAM by estimating absolute distances between camera centers.
We propose syntactically controlled paraphrase networks (SCPNs) and use them to generate adversarial examples that both fool pretrained models and improve the robustness of these models to syntactic variation.
In this paper, we present a novel deep multimodal framework to predict human emotions based on sentence-level spoken language.
We propose an approach for semi-supervised semantic segmentation that learns from limited pixel-wise annotated samples while exploiting additional annotation-free images and achieves new state-of-the-art results.
We quantize the model parameters, activations and layer gradients to 8-bit, leaving at a higher precision only the final step in the computation of the weight gradients.
In this paper, we propose a modification of the popular and efficient multi-dimensional long short-term memory recurrent neural networks (MDLSTM-RNNs) for end-to-end processing of handwritten paragraphs.
In this paper, we propose a centrality-based edge activation probability evaluation method in the independent cascade model. We also propose two algorithms, called NewDiscount and GreedyCIC, for robust influence maximization.
In this paper, we propose a depth image generation method by stereo matching on super-pixel (SP-based) basis, which speeds up while maintaining accuracy.
We propose a scale-aware pixelwise object proposal network (SPOP-net) to tackle the challenges.
We introduce CoMatch Layer that learns to match the second order feature statistics with the target styles. We build a Multi-style Generative Network for style transfer.
We re-examine the locality-preserving character of spectral clustering by constructing a graph over image regions with both global and local connections.
We propose a novel blockwise parallel decoding scheme in which we make predictions for multiple time steps in parallel then back off to the longest prefix validated by a scoring model. This allows for substantial theoretical improvements in generation speed.
This paper addresses the difficult problem of finding an optimal neural architecture design for a given image classification task. We propose a method that aggregates two main results of the previous state-of-the-art in neural architecture search, appealing to the strong sampling efficiency of a search scheme based on sequential model-based optimization (SMBO), and increasing training efficiency by sharing weights among sampled architectures.
We introduce the task of acoustic question answering (AQA) in the area of acoustic reasoning. In this task an agent learns to answer questions on the basis of acoustic context.
We propose LSTM-TSA, a novel deep architecture that incorporates the transferred semantic attributes learnt from images and videos into the CNN plus RNN framework, by training them in an end-to-end manner.
We propose a supervised feature selection algorithm that uses pairwise constraints as supervision information, which achieves similar performance to Fisher Score with full class labels.
We introduce a conceptional solution for multilingual, KB-agnostic Question Answering over the Semantic Web.
We propose Bi-Directional Query Embedding (\textsc{BiQE}), a method that embeds conjunctive queries with bi-directional attention mechanisms.
We address the problem of learning good features for understanding video data. We introduce a model that learns latent representations of image sequences from pairs of successive images.
We propose a robust sparse stereo matching method based on semantic edges, which can improve the robustness of our method.
We develop Deep Discriminative Clustering (DDC) that models the clustering task by investigating relationships between patterns with a deep neural network.
We introduce TextureNet, a neural network architecture designed to extract features from high-resolution signals associated with 3D surface meshes (e.g., color texture maps) using 4-rotational symmetric fields.
We propose a preliminary framework to help address the challenge of explainability, which we call "deep visual explanation" (DVE), and we use relatively straightforward image classification examples and a variety of choices on initial configuration of a deep model building scenario.
Artificial neural networks typically have a fixed, non-linear activation function at each neuron. We have designed a novel form of piecewise linear activation function that learns independently for each neuron using gradient descent.
We extend the exemplar SVM and introduce a kernelized SLEM which can be implemented efficiently through low-rank matrix decomposition and displays improved performance.
We present AQQUCN, an entity search system that combines the best design principles into a public reference implementation.Recent years have witnessed some convergence in the architecture of entity search systems driven by a knowledge graph (KG) and a corpus with annotations.
Optical flow methods are used to estimate pixelwise motion information based on consecutive frames in image sequences. The image sequences traditionally contain frames that are similarly exposed. However, many real-world scenes contain high dynamic range content that cannot be captured well with single exposure setting.
We present a novel method of applying M\"obius transformations to augment input images during training, enabling improved generalization over prior sample-level data augmentation techniques.
We propose a deep visual sentiment analyzer for disaster-related images as a use-case, covering different aspects of visual sentiment analysis starting from data collection, annotation, model selection, implementation and evaluations.
We propose a novel hierarchical approach for text-to-image synthesis by inferring semantic layout, which improves image quality, interpretability of output and semantic alignment.
A novel dense stereo matching algorithm based on edge-aware truncated minimum spanning tree (T-MST)
We extend the NDT registration pipeline by using PointNet, a deep neural network for segmentation and classification of point clouds, to learn and predict per-point semantic labels.
This paper introduces a novel real-time algorithm for cascaded regression, the state-of-the-art approach for facial landmark localisation, which is faster than standard incremental learning.
We propose an out-of-distribution detector based GZSL framework for generalized zero-shot action recognition in videos.
 Query-based Attention CNN(QACNN) for Text Similarity Map, an end-to-end neural network for question answering.
We present an approach for moment detection from weak video-level labels. Given both complete and incomplete sequences, of the same action, we learn temporal attention, along with accumulated completion prediction from all frames.
We propose a novel deep supervised neural network for the task of action recognition in videos, which implicitly takes advantage of visual tracking and shares the robustness of both deep Convolutional Neural Network (CNN) and Recurrent Neural Network.
We show that in some settings, particularly those of low signal-to-noise ratio, it can be helpful to discard all but the signs of stochastic gradient elements while appropriately accounting for their uncertainty.
We present a new method for training pedestrian detectors on an unannotated image set, which is captured by a moving camera with a fixed height and angle from the ground, and use the images to train a Faster R-CNN detector.
In this paper, a direct LO method based on the 2.5D grid map is proposed. Experiments show that this method is superior to both the 3D-NDT and LOAM.
A new likelihood ratio test that combines matched-filter responses, confidence measures and vessel boundary measures for extracting vessels in retinal images.
We propose a novel self-consistent Composition-by-Decomposition (CoDe) network to compose a pair of objects from their joint distributions.
A domain adaptation framework for bridging the gap between synthetic and real point cloud data for vehicle detection from a bird's eye view.
This paper presents a novel localized visual image feature motivated by image segmentation. The proposed feature embeds relative spatial information by learning different image parts while having a compact representation.
We propose a multi-model adaptive response fusion (MAF) mechanism to suppress the interference of background features in target detection stage.
A novel, deep learning-based, method for the detection of sintered and occluded primary particles, which renders a manual tuning of analysis parameters unnecessary.
We exploit three important, but previously understudied factors of employing deep convolutional neural networks to computer-aided detection problems.
In this paper, we introduce a learning model able to conceals personal information from an image, while maintaining any additional information present in the image (e.g. smile, hair-style, brightness).
We propose HAWKEYE, a separate neural network that analyzes the output layer of the DNN, and detects AEs, which can mislead DNN classifiers.
We present SIVO (Semantically Informed Visual Odometry and Mapping), a novel information-theoretic feature selection method for visual SLAM which incorporates machine learning and neural network uncertainty into the feature selection pipeline.
We propose a hybrid network that combines the HourGlass and U-Net architectures which minimizes the number of identity connections within the network and increases the performance for the same parameter budget.
We propose a two-stage detector that outperforms the state of the art in THUMOS14, achieving a mAP@tIoU=0.5 equal to 44.20%.
We propose a scalable photonic neuro-inspired architecture based on the reservoir computing paradigm, capable of recognising video-based human actions with state-of-the-art accuracy.
We propose a correlation-aware adversarial DA and DG framework where the features of the source and target data are minimized using correlation alignment along with adversarial learning.
We propose a compact architecture based on fully convolutional neural networks (FCN) to detect manipulated images of human faces using small resolution input images.
We propose a novel Coupled Projection multi-task Metric Learning (CP-mtML) method for large scale face retrieval.
We propose a multi-granularity generator to perform the temporal action proposal from different granularity perspectives, relying on the video visual features equipped with the position embedding information.
This paper establishes the existence of observable footprints that reveal the "causal dispositions" of object categories appearing in collections of images.
We propose a new evaluation metric for face alignment on 300W and carry out a rigorous evaluation of these methods by making the following contributions.
We propose a novel model (DDINMF) for the prediction of enhancive and degressive DDIs based on semi-nonnegative matrix factorization.
We propose a Graph2Seq based graph-to sequence model for natural question generation and achieve state-of-the-art scores on SQuAD.
We study the problem of coordinating multiple mobile agents to exhibit manipulation behaviors using a reinforcement learning (RL) approach using hierarchical sim2real.
We consider the problem of transferring knowledge within a family of similar Markov decision processes. Our method learns both the generative mapping and an approximate posterior of the latent variables, enabling identification of policies for new tasks by searching only in the latent space.
This paper proposes a novel end-to-end learning model, called skip-connected covariance (SCCov) network, for remote sensing scene classification (RSSC).
We propose a method to construct a selective classifier given a trained neural network. The classifier rejects instances as needed, to grant the desired risk (with high probability).
We describe an image compression method, consisting of a nonlinear analysis transformation, a uniform quantizer, and a non linear synthesis transformation. Using a variant of stochastic gradient descent, we jointly optimize the entire model for rate-distortion performance.
Knowledge Bases (KBs) contain a wealth of structured information about entities and predicates. In KBs, this information is often represented in two formats: (i) via counting predicates such as numberOfChildren and staffSize, that store aggregated integers, and (ii) via enumerating predicates that store individual set memberships. In this paper we aim at uncovering this hidden knowledge.
We address the problem of estimating a parametric model of 3D human mesh from a single image, including joint interdependencies of the model, and propose a new technique for regression that is explicitly informed by the known hierarchical structure.
Learning from Interventions using sub-goals in a hierarchical policy framework trains faster and achieves better asymptotic performance than typical LfD.
An improved crowd counting method based on scale-adaptive convolutional neural network for crowd scenes with few pedestrians.
We automatically analyse the facial behaviour of 91 out-patients -- this is almost 3 times the number of patients in other studies -- and propose SchiNet, a novel neural network architecture that estimates expression-related symptoms in two different assessment interviews.
We propose a Siamese attention architecture that jointly learns spatiotemporal video representations and their similarity metrics for person re-identification.
In Visual Question Answering (VQA), answers have a great correlation with question meaning and visual contents. Thus, we propose a novel trilinear interaction model which simultaneously learns high level associations between these three inputs.
In this paper, we propose CentripetalNet, an instance-based keypoint-based detector that matches corner points more accurately than the conventional embedding approaches.
Sequential Gating Ensemble Network (SGEN) for multi-scale face restoration.
We propose a boundary aware network (BAN) designed to exploit the visual contexts including boundary information and surroundings, named boundary context, and define three types of boundary contexts: side, vertex and in/out-boundary context.
We introduce meshlets, small patches of mesh that we use to learn local shape priors, and use them to reconstruct object meshes in any pose and from unseen classes.
We present SpanBERT, a pre-training method that is designed to better represent and predict spans of text.
We propose a deep recurrent two-stream architecture for the task of distinguishing pain from non-pain in videos of horses.
Multi-Stage HRNet to tackling the problem of multi-person pose estimation in images.
We introduce expressivity as a measure of how much a feature vector informs us about an attribute, where a featurevector can be from internal or final layers of a network.
Enhanced Question Answer Network (EQuANt) extends the successful QANet architecture of Yu et al. to cope with unanswerable questions.
This paper proposes new and evaluates four penalty functions for semi-global matching (SGM) and evaluates their performance.
We revisit two widely used approaches in computer vision, namely filtered channel features and Convolutional Neural Networks (CNN), and absorb merits from both by proposing an integrated method called convolutional Channel Features (CCF), which achieves state-of-the-art performances.
We identified miRNAs overlapped by the 22q11.2 microdeletion and for the first time investigated their predicted target genes, and those implicated by DGCR8, to identify targets that may be involved in the risk for schizophrenia.
Adversarial attack on person re-identification systems using learning-to-mis-rank formulation.
We introduce SDM-NET, a deep generative neural network which produces structured deformable meshes with visual quality, flexible topology, and meaningful structures.
We introduce a model that encodes such graphs as explicit memory in recurrent neural networks, and use it to model coreference relations in text.
We propose an efficient semidefinite programming (SDP) approach to worst-case linear discriminant analysis (WLDA), which is orders of magnitude faster than standard interior-point based WLDA.
Cross-dataset training aims to detect the union of different classes, so that we do not have to label all the classes for all the datasets.
We address the problem of recovering the 3D geometry of a human face from a set of multi-view facial images in multiple views leveraging a novel self-supervised view alignment loss.
In this paper, we propose a novel approach for text detection in natural images in a coarse-to-fine procedure.
We propose a framework containing two perturbation methods for differentially private collaborative filtering to prevent the threat of inference attacks against users.
We present the first comprehensive study of regularization techniques with multiple policy optimization algorithms on continuous control tasks, and find that only regularizing the policy network is typically enough.
The key of local matching algorithm is the selection of similarity measure function and window's size, this paper extracted a relatively simple adaptive window algorithm, that is to say the window size based on the gradient points, and adopt a new measure function instead of the SAD function, not only to reduce noise effects but also to improve matching accuracy.
The term periocular refers to the facial region in the immediate vicinity of the eye that can be used as a biometric trait for face recognition.
We identify uncertainty miscalibration problems in probabilistic LiDAR 3D object detection network, and propose three practical methods to significantly reduce errors in uncertainty calibration.
This paper proposes a simple yet effective method to diagnose feature representations of a pre-trained CNN without any testing samples.
We propose to concatenate the regular content of a conventional (small) patch with a compact representation of its (large) surroundings - its context - to achieve better matches, without the need to increase the database-size.
We propose a robust domain adaptation tracker based on the CNNs. The proposed tracker runs five times faster than MDNet with comparable tracking performance.
We present a conditional generative ConvNet (cgCNN) model which combines deep statistics and the probabilistic framework of generative convolutional neural networks to synthesize high quality dynamic, sound and image textures in a unified manner.
We describe a new optimization scheme for finding high-quality clusterings in planar graphs that uses weighted perfect matching as a subroutine.
We tackle the problem of texture inpainting where the input images are textures with missing values along with masks that indicate the zones that should be generated. For this, we propose a patch-wise real/fake classification and is supervised by input masks.
This paper proposes a domain adaptation framework for vehicle reID (DAVR), which narrows the cross-domain bias by fully exploiting the labeled data from the source domain to adapt the target domain.
We propose a general framework for manifold-aware training of deep neural networks, in which the final outputs are elements on a Riemannian manifold.
We propose a weakly-supervised framework for action labeling in video, where only the order of occurring actions is required during training time.
In this paper, we propose a simple, fast and easy to implement algorithm LOSSGRAD, which automatically modifies the step-size in gradient descent during neural networks training, which is insensitive to the choice of initial learning rate.
Image compression, as one of the fundamental low-level image processing tasks, is very essential for computer vision. Conventional compression methods tend to obtain compressed images by minimizing their appearance discrepancy with the corresponding original images, but pay little attention to their efficacy in downstream perception tasks, e.g., image recognition and object detection.
We develop PathCon, a knowledge graph completion method that harnesses four novel insights to outperform state-of-the-art methods by a large margin.
We unify these existing results by showing a close connection between separable smoothness and $\ell_\infty$-smoothness and argue that the latter is the weaker and more natural assumption.
We present a memristor-based cascaded framework with some basic computation units and several neural network processing units for neuromorphic computing.
In this paper, we aim to predict human eye fixation with view-free scenes based on an end-to-end deep learning architecture based on a skip-layer network structure, which predicts human attention from multiple convolutional layers with various reception fields.
We have validated both ICA architectures on retinal fundus images and selected the one that provides improved contrast values.
We propose a novel end-to-end learning framework that leverages conditional GANs guided by provided face masks for generating faces and allowing more face editing.
A unified attack model that integrates both adversarial inputs and backdoored models within a unified framework for holistic vulnerability.
We describe a novel cross-modal embedding space for actions, named Action2Vec, which combines linguistic cues from class labels with spatio-temporal features derived from video clips, and evaluate its distributional semantics.
We use a hybrid CTC/attention architecture for audio-visual recognition of speech in-the-wild.
Unsupervised recalibration (URC) is a general way to improve the accuracy of an already trained probabilistic classification or regression model upon encountering new data while deployed in the field.
We present a method for learning an embedding that places images of humans in similar poses nearby.
In this paper, taking pedestrian detection as an example, we provide a new perspective where detecting objects is motivated as a high-level semantic feature detection task.
We provide an overview of the current state-of-the-art of robust and efficient machine learning for real-world systems.
Automatic synthesis of faces from visual attributes is an important problem in computer vision and has wide applications in law enforcement and entertainment. With the advent of deep generative convolutional neural networks (CNNs), attempts have been made to synthesize face images from attributes and text descriptions. In this paper, we formulate the original problem as a stage-wise learning problem.
We investigate the problem of image retrieval based on visual queries when the latter comprise arbitrary regions-of-interest (ROI) rather than entire images. Our proposal is a Voronoi-based descriptor that combines the state- of-the-art in content- based descriptor extraction with a multilevel, Voronois-based spatial partitioning.
We propose an extension of U-Net with Densely connected convolutions for medical image segmentation, achieving state-of-the-art performance.
Instantaneously detecting the emotions of video viewers’ emotions from electroencephalogram (EEG) signals and facial expressions.
We propose Evolution-Preserving Trajectory (EPT) descriptors, a novel type of video descriptor that significantly outperforms TraJECTory-pooled Deep-learning Descriptors on Hollywood2 and UCF101 datasets.
Part-based models with restrictive tree-structured interactions for the Human Pose Estimation problem, leave many part interactions unhandled. We address the self-occlusion in a data efficient manner, improving the performance of the basic Mixture of Parts model by a large margin.
We proposed a large new bike-person re-identification dataset named BPReid to address such a novel and practical problem and proposed a new pipeline designed for bike person re-id.
Multi-Domain Pose Network for multi-person pose estimation and tracking in the wild .
We explore a novel model based on a multi-layer and multi-head attention architecture and we pro- pose two innovative approaches to integrate the Simple PPDB (A Paraphrase Database for Simplification), an external paraphrase knowledge base for simplification.
We propose an automatic way to collect accurate 3D human pose annotations for multi-view human pose prediction tasks.
Obtaining common sense knowledge using current information extraction techniques is extremely challenging. In this work, we instead propose to derive simple common sense statements from fully annotated object detection corpora such as the Microsoft Common Objects in Context dataset.
In this paper, we develop a set of reversible data perturbation techniques for large bipartite association graphs that use perturbations keys to control sequential generation of multiple snapshots of the data to offer multi-level access based on privacy levels.
Camera Traps (or Wild Cams) enable the automatic collection of large quantities of image data. The computer vision community has been making strides towards automating the species classification challenge in camera traps, but as we try to expand the scope of these models from specific regions where we have collected training data, we are faced with an interesting problem: how do you classify a species in a new region that you may not have seen in previous training data?
We explore a key architectural aspect of deep convolutional neural networks: the pattern of internal skip connections used to aggregate outputs of earlier layers for consumption by deeper layers.
We propose a method to extract the relationships between users and items and embed them into the latent vectors of the factorization model for collaborative filtering.
We show that it is possible to fine-tune these models and make them perform even better if they are fine-tuned with sum of cross-entropy loss and reverse Kullback-Leibler divergence.
Unconstrained face detection from outdoor surveillance cameras can approach high detection rates albeit with moderate false accept rates.
Large-batch optimization is hard. To solve this problem, we design and implement our own system CPD: A High Performance System for Customized-Precision Distributed DL.
We propose remedies inspired by propositional logic for adversarial examples and propose a new hypothesis on their origins.
We study a budgeted hyper-parameter tuning problem, where we optimize the tuning result under a hard resource constraint, such that we can use the partial training progress of configurations to dynamically allocate the remaining budget.
We propose a discriminative LSR method based on the Fisher discrimination criterion, where the projected features have small within- class scatter and large inter-class scatter simultaneously.
We propose center-click annotations for object class detectors which reduce annotation time by 9x to 18x.
This work proposes a novel integrated temporal scale aggregation network (TSA-Net) for temporal action localization.
In this paper, we address the problem of generating person images conditioned on both pose and appearance information, using deformable skip connections in the generator of our Generative Adversarial Network.
MobileNetV2 improves the state of the art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes.
The goal of this paper is to estimate the 6D pose and dimensions of unseen object instances in an RGB-D image in a cluttered scene.
This paper proposes a method called attention convolution collaborative filtering (Att-ConvCF), which integrates an attention mechanism with a collaborative filtering model to improve the effectiveness of the feature extraction.
We present an algorithm for extracting key-point descriptors using deep convolutional neural networks (CNN) and a face alignment algorithm using these descriptors.
We provide a review of how statistical models can be "trained" on large knowledge graphs, and then used to predict new facts about the world (which is equivalent to predicting new edges in the graph).
We present a two-step approach to question answering from unstructured text, consisting of a retrieval step and a comprehension step. We achieve state-of-the-art performance on W IKI M OVIES dataset.
We present ATOMO, a general framework for atomic sparsification of stochastic gradients, which can operate on any possible atomic decomposition.
We proposed a novel deep learning architecture named as recurrent 3D convolutional neural network (R3D) to extract effective and discriminative spatial-temporal features for action recognition.
We propose a novel transfer learning approach based on meta-learning that can automatically learn what knowledge to transfer from the source network to where in the target network to improve the performance in small-data regime.
We establish a stable backward diffusion model which implements a smart stabilisation approach that can be used in combination with a simple numerical scheme.
In this paper, we formulate the problems of image copy detection and image recognition in terms of sparse representation in order to achieve robustness and security.
In this paper, we take the structural characteristics of heterogeneous relations into consideration and propose a novel Relation structure-aware Heterogeneous Information Network Embedding model (RHINE), which significantly outperforms the state-of-the-art methods in various tasks.
We propose a novel and data driven strategy for adaptively spatial feature fusion (ASFF), which learns the way to spatially filter conflictive information to suppress the inconsistency, thus improving the scale-invariance of features, and introduces nearly free inference overhead.
We introduce a measurable notion of modularity for multi-layer perceptrons (MLPs), and investigate the modular structure of MLPs trained on datasets of small images.
Inspired by the recent success of methods that employ shape priors to achieve robust 3D reconstructions, we propose a novel recurrent neural network architecture that we call the 3D Recurrent Reconstruction Neural Network (3D-R2N2)
We propose a method called Cascade of Tasks (CoT) that combines the use of different tasks (i.e., frame, segment and transition) for AU event detection.
Sequence-to-sequence models are commonly trained via maximum likelihood estimation (MLE). However, standard MLE training considers a word-level objective, predicting the next word given the previous ground-truth partial sentence, and may fail to capture long-range semantic structure. We present a novel solution to alleviate these issues.
We develop a commonsense-related multi-choice question answering dataset for pre-training a neural language representation model.
The role of conversational assistants has become more prevalent in helping people increase their productivity. Document-centered assistance, for example to help an individual quickly review a document, has seen less significant progress, even though it has the potential to tremendously increase a user's productivity.
We generalize the generator step to four new classes of loss functions, most of which are actual divergences (while traditional G loss functions are not), and show that these loss functions converge well and provide comparable data generation quality.
The paper looks at a scaled variant of the stochastic gradient descent algorithm for the matrix completion problem for efficient preconditioning.
We present a large public dataset with more than 6k new photographs, allowing for the first time to tackle at scale the scenarios of practical interest for scholars: one-shot instance recognition and cross-domain watermark recognition amongst more than 16k fine-grained classes.
Data-dependent hashing based on p-stable distribution preserves Euclidean distance preserving property in terms of variance estimation.
In this paper, we propose a system to allow decomposing a single image into a plausible shading decomposition (PSD) that approximates effects such as shadow, diffuse illumination, albedo, and specular shading.
We present a TTS neural network that is able to produce speech in multiple languages, without matching or parallel data.
LiteralE merges entity embeddings with their literal information using a learnable, parametrized function, such as a simple linear or nonlinear transformation.
We propose Mimic and Fool, a task agnostic adversarial attack which can mimic the image feature of the original image.
We propose a unified Semantic-Aware DIscrete Hashing (SADIH) framework, which aims to directly embed the transformed semantic information into the discriminative latent semantic space for efficient hashing function learning.
We represent 3D shape by structured 2D representations of fixed length making it feasible to apply well investigated 2D convolutional neural networks for both discriminative and geometric tasks on 3D shapes.
We propose a novel salient region detection method that captures, in an unsupervised manner, patterns that are both discriminative and common in the dataset. The descriptors derived on salient regions improve particular object retrieval.
Deep learning revolutionized data science, and recently its popularity has grown exponentially, as did the amount of papers employing deep networks. This situation motivates the current study, in which we perform a systematic evaluation and statistical analysis of vanilla deep regression, i.e. convolutional neural networks with a linear regression top layer.
We propose an exploration method that incorporates lookahead search over basic learnt skills and their dynamics, and use it for reinforcement learning (RL) of manipulation policies. We show that the proposed exploration strategy results in effective learning of complex manipulation policies faster than current state-of-the-art RL methods.
We propose to use recurrent connections within the convolutional layers to make networks robust against pixel noise such as could arise from imaging at low light levels, and thereby significantly increase their performance.
We study the notion of consistency between a 3D shape and a 2D observation and propose a differentiable formulation which allows computing gradients of the3D shape given an observation from an arbitrary view.
We propose a novel compact LSTM model, named as TR-LSTM, by utilizing the low-rank tensor ring decomposition (TRD) to reformulate the input-to-hidden transformation in RNNs.
We propose the Bidirectional cGAN (BiCoGAN), which effectively disentangles $z$ and $c$ in the generation process and provides an encoder that learns inverse mappings from $x$ to both latent variables and auxiliary information in a more disentangled way to generate samples.
Polygon-RNN++ is an interactive polygonal annotation tool for high-resolution images that can be used for cross-domain tasks.
We focus on the non-Lambertian object-level intrinsic problem of recovering diffuse albedo, shading, and specular highlights from a single image of an object. Our CNN delivers accurate and sharp results.
We propose the privacy shadow for measuring how long a user remains predictive from an arbitrary time within the network.
We propose a novel yet simple unsupervised video summarization method with attentive conditional Generative Adversarial Networks with frame-level multi-head self-attention.
We propose a new loss, called support neighbor (SN) loss, based on the positive and negative support neighbor sets of each anchor sample, which contain more valuable contextual information and neighborhood structure that are beneficial for stable performance.
We present a new deep learning approach to pose-guided resynthesis of human photographs using a fully-convolutional architecture with deformable convolutions.
We present an approach for end-to-end learning that allows one to jointly learn a feature representation from unlabeled data (with or without labeled data) and predict labels for unl labeled data.
We propose a novel Complementary Temporal Action Proposal (CTAP) generator that captures temporal intervals in videos that are likely to contain an action.
Detecting blood vessels in both normal and abnormal retinal fundus images based on their linear features.
In this paper, we propose a novel framework for salient region detection that uses appearance-based and regression-based schemes for image saliency detection.
We propose an object-adaptive LSTM network to effectively capture the video sequential dependencies and adaptively learn the object appearance variations during online visual tracking.
We present in this chapter an overview of techniques for the performance evaluation of behavioral biometric systems.
In this paper, we proposed a new refinement procedure for the semi-global dense image matching. In order to remove outliers and improve the disparity image, both the local smoothness constraint and point cloud segments are utilized.
Generative adversarial networks (GANs) have achieved impressive results today, but not all generated images are perfect. In this paper, we propose a new research topic, Generated Image Quality Assessment (GIQA), which quantitatively evaluates the quality of each generated image.
Combining poisoning and image-scaling attacks for hiding backdoor and poisoning attacks .
We propose a real-time complementary tracker (RCT), a two-stage tracking framework where DCF and Siamfc share mutual advantages and complement each other.
Aging or gender variation can affect the face recognition performance dramatically. We address these problems on a very large longitudinal database MORPH-II which contains 55,134 face images.
We unify bilinear pooling and the global Gaussian embedding layers through the empirical moment matrix. In addition, we propose a novel sub-matrix square-root layer, which can be used to normalize the output of the convolution layer directly and mitigate the dimensionality problem with off-the-shelf compact pooling methods.
An end-to-end architecture for fabric defect detection on optical image datasets is studied.
We propose to use attributes and parts for recognizing human actions in still images and achieve state-of-the-art classification performance.
The ability to extract the sequence of game events for a given player's play-through has traditionally required access to the game's engine or source code.
We present a robust real-time LiDAR 3D object detector that leverages heteroscedastic aleatoric uncertainties to significantly improve its detection performance.
We present a new method for classification with structured latent variables, where we model a human action as a global root template and a constellation of several “parts”.
We improve training of temporal deep models to better learn activity progression for activity detection and early detection tasks. We design novel ranking losses that directly penalize the model on violation of such monotonicities.
We propose a network for Congested Scene Recognition called CSRNet to provide a data-driven and deep learning method that can understand highly congested scenes and perform accurate count estimation as well as present high-quality density maps.
The objective in video frame interpolation is to predict additional in-between frames in a video while retaining natural motion and good visual quality. In this work, we use a convolutional neural network that predicts two optical flows with pixelwise weights.
We introduce the notion of RLDP (Restricted LDP), which provides a privacy guarantee equivalent to LDP only for sensitive data.
In this paper we propose IoU-Net learning to predict the IoU between each detected bounding box and the matched ground-truth, which improves the NMS procedure.
We investigated how inputs from four node representation algorithms affect performance of a neural link predictor on random- and time-sliced biomedical graphs of real-world sizes containing information relevant to DTI, PPI and LBD.
We propose a new vision task, Internetly supervised semantic segmentation, which only uses Internet data with noisy image-level supervision for segmentation model training.
We propose an effective superpixel-based temporally aligned representation for video-based person re-identification, which represents a video sequence only using one walking cycle.
We demonstrate the possibility of what we call sparse learning: accelerated training of deep neural networks that maintain sparse weights throughout training while achieving performance levels competitive with dense networks.
We present a fully automatic facial expression recognition (FER) system using salient geometric features.
We explore adversarial training for learning contextual encoders that produce invariant representations across languages to facilitate cross-lingual transfer.
We present an interactive sketch-based image retrieval and synthesis system that allows the interactive creation of complex images, and its final compositing results are natural and realistic.
In this paper, a MDSPF method is proposed to learn a robust observation model for representing the targets by training a CNN with a number of video sequences, and it is offline trained by a multi-domain learning strategy.
We propose a novel Structured-Spatial Semantic Embedding model for image deblurring guided by the semantic contents inferred from image captioning.
We propose robust feature based approach to deal with the problem of crowd management for people safety and security.
We exploit this fact to construct data triplets consisting of the same words with different contexts that form a pair of datapoints with matching target labels and an another pair with non-matching labels, leading to better classification results and improved rate of convergence.
A comparison study between different aggregation functions for the combination of RGB color channels in stereo matching problem.
We leverage the power of Deep Convolutional Neural Networks (DCNN) in feature learning, in this work, to achieve this ultimate goal.
We propose UnLearnerVO, a jointly unsupervised learning framework for monocular depth, camera motion estimation from videos, with robustness in a scenario with large camera motion.
We propose two types of fast and energy-efficient architectures for Binarized Neural Network inference and propose a reuse technique to exploit BNN similarity.
This paper proposes a novel method to progressive adapt the semantic models trained on daytime scenes, along with large-scale annotations therein, to nighttime scenes via the bridge of twilight time.
Mesh labeling is the key problem of classifying the facets of a 3D mesh with a label among a set of possible ones. In this paper we propose a novel energy term that acts as a prior, but does not require any prior knowledge about the scene nor scene-specific relationship among classes.
We present DeepICP - a novel end-to-end learning-based 3D point cloud registration framework that achieves comparable registration accuracy to prior state-of-the-art geometric methods.
We propose a novel neural attention architecture for machine comprehension tasks, such as answering Cloze-style queries with respect to a document.
We propose an automatic approach for designing compact multi-task deep learning architectures, on which similar tasks reside in the same branch.
We train deep convolutional neural networks to identify, count, and describe the behaviors of 48 species in the 3.2 million-image Snapshot Serengeti dataset.
We propose a novel deep multi-task adversarial learning method to localize facial landmark, estimate head pose and recognize gender jointly or estimate multiple face attributes simultaneously.
We propose a novel volumetric convolution operation that can effectively model and convolve arbitrary functions in \(\mathbb {B}^3\) around an arbitrary axis, that is useful in function analysis tasks.
This paper proposes to exploit the unlabeled data to mimic the classification characteristics of giant networks, so that the original capacity can be preserved nicely.
We propose Likelihood Regret, an efficient OOD score for generative models based on Variational Auto-encoders (VAE), which obtains the best overall OOD detection performances compared with other OOD method applied on VAE.
A standard model for exposing structured provenance metadata of scientific assertions on the Semantic Web would increase interoperability, discoverability, reliability, and reproducibility for scientific discourse and evidence-based knowledge discovery.
We propose a two-stage visual consistency network (VCN), meant to estimate where to fill (via masks) and generate what to fill, making training a blind inpainting neural system robust against unknown missing region patterns.
This paper proposes 3D-aware features computed from stereo color images in order to capture the appearance and depth peculiarities of the objects in road scenes.
We have designed a convolutional neural network that uses the multi-task learning approach to simultaneously detect manipulated images and videos and locate the manipulated regions for each query.
We formulate a filter-and-refine scheme, where the binary outputs of the weak classifiers in a boosted detector are used to identify a small number of candidate foreground state hypotheses quickly via Hamming Distance or weighted Hamming distance.
We propose a generative model to estimate bounding box label uncertainties from LiDAR point clouds, and define a new representation of the probabilistic boundingbox through spatial distribution, and propose an extension of IoU, called the Jaccard IoU.
We propose a cross-attention mechanism based on self-att attention to capture context dependencies between two domains and adapt transferable context.
The border regression is a key technique of the regional convolution neural network (CNN) to locate the target. For this, a novel target detection method based on the CNN and the particle search is proposed. The method can be used to recognize and locate various kinds of targets.
This paper analyses if RGB and depth data, RGBD data, can actually act as complementary information in a multimodal end-to-end driving approach, producing a better AI driver.
A CNN trained by minimizing the proposed loss is able to predict semantic categories for visible and occluded object parts without requiring to increase the network size.
We propose a cross-lingual QG model which uses the following training regime: Unsupervised pretraining of language models in both primary and secondary languages and joint supervised training for QG in both languages.
We introduce a new algorithmic framework, called Learnable Bregman Splitting, to perform deep-architecture-based operator splitting for nonconvex optimization based on specific task model.
In this work, we propose a combined bottom-up and top-down attention mechanism that enables attention to be calculated at the level of objects and other salient image regions.
A first-principle model of the cell whose phenotypic traits are directly determined from its genome through biophysical properties of protein structures and binding interactions.
This paper presents a new method to define and compute convolution directly on 3D point clouds by the proposed annular convolution by specifying the (regular and dilated) ring-shaped structures and directions in the computation.
A deep image compression scheme is proposed in this paper, offering the state-of-the-art compression efficiency, against the traditional JPEG, JPEG2000, BPG and those popular learning based methodologies.
We describe an end-to-end method for recovering 3D human body mesh from single images and monocular videos. It reduces the complexity and decouples the skeleton from the details.
In this paper, we propose a novel network architecture, called edge-conditioned convolutional neural network (EC-CNN), for thermal image semantic segmentation.
In this paper, we introduce a framework to generate an optimal mutual virtual space for a multi-user interaction setting, where finding a common accessible virtual ground physically accessible for all participants becomes challenging.
We propose a novel multilayer sparse coding network capable of efficiently adapting its own regularization parameters to a given dataset.
We test bias in benchmark data sets by separating a small area from each image such that the area is seemingly blank, and too small to allow manual recognition of the object.
Evaluating multi-target tracking based on ground truth data is a surprisingly challenging task. The goal of this paper is to raise awareness of common pitfalls related to objective ground truth evaluation.
In this paper, we present a complete loop detection and correction system developed for data originating from lidar scanners.
In this paper, we propose a graph convolution network to regress 3D face coordinates, where the geometric structure and details are well preserved.
We propose a novel type of aesthetic QR codes, Stylized aEsthEtic (SEE) QR code, and a three-stage approach to automatically produce such robust style-oriented codes.
We propose a neural network component, the regional aggregation layer, that makes it possible to train a pixel-level density estimator using only coarse-grained density aggregates, which reflect the number of objects in an image region.
We propose a method to address this problem, and show in experiments that our method can help this joint vision and language modeling task with vision-only and text-only data.
We rerank with scores from pretrained masked language models like BERT and RoBERTa to improve ASR and NMT performance.
We propose a quantitative evaluation metric for the consistency between attention maps and human annotations, using recently released datasets with alignment between regions in images and entities in captions. We propose novel models with different levels of explicit supervision for learning attention maps during training.
We demonstrate the importance of encoding such relations by showing the limited effective receptive field of ResNet on two datasets, and propose to model the visual attention as a multivariate distribution over a Conditional Random Field on image regions.
Region-based image retrieval (RBIR) is revisited by incorporating semantic specification of objects and intuitive specification of spatial relationships.
Deep evolutionary network structured representation (DENSER) is a novel evolutionary approach for the automatic generation of deep neural networks (DNNs) which combines the principles of genetic algorithms (GAs) with those of dynamic structured grammatical evolution (DSGE).
Extended RBM to model spatio-temporal patterns among high-dimensional motion data.Generative approach to perform classification using RBM, for both binary and multi-class classification.
We address the problem of searching for semantically similar images from a large database using supervised quantization, a compact coding approach.
In this paper, we propose a handwriting generative adversarial network framework for synthesizing handwritten stroke data.
We show that the task of question answering (QA) can significantly benefit from the transfer learning of models trained on a different large, fine-grained QA dataset.
We train a generator by maximum likelihood and an independent critic trained to approximate Wasserstein distance between the validation set and the generator distribution helps detect overfitting.
We propose a nonlinear local metric learning method to improve the state-of-the-art performance of person re-identification.
In this work, we propose a new story-to-image-sequence generation model, StoryGAN, based on the sequential conditional GAN framework, for story visualization.
We exploit Markov decision process to integrate the discriminative correlation filters-based tracking method into our MOT framework and address the update problem of the appearance model in DCFB tracking method.
We propose a frame-to-frame stereo visual odometry (VO) method based on carefully selected components and parameters.
We show for the first time that it is possible to jointly learn the retriever and reader from question-answer string pairs and without any IR system.
In this paper we unify the two viewpoints in a Deep Learning Inference Stack and take an across-stack approach by implementing and evaluating the most common neural network compression techniques (weight pruning, channel prune, and quantisation) and optimising their parallel execution with a range of programming approaches (OpenMP, OpenCL) and hardware architectures (CPU, GPU).
We introduce a new gesture recognition framework based on learning local motion signatures (LMSs) of HOG descriptors introduced by [1].
In this work we propose a novel neural network architecture for the problem of human action recognition in videos. The proposed architecture expresses the processing steps of classical Fisher vector approaches as a single neural network.
In this paper we consider the problem of estimating a dense depth map from a set of sparse LiDAR points using only three layers and 1800 parameters.
We present a stereo-based dense mapping algorithm for large-scale dynamic urban environments. In contrast to other existing methods, we simultaneously reconstruct the static background, the moving objects, and the potentially moving but currently stationary objects separately.
This paper aims at learning discriminative relation between actors efficiently using deep models for group activity recognition.
We develop a general co-expression network-based approach for analyzing both genes and samples in microarray data, which is effective in discovering functional gene modules in synthetic and real data.
In this letter, we present a new approach for object classification in continuously streamed Lidar point clouds collected from urban areas. We propose a complete pipeline developed especially for distinguishing outdoor 3-D urban objects.
In this paper, we propose 3D shape programs, integrating bottom-up recognition systems with top-down, symbolic program structure to capture both low-level geometry and high-level structural priors for 3D shapes.
We propose an artwork type enriched image captioning model where the encoder represents an input artwork image as a 512-dimensional vector and the decoder generates a corresponding caption based on the input image vector.
We propose a compact convolutional neural network for crowd counting which learns a more efficient model with a small number of parameters.
This paper proposes CQ-VQA, a novel 2-level hierarchical but end-to-end model to solve the task of visual question answering ( VQA).
The paper presents a new model for single channel images low-level interpretation. The image is decomposed into a graph which captures a complete set of structural features.
Comparison of thirteen state-of-the-art superpixel algorithms utilizing depth information.
Automatic diagnosing lung cancer from computed tomography scans involves two steps: detect all suspicious lesions (Pulmonary nodules) and evaluate the whole-lung/pulmonary malignancy. We propose a 3-D deep neural network to solve this problem.
We propose a new framework (Consistent Rank Logits, CORAL) with theoretical guarantees for rank-monotonicity and consistent confidence scores.
We propose a computationally efficient channel pruning approach based on the coarse ranking that utilizes the intermediate results during fine-tuning to rank the importance of filters, built upon state-of-the-art works.
We propose a novel latent ap-svm classifier that minimizes a carefully designed upper bound on the ap-based loss function over weakly supervised samples.
We propose the Adaptive and Momental Bound (AdaMod) method to restrict the adaptive learning rates with adaptive and momental upper bounds and bring significant improvements especially on complex networks such as DenseNet and Transformer.
In urban driving scenarios, forecasting future trajectories of surrounding vehicles is of paramount importance. While several approaches for the problem have been proposed, the best-performing ones tend to require extremely detailed input representations. In this paper, we propose intermediate representations that are particularly well-suited for future prediction.
This paper proposes the SVDNet for retrieval problems, with focus on the application of person re-identification (reID).
We propose a generic iterative framework for fine-grained categorization and dataset bootstrapping using deep metric learning with humans in the loop that handles these three challenges.
CNN-CAtt-ConvLSTM: A attention-based neural network for pedestrian attribute recognition .
We address the frame-based perception of the universal human facial expressions (happiness, surprise, anger, disgust, fear, and sadness), with the help of several geometrical features.
This work poses video prediction and interpolation as unsupervised latent structure inference followed by a temporal prediction in this latent space in order to achieve predictable motion interpolation and extrapolation.
We introduce an asymmetric sparse approximate embedding optimized for fast kernel comparison operations arising in large-scale visual search.
This paper describes what is known to date about the famous BERT model, synthesizing over 40 analysis studies. We then outline the directions for further research.
We propose a framework based on graph convolutional network, which combines a detection and a segmentation module to pinpoint face clusters, which, as a result, lead to further performance gain in face recognition.
In this paper, we address the problem of hand-drawn sketch recognition. Inspired by the Bayesian decision theory, we present a deep metric learning loss with the objective to minimize theBayesian risk of misclassification.
We present an adaptive scenario discovery framework for crowd counting.
We propose a novel two stage 3D object detection method aimed at get the optimal solution of object location in 3D space based on regressing two additional3D object properties by a deep convolutional neural network and combined with cascaded geometric constraints between the 2D and 3D boxes.
We develop several graph cut based optimization algorithms for truncated convex priors, which imply piecewise smoothness assumption. We develop new "range" moves which act on a larger set of labels.
We propose a novel deep learning model that combines the dilated residual convolution and multi-scale convolution groups to achieve promising denoising results.
We propose a novel encoder-decoder architecture that outperforms previous unsupervised monocular depth estimation networks by (i) taking into account ambiguities, (ii) efficient fusion between encoder and decoder features with rectangular convolutions and (iii) domain transformations.
In this paper, we propose a novel ProtoNet, capable of handling these two types of noises together, without the supervision of clean images in the training stage.
Combined in silico techniques for the discovery of potential inhibitors to β-ketoacyl-ACP synthase (MtKasA) in tuberculosis.
We announce a shared task on UCCA parsing in English, German and French and call for participants to submit their systems.
We propose a new loss formulation which directly optimizes over all parameters, i.e. 3D orientation, translation, scale and shape at the same time.
We propose a simple but effective method, called extended batch normalization (EBN), for NCHW format feature maps, which alleviates the problem ofbatch normalization with small batch size.
We present an efficient blind image inpainting algorithm to directly restore a clear image from a corrupted input. Our algorithm can predict the missing information in corrupted regions, thus facilitating the clear image restoration.
In this paper, we focus on implementing a reliable and real-time method which parses an image and detects faces, estimates their pose and locates landmark points on the face.
We analyse how adversarial perturbations can affect the task of Semantic Segmentation.
In this paper, we propose a novel meta learning approach for automatic channel pruning of very deep neural networks.
We propose Deep Robust One Class Classification (DROCC) method that is robust to such a collapse by training the network to distinguish the training points from their perturbations, generated adversarially.
We propose a feasible framework for multi-lingual arbitrary-shaped STR, including instance segmentation based text detection and language model based attention mechanism for text recognition.
We propose a hierarchically structured reinforcement learning approach to address the challenges of planning for generating coherent multi-sentence stories for the visual storytelling task.
We propose a discriminative single-shot segmentation tracker, which narrows the gap between visual object tracking and video object segmentation, while running an order of magnitude faster.
In this paper, we propose a novel Rule and Path-based Joint Embedding scheme, which takes full advantage of the explainability and accuracy of logic rules, the generalization of KG embedding as well as the supplementary semantic structure of paths for improving the accuracy and explainability of representation learning.
In this paper, we propose a event-based and events based optical flow estimation approach that can naturally handle both blurred and sharp images to improve flow estimates.
A local fragment-based object tracking algorithm that only selects discriminative, unique, and valid fragments for tracking in the presence of partial occlusion and other disturbances.
We study how general-purpose ontologies can improve state-of-the-art vision systems when properly filtered to select meaningful visual relations.
In this paper, we apply the entitymetrics model to our constructed Gene-Citation-Gene (GCG) network of gene pairs implicitly connected through citation.
In real-time bidding (RTB systems for display advertising, a demand-side platform (DSP) serves as an agent for advertisers and plays an important role in competing for online advertising spaces by placing proper bidding prices.
The goal of transfer learning is to improve the performance of target learning task by leveraging information (or transferring knowledge) from other related tasks. In this paper, we examine the problem of transfer distance metric learning (DML), which usually aims to mitigate the label information deficiency issue in the target DML.
We describe a simple approach to semantic parsing based on a tensor product kernel. This is comparable to more complex systems but is simpler to implement and runs faster.
In order to perform autonomous sequential manipulation tasks, perception in cluttered scenes remains a critical challenge for robots. We propose a probabilistic approach for robust sequential scene estimation and manipulation.
In this paper, we propose a new alignment framework, called 3D Dense Face Alignment (3DDFA), in which a dense 3D face model is fitted to the image via convolutional neutral network (CNN) and propose a method to synthesize large-scale training samples in profile views.
We use Relation Networks as a simple plug-and-play module to solve problems that fundamentally hinge on relational reasoning.
Facial verification systems are vulnerable to poisoning attacks that make use of multiple-identity images (MIIs) that resemble multiple persons, such that novel images of any of the constituent persons are verified as matching the identity of the MII.
Extensive evaluation on a large number of word embedding models for language processing applications is conducted in this work. It is shown that different evaluators focus on different aspects of word models, and some are more correlated with natural language processing tasks.
We propose dual co-matching network for multi-choice reading comprehension which models the relationship among passage, question and answer options bidirectionally.
This article presents REVAMP2T, Real-time Edge Video Analytics for Multi-camera Privacy-aware Pedestrian Tracking, as an integrated end-to-end IoT system for privacy-built-in decentralized situational awareness.
We develop an online person re-identification model that adapts the re-id model based on each newly observed data and no passed data are directly used for each update.
We propose an end-to-end model, named FAMNet, where Feature extraction, Affinity estimation and Multi-dimensional assignment are refined in a single network for robust data association-based multiple object tracking.
This paper presents a unified framework that can solve any pose problem by alternating optimization techniques between two set of parameters, rotation and translation.
The rise of intelligent vehicle systems will lead to more human-machine interactions and so there is a need to create a bridge between the system and the actions and behaviours of the people inside the vehicle. In this paper, we propose a dual camera setup to monitor the Actions and behaviour of vehicle passengers and a deep learning architecture which can utilise video data to classify them.
We introduce the STEM Dataset for Scientific Entity Extraction, Classification, and Resolution, version 1.0 (STEM-ECR v1.0).
We show that the adversarial perturbations prevail in the Y-channel of the YCbCr space and propose a defence against adversarial images in an upsampling framework.
We construct a novel dataset called WikiSatNet by pairing georeferenced Wikipedia articles with satellite imagery of their corresponding locations.
We propose a new method for preserving learned knowledge by modeling the high-level feature space and the output space to be mutually informative, and constraining feature vectors to lie in the modeled space during training.
Image de-fencing using conditional Generative Adversarial Networks (cGANs).
We train multiple convolutional networks at a batch size of one, completely replacing batch parallelism with fine-grained pipeline parallelism.
We propose a logic graph embedding network that projects d-DNNF formulae (and assignments) onto a manifold via an augmented Graph Convolutional Network (GCN).
A Siamese network guided by Intersection Over Union while training, to predict precise bounding box.
A novel two-way neural sequence transduction model that connects three modalities, allowing it to learn two tasks simultaneously and mutually benefit one another.
We incorporate the anisotropic edge strength into the distance measure between neighboring superpixels, thereby improving the performance of an existing graph-based superpixel segmentation method.
This paper contains a survey of the recent state-of-the-art deep learning techniques that mainly focused on point cloud data.
A 3D landmark detection method for 3D facial scans with state-of-the-art accuracy and robustness.
We propose a unified explanation for the beneficial properties of self-modularization, and propose a new activation function that implements local competition between small groups of computational units.
We propose a novel mask based deep ranking neural network with a skipped fusing layer for person retrieval.
We propose a novel end-to-end deep parallel neural network for point cloud odometry, which can estimate the 6-DOF poses using consecutive point clouds.
We propose two data reconstruction methods that derive original private information from disguised data in existing perturbation collaborative filtering schemes while still producing accurate recommendations.
In this work, we uncover a theoretical connection between two language model interpolation techniques, count merging and Bayesian interpolation, showing that both techniques perform similarly.
This paper proposes an agile domain-specific benchmarking methodology for end-to-end applications. We propose the permutations of essential AI and non-AI component benchmarks as end- to-end benchmarks.
We introduce a modular continual reinforcement learning paradigm that learns new tasks robustly in the very large state and action spaces required by such an environment.
We address the problem of hallucinating high-resolution facial images from low-resolution inputs at high magnification factors and propose a novel (deep) face hallucination model that incorporates identity priors into the learning procedure.
We present a novel defense which operates in the DNN feature domain and effectively defends against such universal adversarial attacks.
The use of robo-readers to analyze news texts is an emerging technology trend in computational finance. However, based on experience from fields that commonly analyze sentiment, it is well known that the overall semantic orientation of a sentence may differ from that of individual words. This article investigates how semantic orientations can be better detected in financial and economic news.
We prove stable recurrent neural networks are well approximated by feed-forward networks for the purpose of both inference and training by gradient descent.
In this paper, we present a multimodal dialogue system for Conversational Image Editing.
The problem of jointly segmenting objects, according to cardinality L, from a set of images (of cardinality K) to produce K individual segmentations plus one joint segmentation, can be cast as a Markov random field model. Coupling terms in the considered energy function enforce the consistency between the Individual segmentations and the joint segmentations.
In this paper, the GPS approach is reformulated, by adapting a recently proposed, lifelong-learning method, and elastic weight consolidation, to operate in sequential multitask learning.
We propose a novel problem of unconstrained foreground object search and introduce a solution that supports efficient search by encoding the background image in the same latent space.
Precisely estimating a robot’s pose in a prior, global map is a fundamental capability for mobile robotics, e.g., autonomous driving or exploration in disaster zones.
We propose a novel Online Meta-Learning model with Adaption for stereo depth estimation that exploits feature alignment for faster convergence in an online learning setting.
We introduce a method called Feature-extractor Optimization through Classifier Anonymization (FOCA), which avoids an explicit co-adaptation between a feature extractor and a classifier by using many randomly-generated, weak classifiers during optimization.
We propose a new approach to study image representations by inverting them with an up-convolutional neural network, revealing that there is surprisingly rich information contained in these features.
We propose a hierarchical compositional reasoning model called the"Linguistically driven Graph Capsule Network", where the compositional process is guided by the linguistic parse tree, which results in a compositional Reasoning process inside a CNN.
TCE: Temporally Coherent Embeddings for self-supervised video representation learning.
We investigate these issues, with an emphasis on time to convergence and total computational cost, through an extensive empirical analysis of network training across several architectures and problem domains, including image classification, image segmentation, and language modeling.
This work presents CascadeCNN, an automated toolflow that pushes the quantisation limits of any given CNN model, aiming to perform high-throughput inference.
This paper adapts state-of-the-art methods for detecting out of distribution images for image classification to a new task of localising the unusual objects. The evaluation shows that the performance ranking of the compared methods does not transfer to the new task and every method performs significantly worse.
We explore the biases in the MovieQA dataset and propose a strikingly simple model which can exploit them.
This paper introduces a comparative study of age estimation based on the analysis of facial images using pre-trained deep convolutional neural networks.
BlendMask combines instance-level information with semantic information with lower-level fine-granularity for fast and efficient instance segmentation.
A novel application of the U-Net semantic segmentation architecture (based on FCNs) on the discrimination of arteries and veins in fundus images is presented.
This work addresses the problem of semantic segmentation of nighttime images. We focus on improving the performance of state-of-the-art methods by adapting them to nighttime data without extra annotations, and designing a new evaluation framework to address the uncertainty of semantics in nighttime data.
We propose a method which scores each candidate window in the context of all other windows in an image, taking into account their similarity in appearance space as well as their spatial relations in the image plane.
We introduce a Causal And-Or Graph (C-AOG) to represent the causal-effect relations between an object's visibility fluents and its activities, and develop a probabilistic graph model to jointly reason the visibility fluent change (e.g., from visible to invisible) and track humans in videos.
We propose Show-and-Fool, a novel algorithm for crafting effective adversarial examples for image captioning.
We study weakly supervised learning approaches for salient object detection. Given a set of background images and salient object images, we propose a solution toward jointly addressing the salient object existence and detection tasks.
We analyze and discover that inconsistency is the major factor limiting the performance. A multistage object detector named Cas-RetinaNet achieves stable performance gains across different models and input scales.
We propose a novel approach to geometry-aware deep LiDAR odometry trainable via both supervised and unsupervised frameworks. We incorporate the Iterated Closest Point (ICP) algorithm into a deep-learning framework.
We present a novel solution to the problem of simulation-to-real transfer, which builds on recent advances in robot skill decomposition. Rather than focusing on minimizing the simulation-reality gap, we learn a set of diverse policies that make them easily reusable.
We propose a Frame Segmentation Network (FSN) that places a temporal CNN on top of the 2D spatial CNNs that can make dense predictions at frame-level for temporal action localization.
We propose a GAN-like method to transform a simple distribution to a data distribution in the latent space by solving only a minimization problem.
An improved multi-column convolution neural network for crowd counting based on the cascaded learning method.
We propose a novel network architecture, the efficient second-order minimization (ESM) layer, which performs the ESM algorithm on deep feature maps, for robust visual tracking.
We present Convolutional Oriented Boundaries (COB), which produces multiscale oriented contours and region hierarchies starting from generic image classification convolutional Neural Networks (CNNs).
We quantify the relation between ASR and SER by studying the relevance of features learned between both tasks in deep convolutional neural networks using transfer learning.
This paper shows that it is possible to train large and deep convolutional neural networks for JPEG compression ::: artifacts reduction, and that such networks can provide significantly better reconstruction quality compared to ::: previously used smaller networks.
Automated Holstein Friesian cattle detection and localisation using off-the-shelf deep neural networks in agriculturally relevant setups.
We present a novel unsupervised 3D-zoom learning problem where images with an arbitrary zoom factor can be generated from a given single image, not requiring a 3Dsoom ground truth.
We propose rectified binary convolutional networks, towards optimized BCNNs, by combining full-precision kernels and feature maps to rectify the binarization process in a unified framework.
We propose a simple, lightweight, but powerful bimodal encoding method that improves VLAD-based video encoding by large margins in action recognition.
We present a novel CL strategy for learning the geometry of monocular Visual Odometry by gradually making the learning objective more difficult during training.
In this paper, we propose to apply adversarial training to SER to learn speaker-invariant representations.
We propose an explanation method that pairs a saliency map identifying important image regions with an attribute that best explains the match.
We propose to integrate predictive models of nodule malignancy in an automated end-to-end existing pipeline of lung cancer detection and to integrate it in the baseline pipeline.
We propose an end-to-end multi-scale correspondence structure learning (MSCSL) approach for optical flow estimation.
An intermediate image-to-attributes layer can dramatically improve captioning results over the current approach which directly connects an RNN to a CNN.
We present a more effective approach of video representation using improved salient dense trajectories for human action recognition.
In this paper, we generalize the Earley parser to parse sequence data which is neither segmented nor labeled and make top-down future predictions.
We introduce a new annotation scheme, corpus, and task for the disambiguation of prepositions and possessives in English.
A CNN-REgularized ADMM framework for fast and accurate compressed sensing reconstruction of natural images.
Automated learning of shallow learning algorithms for character recognition and object recognition .
This paper presents a membership privacy analysis and evaluation system, called MPLens, with three unique contributions. We show that risk from membership inference attacks is routinely increased when models use skewed training data, particularly when the training data itself is skewed.
We address a question answering task on real-world images that is set up as a Visual Turing Test, where the language output (answer) is conditioned on visual and natural language inputs (image and question).
A deep hybrid similarity learning (DHSL) method for person Re-ID based on a convolution neural network.
This paper proposed a large-scale dataset named AIC (AI Challenger) with three sub-datasets, human keypoint detection (HKD), large- scale attribute dataset (LAD) and image Chinese captioning (ICC) for complex Computer Vision tasks beyond classification.
We propose Quantized SGD, a family of compression schemes which allow the compression of gradient updates at each node, while guaranteeing convergence under standard assumptions.
A novel family of 2D and 3D geometrically invariant features, called summation invariants, is proposed for the recognition of the 3D surface of human faces.
We propose a soft attention based model for the task of action recognition in videos which learns to focus selectively on parts of the video frames and classifies videos after taking a few glimpses.
We evaluate a state-of-the-art DNN audio model based on a Bi-directional Long Short-Term Memory network architecture for speaker count estimations.
This article explores the subpixel accuracy attainable for the disparity computed from a rectified stereo pair of images with small baseline under Shannon-Whittaker conditions.
We tackle an unsupervised domain adaptation problem for which the domain discrepancy between labeled source and unlabeled target domains is large, due to many factors of inter and intra-domain variation.
We introduce the EEV dataset, a large-scale dataset for studying viewer responses to videos based on their facial expressions.
In this paper, we propose a two-stage fully 3D network, namely \textbf{DeepFuse}, to estimate human pose in 3D space by fusing body-worn Inertial Measurement Unit data and multi-view images deeply.
We present Zeno, a technique to make distributed machine learning, particularly Stochastic Gradient Descent, tolerant to an arbitrary number of faulty workers.
We extend the work of [11] on using variational autoencoders (VAEs) for collaborative filtering with implicit feedback by proposing a hybrid, multi-modal approach.
This paper investigates the problem of learning an image representation that minimizes such leakage of user information. We formulate the problem as an adversarial non-zero sum game with two competing goals: to retain as much task dependent discriminative image information as possible, while simultaneously minimizing the amount of information, as measured by entropy, about other sensitive attributes of the user.
We design a multiscopic vision system that utilizes a low-cost monocular RGB camera to acquire accurate depth estimation for robotic applications.
We introduce a novel social recommender based on the idea that distance reflects likability, which improves the recommendation accuracy.
We propose an iterative ADMM-based algorithm that outperforms existing schemes, and shows significant potential for performance improvement on real content datasets.
We establish rigorous benchmarks for image classifier robustness and propose a new kind of robustness, surface variation robustness. We find that there are negligible changes in relative corruption robustness from AlexNet to ResNet classifiers, and we discover ways to enhance Corruption Robustness.
We propose HoloScope, a novel metric that integrates information from graph topology and spikes to more accurately detect fraudulent users and objects.
This paper proposes a dictionary learning framework that combines the proposed block/group (BGSC) sparse coding schemes with the novel Intra-block Coherence Suppression Dictionary Learning algorithm.
We propose an attentionbased LSTM model for human activity recognition, by attending to salient visual information through a jointly learned soft-attention networks.
We propose an unsupervised visual tracking method that achieves baseline accuracy of fully supervised trackers, which require complete and accurate labels.
We propose an iterative scheme of building a rich training set and using it to learn a scoring function that is an explicit proxy for the target tracking metric.
We propose and systematically evaluate three strategies for training dynamically-routed artificial neural networks. Though some approaches have advantages over others, the resulting networks are often qualitatively similar.
In this paper, we build on a deep translational action recognition network which takes RGB frames as input to learn to predict both action concepts and auxiliary supervisory feature descriptors e.g., Optical Flow Features and/or Improved Dense Trajectory descriptors.
We present a novel approach to this problem by exploiting the sparsity of the frequent micro-temporal motion patterns of the face and body region for a compact and discriminative representation of facial and body expressions.
Variance Suppression Gradient Descent can accelerate the training process, effectively prevent overfitting, improve the networks learning capacity from small samples.
We propose a low complexity solution to cover the failure cases of the single-frame recognition methods which yields an increased stability in multi- frame recognition during test time.
This article demontrates that we can apply deep learning to text understanding from character-level inputs all the way up to abstract text concepts, using temporal convolutional networks (ConvNets).
We propose a new supervised DR method called Optimized Projection for Sparse Representation based Classification.
A discriminatively learned CNN embedding is proposed for remote sensing image scene classification.
In this paper, we focus on NLP, introducing methods and resources for training models insensitive to spurious patterns in training data.
Adaptive multi- view harmonium for multi-view feature extraction .
A novel multi-scale operator for unorganized 3D point clouds is introduced. The Difference of Normals (DoN) provides a computationally efficient, multi- scale approach to processing large unorganized point clouds.
We demonstrate an analog mode of operation observed in our silicon oxide memristors and apply this to the problem of edge detection and demonstrate a scalable solution to the task.
We examine the novel task of domain-independent scientific concept extraction from abstracts of scholarly articles and propose active learning to deal with different domains in our task.
In this paper, we propose a novel framework for person re-identification by analyzing camera viewpoints and person poses in a so-called Pose-aware Multi-shot Matching (PaMM), which robustly estimates people's poses and efficiently conducts multi-shot matching based on pose information.
This paper describes the MeMAD project entry to the WMT Multimodal Machine Translation Shared Task. In this paper, we also describe the preliminary experiments with text-only translation systems leading us up to this choice.
A practical and efficient edge-aware neural network is proposed for semantic segmentation.
We explore using learnable box filters to allow for convolution with arbitrarily large kernel size, while keeping the number of parameters per filter constant.
A multi-layered, spatial, virtual, human pose reconstruction framework is presented in this study to recover deficient information in planar images.
We propose a novel transfer deep learning approach to tag personal photos. The proposed tagging approach is able to achieve a performance gain of $12.8$ and $4.5$ in terms of NDCG@5.
We design an unsupervised loss based on occlusion-aware bidirectional flow estimation and the robust census transform to circumvent the need for ground truth flow for optical flow.
This paper examines various unsupervised pretraining objectives for learning dialog context representations. Two novel methods of pretraining dialog context encoders are proposed, a total of four methods are examined.
We propose non-correlating multiplicative noise (NCMN), which exploits batch normalization to remove the correlation effect in a simple yet effective way.
We propose using deep generative classifiers to automatically diagnose thorax diseases from the chest X-ray images.
One-stage object detectors such as SSD or YOLO already have shown promising accuracy with small memory footprint and fast speed. However, it is widely recognized that one-stage detectors have difficulty in detecting small objects while they are competitive with two-stage methods on large objects. In this paper, we investigate how to alleviate this problem.
We propose associating natural language utterances to a mental workspace of their meaning, encoded as 3D visual feature representations of the world scenes they describe. We then train modular neural models to generate such 3D feature representations, to localize the objects an utterance mentions in the3D feature representation inferred from an image, to predict the desired 3D object locations given a manipulation instruction.
This paper proposes a framework for stereo image coding with effective representation of geometry in 3D scenes.
Our proposed Out-In-Channel Sparsity Regularization (OICSR) considers correlations between successive layers to further retain predictive power of the compact network.
We propose an unsupervised online learning approach based on a convolutional neural network (CNN) that estimates such a motion model individually for each frame.
We present a method for training deep spiking neural networks using an iterative modification of the backpropagation optimization algorithm, which effectively and reliably configures a network for a spiking hardware target.
A novel unsupervised deep learning framework is proposed to detect anomaly events in crowded scenes in crowd scenes.
Transfer learning using domain randomization for robotic control problems with discrepancies in the training and testing environment.
We propose LU-Net, an end-to-end architecture for LiDAR point cloud semantic segmentation that efficiently solves the problem as an image processing problem.
We proposed a DCNN architecture for image compression, where the encoder, quantizer and decoder are jointly learned through end-to-end training.
We propose an end-to-end domain adaptation framework for cross-domain 3D objects retrieval (C3DOR-Net), which learns a joint embedding space for 3Dobjects from different domains in an end toend manner.
We propose a generative learning-based approach to complete incomplete 3D shapes through generative modeling and latent manifold optimization.
In this paper, we propose a novel, efficient stereo visual-odometry algorithm for ground vehicles moving in outdoor environments without any additional batch optimization.
Locality Constrained Joint Dynamic Sparse Representation-based Classification for Robust Face Recognition .
This paper presents a new approach for 3D human posereconstruction based on the iterative calculation of a high-precision human model and conformal geometric algebra,captured by a monocular camera.
A large-scale annotation campaign with real human annotators, producing masks for 2.5M instances on the OpenImages dataset, forming the largest existing dataset for instance segmentation.
We present a method for visual retrieval based image captioning, in which we use a multi criteria decision making algorithm to effectively combine several criteria with proportional impact weights to retrieve the most relevant caption for the query image.
Context-aware approaches for learning semantics and improve personalized information retrieval in tagging systems.
We introduce Tensor Product Decomposition Networks (TPDNs), which use TPRs to approximate linear and tree-based RNN autoencoder representations, suggesting that these representations exhibit interpretable compositional structure.
This paper proposes a unified model that can estimate the emotional states of others and generate emotional self-expressions through self-organized learning.
We propose Deformable U-Net (DUNet), which exploits the retinal vessels’ local features with a U-shape architecture in an end to end manner for retinal vessel segmentation.
We address the problem of joint optical flow and camera motion estimation in rigid scenes by incorporating geometric constraints into an unsupervised deep learning framework, allowing end-to-end training of the network.
We present the multiplicative recurrent neural network as a general model for compositional meaning in language, and evaluate it on the task of fine-grained sentiment analysis.
In this paper we present a novel deep learning method for 3D object detection and 6D pose estimation from RGB images.
We address the problem of retrieving all the images containing a specific object in a large image collection, where the input query is given as a set of representative images of the object.
This paper proposes a novel Style-based Super-Resolution Variational Autoencoder network (SSRVAE) that contains a style Variational autoencoders and a SR Network.
We address the problem of integrating textual and visual information in vector space models for word meaning representation. We first present the Residual CCA (R-CCA) method, that complements the standard CCA method by representing the difference between the original signal and the signal projected to the shared, max correlation, space.
This paper addresses the problem of learning similarity-preserving binary codes for efficient similarity search in large-scale image collections using iterative quantization.
In this paper, we address the challenge of gender classification using large databases of images with two goals.
The ability of semantic reasoning over the sentence pair is essential for many natural language understanding tasks, e.g., natural language inference and machine reading comprehension. We propose to augment the NSP task to a 3-class categorization task, which includes a category for previous sentence prediction (PSP), which encourages the model to focus on the informative semantics to determine the sentence order.
We study the effects of various properties of labels and introduce the Label Refinery: an iterative procedure that updates the ground truth labels after examining the entire dataset.
Fractal dimension (FD) has been considered as a potential biomarker for retina-based disease detection. This motivates us to examine the stability of the FD on dierent (1) vessel segmentations obtained from human observers, (2) automatic segmentation methods, and (3) threshold values.
We introduce a principled approach to capture link information and propose a linked Recurrent Neural Network (LinkedRNN), which models sequential and link information coherently.
We introduce an image-based synthesis engine that artificially augments a dataset of real images with 2D human pose annotations using 3D motion capture data. The resulting images are used to train an end-to-end CNN for full-body 3D pose estimation.
We treat dense instance segmentation as a prediction task over 4D tensors and present a general framework called TensorMask that explicitly captures this geometry and enables novel operators on 4D Tensors.
This paper aims at developing a real-time vessel detection and tracking system using surveillance cameras in harbours with the purpose to improve the current Vessel Tracking Systems (VTS) performance.
We propose a novel task setting called zero-shot temporal activity detection (ZSTAD), where activities that have never been seen in training can still be detected. We design an end-to-end deep network based on R-C3D.
We address a problem of learning ordinal classifiers from partially annotated examples. We introduce a V-shaped interval-insensitive loss function to measure discrepancy between predictions of an Ordinal classifier and a partial annotation.
This paper describes a new image generation algorithm based on generative adversarial network, which can learn interpretable representations from the input images.
We train generative ‘up-convolutional’ neural networks which are able to generate images of objects given object style, viewpoint, and color.
We present CoverNet, a new method for multimodal, probabilistic trajectory prediction for urban driving, and it outperforms state-of-the-art methods.
TEA-DNN leverages energy and execution time measurements on embedded hardware when exploring the Pareto-optimal curves across accuracy, execution time, and energy consumption of CNN workloads on embedded architectures.
A generative merge model for Arabic image captioning based on a deep RNN-LSTM and CNN model.
We introduce a novel approach to extract relevant visual and temporal features from untrimmed sequences for the temporal localization of sub-activities within complex actions without any labeling information.
We propose and study a task we name panoptic segmentation (PS) that unifies the typically distinct tasks of semantic segmentation and instance segmentation in an interpretable and unified manner.
We propose a scalable and robust deep learning framework to learn embedded representations to unify known gene interactions and gene expression for gene interaction predictions.
We utilize a line based pose representation to recognize human actions in videos and propose a new method that matches line-pairs of two poses to compute similarity between them.
A support vector machine model to predict potential Arabidopsis protein interactions based on a variety of indirect evidence.
We present CFL (Corners for Layout), the first end-to-end model that predicts layout corners for 3D layout recovery on $\mathbf {{360}^\circ }$ images.
We propose an end-to-end framework, MeSHProbeNet (formerly named as xgx), which utilizes deep learning and self-attentive MeSH probes to extract comprehensive biomedical knowledge from an input article.
Region anchors are the cornerstone of modern object detection techniques. In this paper, we revisit this foundational stage and propose an alternative scheme, named Guided Anchoring, which uses semantic features to guide the anchoring.
In this paper, we present convolutional patch networks, which can be used for pixel-wise labeling and for road detection and scene understanding.
MT-DNN extends the model proposed in Liu et al. (2015) by incorporating a pre-trained bidirectional transformer language model, known as BERT, for learning representations across multiple natural language understanding tasks.
An exhaustive insight of challenges known so far for building QA systems, with a special focus on employing structured data (i.e. knowledge graphs).
In the Bag-of-Words (BoW) model based image retrieval task, the precision of visual matching plays a critical role in improving retrieval performance. To address this problem, this paper defines "true match" as a pair of keypoints which are similar on three levels, i.e., local, regional, and global.
In this paper, we propose several novel deep learning methods for object saliency detection based on the powerful convolutional neural networks.
Focal Visual-Text Attention network (FVTA) for collective reasoning in visual question answering.
Sparse coding is a proven principle for learning compact representations of images. However, sparse coding by itself often leads to very redundant dictionaries. We propose a factored model in which factors of variation (e.g. position, scale and orientation) are untangled from the underlying Gabor-like filters. Our model requires only a single dictionary element to outperform standard sparse coding.
We propose a scalable and robust deep learning framework to learn embedded representations to unify known gene interactions and gene expression for gene interaction predictions.
We propose an end-to-end differentiable neural network for entailment that achieves state-of-the-art accuracy on a textual entailment dataset.
Hand-CNN extends MaskRCNN with a novel attention mechanism for detecting hand masks and predicting hand orientations in unconstrained images.
Unsupervised generative model of sample loss values during training to allow online estimation of the probability that a sample is mislabelled and correct the loss by relying on the network prediction.
In this paper, an effective tracking algorithm is proposed to decontaminate features for each video sequence adaptively, where the visual modeling is treated as an optimization problem from the perspective of evolution.
In this work, we propose"tangent images,"a spherical image representation that facilitates transferable and scalable $360^\circ$ computer vision.
We propose two novel generative autoencoders, AE-OTtrans andAE-OTgen, which rely on optimal transport instead of adversarial training.
We propose a "Context Less-Aware" (CoLA) pipeline, which produces RGB-D object-predominated images that have less background context, and enables a scale-aware training and testing with 3D information.
In this paper, we show that the latent space operations used in the literature so far induce a distribution mismatch between the resulting outputs and the prior distribution the model was trained on. To address this, we propose to use distribution matching transport maps to ensure that such latent space Operations preserve the prior distributions, while minimally modifying the original operation.
We introduce Spatial Group Convolution (SGC) for accelerating the computation of 3D dense prediction tasks.
In this paper, we propose a differentiable global-flow local-attention framework to reassemble the inputs at the feature level for pose-guided person image generation.
We propose a novel Spatially Constrained Generative Adversarial Network (SCGAN), which decouples the spatial constraints from the latent vector and makes these constraints feasible as additional controllable signals.
Latent factor models and decision tree based models are widely used in tasks of prediction, ranking and recommendation. We propose a new model, called GB-CENT, which leverages latent factor embedding and tree components to achieve the merits of both while avoiding their demerits.
This paper presents a general subword-augmented embedding framework for learning and composing sub word-level representations. We survey a series of unsupervised segmentation methods for subword acquisition and different subword augmentation strategies.
This paper offers a novel low-cost deep learning approach to easily implement vacancy detection at outdoor parking spaces with CCTV surveillance.
In this paper, to better align image and language domains in diverse and unrestricted cases, we propose a novel neural network model that performs global reasoning on a dependency tree parsed from the question, and we thus phrase our model as parse-tree-guided reasoning network.
We propose an explicit context model to augment training images by using a convolutional neural network, which predicts whether an image region is suitable for placing a given object or not.
This paper proposes a geometry-aware Face Completion and Editing NETwork (FCENet) by systematically studying facial geometry from the unmasked region.
We propose a graph based segmentation method which uses the class activation maps trained on food datasets as a top-down saliency model.
We have tried to reproduce the results of the paper "Natural Language Inference over Interaction Space" submitted to ICLR 2018 conference as part of the I CLR 2018 Reproducibility Challenge.
In this paper, we introduce C-Flow, a novel conditioning scheme that brings normalizing flows to an entirely new scenario with great possibilities for multi-modal data modeling.
We propose new filters based on 3D rotating frames in so-called orientation scores, which are functions on the Lie-group domain of positions and orientations.
We identified TGF-β signaling and apoptosis as two of the main functional modules involved in primary and secondary infection in zebrafish and identified Smad7, a member of the inhibitor SMADs, as an important regulator of innate and adaptive immune responses.
We propose a new regularization approach for Extreme Learning Machine-based Single- hidden Layer Feedforward Neural network training that weights the ELM space according to the importance of the network's hidden layer weights, without imposing additional computational and memory costs.
We provide the first theoretical analysis on the convergence rate of the asynchronous stochastic variance reduced gradient (SVRG) descent algorithm on non-convex optimization.
We combine a state-of-the-art figurative usage detection with CNN-based personal health mention detection to improve personalhealth mention detection.
We present a conditional generative adversarial model to draw realistic samples from paired fashion clothing distribution and provide real samples to pair with arbitrary fashion units, based on similarity of search results.
We show that it is possible to edit a facial image according to expression and speech blendshapes, using sliders that control the continuous values of the blendshape model.
We introduce a new bounding-box free network (BBFNet) for panoptic segmentation that exploits class boundaries from an off-the-shelf semantic segmentation network and refine them to predict instance labels.
We present a simple sequential sentence encoder based on stacked bidirectional LSTM-RNNs with shortcut connections and fine-tuning of word embeddings.
In this paper, we present a Homotopy Training Algorithm (HTA) to solve optimization problems arising from fully connected neural networks with complicated structures.
We propose a fast interactive video object segmentation method, that can accurately segment objects with only a handful of clicks.
In this paper, we propose a generative model to reconstruct the missing parts of the face which are under occlusion.
Pre-training general-purpose visual features with convolutional neural networks without relying on annotations is a challenging and important task. Our goal is to bridge the gap between unsupervised methods trained on curated data, which are costly to obtain, and massive raw datasets that are easily available.
We propose an end-to-end recurrent neural network architecture with an attention mechanism to model a human-like counting process, and produce detailed instance segmentations.
Robust Out-of-Distribution Detection with Adversarially Crafted Inlier and Outlier Examples .
This paper considers the problem of localizing actions in videos as sequences of bounding boxes. We introduce an approach to generate action proposals from spatiotemporal super-voxels in an unsupervised manner, we call them Tubelets.
We propose a new model for detecting visual relationships, such as "person riding motorcycle" or "bottle on table", that allows to model pairwise interactions between objects using standard object detection pipelines.
We explore various methods for computing sentence representations from pre-trained word embeddings without any training, i.e., using nothing but random parameterizations.
This paper introduces Non-Autonomous Input-Output Stable Network (NAIS-Net), a very deep architecture where each stacked processing block is derived from a time-invariant non-autonomous dynamical system.
A LiDAR based vehicle detection approach using the Probability Hypothesis Density (PHD) filter.
We introduce a model-driven framework for the automatic annotation of apparent age and gender attributes in large-scale image datasets and conduct the first demographic audit of ImageNet.
A Context-Aware Visual Policy network for sequence-level image captioning.
This work introduces a survey for the Text Para-phrasing task. The survey covers the different types of tasks around text paraphrasing.
We present an extensive evaluation of three recently proposed methods for contextualized embeddings on 89 corpora in 54 languages of the Universal Dependencies 2.3 in three tasks: POS tagging, lemmatization, and dependency parsing.
We show that the greedy algorithm provably performs better as the sharpness of the submodular function increases.
We propose a novel Conditional Ordinal Random Field (CORF) model for context-sensitive modeling of the facial action unit intensity, where the W5+ ( who , when , what , where , why and how ) definition of the context is used.
We propose a scalable Deep Graph Bayesian Optimization (DGBO) method on attributed graphs, which can scale linearly with the number of observations.
The xOperator concept is based on the idea of creating an overlay network of collaborative information agents on top of social IM networks. We present a strategy and implementation which deeply integrates Instant Messaging networks with the Semantic Web.
We present a simple nearest-neighbor approach that synthesizes high-frequency photorealistic images from an "incomplete" signal such as a low-resolution image, a surface normal map, or edges.
We improve an Unsupervised Domain Adaptation (UDA) method to better align source and target domains using consistency constraints, reaching state of the art on a few UDA tasks.
Tensor, a multi-dimensional data structure, has been exploited recently in the machine learning community. In this paper, we propose a tensor train-based kernel technique for the first time, and apply it to the conventional support vector machine.
We evaluate whether adversarial learning can be used in NLI to encourage models to learn representations free of hypothesis-only biases.
A novel multi-task model based on the conventional neural network and temporal attention strategy for video-based pedestrian attribute recognition.
We leverage an unsupervised variational model to learn rich motion patterns in the form of long-term bi-directional flow fields, and apply the predicted flows to generate high-quality video sequences.
This paper investigates the automatic monitoring of tool usage during a surgery, with potential applications in report generation, surgical training and real-time decision support.
For robot systems, robust facial landmark detection is the first and critical step for face-based human identification and facial expression recognition.
We introduce ReCode, a method based on subtree retrieval that makes it possible to explicitly reference existing code examples within a neural code generation model.
In this paper, we brought out a novel pedestrian detection framework for the advanced driver assistance system of mobile platform under the normal urban street environment under the street scenes.
Simultaneous Compression and Quantization for Unsupervised Data-Dependent Hashing .
We propose CornerNet, a new approach to object detection where we detect an object bounding box as a pair of keypoints, the top-left corner and the bottom-right corner, using a single convolution neural network.
We present a robot navigation system that uses an imitation learning framework to successfully navigate in complex environments using RGBD information.
This study aims at solving Machine Reading Comprehension problem where questions have to be answered given a context passage. The challenge is to develop a computationally faster model which will have improved inference time.
We propose an incremental learning framework based on a grow-and-prune neural network synthesis paradigm that improves accuracy, shrinks network size, and significantly reduces the additional training cost for incoming data compared to conventional approaches.
This work focuses on designing a symbolic intermediate representation to be used in multi-stage neural generation with the intention of reducing the frequency of failed outputs.
We exploit the notion of domain adaptation and propose a data efficient approach to adapt already learned classifiers to new unseen contexts for facial behavior analysis.
In this paper, we propose a novel regularization method, RotationOut, for neural networks. Different from Dropout that handles each neuron/channel independently.
We propose a general face hallucination method that can integrate model-based optimization and discriminative inference and achieve promising super-resolution results.
Open set recognition is a classification-like task. It is accomplished not only by the identification of targeted classes (i.e., the classes among those represented in the training sample which should be later recognized) but also by the rejection of inputs from other classes in the problem domain.
A scale-insensitive convolutional neural network for fast detecting vehicles with a large variance of scales.
BiOnt employs four types of biomedical ontologies for biomedical relation extraction and achieves state-of-the-art results.
We train a bidirectional language model (Bi-LM) on unlabeled data and transfer its weights to a NER model with the same architecture as the Bi-LM, which results in a better parameter initialization of the NERmodel.
We address the problem of online localization and tracking of multiple moving speakers in reverberant environments. We use the direct-path relative transfer function (DP-RTF), an inter-channel feature that encodes acoustic information robust against reverberation, and we propose an online algorithm well suited for estimating DP-RFTs associated with moving audio sources.
We propose a novel object bounding box representation using points and links and implemented using deep ConvNets, termed as Point Linking Network (PLN).
In this paper, we introduce a novel architecture named dilated residual networks for learning optical flow, which can avoid the loss of details of the U-Net architecture and can directly learn the residual functions rather than the unreferenced functions.
We propose an end-to-end Instance Segmentation system that produces a segmentation map where each pixel is assigned an object class and instance identity label.
We address the limitations of CNNs by developing novel, simple, and interpretable models for few-shot learn- ing, which are interpretable visual cues represented by the feature vectors within CNNs.
We propose a novel learning rule based on the hybrid neural network with shared weights, wherein a rate-based SNN is used during the forward propagation to determine precise spike counts and spike trains, and an equivalent ANN is used to approximate the gradients for the coupled SNN.
We propose a novel Multi-scale Location-aware Kernel Representation (MLKP) to capture high-order statistics of deep features in proposals.
In this paper, we consider the task of one-shot object detection, which consists in detecting objects defined by a single demonstration. We build the one-stage system that performs localization and recognition jointly, which allows end-to-end training.
This paper proposes a minimal contrastive divergence method for learning energy-based generative ConvNet models of images at multiple grids (or scales) simultaneously.
Automatic person re-identification using generative adversarial network for multi-camera surveillance system .
We train generative encoder-decoder models with visual attention to generate fashion feedback on outfit images, and propose an alternative decoding technique based on the Maximum Mutual Information objective function.
We introduce Deep Sigma Point Processes, a class of parametric models inspired by the compositional structure of Deep Gaussian Processes (DGPs).
We propose a lightweight and effective point-based 3D single stage object detector, named 3DSSD, achieving a good balance between accuracy and efficiency.
We propose a new multi-target visual tracker based on the recently developed Hypothesized and Independent Stochastic Population (HISP) filter.
We propose a Multiple Instance Learning approach that selects anchors and jointly optimizes the two modules of a CNN-based object detector and achieves new state-of-the-art detection performance.
We learn to estimate optical flow by combining a layered motion representation with deep learning using the proposed soft-mask module.
We propose a neural network that predicts joints in a camera centered coordinate system instead of a root-relative one and achieves state-of-the-art results.
In this paper, we propose a novel algorithm called Trend-Smooth which can be adapted to the asynchronous parallel environment to overcome the above problems.
This paper presents a novel approach for synthesizing facial affect; either categorical, in terms of the six basic expressions (i.e., anger, disgust, fear, happiness, sadness and surprise), or dimensional, based on the selection of apex frames of posed expression sequences from the 4DFAB.
We compare ten trackers based on deep learning techniques on four aerial datasets. We choose top performing trackers utilizing different approaches, specifically tracking by detection, discriminative correlation filters, Siamese networks and reinforcement learning.
We propose a quantization scheme that allows inference to be carried out using integer-only arithmetic, which can be implemented more efficiently than floating point inference on commonly available integer- only hardware.
To achieve dynamic inference in pixel labeling tasks, we propose Pixel-wise Attentional Gating (PAG), which learns to selectively process a subset of spatial locations at each layer of a deep convolutional network.
We propose a novel shared and cluster-specific dictionaries learning method for SISR that preserves the relationship and structure among the training data in dictionary learning.
This paper presents a light CNN framework to learn a compact embedding on the large-scale face data with massive noisy labels.
Domain adaptation aims to learn models on a supervised source domain that perform well on an unsupervised target. The model is adapted sequentially over incoming streaming data batches.
This paper presents a generic face animator that is able to control the pose and expressions of a given face image using interpretable control signals.
The recently proposed audio-visual scene-aware dialog task paves the way to a more data-driven way of learning virtual assistants, smart speakers and car navigation systems.
Large-scale text mining for plant biology research in general and for network biology in particular using a state-of-the-art text mining system applied to PubMed abstracts and PubMed Central full texts.
We proposed an online hashing scheme, termed Hadamard Codebook based Online Hashing (HCOH), which aims to solve the above problems towards robust and supervised online hashing.
We propose an efficient method to extract a fair amount of multi-scale dense local activations from a pre-trained CNN and use them as a primary image representation.
We seek to better understand how neural extractive summarization systems could benefit from different types of model architectures, transferable knowledge and ::: learning schemas.
We show that consistency regularization can introduce artifacts into the GAN samples and propose several modifications to improve its performance.
In this paper we present BioFaceNet, a deep CNN that learns to decompose a single face image into biophysical parameters maps, diffuse and specular shading maps as well as estimating spectral power distribution of the scene illuminant and the spectral sensitivity of the camera.
In this paper, we propose CSID: a Center, Scale, Identity-and-Density-aware pedestrian detector with a novel Identity- and density-aware NMS (ID-NMS) algorithm to refine the results of anchor free pedestrian detection.
We explore word representations in Hyperbolic space as a means of preserving privacy in text. Privacy is provided by perturbing vector representations of words in high dimensional HyperBolic space to obtain a semantic generalization.
We identified four ligands that bind to sites on the Asu-ACR-16 receptor of Ascaris suum and tested their activity using electrophysiological recording.
A novel framework for dense video captioning that unifies the localization of temporal event proposals and sentence generation of each proposal, by jointly training them in an end-to-end manner.
We propose the use of deep residual network (ResNet), which has been a widely used for many image recognition tasks, but not in the context of recognizing facial expressions in video surveillance.
We present Semantic One-Shot Video Object Segmentation, based on a fully-convolutional neural network architecture that is able to successively transfer generic semantic information, learned on ImageNet, to the task of foreground segmentation.
We formulate the multi-frame data association step as an energy minimization problem, designing an energy that efficiently exploits sparse representations of all detections.
Feature pyramid networks have been widely adopted in the object detection literature to improve feature representations for better handling of variations in scale. In this paper, we present Feature Pyramid Grids (FPG), a deep multi-pathway feature pyramid, that represents the feature scale-space as a regular grid of parallel bottom-up pathways which are fused by multi-directional lateral connections.
In this paper, we propose a object alignment method that detects the landmarks of an object in 2D images in the regression forests framework.
This paper considers the challenging task of long-term video interpolation. In this paper, we present a novel deep architecture called bidirectional predictive network that predicts intermediate frames from two opposite directions.
We propose functional adversarial attacks, a novel class of threat models that allow both small, individual perturbations and large, uniform changes to an input.
In this paper, we propose a novel fashion collocation framework, Neural Graph Filtering, that models a flexible set of fashion items via a graph neural network, which enables the collocation of significantly diverse styles.
We present a method to leverage coarsely annotated data along with fine supervision to produce better segmentation results than would be obtained when training only the fine data.
We propose a monocular VO based on direct sparse odometry to solve the problems arising in a dynamic environment.
Procrustes analysis (PA) has been a popular technique to align and build 2-D statistical models of shapes. To address previous issues, this paper proposes subspace PA (SPA), a continuous approach to uniformly sample the space of 3-D rotations, being more efficient in space and time.
A novel conditional random field (CRF) model to effectively utilize depth information for semantic labeling of indoor scenes.
Automatic tagging of music has mostly been treated as a classification problem. In this framework, the association of a tag to a song is characterized in a “hard” fashion: the tag is either relevant or not.
This paper presents a robust stereo visual odometry by probabilistic matches and rejecting the outliers of dynamic objects through motion segmentation.
This work was supported by the Australian Research Council’s Discovery Projects Funding Scheme under Project DP150104645.
We propose Federated Neural Architecture Search, a new DNN training paradigm for decentralized data that leverages the key opportunity of insufficient model candidate re-training during the architecture search process.
We propose a revision to the most specific concept method, allowing it to generate much simpler and smaller concepts that are specific enough to answer a given query.
We propose a computer-aided method of retinal blood vessel segmentation using Bidirectional Symmetric Cascade Network where each layer is supervised by vessel contour labels.
We represent 3D spaces as volumetric fields, and propose a novel design that employs field probing filters to efficiently extract features from them.
This paper introduces a novel meta-learning algorithm for time series forecasting. The efficient Bayesian multivariate surface regression approach is used to model forecast error as a function of features calculated from time series.
Autoregressive state transitions, where predictions are conditioned on past predictions, are the predominant choice for both deterministic and stochastic sequential models. However, autoregressive feedback exposes the evolution of the hidden state trajectory to potential biases from well-known train-test discrepancies.
We address this shortcoming by introducing a dual optimization procedure for Variational Autoencoder (VAE)-based approaches.
This paper revisits both retrieval stages, namely initial search and re-ranking, by employing the same primitive information derived from the CNN. We build compact feature vectors that encode several image regions without the need to feed multiple inputs.
This paper looks at the work that has already been done in this area for detecting deliberately deceptive news articles.Over the past couple of years, the topic of "fake news" and its influence over people's opinions has become a growing cause for concern.
Conditional image-to-image translation with GANs and dual learning .
A scene graph based approach for unpaired image captioning without using any image-caption training pairs.
We propose Mask-ShadowGAN, a new deep framework that learns to produce a shadow mask from the input shadow image and then takes the mask to guide the shadow generation via re-formulated cycle-consistency constraints.
In this paper, we present a method to learn a joint multimodal representation space that allows for the recognition of unseen activities in videos.
We introduce A3GAN, an Attribute-Aware Attentive face aging model to address the above issues.
We propose a soft-target method for pedestrian pose orientation estimation using a semi-supervised learning method, which achieves better generalisation than a convolutional neural network based method.
A key challenge within the social network literature is the problem of network generation - that is, how can we create synthetic networks that match characteristics traditionally found in most real world networks?
We are interested in large-scale learning of Mahalanobis distances, with a particular focus on person re-identification. We propose a metric learning formulation called Weighted Approximate Rank Component Analysis (WARCA) which optimizes the precision at top ranks by combining the WARP loss with a regularizer that favors orthonormal linear mappings and avoids rank-deficient embeddings.
We address the problem of video representation learning without human-annotated labels. In this paper we propose a novel self-supervised approach to learn spatio-temporal features for video representation, given only the input video data.
We present ContactGrasp, a framework for functional grasp synthesis from object shape and contact on the object surface.
We revisit a particular visual grounding method: the "Image Retrieval Using Scene Graphs" (IRSG) system of Johnson et al. (2015). Our experiments indicate that the system does not effectively use its learned object-relationship models. We find that these datasets exhibit biases that allow methods that ignore relationships to perform relatively well.
In this paper, we evaluate the overall performance of the most efficient detectors and descriptors in terms of speed and efficiency.
We address these questions empirically using attention-based sequence-to-sequence models for natural language inference, showing that pretrained embeddings outperform both random and retrofitted ones in a large NLI corpus.
This paper contributes the first large-scale systematic study comparing different pretraining tasks in this context, both as complements to language modeling and as potential alternatives.
Unsupervised Multi-task Mid-level Feature Alignment network for unsupervised cross-dataset person re-identification.
We exploit a multi-channel attention mechanism in feature space in CNN to obtain different attention mask for each feature and for each attribute.
We propose a novel spinning convolution layer and a brand-new lane parameterization branch in our network to detect lane boundaries from a global perspective.
The success of correlation filters in visual tracking has attracted much attention in computer vision due to their high efficiency and performance. However, they are not equipped with a mechanism to cope with challenging situations like scale variations, out-of-view, and camera motion. A collaborative scheme based on discriminative and generative models is proposed.
In this paper, inspired by the geometry that data can be decomposed by two components from the forward operator and the range space of its pseudo-inverse, we train neural networks to learn the two components and therefore learn the decomposition, i.e. we explicitly reformulate the neural network layers as learning range-nullspace decomposition functions with reference to the layer inputs.
To measure the ability of a machine to understand professional-level scientific articles, we construct a scientific question answering task called PaperQA.
We propose a semantic attention mechanism for image caption generation, called text-conditional semantic attention, which allows the caption generator to automatically learn which parts of the image feature to focus on given previously generated text.
We present a simple yet effective prediction module for a one-stage detector, mimicking two-stage detectors in an efficient manner.
This paper addresses the problem of high-level road modeling for urban environments. The approach presented in this paper generates a model based on the information provided by a digital navigation map and a vision-based sensing module.
We propose a novel method for class imbalanced learning by scaling the weight vectors.
We propose the Deep Collaboration Network (DCNet), a novel approach for connecting task-specific CNNs in a multi-task learning (MTL) framework.
We present a new perspective on neural knowledge base (KB) embeddings, from which we build a framework that can model symbolic knowledge in the KB together with its learning process.
We propose a novel offline-trained Meta-Updater to address an important but unsolved problem: Is the tracker ready for updating in the current frame?
Perceptual discriminator network inside generative adversarial learning framework for image translation.
We address the problem of jointly learning vision and language to understand the object in a fine-grained manner using hybrid end-to-end CNN-LSTM networks.
Wikipedia is the largest collaborative encyclopedia and is used as the source for DBpedia, a central dataset of the LOD cloud. Wikipedia contains numerous numerical measures on the entities it describes, as per the general character of the data it encompasses.
We propose a novel and efficient training algorithm inspired by alternating direction method of multipliers (ADMM) for supervised learning of hash codes.
We introduce the "adversarial code learning" (ACL) module that improves overall image generation performance to several types of deep models.
This paper presents a novel stereo SLAM framework, where a robust loop chain matching scheme for tracking keypoints is combined with an effective frame selection strategy.
The field of object detection has made significant advances riding on the wave of region-based ConvNets, but their training procedure still includes many heuristics and hyperparameters that are costly to tune.
In this paper, we propose an effective and efficient face deblurring algorithm by exploiting semantic cues via deep convolutional neural networks.
We developed a fundus retinal vessels segmentation based on the improved deep learning U-Net model.
We make two key contributions towards improving A* tree search. First, we show that the consensus maximization tree structure used previously actually contains paths that connect nodes at both adjacent and non-adjacent levels. We propose a new strategy that avoids such redundant paths.
We propose a novel cascaded captioning-revising network that can accurately describe images with unknown (novel) objects.
DeepFurniture, a richly annotated large indoor scene dataset, including 24k indoor images, 170k furniture instances and 20k unique furniture identities.
This chapter describes the development of an integrated stereovision sensor intended to be embedded on mobile platforms like robots or intelligent vehicles for motion control of these platforms.
Image retargeting is the task of making images capable of being displayed on screens with different sizes. This work should be done so that high-level visual information and low-level features such as texture remain as intact as possible to the human visual system.
We first develop a novel weakly-supervised TAL framework called AutoLoc to directly predict the temporal boundary of each action instance. We propose a novel Outer-Inner-Contrastive (OIC) loss to automatically discover the needed segment-level supervision.
In this paper, we propose to incorporate the attention learning as additional objectives in a person ReID network without changing the original structure, thus maintain the same inference time and model size.
We introduce a deep learning-based 3D object detection model with radar only that was trained on the public radar dataset.
S-DCNet only learns from a closed set but can generalize well to open-set scenarios via S-DC.
In semi-supervised learning, partial label information can be inferred from otherwise unlabeled examples and used to improve the model learned from labeled examples.
We provide a comparison of state-of-the-art face detectors on OR data and also present an approach to train a face detector for the OR by exploiting non-annotated OR images.
We revisit dual-decomposition-based approaches to CRF optimization, an alternative to mean-field approximation, providing optimality certificates on the way.
Image inpainting technology can patch images with missing pixels. However, if the missing part is too large to provide useful information, the result will exist blur, color mixing, and object confusion.
We investigate state-of-the-art methods for counting pedestrians and the related performance of aerial footage. We analyze this performance with respect to the congestion levels of the images.
In this paper, we propose a simple training variation where suitable weights are defined and assist the training of the Generator.
We propose a pseudo-supervised deep learning method for disentangling multiple latent factors of variation in face images captured in-the-wild.
This paper studies the topic modeling problem of tagged documents and images. We propose the tag-topic models (TTM) to depict such higher-order topic structural dependencies within the Markov random field (MRF) framework. Efficient loopy BP algorithm is developed to learn TTM.
We present a simple, fully-convolutional model for real-time (>30 fps) instance segmentation that achieves competitive results on MS COCO evaluated on a single Titan Xp, which is significantly faster than any previous state-of-the-art approach.
A constrained latent space model (CLSM) infers community membership based on two modalities in multi-modal social network data: network topology and node attributes. In this paper, we extend CLSM in two ways.
The state-of-the-art semantic segmentation solutions usually leverage different receptive fields via multiple parallel branches to handle objects with different sizes. However, employing separate kernels for individual branches degrades the generalization and representation abilities of the network, and the amount of parameters increases by the times of the number of branches. To tackle this problem, we propose a novel network structure namely Kernel-Sharing Atrous Convolution.
A generative probabilistic model to model the facial aging process at multiple short-term stages with tractable density function.
We propose FearNet for incremental class learning, a generative model that does not store previous examples and achieves state-of-the-art performance on image and audio classification benchmarks.
In this paper, we present a novel framework to boost the spatio-temporal representation learning by Local and Global Diffusion (LGD).
We propose a novel self-supervised hybrid model (DAE-GAN) that learns how to reenact face naturally given large amounts of unlabeled videos.
In this paper we propose a method to consistently recover the pose of an object from a known class in a video sequence even if single-frame pose evidence is sometimes inaccurate.
This paper aims to design an algorithm that exploits both the content and linkage information, by carrying out a joint factorization on both the linkage adjacency matrix and the document-term matrix and derives a new representation for web pages in a low-dimensional factor space, without explicitly separating them as content, hub or authority factors.
We propose a novel Generative Adversarial Network (GAN)-based framework for depth map super-resolution that is able to preserve the smooth areas, as well as the sharp edges at the boundaries of the depth map.
FeatureNMS recognizes duplicates not only based on intersection over union between bounding boxes, but also based on the difference of feature vectors.
We propose a large displacement optical flow method that introduces a new strategy to compute a good local minimum of any optical flow energy functional which is very robust to the inevitable outliers of the sparse matcher.
We formalize the word substitution-based attack as a combinatorial optimization problem. We propose a novel attack model, which comprises a sememe-based word substitution strategy and the particle swarm optimization algorithm.
We show that a model trained from scratch with coreference as auxiliary supervision for self-attention outperforms the largest GPT-2 model, setting the new state-of-the-art.
We propose a new acoustic feature, Long time frame Analysis Weighted Wavelet Packet Cepstral Coefficient (LW-WPCC), for better robustness.
We present a novel, end-to-end approach to align CAD models to an 3D scan of a scene, enabling transformation of a noisy, incomplete3D scan to a compact, CAD reconstruction with clean, complete object geometry.
In this paper, we reformulate the calculus graph as a dynamic process, which is guided by logic flow. Within our novel methodology, traditional algorithms could empower numerical neural network.
We present a biologically inspired modular unit implemented as an algorithm for face recognition that applies pixel-wise local binary decisions on similarity of spatial-intensity change features for robust and high recognition performance.
In this paper, we propose a novel method called Dynamic Multi-path Neural Network (DMNN), which provides more path selection choices in terms of network width and depth during inference.
We show how to teach machines to paint like human painters, who can use a small number of strokes to create fantastic paintings.
We propose to use a novel deep convolutional neural network for environmental sound classification tasks.
We present the first publicly available human-annotated dataset of images obtained by the Scanning Electron Microscopy (SEM)
We generalize Confident Learning, building on the assumption of a classification noise process, to directly estimate the joint distribution between noisy (given) labels and uncorrupted (unknown) labels.
We present a novel end-to-end visual odometry architecture with guided feature selection based on deep convolutional recurrent neural networks.
In this paper, we introduce a novel framework for image captioning which can generate diverse descriptions by allowing both grounding and controllability, in a semi-automatic manner.
NeuroMask is a novel method for generating an interpretable explanation of classification model results by localizing the parts of the input image which are most relevant to DNN decision.
This paper proposes a multi-grid method for learning energy-based generative ConvNet models of images.
We propose a novel architecture decoupling method, which dynamically discovers the hierarchical path consisting of activated filters for each input image, and use it for interpretation, acceleration and adversarial attacking.
We build on top of one such model and propose a hierarchy of bidirectional LSTM and max pooling layers that implements an iterative refinement strategy and yields state of the art results on the SciTail dataset as well as strong results for Stanford Natural Language Inference and Multi-Genre Natural language Inference.
Transferring knowledge from a source domain to another domain is useful, especially when gathering new data is very expensive and time-consuming. In this paper, two main methods (INIT and MULT) in this field are examined. A new method named Intelligent sample selection (ISS-MULT) is proposed to improve the MULT method for question answering tasks.
In recent research, many approaches based on association rules have been proposed to improve the accuracy of recommender systems. In this study, we propose a new model based on statistical implication rules.
We describe and analyze a simple random feature scheme (RFS) from prescribed compositional kernels.
Self-supervised monocular depth estimation methods generally suffer the occlusion fading issue due to the lack of supervision by the per pixel ground truth. In this paper, we propose a novel Edge-Guided post-processing to reduce the occlude fading issue and introduce Atrous Spatial Pyramid Pooling to improve the inference performance.
Distraction-aware HAR enhances deep CNN feature learning by improving attribute localization through a coarse-to-fine attention mechanism.
We propose a Lifelong 3D Object Classification (i.e., L3DOC) framewor, which can consecutively learn new 3D object classification tasks via imitating 'human learning'.
We introduce a StD benchmark that learns from ten StD datasets of various domains in a multi-dataset learning (MDL) setting, as well as from related tasks via transfer learning. The benchmark dataset and code is made available.
In this paper, an automatic retinal vessel segmentation method utilizing matched filter techniques coupled with an AdaBoost classifier is proposed.
