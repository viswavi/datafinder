{"tldr": "This paper proposes an attention boosted natural language inference model named aESIM by adding word attention and adaptive direction-oriented attention mechanisms to the traditional Bi-LSTM layer ofnatural language inference models.", "positives": ["MultiNLI", "Quora", "SNLI"], "year": 2018}
{"tldr": "In this paper, we propose a flexible adversarial training framework, and prove this framework not only ensures the generator converges to the true data distribution, but also enables the discriminator to retain the density information at the global optimal.", "positives": ["CIFAR-10"], "year": 2017}
{"tldr": "This paper proposes dynamic chunk reader (DCR), an end-to-end neural reading comprehension (RC) model that is able to extract and rank a set of answer candidates from a given document to answer questions.", "positives": ["SQuAD"], "year": 2016}
{"tldr": "We show that responses at the final layer of DCNNs are not sufficiently localized for accurate object segmentation. We overcome this poor localization property of deep networks by combining them with a fully connected Conditional Random Field (CRF) to achieve state-of-art results.", "positives": ["CamVid", "Cityscapes", "PASCAL VOC", "SUN RGB-D"], "year": 2014}
{"tldr": "We propose a simple neural architecture for natural language inference that uses attention to decompose the problem into subproblems that can be solved separately, thus making it trivially parallelizable.", "positives": ["SNLI"], "year": 2016}
{"tldr": "We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet, the VGG net, and GoogLeNet) and transfer their learned representations to the segmentation task.", "positives": ["ADE20K", "Cityscapes", "PASCAL Context", "PASCAL VOC", "SUN RGB-D"], "year": 2017}
{"tldr": "We propose a machine reader which processes text incrementally from left to right, while linking the current word to previous words stored in memory and implicitly discovering lexical dependencies facilitating understanding.", "positives": ["SNLI"], "year": 2016}
{"tldr": "A number of recent works have proposed attention models for Visual Question Answering (VQA) that generate spatial maps highlighting image regions relevant to answering the question. In this paper, we propose a novel co-attention model for VQA that jointly reasons about image and question attention.", "positives": ["COCO"], "year": 2016}
{"tldr": "We present a semi-supervised learning framework based on graph embeddings. Given a graph between instances, we train an embedding for each instance to jointly predict the class label and neighborhood context in the graph.", "positives": ["Citeseer", "Cora", "NELL", "Pubmed"], "year": 2016}
{"tldr": "We propose a simple yet effective regularization term to address the mode collapse issue for conditional generative adversarial networks. The proposed method explicitly maximizes the ratio of the distance between generated images with respect to the corresponding latent codes.", "positives": ["CIFAR-10"], "year": 2019}
{"tldr": "In image classification, visual separability between different object categories is highly uneven, and few efforts have been made to leverage the hierarchical structure of categories. In this paper, we introduce hierarchical deep CNNs (HD-CNNs) by embeddingDeep CNNs into a category hierarchy.", "positives": ["CIFAR-100"], "year": 2015}
{"tldr": "In this paper we study the use of convolutional neural networks (convnets) for the task of pedestrian detection and present the best convnet detectors on the Caltech and KITTI datasets.", "positives": ["ImageNet"], "year": 2015}
{"tldr": "This paper presents the machine learning architecture of the Snips Voice Platform, a software solution to perform Spoken Language Understanding on microprocessors typical of IoT devices.", "positives": ["LibriSpeech"], "year": 2018}
{"tldr": "We propose CornerNet, a new approach to object detection where we detect an object bounding box as a pair of keypoints, the top-left corner and the bottom-right corner, using a single convolution neural network.", "positives": ["COCO"], "year": 2018}
{"tldr": "We propose bootstrapped DQN, a simple algorithm that explores in a computationally and statistically efficient manner through use of randomized value functions, which can lead to exponentially faster learning.", "positives": ["Arcade Learning Environment", "AtariARI"], "year": 2016}
{"tldr": "We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs.", "positives": ["Citeseer", "Cora", "NELL", "Pubmed"], "year": 2016}
{"tldr": "We consider an agent's uncertainty about its environment and the problem of generalizing this uncertainty across observations, and propose a novel algorithm for deriving a pseudo-count from an arbitrary sequential density model.", "positives": ["Arcade Learning Environment"], "year": 2016}
{"tldr": "We explore the effects of transfer learning for neural sequence taggers, where a source task with plentiful annotations is used to improve performance on a target task with fewer available annotations, and show that significant improvement can often be obtained.", "positives": ["CoNLL-2003", "Penn Treebank"], "year": 2017}
{"tldr": "We present a system, called FaceNet, that directly learns a mapping from face images to a compact Euclidean space where distances directly correspond to a measure of face similarity.", "positives": ["IJB-C", "LFW", "MegaFace"], "year": 2015}
{"tldr": "We propose node2vec, an algorithmic framework for learning continuous feature representations for nodes in networks. We define a flexible notion of a node's network neighborhood and design a biased random walk procedure which efficiently explores diverse neighborhoods.", "positives": ["BlogCatalog", "KILT"], "year": 2016}
{"tldr": "We introduce a novel region proposal network that uses subcategory information to guide the proposal generating process, and a new detection network for joint detection and subcategory classification.", "positives": ["PASCAL VOC 2007"], "year": 2017}
{"tldr": "We propose a novel approach to overcome these limitations by using geometric deep learning on graphs, using graph convolutional neural networks and recurrent neural networks to learn meaningful statistical graph-structured patterns and the non-linear diffusion process.", "positives": ["MovieLens", "Netflix Prize"], "year": 2017}
{"tldr": "We propose a framework for learning convolutional neural networks for arbitrary graphs that operate on locally connected regions of the input, and propose a general approach to extracting locally connected Regions from graphs.", "positives": ["IMDB-BINARY", "MUTAG", "NCI1", "RailEye3D Dataset"], "year": 2016}
{"tldr": "We propose a principled loss function inspired by a metric learning objective for semantic instance segmentation and achieve competitive performance on Cityscapes and CVPPP leaf segmentation benchmarks.", "positives": ["MHP", "TuSimple"], "year": 2017}
{"tldr": "We introduce a novel matching algorithm, called DeepMatching, to compute dense correspondences between images. The proposed matching algorithm can handle non-rigid deformations and repetitive textures and efficiently determines density correspondences in the presence of significant changes between images .", "positives": ["HPatches"], "year": 2016}
{"tldr": "We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes.", "positives": ["CIFAR-10"], "year": 2017}
{"tldr": "We investigate character-level extensions to sequence labeling architectures and propose a novel architecture for combining alternative word representations. By using an attention mechanism, the model is able to dynamically decide how much information to use from a character- level component.", "positives": ["FCE", "Penn Treebank"], "year": 2016}
{"tldr": "We study the segmental recurrent neural network for end-to-end acoustic modelling, and propose a method to accelerate the training and decoding of CRF-based acoustic models.", "positives": ["TIMIT"], "year": 2016}
{"tldr": "This paper introduces the Deep Recurrent Attentive Writer (DRAW) neural network architecture for image generation, a novel spatial attention mechanism that mimics the foveation of the human eye, with a sequential variational auto-encoding framework.", "positives": ["CIFAR-10"], "year": 2015}
{"tldr": "We propose a unified model, called U-Net, with three important components: answer pointer, no-answer pointer, and answer verifier, which can effectively predict the unanswerability of questions and achieves F1 score of 71.7 on [DATASET].", "positives": ["SQuAD"], "year": 2018}
{"tldr": "We show that sequence-to-sequence method achieves state-of-the-art results on syntactic parsing, whilst making almost no assumptions about the structure of the problem.", "positives": ["Penn Treebank"], "year": 2014}
{"tldr": "Pedestrian detection in crowded scenes is a challenging problem since the pedestrians often gather together and occlude each other. In this paper, we propose a new occlusion-aware R-CNN (OR-CNN) to improve the detection accuracy in the crowd.", "positives": ["CityPersons", "ImageNet"], "year": 2018}
{"tldr": "We introduce Related Memory Network, an end-to-end neural network architecture exploiting both memory network and relation network structures. It achieves the state-of-the-art results in jointly trained [DATASET] story-based question answering and dialog dataset.", "positives": ["bAbI"], "year": 2018}
{"tldr": "This paper presents a Deep convolutional network model for Identity-Aware Transfer (DIAT) of facial attributes. Given the source input image and the reference attribute, DIAT aims to generate a facial image that owns theReference attribute as well as keeps the same identity to the input image.", "positives": ["RaFD"], "year": 2016}
{"tldr": "We start from a group of relatively shallow networks, which perform as well or even better than the current (much deeper) state-of-the-art models on the ImageNet classification dataset, and tune them for semantic image segmentation.", "positives": ["Cityscapes", "PASCAL VOC"], "year": 2016}
{"tldr": "We propose a Shorten Spatial-spectral RNN with Parallel-GRU for hyperspectral sensing image (HSI) classification.", "positives": ["Indian Pines", "Pavia University"], "year": 2018}
{"tldr": "Hypernymy, textual entailment, and image captioning can be seen as special cases of a single visual-semantic hierarchy over words, sentences, and images. In this paper we advocate for explicitly modeling the partial order structure of this hierarchy.", "positives": ["SNLI"], "year": 2015}
{"tldr": "We propose a novel method named sliding line point regression (SLPR) in order to detect arbitrary-shape text in natural scene. SLPR regresses multiple points on edge of text line and then utilizes these points to sketch the outlines of the text.", "positives": ["SCUT-CTW1500"], "year": 2018}
{"tldr": "Inspired by recent successes of deep learning in computer vision, we propose a novel application of deep convolutional neural networks to facial expression recognition, in particular smile recognition.", "positives": ["DISFA"], "year": 2016}
{"tldr": "A biologically plausible, wide and deep artificial neural network architectures can match human performance on tasks such as the recognition of handwritten digits or traffic signs.", "positives": ["CIFAR-10", "GTSRB", "MNIST"], "year": 2012}
{"tldr": "We present a novel and practical deep fully convolutional neural network architecture for semantic pixel-wise segmentation, which provides competitive inference time and most efficient inference memory-wise as compared to other architectures.", "positives": ["ADE20K", "CamVid", "Cityscapes", "SUN RGB-D"], "year": 2017}
{"tldr": "We propose a principled method for gradient-based regularization of the critic of GAN-like models trained by adversarially optimizing the kernel of a Maximum Mean Discrepancy (MMD).", "positives": ["CIFAR-10"], "year": 2018}
{"tldr": "We show that sentence embeddings trained using the supervised data of the Stanford Natural Language Inference datasets can consistently outperform unsupervised methods like SkipThought vectors on a wide range of transfer tasks.", "positives": ["SNLI", "SentEval", "XNLI"], "year": 2017}
{"tldr": "In this work, we evaluate encoders to inverse the mapping of a cGAN, i.e., mapping a real image into a latent space and a conditional representation.", "positives": ["RaFD"], "year": 2016}
{"tldr": "We propose a simple yet powerful pipeline that yields fast and accurate text detection in natural scenes, eliminating unnecessary intermediate steps (e.g., candidate aggregation and word partitioning), with a single neural network.", "positives": ["SCUT-CTW1500"], "year": 2017}
{"tldr": "We propose a novel ResNet-like architecture that combines multi-scale context with pixel-level accuracy for Semantic Image Segmentation.", "positives": ["Cityscapes"], "year": 2017}
{"tldr": "We propose an approach to 3D image segmentation based on a volumetric, fully convolutional, neural network. We introduce a novel objective function, that we optimise based on Dice coefficient.", "positives": ["PROMISE12"], "year": 2016}
{"tldr": "In this paper we introduce the Bi-Directional Attention Flow (BIDAF) network, a multi-stage hierarchical process that represents the context at different levels of granularity and uses bi-directional attention flow mechanism to obtain a query-aware context representation without early summarization.", "positives": ["CNN/Daily Mail", "MS MARCO", "NarrativeQA", "QUASAR-T", "SQuAD"], "year": 2016}
{"tldr": "In this paper, we propose a deep architecture to model the strong interaction of sentence pair with two coupled-LSTMs, coupling the local contextualized interactions of two sentences.", "positives": ["SNLI"], "year": 2016}
{"tldr": "We propose a CNN architecture that can reconstruct the whole 3D facial geometry (including the non-visible parts of the face) bypassing the construction (during training) and fitting (during testing) of a Morphable Model.", "positives": ["Florence"], "year": 2017}
{"tldr": "We propose LeakGAN, a generative adversarial network for long text generation, which can learn sentence structures only through the interaction between Manager and Worker.", "positives": ["COCO Captions"], "year": 2017}
{"tldr": "We present a simple, highly modularized network architecture for image classification that maximizes cardinality and improves classification accuracy under the restricted condition of maintaining complexity.", "positives": ["ImageNet"], "year": 2017}
{"tldr": "We propose the task of free-form and open-ended Visual Question Answering (VQA). Given an image and a natural language question about the image, the task is to provide an accurate natural language answer.", "positives": ["COCO"], "year": 2015}
{"tldr": "In this paper, we propose a novel generative model named Stacked Generative Adversarial Networks (SGAN), which is trained to invert the hierarchical representations of a bottom-up discriminative network, leveraging the powerful discrim inative representations to guide the generative process.", "positives": ["CIFAR-10"], "year": 2017}
{"tldr": "We introduce \"DenseReg\", a fully-convolutional neural network (F-CNN) that densely regresses at every foreground pixel a pair of U-V template coordinates in a single feedforward pass in order to establish dense correspondences.", "positives": ["COCO"], "year": 2017}
{"tldr": "We propose a scalable and efficient exploration method based on assigning exploration bonuses from a concurrently learned model of the system dynamics that can be applied to tasks with complex, high-dimensional state spaces.", "positives": ["Arcade Learning Environment"], "year": 2015}
{"tldr": "This paper describes InfoGAN, an information-theoretic extension to the Generative Adversarial Network that is able to learn disentangled representations in a completely unsupervised manner.", "positives": ["MNIST"], "year": 2016}
{"tldr": "This paper explores a simple and efficient baseline for text classification. Our fast text classifier fastText is often on par with deep learning classifiers in terms of accuracy, and many orders of magnitude faster for training and evaluation.", "positives": ["AG News", "DBpedia", "SPOT"], "year": 2016}
{"tldr": "In this paper, we propose Gumbel Tree-LSTM, a novel tree-structured long short-term memory architecture that learns how to compose task-specific tree structures only from plain text data efficiently.", "positives": ["SNLI"], "year": 2017}
{"tldr": "SiamMask improves the offline training procedure of popular fully-convolutional Siamese approaches for object tracking by augmenting their loss with a binary segmentation task.", "positives": ["VOT2018"], "year": 2019}
{"tldr": "We propose a dual pathway, 11‐layers deep, multi‐scale, three‐dimensional Convolutional Neural Network for the challenging task of brain lesion segmentation.", "positives": ["BraTS 2015"], "year": 2017}
{"tldr": "We address the zero-shot and few-shot learning scenarios as obtaining labeled data is especially difficult for fine-grained classification tasks. We argue that learning a joint embedding space, that maximizes the compatibility between the input and output embeddings, is highly effective for zero/few- shot learning.", "positives": ["CUB-200-2011"], "year": 2014}
{"tldr": "We introduce an efficient sub-pixel convolution layer which learns an array of upscaling filters to upscale the final LR feature maps into HR output.", "positives": ["BSD", "Set14", "Set5"], "year": 2016}
{"tldr": "We propose a simple but effective extension of a sinusoidal positional encoding (Vaswani et al, 2017) to enable neural encoder-decoder model to preserves the length constraint.", "positives": ["DUC 2004"], "year": 2019}
{"tldr": "We propose a novel ResNet block architecture where we decrease depth and increase width of residual networks, achieving state-of-the-art results on [DATASET], [DATASET], COCO, and significant improvements on ImageNet.", "positives": ["CIFAR-10", "CIFAR-100", "SVHN"], "year": 2016}
{"tldr": "Cascade R-CNN is proposed to address these problems. It consists of a sequence of detectors trained with increasing IoU thresholds, to be sequentially more selective against close false positives, leveraging the observation that the output of a detector is a good distribution for training the next higher quality detector.", "positives": ["COCO"], "year": 2018}
{"tldr": "In this paper we present an alternative network that outperforms FlowNet2 on Sintel final pass and KITTI benchmarks, while being 30 times smaller in the model size and 1.36 times faster in the running speed.", "positives": ["MPI Sintel"], "year": 2018}
{"tldr": "In this work we present a new reinforcement learning agent, called Reactor (for Retrace-actor), based on an off-policy multi-step return actor-critic architecture that achieves state-of-the-art performance.", "positives": ["Arcade Learning Environment"], "year": 2017}
{"tldr": "In this paper we present seven techniques that everybody should know to improve example-based single image super resolution (SR): 1) augmentation of data, 2) use of large dictionaries with efficient search structures, 3) cascading, 4) image self-similarities, 5) back projection refinement, 6) enhanced prediction by consistency check, and 7) context reasoning.", "positives": ["BSD", "Set14", "Set5"], "year": 2016}
{"tldr": "We formulate weakly supervised detection as a Multiple Instance Learning problem, where instance classifiers (object detectors) are put into the network as hidden nodes, and train the network end-to-end with only image-level supervision, i.e., without object location information.", "positives": ["ImageNet", "PASCAL VOC", "PASCAL VOC 2007"], "year": 2017}
{"tldr": "The objective of this paper is to learn a compact representation of image sets for template-based face recognition. We make the following contributions: first, we propose a network architecture which aggregates and embeds the face descriptors produced by deep convolutional neural networks into a compact fixed-length representation.", "positives": ["IJB-A", "IJB-B"], "year": 2018}
{"tldr": "LISA combines multi-head self-attention with multi-task learning across dependency parsing, part-of-speech tagging, predicate detection and SRL, achieving new state- of-the-art performance.", "positives": ["CoNLL-2012"], "year": 2018}
{"tldr": "In this paper, we present the Lipschitz regularization theory and algorithms for a novel Loss-Sensitive Generative Adversarial Network (LS-GAN) that can better generalize to produce new data from a reasonable number of training examples than the classic GAN.", "positives": ["CIFAR-10", "SVHN"], "year": 2019}
{"tldr": "We propose an image super-resolution method using a deeply-recursive convolutional network (DRCN) using a very deep recursive layer (up to 16 recursions).", "positives": ["BSD", "Set14", "Set5"], "year": 2016}
{"tldr": "We propose a Multi-sentiment-resource Enhanced Attention Network (MEAN) to integrate three kinds of sentiment linguistic knowledge into the deep neural network via attention mechanisms for sentiment prediction.", "positives": ["MR", "SST"], "year": 2018}
{"tldr": "We present a data augmentation network that can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures.", "positives": ["CHASE_DB1", "DRIVE", "LUNA", "STARE"], "year": 2015}
{"tldr": "Neural machine translation is a recently proposed approach to machine translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as hard segment explicitly.", "positives": ["WMT 2014"], "year": 2014}
{"tldr": "We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping.", "positives": ["Cityscapes"], "year": 2016}
{"tldr": "Depthwise separable convolutions reduce the number of parameters and computation used in convolutional operations while increasing representational efficiency. We introduce a new architecture inspired by Xception and ByteNet, which enables a significant reduction of the parameter count and amount of computation needed to obtain results like ByteNet.", "positives": ["WMT 2014"], "year": 2017}
{"tldr": "We introduce a generative model that generates images from natural language descriptions. The proposed model iteratively draws patches on a canvas, while attending to the relevant words in the description.", "positives": ["COCO"], "year": 2015}
{"tldr": "In this paper, we introduce two new neural architectures based on bidirectional LSTMs and conditional random fields, and the other that constructs and labels segments using a transition-based approach inspired by shift-reduce parsers.", "positives": ["CoNLL-2003"], "year": 2016}
{"tldr": "We propose a real-time RGB-based pipeline for object detection and 6D pose estimation. We further increase performance by correcting 3D orientation estimates to account for perspective errors when the object deviates from the image center and show extended results.", "positives": ["T-LESS"], "year": 2019}
{"tldr": "We propose an end-to-end neural model that enables those answer candidates from different passages to verify each other based on their content representations.", "positives": ["MS MARCO"], "year": 2018}
{"tldr": "In this work, we present a simple, highly efficient and modularized Dual Path Network (DPN) for image classification which presents a new topology of connection paths internally.", "positives": ["ImageNet"], "year": 2017}
{"tldr": "This paper proposes an innovative framework to learn a nonlinear 3DMM model from a large set of unconstrained face images, without collecting 3D face scans.", "positives": ["AFLW2000-3D"], "year": 2018}
{"tldr": "We develop a graph-walking agent called M-Walk, which consists of a deep recurrent neural network (RNN) and Monte Carlo Tree Search (MCTS) and combine MCTS with the neural policy to effectively train from sparse rewards.", "positives": ["WN18"], "year": 2018}
{"tldr": "We propose a deep learning method for single image super-resolution (SR). Our method directly learns an end-to-end mapping between the low/high-resolution images.", "positives": ["BSD", "Manga109", "Set14", "Set5", "Urban100"], "year": 2016}
{"tldr": "We show how a simple convolutional neural network can be trained to accurately and robustly regress 6 degrees of freedom (6DoF) 3D head pose, directly from image intensities.", "positives": ["300W", "IJB-A", "IJB-B"], "year": 2017}
{"tldr": "We evaluate an attention-based encoder-decoder with a subword-level encoder and a character-level decoder on four language pairs using the parallel corpora from WMT'15.", "positives": ["WMT 2015"], "year": 2016}
{"tldr": "In statistical relational learning, the link prediction problem is key to automatically understand the structure of large knowledge bases. As in previous studies, we propose to solve this problem through latent factorization. However, we make use of complex valued embeddings.", "positives": ["WN18"], "year": 2016}
{"tldr": "We introduce a simple and effective method for regularizing large convolutional neural networks. We replace the conventional deterministic pooling operations with a stochastic procedure and achieve state-of-the-art performance on four image datasets.", "positives": ["CIFAR-10", "CIFAR-100", "SVHN"], "year": 2013}
{"tldr": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. We propose a new simple architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.", "positives": ["Penn Treebank", "WMT 2014"], "year": 2017}
{"tldr": "In this paper, we propose a novel neural network model called RNN Encoder‐ Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other RNN decodes the representation into another vector representation.", "positives": ["WMT 2014"], "year": 2014}
{"tldr": "We propose a simple, interpretable framework for solving a wide range of image reconstruction problems such as denoising and deconvolution. The model parameters are learned using supervised or self-supervised training.", "positives": ["Set14", "Set5"], "year": 2018}
{"tldr": "We present a novel feature fusion strategy that proceeds in a hierarchical fashion, first fusing the modalities two in two and only then fusing all three modalities for multimodal sentiment analysis.", "positives": ["IEMOCAP", "Multimodal Opinionlevel Sentiment Intensity"], "year": 2018}
{"tldr": "We introduce the\"exponential linear unit\"(ELU) which speeds up learning in deep neural networks and leads to higher classification accuracies.", "positives": ["CIFAR-10", "CIFAR-100"], "year": 2015}
{"tldr": "This paper proposes a state-of-the-art recurrent neural network (RNN) language model that combines probability distributions computed not only from a final RNN layer but also from middle layers.", "positives": ["Penn Treebank", "WikiText-2"], "year": 2018}
{"tldr": "In this paper we introduce a simple approach for exploration in reinforcement learning that allows us to develop theoretically justified algorithms in the tabular case but that is also extendable to settings where function approximation is required.", "positives": ["Arcade Learning Environment"], "year": 2018}
{"tldr": "Faster RCNN has achieved great success for generic object detection including PASCAL object detection and MS COCO object detection. In this report, we propose a new Faster RCNN method named FDNet1.0 for face detection.", "positives": ["WFLW"], "year": 2018}
{"tldr": "We propose a new deep learning framework for person search. Instead of breaking it down into two separate tasks---pedestrian detection and person re-identification, we jointly handle both aspects in a single convolutional neural network.", "positives": ["DukeMTMC-reID"], "year": 2017}
{"tldr": "We reformulate existing models into a single common framework we call Message Passing Neural Networks (MPNNs) and explore additional novel variations within this framework and demonstrate state of the art results on an important molecular property prediction benchmark.", "positives": ["QM9"], "year": 2017}
{"tldr": "We propose a Discriminative Feature Network (DFN) for semantic segmentation and achieve state-of-the-art performance on [DATASET] and [DATASET] dataset.", "positives": ["Cityscapes", "PASCAL VOC"], "year": 2018}
{"tldr": "The FlowNet demonstrated that optical flow estimation can be cast as a learning problem. In this paper, we advance the concept of end-to-end learning of optical flow and make it work really well.", "positives": ["HPatches"], "year": 2017}
{"tldr": "We focus on the challenging task of real-time semantic segmentation in this paper. We propose an image cascade network (ICNet) that incorporates multi-resolution branches under proper label guidance to address this challenge.", "positives": ["CamVid", "Cityscapes"], "year": 2017}
{"tldr": "We introduce the Stanford Natural Language Inference corpus, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning.", "positives": ["SNLI"], "year": 2015}
{"tldr": "We present a neural network architecture and training method designed to enable very rapid training and low implementation complexity. We demonstrate the efficacy of the method by applying it to image classification.", "positives": ["CIFAR-10", "MNIST", "SVHN"], "year": 2015}
{"tldr": "We propose spectral pooling and complex-coefficient spectral parameterization of convolutional neural networks, which achieve competitive results on classification and approximation tasks without using any dropout or max-pooling.", "positives": ["CIFAR-10", "CIFAR-100"], "year": 2015}
{"tldr": "We introduce a structured low-rank recovery model that makes use of proximity information about rows and columns by assuming they form communities. We borrow ideas from manifold learning to constrain our solution to be smooth on these graphs.", "positives": ["MovieLens"], "year": 2014}
{"tldr": "SwiDeN: our Convolutional Neural Network (CNN) architecture which recognizes objects regardless of how they are visually depicted (line drawing, realistic shaded drawing, photograph etc.)", "positives": ["Cityscapes"], "year": 2016}
{"tldr": "We explore the benefits of using a man- ifold network structure for covariance pooling to improve facial expression recognition in an end-to-end deep learning manner.", "positives": ["RAF-DB", "SFEW"], "year": 2018}
{"tldr": "This work introduces a novel convolutional network architecture for the task of human pose estimation. We show how repeated bottom-up, top-down processing used in conjunction with intermediate supervision is critical to improving the performance of the network.", "positives": ["FLIC", "MPII Human Pose"], "year": 2016}
{"tldr": "We introduce a count-based optimistic exploration algorithm for Reinforcement Learning that is feasible in environments with high-dimensional state-action spaces and achieves state-of-the-art results.", "positives": ["Arcade Learning Environment"], "year": 2017}
{"tldr": "We re-evaluate the state of the art for object recognition from small images with convolutional networks, questioning the necessity of different components in the pipeline. We find that max-pooling can simply be replaced by a Convolutional layer with increased stride without loss in accuracy.", "positives": ["CIFAR-10", "CIFAR-100"], "year": 2014}
{"tldr": "In this paper, we present MultiPoseNet, a novel bottom-up multi-person pose estimation architecture that combines a multi-task model with a novel assignment method.", "positives": ["COCO"], "year": 2018}
{"tldr": "We introduce a globally normalized transition-based neural network model that achieves state-of-the-art part ofspeech tagging, dependency parsing and sentence compression results.", "positives": ["Penn Treebank"], "year": 2016}
{"tldr": "In this paper we introduce a generic variational inference framework for generative and conditional models of text. We validate this framework on two very different text modelling applications, generative document modelling and supervised question answering.", "positives": ["WikiQA"], "year": 2015}
{"tldr": "We propose to fine-tune CNN for image retrieval from a large collection of unordered images in a fully automated manner in a state-of-the-art manner.", "positives": ["Oxford Town Center", "Oxford5k", "Paris-Lille-3D"], "year": 2016}
{"tldr": "We present a new, simple model that uses attention to directly pick the answer from the context as opposed to computing the answer using a blended representation of words in the document.", "positives": ["CBT", "CNN/Daily Mail", "SearchQA"], "year": 2016}
{"tldr": "We describe a very simple bag-of-words baseline for visual question answering. This baseline concatenates the word features from a question and CNN features from the image to predict the answer.", "positives": ["COCO"], "year": 2015}
{"tldr": "We introduce a neural network with a recurrent attention model over a possibly large external memory. The architecture is a form of Memory Network (Weston et al, 2015) but unlike the model in that work, it is trained end-to-end, and hence requires significantly less supervision during training.", "positives": ["bAbI"], "year": 2015}
{"tldr": "We combine the strengths of both architectures and propose a novel and unified model called C-LSTM for sentence representation and text classification, which achieves excellent performance on these tasks.", "positives": ["SST", "TRECVID"], "year": 2015}
{"tldr": "We present an integrated framework for using Convolutional Networks for classification, localization and detection. We show how a multiscale and sliding window approach can be efficiently implemented within a ConvNet.", "positives": ["ImageNet"], "year": 2013}
{"tldr": "We present a method that partially shuffles the training data between epochs, while keeping most sentence ordering intact. It achieves new state of the art results on word-level language modeling on both the [DATASET] and [DATASET] datasets.", "positives": ["Penn Treebank", "WikiText-2"], "year": 2019}
{"tldr": "We propose TuckER, a relatively straightforward but powerful linear model based on Tucker decomposition of the binary tensor representation of knowledge graph triples.", "positives": ["FB15k", "WN18"], "year": 2019}
{"tldr": "We propose an end-to-end differentiable neural network for entailment that achieves state-of-the-art accuracy on a textual entailment dataset.", "positives": ["SNLI"], "year": 2015}
{"tldr": "In this paper, we introduce a novel neural network architecture called Multi-layer Embedding with Memory Network(MEMEN) for machine reading task, which achieves state-of-the-art results on [DATASET] dataset.", "positives": ["SQuAD", "TriviaQA"], "year": 2017}
{"tldr": "In this paper we study the problem of answering cloze-style questions over documents. Our model, the Gated-Attention (GA) Reader, integrates a multi-hop architecture with a novel attention mechanism, which is based on multiplicative interactions between the query embedding and the intermediate states.", "positives": ["CBT", "CNN/Daily Mail", "QUASAR-T"], "year": 2016}
{"tldr": "We propose a model for fine-grained categorization that overcomes these limitations by leveraging deep convolutional features computed on bottom-up region proposals.", "positives": ["CUB-200-2011"], "year": 2014}
{"tldr": "This paper investigates two alternative methods for artificially generating writing errors, in order to create additional resources. We propose treating error generation as a machine translation task, where grammatically correct text is translated to contain errors.", "positives": ["FCE"], "year": 2017}
{"tldr": "We present a new neural network architecture for model-free reinforcement learning. The dueling network represents two separate estimators for the state value function and one for the action advantage function.", "positives": ["Arcade Learning Environment"], "year": 2015}
{"tldr": "This paper proposes the SVDNet for retrieval problems, with focus on the application of person re-identification (reID) using Singular Vector Decomposition.", "positives": ["DukeMTMC-reID", "Market-1501"], "year": 2017}
{"tldr": "We demonstrate that large-scale unsupervised language modeling combined with finetuning offers a practical solution to this task on difficult datasets, including those with label class imbalance and domain-specific context.", "positives": ["SST", "SemEval 2014 Task 4 Sub Task 2"], "year": 2018}
{"tldr": "We propose CollaboNet which utilizes a combination of multiple NER models for biomedical named entity recognition and achieved state-of-the-art performance in terms of precision, recall and F1 score.", "positives": ["BC5CDR"], "year": 2018}
{"tldr": "Neural machine translation (NMT) models typically operate with a fixed vocabulary, but translation is an open-vocabulary problem. We introduce a simpler and effective approach, encoding rare and unknown words as sequences of subword units.", "positives": ["WMT 2015"], "year": 2015}
{"tldr": "PyDCI is a Python implementation of Distributional Correspondence Indexing, a transfer learning method for cross-domain and cross-lingual text classification for which we had provided JaDCI, a Java framework for text classification.", "positives": ["Multi-Domain Sentiment Dataset v2.0"], "year": 2018}
{"tldr": "We represent 3D spaces as volumetric fields, and propose a novel design that employs field probing filters to efficiently extract features from them, while providing state-of-the-art performance, on classification tasks for 3D object recognition benchmark datasets.", "positives": ["ModelNet"], "year": 2016}
{"tldr": "We propose a repulsive loss function for GAN that actively learns the difference among the real data by simply rearranging the terms in MMD.", "positives": ["CIFAR-10"], "year": 2018}
{"tldr": "We propose a margin-based method to score, mine and filter large parallel corpora based on multilingual sentence embeddings, improving on existing methods.", "positives": ["BUCC"], "year": 2018}
{"tldr": "We show how to improve semantic segmentation through the use of contextual information; specifically, we explore `patch-patch' context between image regions, and 'patch-background' context, and propose a deep structured model that achieves state-of-the-art performance.", "positives": ["PASCAL Context"], "year": 2016}
{"tldr": "In this paper, we propose a novel model: Deep Interest Network (DIN) which tackles this challenge by designing a local activation unit to adaptively learn the representation of user interests from historical behaviors with respect to a certain ad.", "positives": ["Amazon Fine Foods", "MovieLens"], "year": 2018}
{"tldr": "We propose and analyze a POS tagging model that exploits adversarial training (AT), and we find that AT not only improves the overall tagging accuracy, but also prevents overfitting in low resource languages.", "positives": ["Penn Treebank", "Universal Dependencies"], "year": 2017}
{"tldr": "This paper aims to highlight vision related tasks centered around “car”, which has been largely neglected by vision community in comparison to other objects. To facilitate future car-related research, in this paper we present our on-going effort in collecting a large-scale dataset, “[DATASET]”.", "positives": ["CompCars"], "year": 2015}
{"tldr": "In this paper, we explicitly consider this challenge by introducing camera style (CamStyle) adaptation, a data augmentation approach that smooths the camera style disparities caused by different cameras.", "positives": ["DukeMTMC-reID", "Market-1501"], "year": 2018}
{"tldr": "This paper presents an end-to-end model for both dependency and span SRL with unified argument representation to deal with two different types of argument annotations in a uniform fashion.", "positives": ["OntoNotes 5.0"], "year": 2019}
{"tldr": "We present a conceptually simple, flexible, and general framework for instance-level recognition, extending Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition.", "positives": ["COCO", "MHP"], "year": 2020}
{"tldr": "We participated in the [DATASET] shared news translation task by building neural translation systems for four language pairs, each trained in both directions, using BPE subword segmentation for open-vocabulary translation with a fixed vocabulary.", "positives": ["WMT 2016"], "year": 2016}
{"tldr": "We present DeepWalk, a novel approach for learning latent representations of vertices in a network, which encode social relations in a continuous vector space, which is easily exploited by statistical models.", "positives": ["BlogCatalog", "Citeseer", "Cora", "KILT", "NELL", "Pubmed"], "year": 2014}
{"tldr": "We propose a new regularization method based on decoding the last token in the context using the predicted distribution of the next token. This biases the model towards retaining more contextual information, in turn improving its ability to predict the nexttoken.", "positives": ["Penn Treebank", "WikiText-2"], "year": 2018}
{"tldr": "We present a technique for adding global context to deep convolutional networks for semantic segmentation. The approach is simple, using the average feature for a layer to augment the features at each location.", "positives": ["PASCAL Context", "PASCAL VOC"], "year": 2015}
{"tldr": "We propose a new framework (Consistent Rank Logits, CORAL) with theoretical guarantees for rank-monotonicity and consistent confidence scores for ordinal regression.", "positives": ["CACD", "MORPH", "UTKFace"], "year": 2019}
{"tldr": "DasNet leverages the power of sequential processing to improve classification performance, by allowing the network to iteratively focus its internal attention on some of its convolutional filters.", "positives": ["CIFAR-10", "CIFAR-100"], "year": 2014}
{"tldr": "We propose novel models using deep neural networks (DNNs) to automatically learn effective patterns from categorical feature interactions and make predictions of users’ ad clicks.", "positives": ["Criteo", "iPinYou"], "year": 2016}
{"tldr": "We conduct a thorough examination of this new reading comprehension task and show that simple, carefully designed systems can obtain accuracies of 73.6% on these two datasets, exceeding current state-of-the-art results.", "positives": ["CNN/Daily Mail"], "year": 2016}
{"tldr": "Weakly supervised learning of object detection is an important problem in image understanding that still does not have a satisfactory solution. In this paper, we address this problem by exploiting the power of deep neural networks pre-trained on large-scale image-level classification tasks.", "positives": ["PASCAL VOC 2007"], "year": 2016}
{"tldr": "We introduce PoseCNN, a new Convolutional Neural Network for 6D object pose estimation that is robust to occlusions, can handle symmetric objects, and provide accurate pose estimation using only color images as input.", "positives": ["LINEMOD", "YCB-Video"], "year": 2017}
{"tldr": "We address the problem of Visual Question Answering (VQA), which requires joint image and language understanding to answer a question about a given photograph. Our Spatial Memory Network stores neuron activations from different spatial regions of the image in its memory and uses the question to choose relevant regions for computing the answer.", "positives": ["COCO"], "year": 2015}
{"tldr": "We present PointFusion, a generic 3D object detection method that leverages both image and 3D point cloud information. Unlike existing methods that either use multi-stage pipelines or hold sensor and dataset-specific assumptions.", "positives": ["YCB-Video"], "year": 2018}
{"tldr": "This paper designs a high-performance deep convolutional network (DeepID2+) for face recognition. Through empirical studies, we have discovered three properties of its deep neural activations critical for the high performance: sparsity, selectiveness and robustness.", "positives": ["LFW"], "year": 2015}
{"tldr": "We generalize a recently proposed model architecture based on self-attention, the Transformer, to a sequence modeling formulation of image generation, improving the current state of the art in image generation on ImageNet.", "positives": ["CIFAR-10"], "year": 2018}
{"tldr": "We investigate models that use recurrent neural networks with sentence-level context for initial character and word-based representations for part-of-speech tagging accuracy.", "positives": ["Penn Treebank"], "year": 2018}
{"tldr": "MultiGrain is a network architecture producing compact vector representations that are suited both for image classification and particular object retrieval, with state-of-the-art classification accuracy.", "positives": ["INRIA Holidays Dataset", "ImageNet"], "year": 2019}
{"tldr": "We present a deep neural network that sequentially predicts the pixels in an image along the two spatial dimensions and achieve log-likelihood scores on natural images that are considerably better than the previous state of the art.", "positives": ["CIFAR-10"], "year": 2016}
{"tldr": "This paper introduces a neural model for concept-to-text generation that scales to large, rich domains. We experiment with a new dataset of biographies from Wikipedia.", "positives": ["WikiBio"], "year": 2016}
{"tldr": "We propose to overcome the SSS problem in re-identification distance metric learning by matching people in a discriminative null space of the training data.", "positives": ["Market-1501"], "year": 2016}
{"tldr": "Random omitting half of the feature detectors on each training case improves on held-out test data and sets new records for speech and object recognition.", "positives": ["CIFAR-10"], "year": 2012}
{"tldr": "We propose a novel fluency boost learning and inference mechanism for grammatical error correction, achieving state-of-the-art performance on CoNLL-2014 10 and [DATASET] tests.", "positives": ["JFLEG"], "year": 2018}
{"tldr": "We learn to compute optical flow by combining a classical spatial-pyramid formulation with deep learning. Unlike FlowNet approach, the networks do not need to deal with large motions, these are dealt with by the pyramid.", "positives": ["HPatches", "MPI Sintel"], "year": 2017}
{"tldr": "This paper presents stacked attention networks (SANs) that learn to answer natural language questions from images. SANs use semantic representation of a question as query to search for the relevant visual clues that lead to the answer of the question.", "positives": ["COCO"], "year": 2016}
{"tldr": "GHM-C and GHM-R are novel loss functions designed to balancing the gradient flow for single-stage detector and achieve state-of-the-art results on [DATASET].", "positives": ["COCO"], "year": 2018}
{"tldr": "We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick,\" allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input.", "positives": ["ImageNet"], "year": 2018}
{"tldr": "We present a state-of-the-art speech recognition system developed using end-to-end deep learning. We do not need a phoneme dictionary, nor even the concept of a \"phoneme,\" but instead directly learns a function that is robust to such effects.", "positives": ["Switchboard-1 Corpus", "VoxForge"], "year": 2014}
{"tldr": "This study tackles generative reading comprehension (RC), which consists of answering questions based on textual evidence and natural language generation (NLG). We propose a multi-style abstractive summarization model for question answering.", "positives": ["MS MARCO"], "year": 2019}
{"tldr": "We address these issues by introducingtheStack-augmentedParser-Interpreter NeuralNetwork(SPINN),whichcombines parsing and interpretation within a single tree-sequence hybrid model by integrating tree-structured sentence interpretation into the linear sequential structure of a shiftreduceparser.", "positives": ["SNLI"], "year": 2016}
{"tldr": "We present an elegant and robust way to determine pose by training a multi-loss convolutional neural network on 300W-LP, a large synthetically expanded dataset, to predict intrinsic Euler angles (yaw, pitch and roll) directly from image intensities.", "positives": ["AFLW2000-3D", "BIWI"], "year": 2017}
{"tldr": "We extend variational autoencoders (VAEs) to collaborative filtering for implicit feedback and use Bayesian inference to learn a generative model with multinomial likelihood.", "positives": ["MSD", "MovieLens", "Netflix Prize"], "year": 2018}
{"tldr": "Image restoration, including image denoising, super resolution, inpainting, and so on, is a well-studied problem in computer vision and image processing, as well as a test bed for low-level image modeling algorithms. In this work, we propose a very deep fully convolutional auto-encoder network for image restoration, which is composed of multiple layers of convolution and de-convolution operators.", "positives": ["BSD", "Urban100"], "year": 2016}
{"tldr": "We propose a recurrent scale approximation algorithm for multi-scale object detection, which achieves comparable results to state-of-the-art methods on face detection benchmarks.", "positives": ["AFW"], "year": 2017}
{"tldr": "In this paper we propose a novel approach (namely, Orthogonal Embedding CNNs, or OE-CNNs) to learn the age-invariant deep face features.", "positives": ["MORPH"], "year": 2018}
{"tldr": "We extend the attention-mechanism with features needed for speech recognition and propose a novel and generic method of adding location-awareness to the attention mechanism to alleviate this issue.", "positives": ["TIMIT"], "year": 2015}
{"tldr": "We present a simple sequential sentence encoder for multi-domain natural language inference, based on stacked bidirectional LSTM-RNNs with shortcut connections and fine-tuned word embeddings.", "positives": ["SNLI"], "year": 2017}
{"tldr": "We present 3DMatch, a data-driven model that learns a local volumetric patch descriptor for establishing correspondences between partial 3D data, which improves state-of-the-art methods.", "positives": ["Scan2CAD"], "year": 2017}
{"tldr": "We propose a Recurrent Residual Convolutional Neural Network (RRCNN) based on U-Net for medical image segmentation.", "positives": ["CHASE_DB1", "DRIVE", "LUNA", "STARE"], "year": 2018}
{"tldr": "In this work, we cast text summarization as a sequence-to-sequence problem and apply the attentional encoder-decoder RNN that has been shown to be successful for Machine Translation (Bahdanau et al. (2014)).", "positives": ["Chinese Gigaword", "DUC 2004"], "year": 2016}
{"tldr": "We introduce a novel framework, EXplicit interAction Model (dubbed as EXAM), equipped with the interaction mechanism to incorporate word-level matching signals into the text classification task.", "positives": ["AG News", "DBpedia"], "year": 2018}
{"tldr": "We present an approach to synthesizing photographic images conditioned on semantic layouts by a single feedforward network with appropriate structure, trained end-to-end.", "positives": ["ADE20K", "COCO-Stuff", "Cityscapes"], "year": 2017}
{"tldr": "We evaluate bi-LSTMs with word, character, and unicode byte embeddings for POS tagging and propose a novel loss function that combines the POS tagging loss function with an auxiliary loss function for rare words.", "positives": ["Penn Treebank", "Universal Dependencies"], "year": 2016}
{"tldr": "Feature pyramids are a basic component in recognition systems for detecting objects at different scales. In this paper, we exploit the inherent multi-scale, pyramidal hierarchy of deep convolutional networks to construct feature pyramids with marginal extra cost.", "positives": ["COCO"], "year": 2017}
{"tldr": "We propose a meta attention-based aggregation scheme which adaptively and fine-grained weighs the feature along each feature dimension among all frames to form a compact and discriminative representation for video face recognition task.", "positives": ["IJB-A"], "year": 2017}
{"tldr": "Large scale supervised reading comprehension data allows us to develop a class of attention based neural networks that learn to read real documents and answer complex questions with minimal prior knowledge of language structure.", "positives": ["CNN/Daily Mail"], "year": 2015}
{"tldr": "Multi-Center Learning with multiple shape prediction layers for face alignment with real-time performance.Abstract Facial landmarks are highly correlated with each other since a certain landmark can be estimated by its neighboring landmarks. Most of the existing deep learning methods only use one fully-connected layer called shape prediction layer to estimate the locations of facial landmarks. In this paper, we propose a novel deep learning framework named Multi-Center learning with multiple shapes prediction layers.", "positives": ["AFLW2000-3D"], "year": 2018}
{"tldr": "We study feature learning techniques for graph-structured inputs and demonstrate state-of-the-art performance on a program verification task.", "positives": ["QM9", "WikiSQL"], "year": 2015}
{"tldr": "SegLink is an end-to-end trained, fully-convolutional neural network based on Segment Linking, an oriented text detection method.", "positives": ["ICDAR 2003", "SCUT-CTW1500"], "year": 2017}
{"tldr": "Multimodal Residual Networks (MRN) for the multimodal residual learning of visual question-answering, which extends the idea of the deep residual learning.", "positives": ["COCO"], "year": 2016}
{"tldr": "We propose the Laplacian Pyramid Super-Resolution Network (LapSRN) to progressively reconstruct the sub-band residuals of high-resolution images and achieve high-quality reconstruction.", "positives": ["BSD", "Set14", "Urban100"], "year": 2017}
{"tldr": "This article offers an empirical exploration on the use of character-level convolutional networks (ConvNets) for text classification, showing state-of-the-art or competitive results.", "positives": ["AG News", "DBpedia", "SPOT"], "year": 2015}
{"tldr": "We examine two fundamental tasks associated with graph representation learning: link prediction and semi-supervised node classification. We present a novel autoencoder architecture capable of learning a joint representation of both local graph structure and available node features.", "positives": ["Citeseer", "Cora", "Pubmed"], "year": 2018}
{"tldr": "ReasoNets make use of multiple turns to effectively exploit and then reason over the relation among queries, documents, and answers, achieving superior performance in machine comprehension tasks.", "positives": ["CNN/Daily Mail", "SQuAD"], "year": 2017}
{"tldr": "We propose a region-based face detector based on Region-based Fully Convolutional Networks (R-FCN), which achieves superior performance over state-of-the-arts.", "positives": ["FDDB", "WFLW"], "year": 2017}
{"tldr": "We train a CNN to predict a two-dimensional vector field, which maps each scene point to a candidate skeleton pixel, in the spirit of flux-based skeletonization algorithms.", "positives": ["SK-LARGE"], "year": 2019}
{"tldr": "We develop a new reading architecture for the dynamic integration of explicit background knowledge in neural natural language understanding (NLU) systems that learns to exploit knowledge selectively.", "positives": ["TriviaQA"], "year": 2017}
{"tldr": "We examine two fundamental tasks associated with graph representation learning: link prediction and node classification. We present a new autoencoder architecture capable of learning a joint representation of local graph structure and available node features for the simultaneous multi-task learning of unsupervised link prediction.", "positives": ["Citeseer", "Cora", "Pubmed"], "year": 2018}
{"tldr": "We study the effects of template size, negative set construction and classifier fusion on performance, then compare template adaptation to convolutional networks with metric learning, 2D and 3D alignment.", "positives": ["IJB-A"], "year": 2018}
{"tldr": "We propose StarGAN, a novel and scalable approach that can perform image-to-image translations for multiple domains using only a single model.", "positives": ["RaFD"], "year": 2017}
{"tldr": "In this paper, we propose the first, to the best of our knowledge, in-the-wild 3DMM by combining a powerful statistical model of 3D facial shape and texture, which describes both identity and expression, with an in- the-wild texture model.", "positives": ["Florence"], "year": 2017}
{"tldr": "We formulate language modeling as a matrix factorization problem, and show that the expressiveness of Softmax-based models (including the majority of neural language models) is limited by a Softmax bottleneck.", "positives": ["Penn Treebank", "WikiText-2"], "year": 2017}
{"tldr": "We propose a unified formulation for the problem of 3D human pose estimation from a single raw RGB image that reasons jointly about 2D joint estimation and 3D pose reconstruction to improve both tasks.", "positives": ["Human3.6M"], "year": 2017}
{"tldr": "We introduce a new, large-scale corpus of data records paired with descriptive documents, propose a series of extractive evaluation methods for analyzing performance, and obtain baseline results using current neural generation methods.", "positives": ["RotoWire"], "year": 2017}
{"tldr": "We propose to learn an adversarial network that generates examples with occlusions and deformations. The hope is that the final classifier can use these examples to learn invariances.", "positives": ["PASCAL VOC 2007"], "year": 2017}
{"tldr": "We apply knowledge distillation to neural machine translation and introduce two novel sequence-level distillation approaches that improve performance and reduce the need for beam search.", "positives": ["WMT 2014"], "year": 2016}
{"tldr": "We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations.", "positives": ["Cora"], "year": 2017}
{"tldr": "We expose and tackle some of the basic weaknesses of a GCNN model with a capsule idea and propose our Graph Capsule Network (GCAPS-CNN) model to solve especially graph classification problem which current GCNN models find challenging.", "positives": ["IMDB-BINARY", "NCI1", "RailEye3D Dataset"], "year": 2018}
{"tldr": "We introduce recurrent relational networks which increase the suite of solvable tasks to those that require an order of magnitude more steps of relational reasoning, where relational networks fail to solve any.", "positives": ["bAbI"], "year": 2017}
{"tldr": "We propose a model for Incremental Learning in Person Re-Identification, provide state-of-the-art results on variety of tasks and still achieve considerable accuracy later on.", "positives": ["DukeMTMC-reID", "Market-1501"], "year": 2018}
{"tldr": "Multi-Scale Context-Aware Network (MSCAN) to learn powerful features over full body and body parts for person Re-identification.", "positives": ["Market-1501"], "year": 2017}
{"tldr": "MT-DNN extends the model proposed in Liu et al. (2015) by incorporating a pre-trained bidirectional transformer language model, known as BERT, for learning representations across multiple natural language understanding tasks.", "positives": ["MultiNLI", "Quora", "SNLI", "SST", "SciTail"], "year": 2019}
{"tldr": "We present an exhaustive investigation of recent Deep Learning architectures, algorithms and strategies for the task of document image classification to finally reduce the error by more than half.", "positives": ["RVL-CDIP"], "year": 2017}
{"tldr": "We introduce a differentiable, end-to-end trainable framework for solving pixel-level grouping problems such as instance segmentation consisting of a recurrent neural network parameterized by kernel bandwidth and mean-shift clustering.", "positives": ["ImageNet"], "year": 2018}
{"tldr": "We propose an adversarial autoencoder that uses the recently proposed generative adversarial networks to perform variational inference and achieve competitive results in generative modeling and semi-supervised classification.", "positives": ["MNIST"], "year": 2015}
{"tldr": "We propose a novel structure-aware seq2seq architecture which consists of field-gating encoder and description generator with dual attention to encode both the content and the structure of a table.", "positives": ["WikiBio"], "year": 2017}
{"tldr": "Recurrent neural network grammars are probabilistic generative models for natural language. We investigate what information they learn, from a linguistic perspective, through various ablations to the model and the data, and by augmenting the model with an attention mechanism.", "positives": ["Penn Treebank"], "year": 2016}
{"tldr": "In this paper, we revise one of the most popular RNN models, namely, gated recurrent units (GRUs), and propose a simplified architecture that turned out to be very effective for ASR.", "positives": ["TIMIT"], "year": 2018}
{"tldr": "This paper studies CNN on text categorization to exploit the 1D structure (namely, word order) of text data for accurate prediction.", "positives": ["IMDb Movie Reviews"], "year": 2014}
{"tldr": "An important goal in visual recognition is to devise image representations that are invariant to particular transformations. In this paper, we address this goal with a new type of convolutional neural network (CNN) whose invariance is encoded by a reproducing kernel.", "positives": ["CIFAR-10", "MNIST", "STL-10"], "year": 2014}
{"tldr": "A simple re-implementation of BERT for query-based passage re-ranking, state of the art on the TREC-CAR dataset and the top entry in the leaderboard of the [DATASET] passage retrieval task.", "positives": ["MS MARCO"], "year": 2019}
{"tldr": "We propose a scale-Aware Fast R-CNN framework for pedestrian detection in natural scenes that is robust to large variance in instance scales, and achieves state-of-the-art performance on several challenging datasets.", "positives": ["ImageNet"], "year": 2018}
{"tldr": "3D hand and human pose estimation from a single depth map using a 3D convolutional neural network that performs perspective distortion-invariant estimation.", "positives": ["ICVL Hand Posture", "ITOP", "MSRA Hand", "NYU Hand"], "year": 2018}
{"tldr": "We propose a hypernetwork architecture that generates simplified relation-specific convolutional filters that outperforms ConvE and all previous approaches across standard datasets for link prediction.", "positives": ["FB15k", "WN18"], "year": 2018}
{"tldr": "We propose coupled generative adversarial network (CoGAN) for learning a joint distribution of multi-domain images. In contrast to the existing approaches, which require tuples of corresponding images in different domains in the training set, CoGAN can learn the joint distribution without any tuple of correspondingimages.", "positives": ["Cityscapes"], "year": 2016}
{"tldr": "A semantic segmentation network for tumor subregion segmentation from 3D MRIs based on encoder-decoder architecture based on variational auto-encoder branch.", "positives": ["BraTS 2018"], "year": 2018}
{"tldr": "We adapt the greedy Stack-LSTM dependency parser of Dyer et al. (2015) to support a training-with-exploration procedure using dynamic oracles(Goldberg and Nivre, 2013) instead of cross-entropy minimization.", "positives": ["Penn Treebank"], "year": 2016}
{"tldr": "We propose Weighted Transformer, a Transformer with modified attention layers, that not only outperforms the baseline network in BLEU score but also converges 15-40% faster.", "positives": ["WMT 2014"], "year": 2017}
{"tldr": "We present SNIPER, an algorithm for performing efficient multi-scale training in instance level visual recognition tasks. Instead of processing every pixel in an image pyramid, SNIPer processes context regions around ground-truth instances (referred to as chips) at the appropriate scale.", "positives": ["COCO", "PASCAL VOC 2007"], "year": 2018}
{"tldr": "We introduce a new form of convolutional neural network that combines the strengths of Convolutional Neural Networks (CNNs) and Conditional Random Fields (CRFs)-based probabilistic graphical modelling for pixel-level labelling tasks.", "positives": ["Cityscapes", "PASCAL Context", "PASCAL VOC"], "year": 2015}
{"tldr": "We present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure and achieves state of the art performance on WMT-14 translation tasks.", "positives": ["WMT 2014"], "year": 2014}
{"tldr": "A critical issue in pedestrian detection is to detect small-scale objects that will introduce feeble contrast and motion blur in images and videos, which in our opinion should partially resort to deep-rooted annotation bias. We propose a novel method integrated with somatic topological line localization (TLL) and temporal feature aggregation for detecting multi-scale pedestrians.", "positives": ["CityPersons"], "year": 2018}
{"tldr": "We tackle the problem of efficient keypoint-based object detection and introduce CornerNet-Lite, a combination of two efficient variants of CornerNet, which use an attention mechanism to eliminate the need for exhaustively processing all pixels of the image.", "positives": ["COCO"], "year": 2019}
{"tldr": "We describe a new method based on recurrent neural networks that keeps track of the individual party states throughout the conversation and uses this information for emotion classification.", "positives": ["IEMOCAP"], "year": 2018}
{"tldr": "We propose the Variational Shape Learner (VSL), a generative model that learns the underlying structure of voxelized 3D shapes in an unsupervised fashion.", "positives": ["ModelNet"], "year": 2018}
{"tldr": "In this paper we first propose a method of incorporating high-level concepts into the successful CNN-RNN approach, and show that it achieves a significant improvement on the state-of-the-art in both image captioning and visual question answering.", "positives": ["COCO"], "year": 2018}
{"tldr": "We aim to enrich the state-of-the-art neural natural language inference models with external knowledge, which further improve the state of the art on the [DATASET] dataset.", "positives": ["SNLI"], "year": 2017}
{"tldr": "The popular Q-learning algorithm is known to overestimate action values under certain conditions. We propose a specific adaptation to the DQN algorithm and show that the resulting algorithm not only reduces the observed overestimations, as hypothesized, but that this also leads to much better performance on several games.", "positives": ["Arcade Learning Environment"], "year": 2015}
{"tldr": "We propose a novel dependent reading bidirectional LSTM network (DR-BiLSTM) to efficiently model the relationship between a premise and a hypothesis during encoding and inference.", "positives": ["SNLI"], "year": 2018}
{"tldr": "We consider the problem of adapting neural paragraph-level question answering models to the case where entire documents are given as input. Our proposed solution trains models to produce well calibrated confidence scores for their results on individual paragraphs.", "positives": ["SQuAD", "TriviaQA"], "year": 2017}
{"tldr": "In this paper, we propose a new alignment framework, called 3D Dense Face Alignment (3DDFA), in which a dense 3D face model is fitted to the image via convolutional neutral network (CNN) and propose a method to synthesize large-scale training samples in profile views to solve the third problem of data labelling.", "positives": ["AFLW2000-3D", "BIWI", "Florence"], "year": 2015}
{"tldr": "We propose an approach based on disentangled representation for producing diverse outputs without paired training images. We introduce a novel cross-cycle consistency loss to handle unpaired training data.", "positives": ["GTA5"], "year": 2018}
{"tldr": "In this paper, we propose a dilated convolution based inception module to learn multi-scale information and design a deep network for single image super-resolution.", "positives": ["Set14", "Set5"], "year": 2017}
{"tldr": "This paper proposes a Fast Region-based Convolutional Network method (Fast R-CNN) for object detection using deep convolutional networks, which improves training and testing speed while also increasing detection accuracy.", "positives": ["PASCAL VOC 2007"], "year": 2015}
{"tldr": "This paper proposes a new Generative Partition Network (GPN) to address the challenging multi-person pose estimation problem. Different from existing models that are either completely top-down or bottom-up, the proposed GPN introduces a novel strategy--it generates partitions for multiple persons from their global joint candidates and infers instance-specific joint configurations simultaneously.", "positives": ["MPII"], "year": 2017}
{"tldr": "We investigate an alternative LSTM structure for encoding text, which consists of a parallel state for each word. Recurrent steps are used to perform local and global information exchange between words simultaneously.", "positives": ["CoNLL-2003", "IMDb Movie Reviews", "MR", "Penn Treebank"], "year": 2018}
{"tldr": "We propose a viewpoint invariant model for 3D human pose estimation from a single depth image, which achieves competitive performance on frontal views while achieving state-of-the-art performance on alternate viewpoints.", "positives": ["ITOP"], "year": 2016}
{"tldr": "We propose the Global-Locally Self-Attentive Dialogue State Tracker (GLAD), which learns representations of the user utterance and previous system actions with global-local modules and achieves state-of-the-art performance on WoZ and DSTC2 state tracking tasks.", "positives": ["Dialogue State Tracking Challenge", "Wizard-of-Oz"], "year": 2018}
{"tldr": "We propose an approach that jointly solves the tasks of detection and pose estimation: it infers the number of persons in a scene, identifies occluded body parts, and disambiguates body parts between people in close proximity of each other.", "positives": ["MPII Human Pose"], "year": 2016}
{"tldr": "In this paper, we propose to jointly learn the discriminant low dimensional subspace and the distance metric for person re-identification, which is comparable to state of the art.", "positives": ["DukeMTMC-reID", "Market-1501"], "year": 2014}
{"tldr": "We propose a novel 2D-assisted self-supervised learning (2DASL) method that can effectively use \"in-the-wild\" 2D face images with noisy landmark information to substantially improve 3D face model learning.", "positives": ["AFLW2000-3D"], "year": 2019}
{"tldr": "We propose a method of weight re-initialization by repeated annealing and injection of noise in the training process, which improves language modeling performance by up to 7.91 perplexity.", "positives": ["SNLI"], "year": 2018}
{"tldr": "In this paper, we study the effectiveness of convnet activation features for tasks requiring correspondence. We present evidence that convnet features localize at a much finer scale than their receptive field sizes, that they can be used to perform intraclass aligment as well as conventional hand-engineered features.", "positives": ["PASCAL3D+"], "year": 2014}
{"tldr": "We propose a new reality oriented adaptation approach for urban scene semantic segmentation by learning from synthetic data. We achieve a new state-of-the-art of 39.4% mean IoU on the Cityscapes dataset by adapting from the GTAV dataset.", "positives": ["GTA5"], "year": 2018}
{"tldr": "In this work, we study 3D object detection from [DATASET] data in both indoor and outdoor scenes. While previous methods focus on images or 3D voxels, often obscuring natural 3D patterns and invariances, our method leverages both mature 2D object detectors and advanced 3D deep learning for object localization, achieving efficiency as well as high recall for even small objects.", "positives": ["KITTI", "SUN RGB-D"], "year": 2018}
{"tldr": "The key challenge of face recognition is to develop effective feature representations for reducing intra-personal variations while enlarging inter-personal differences. In this paper, we show that it can be well solved with deep learning and using both face identification and verification signals as supervision.", "positives": ["LFW"], "year": 2014}
{"tldr": "We address the problem of 3D reconstruction from a single image, generating a straight-forward form of output – point cloud coordinates. Driven by this unorthordox output form and the inherent ambiguity in groundtruth, we design architecture, loss function and learning paradigm that are novel and effective.", "positives": ["MSRDailyActivity3D"], "year": 2017}
{"tldr": "We introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals.", "positives": ["PASCAL VOC 2007"], "year": 2017}
{"tldr": "We introduce a theoretical framework that facilitates better learning in language modeling, and show that our framework leads to state of the art performance on the [DATASET] with a variety of network models.", "positives": ["Penn Treebank"], "year": 2016}
{"tldr": "We present Multitask Network Cascades for instance-aware semantic segmentation. We develop an algorithm for end-to-end training of this causal, cascaded structure.", "positives": ["PASCAL-Person-Part"], "year": 2016}
{"tldr": "In this paper, we identify and address several deficiencies of existing unsupervised SMT approaches by exploiting subword information, developing a theoretically well founded Unsupervised tuning method, and incorporating a joint refinement procedure. Together, we obtain large improvements over the previous state-of-the-art in un Supervised machine translation.", "positives": ["WMT 2014", "WMT 2016"], "year": 2019}
{"tldr": "We propose a dimensionality stretching strategy that enables a single convolutional super-resolution network to take two key factors of the SISR degradation process, i.e., blur kernel and noise level, as input.", "positives": ["BSD", "Set14", "Set5", "Urban100"], "year": 2018}
{"tldr": "An efficient learner is one who reuses what they already know to tackle a new problem. Towards this goal, we demonstrate an extension of a variational autoencoder that can learn a method for computing representations, or statistics, of datasets in an unsupervised fashion.", "positives": ["Omniglot"], "year": 2016}
{"tldr": "We introduce an architecture based entirely on convolutional neural networks for sequence to sequence learning and outperform the accuracy of the deep LSTM setup of Wu et al. (2016) on both WMT'14 English-German translation at an order of magnitude faster speed.", "positives": ["CoNLL-2003", "WMT 2014", "WMT 2016"], "year": 2017}
{"tldr": "We propose a convolutional neural network (CNN) architecture for facial expression recognition. The proposed architecture is independent of any hand-crafted feature extraction and performs better than the state of the art using CNNs.", "positives": ["MMI"], "year": 2015}
{"tldr": "We propose a novel neural architecture Transformer-XL that enables learning longer-term dependency beyond a fixed length without disrupting temporal coherence, achieving state-of-the-art performance on both short and long sequences.", "positives": ["Billion Word Benchmark", "Hutter Prize", "Penn Treebank", "WikiText-103"], "year": 2019}
{"tldr": "We propose a novel Progressive Scale Expansion Network (PSENet), which can precisely detect text instances with arbitrary shapes, making it easier to use segmentation-based methods to detect arbitrary-shaped text instances.", "positives": ["ICDAR 2017", "SCUT-CTW1500"], "year": 2019}
{"tldr": "We present a novel neural network for processing sequences. The ByteNet is a one-dimensional convolutional neural network that is composed of two parts, one to encode the source sequence and other to decode the target sequence.", "positives": ["WMT 2014", "WMT 2015"], "year": 2016}
{"tldr": "We increase the feature map dimension at downsampling locations to involve as many locations as possible to increase generalization ability, which improves the classification accuracy.", "positives": ["CIFAR-10"], "year": 2017}
{"tldr": "In this paper, we propose quantized densely connected U-Nets for efficient visual landmark localization. The idea is that features of the same semantic meanings are globally reused across the stacked U-Net, yielding improved localization accuracy.", "positives": ["MPII Human Pose"], "year": 2018}
{"tldr": "This paper proposes to improve visual question answering (VQA) with structured representations of both scene contents and questions, and we describe a deep neural network that exploits the structure in these representations.", "positives": ["COCO"], "year": 2017}
{"tldr": "In this paper we propose a number of architectural advances in CNNs for LVCSR. First, we introduce a very deep convolutional network architecture with up to 14 weight layers, with small 3x3 kernels, inspired by the VGG Imagenet 2014 architecture.", "positives": ["Switchboard-1 Corpus"], "year": 2016}
{"tldr": "This paper proposes to integrate multiple feature views in quaternion-valued convolutional neural network (QCNN) for sequence-to-sequence mapping with the CTC model.", "positives": ["TIMIT"], "year": 2018}
{"tldr": "We propose a new method for exploiting handcrafted features as part of a novel hybrid learning approach, incorporating a feature auto-encoder loss component, which improves the performance of a neural CRF model.", "positives": ["CoNLL-2003"], "year": 2018}
{"tldr": "In this work we explore recent advances in Recurrent Neural Networks for large scale Language Modeling, a task central to language understanding, and extend current models to deal with two key challenges present in this task.", "positives": ["Billion Word Benchmark"], "year": 2016}
{"tldr": "We make one of the earliest efforts to bridge saliency detection and WOD tasks and achieve the state-of-the-art object detection results under the weak supervision.", "positives": ["PASCAL VOC 2007"], "year": 2017}
{"tldr": "We describe a collection of acoustic and language modeling techniques that lowered the word error rate of our English conversational telephone LVCSR system to a record 6.6% on the Switchboard subset of Hub5 2000 evaluation testset.", "positives": ["Switchboard-1 Corpus"], "year": 2016}
{"tldr": "Convolutional networks are at the core of most state of-the-art computer vision solutions for a wide variety of tasks. Here we are exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization.", "positives": ["ImageNet"], "year": 2016}
{"tldr": "This paper aims to classify and locate objects accurately and efficiently, without using bounding box annotations. In this paper, we propose a novel classification architecture ProNet based on convolutional neural networks.", "positives": ["COCO"], "year": 2016}
{"tldr": "This paper studies the problem of embedding very large information networks into low-dimensional vector spaces, which is useful in many tasks such as visualization, node classification, and link prediction.", "positives": ["BlogCatalog", "KILT"], "year": 2015}
{"tldr": "In this paper, we present the first experiments using neural network models for the task of error detection in learner writing and propose a framework for error detection using bidirectional LSTMs.", "positives": ["FCE"], "year": 2016}
{"tldr": "This paper starts from the observation that multiple top performing pedestrian detectors can be modelled by using an intermediate layer filtering low-level features in combination with a boosted decision forest.", "positives": ["ImageNet"], "year": 2015}
{"tldr": "We propose Cross-View Training (CVT), a semi-supervised learning algorithm that improves the representations of a Bi-LSTM sentence encoder using a mix of labeled and unlabeled data.", "positives": ["CoNLL-2003", "OntoNotes 5.0", "Penn Treebank"], "year": 2018}
{"tldr": "We present a novel family of language model (LM) estimation techniques named Sparse Non-negative Matrix (SNM) estimation, promising an approach that has the same flexibility in combining arbitrary feature s effectively and yet should scale to very large amounts of data.", "positives": ["Billion Word Benchmark"], "year": 2014}
{"tldr": "In this paper, we describe the PixelGAN autoencoder in which the generative path is a convolutional autoregressive neural network on pixels (PixelCNN) that is conditioned on a latent code, and the recognition path uses a generative adversarial network to impose a prior distribution on the latent code.", "positives": ["MNIST"], "year": 2017}
{"tldr": "In this paper, we propose the TBCNN-pair model to recognize entailment and contradiction between two sentences. In our model, a tree-based convolutional neural network (TBCNN) captures sentence-level semantics; then heuristic matching layers like concatenation, element-wise product/difference combine the information in individual sentences.", "positives": ["SNLI"], "year": 2015}
{"tldr": "We propose a deep convolutional neural network architecture codenamed Inception that achieves the state of the art for classification and detection in the [DATASET] Large-Scale Visual Recognition Challenge 2014 (ILSVRC14)", "positives": ["ImageNet"], "year": 2015}
{"tldr": "We propose a novel feature-augmented random forest for image super-resolution, where the conventional gradient-based features are augmented with gradient magnitudes and different feature recipes are formulated on different stages in an RF.", "positives": ["BSD", "Set14", "Set5"], "year": 2017}
{"tldr": "We introduce an architecture to learn joint multilingual sentence representations for 93 languages, belonging to more than 30 different families and written in 28 different scripts.", "positives": ["BUCC", "MLDoc", "XNLI"], "year": 2019}
{"tldr": "We explore new structures for SR based on this compact RNN view, leading us to a dual-state design, the Dual-State Recurrent Network.", "positives": ["BSD", "Set14", "Set5", "Urban100"], "year": 2018}
{"tldr": "We introduce Interactive Inference Network (IIN), a novel class of neural network architectures that is able to achieve high-level understanding of the sentence pair by hierarchically extracting semantic features from interaction space.", "positives": ["Quora", "SNLI"], "year": 2017}
{"tldr": "This paper investigates deep recurrent neural networks, which combine the multiple levels of representation that have proved so effective in deep networks with the flexible use of long range context that empowers RNNs for sequence labelling problems where the input-output alignment is unknown.", "positives": ["TIMIT"], "year": 2013}
{"tldr": "In this paper, we propose a very deep fully convolutional encoding-decoding framework for image restoration such as denoising and super-resolution.", "positives": ["BSD", "Set5"], "year": 2016}
{"tldr": "In this article, we revisit two popular convolutional neural networks in person re-identification (re-ID) and propose a Siamese network that learns discriminative embedding and similarity measurement at the same time.", "positives": ["Market-1501"], "year": 2017}
{"tldr": "We propose an adversarial learning method for domain adaptation in the context of semantic segmentation that performs favorably against state-of-the-art methods in terms of accuracy and visual quality.", "positives": ["GTA5"], "year": 2018}
{"tldr": "We propose a distributed architecture for deep reinforcement learning at scale, that enables agents to learn effectively from orders of magnitude more data than previously possible.", "positives": ["Arcade Learning Environment"], "year": 2018}
{"tldr": "A graph-to-sequence neural encoder-decoder model that maps an input graph to a sequence of vectors and uses an attention-based LSTM method to decode the target sequence from these vectors.", "positives": ["WikiSQL"], "year": 2018}
{"tldr": "We present YOLO, a new approach to object detection. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation.", "positives": ["PASCAL VOC 2007"], "year": 2016}
{"tldr": "In this work, we build on recent advances in distributional reinforcement learning to give a generally applicable, flexible, and state-of-the-art distributional variant of DQN.", "positives": ["Arcade Learning Environment"], "year": 2018}
{"tldr": "We build an anchor-based deep face detector, which only output a single feature map with small anchors, to specifically learn small faces and train it by a novel hard image mining strategy.", "positives": ["AFW", "FDDB", "PASCAL Face", "WFLW"], "year": 2018}
{"tldr": "Pose Machines provide a sequential prediction framework for learning rich implicit spatial models. Our approach addresses the characteristic difficulty of vanishing gradients during training by providing a natural learning objective function that enforces intermediate supervision and conditioning the learning procedure.", "positives": ["FLIC", "LSP", "MPII Human Pose"], "year": 2016}
{"tldr": "We propose a novel deep Nested Adversarial Network (NAN) model for multi-human parsing, which improves the state-of-the-art in understanding humans in crowded scenes, such as group behavior analysis, person re-identification and autonomous driving.", "positives": ["MHP", "PASCAL-Person-Part"], "year": 2018}
{"tldr": "In this paper, we propose a novel deep network for Weakly Supervised Object Detection (WSOD), using multiple streams in convolutional neural networks to learn refined instance classifiers by iterative process.", "positives": ["ImageNet", "PASCAL VOC", "PASCAL VOC 2007"], "year": 2020}
{"tldr": "We borrow the concept of channel features to the face detection domain, make a full exploration of feature design, and discover a multiscale version of features with better performance.", "positives": ["WFLW"], "year": 2014}
{"tldr": "The field of object detection has made significant advances riding on the wave of region-based ConvNets, but their training procedure still includes many heuristics and hyperparameters that are costly to tune. We present a simple yet surprisingly effective online hard example mining (OHEM) algorithm for training region- based ConvNet detectors.", "positives": ["PASCAL VOC 2007"], "year": 2016}
{"tldr": "We describe Microsoft's conversational speech recognition system, in which we combine recent developments in neural network-based acoustic and language modeling to advance the state of the art on the Switchboard recognition task.", "positives": ["Switchboard-1 Corpus"], "year": 2016}
{"tldr": "In this paper, we exploit the capability of global context information by different-region-based context aggregation through our pyramid pooling module together with the proposed pyramid scene parsing network (PSPNet)", "positives": ["ADE20K", "CamVid", "Cityscapes", "PASCAL VOC"], "year": 2017}
{"tldr": "In this paper we propose an approach for articulated tracking of multiple people in unconstrained videos that achieves state-of-the-art results while using only a fraction of time.", "positives": ["MPII"], "year": 2017}
{"tldr": "This paper presents a system which learns to answer questions on a broad range of topics from a knowledge base using few hand-crafted features.", "positives": ["WebQuestions"], "year": 2014}
{"tldr": "We propose a novel Compressed Interaction Network (CIN), which aims to generate feature interactions in an explicit fashion and at the vector-wise level. We combine a CIN and a classical DNN into one unified model, and named this new model eXtreme Deep Factorization Machine.", "positives": ["Criteo"], "year": 2018}
{"tldr": "We propose an attention based neural matching model for ranking short answer text, which is competitive with other neural network models that have been used for the question answering task.", "positives": ["TrecQA"], "year": 2016}
{"tldr": "We propose a novel generalized framework for adversarial adaptation which combines discriminative modeling, untied weight sharing, and a GAN loss, and demonstrate the promise of our approach by exceeding state-of-the-art unsupervised adaptation results.", "positives": ["MNIST"], "year": 2017}
{"tldr": "We address the problem of 3D human pose estimation from a sequence of 2D human poses and propose a sequence-to-sequence network that can recover temporally consistent 3D poses even when the 2D pose detector fails.", "positives": ["Human3.6M"], "year": 2017}
{"tldr": "We propose an end-to-end deep learning architecture that produces a 3D shape in triangular mesh from a single color image by progressively deforming an ellipsoid, leveraging perceptual features extracted from the input image.", "positives": ["ShapeNet"], "year": 2018}
{"tldr": "We propose a curriculum-style learning approach to minimize the domain gap in semantic segmentation, which is a core task of various emerging industrial applications such as autonomous driving and medical imaging.", "positives": ["GTA5"], "year": 2017}
{"tldr": "We introduce a novel method for 3D object detection and pose estimation from color images only. By contrast with recent patch-based methods, we rely on a \"holistic\" approach: We apply to the detected objects a Convolutional Neural Network (CNN) trained to predict their 3D poses in the form of 2D projections of the corners of their3D bounding boxes.", "positives": ["LINEMOD"], "year": 2017}
{"tldr": "We present a simple and effective scheme for dependency parsing which is based on bidirectional-LSTMs (BiLSTM), and apply it to a graph-based parser.", "positives": ["Penn Treebank"], "year": 2016}
{"tldr": "We address this problem by segmenting the parts of objects at an instance-level, such that each pixel in the image is assigned a part label, as well as the identity of the object it belongs to.", "positives": ["PASCAL-Person-Part"], "year": 2017}
{"tldr": "We propose a novel fully convolutional network, named as CoupleNet, to couple the global structure with local parts for object detection.", "positives": ["PASCAL VOC 2007"], "year": 2017}
{"tldr": "This paper proposes an approach that couples a deep CNN-based approach with a low-dimensional discriminative embedding step, learned using triplet probability constraints to address the unconstrained face verification problem.", "positives": ["IJB-A"], "year": 2016}
{"tldr": "We present a new method for synthesizing high-resolution photo-realistic images from semantic label maps using conditional generative adversarial networks (conditional GANs) using a novel adversarial loss.", "positives": ["ADE20K", "COCO-Stuff", "Cityscapes"], "year": 2018}
