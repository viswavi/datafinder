'''
export OPENAI_API_KEY='sk-...'
python train_data/gpt3_tagging.py 
'''

import argparse
import jsonlines
import openai
import os
import time
from tqdm import tqdm

parser = argparse.ArgumentParser()
parser.add_argument("--test-set-queries", default="/Users/vijay/Documents/code/dataset-recommendation/scirex_abstracts.temp")
parser.add_argument("--output-file", default="/Users/vijay/Documents/code/dataset-recommendation/scirex_abstracts_parsed_by_gpt3.jsonl")

def load_prompt():
    prompt = """Given an abstract from an artificial intelligence paper:
1) extract keyphrases regarding the task (e.g. image classification), data modality (e.g. images or speech), domain (e.g. biomedical or aerial), training style (unsupervised, semi-supervised, fully supervised, or reinforcement learning), text length (sentence-level or paragraph-level), language required (e.g. English)
2) write a very short, single-sentence summary that contains these relevant keyphrases, only including other information if critical to understanding the abstract.

Abstract:
We study automatic question generation for sentences from text passages in reading comprehension. We introduce an attention-based sequence learning model for the task and investigate the effect of encoding sentence- vs. paragraph-level information. In contrast to all previous work, our model does not rely on hand-crafted rules or a sophisticated NLP pipeline; it is instead trainable end-to-end via sequence-to-sequence learning. Automatic evaluation results show that our system significantly outperforms the state-of-the-art rule-based system. In human evaluations, questions generated by our system are also rated as being more natural (i.e., grammaticality, fluency) and as more difficult to answer (in terms of syntactic and lexical divergence from the original text and reasoning needed to answer).

Output: (Task | Modality | Domain | Training Style | Text Length |  Language Required | Final Summary)
Task: question generation
Modality: text
Domain: N/A
Training Style: fully supervised
Text Length: paragraph-level
Language Required: N/A
Final Summary: I propose an improved end-to-end system for automatic question generation.
--

Abstract:
We present a self-supervised approach to estimate flow in camera image and top-view grid map sequences using fully convolutional neural networks in the domain of automated driving. We extend existing approaches for self-supervised optical flow estimation by adding a regularizer expressing motion consistency assuming a static environment. However, as this assumption is violated for other moving traffic participants we also estimate a mask to scale this regularization. Adding a regularization towards motion consistency improves convergence and flow estimation accuracy. Furthermore, we scale the errors due to spatial flow inconsistency by a mask that we derive from the motion mask. This improves accuracy in regions where the flow drastically changes due to a better separation between static and dynamic environment. We apply our approach to optical flow estimation from camera image sequences, validate on odometry estimation and suggest a method to iteratively increase optical flow estimation accuracy using the generated motion masks. Finally, we provide quantitative and qualitative results based on the KITTI odometry and tracking benchmark for scene flow estimation based on grid map sequences. We show that we can improve accuracy and convergence when applying motion and spatial consistency regularization.

Output: (Task | Modality | Domain | Training Style | Text Length |  Language Required | Final Summary)
Task: optical flow estimation
Modality: images and top-view grid map sequences
Domain: autonomous driving
Training Style: unsupervised
Text Length: N/A
Language Required: N/A
Final Summary: We want to build a system for optical flow estimation from images and top-down maps.
--

Abstract:
Bidirectional Encoder Representations from Transformers (BERT) has shown marvelous improvements across various NLP tasks. Recently, an upgraded version of BERT has been released with Whole Word Masking (WWM), which mitigate the drawbacks of masking partial WordPiece tokens in pre-training BERT. In this technical report, we adapt whole word masking in Chinese text, that masking the whole word instead of masking Chinese characters, which could bring another challenge in Masked Language Model (MLM) pre-training task. The proposed models are verified on various NLP tasks, across sentence-level to document-level, including machine reading comprehension (CMRC 2018, DRCD, CJRC), natural language inference (XNLI), sentiment classification (ChnSentiCorp), sentence pair matching (LCQMC, BQ Corpus), and document classification (THUCNews). Experimental results on these datasets show that the whole word masking could bring another significant gain. Moreover, we also examine the effectiveness of the Chinese pre-trained models: BERT, ERNIE, BERT-wwm, BERT-wwm-ext, RoBERTa-wwm-ext, and RoBERTa-wwm-ext-large. We release all the pre-trained models:

Output: (Task | Modality | Domain | Training Style | Text Length |  Language Required | Final Summary)
Task: machine reading comprehension, natural language inference, sentiment classification, sentence pair matching, document classification
Modality: text
Domain: autonomous driving
Training Style: N/A
Text Length: sentence-level, paragraph-level
Language Required: Chinese
Final Summary: A large language model for Chinese language processing, applied to a variety of Chinese NLP benchmarks.
--"""
    return prompt

def fill_prompt(abstract):
    filled_prompt = f"""{load_prompt()}

Abstract:
{abstract}

Output: (Task | Modality | Domain | Training Style | Text Length |  Language Required | Final Summary)
Task:"""
    return filled_prompt


def remove_prompt(prompt, generated_text):
    generated_chunks = generated_text.split("""
    --""")
    match_found = False
    for chunk in reversed(generated_chunks):
        if "Final Summary:" in chunk and "Language Required:" in chunk and "Text Length:" in chunk and "Training Style:" in chunk:    
            match_found = True    
            break
    if match_found:
        return chunk.strip()
    else:
        return None

def parse_fields(text, abstract):
    out_dict = {"abstract": abstract}
    if text is None:
        out_dict["parsing_successful"] = "False"
    else:
        out_dict["parsing_successful"] = "True"

    num_matched = 0
    fields = ["Task", "Modality", "Domain", "Training Style", "Text Length", "Language Required", "Final Summary"]
    for line in text.split("\n"):
        stripped_line = line.strip()
        for field in fields:
            if f"{field}:" in stripped_line:
                field_value = stripped_line[len(f"{field}:"):].strip()
                out_dict[field] = field_value
                num_matched += 1
    if num_matched != len(fields):
        out_dict["parsing_successful"] = "False"

    out_dict["raw_text"] = text
    return out_dict

def run_gpt(formatted_prompt):
    response = openai.Completion.create(
        model="text-curie-001",
        prompt=formatted_prompt,
        temperature=0.7,
        max_tokens=230,
        top_p=1,
        frequency_penalty=0.0,
        presence_penalty=0.0,
        stop=["--"]
    )

    truncated_text = "Task:" + response.choices[0].text
    fields_parsed = parse_fields(truncated_text, ab)

    used_davinci = False
    if fields_parsed["parsing_successful"] == "False":
        response = openai.Completion.create(
            model="text-davinci-003",
            prompt=formatted_prompt,
            temperature=0.7,
            max_tokens=230,
            top_p=1,
            frequency_penalty=0.0,
            presence_penalty=0.0,
            stop=["--"]
        )
        truncated_text = "Task:" + response.choices[0].text
        fields_parsed = parse_fields(truncated_text, ab)
    return fields_parsed

if __name__ == "__main__":
    args = parser.parse_args()

    openai.api_key = os.getenv("OPENAI_API_KEY")

    abstracts = []
    parsed_ = []

    current_lines = list(jsonlines.open(args.output_file))

    with open(args.output_file, 'w') as file:
        writer = jsonlines.Writer(file, flush=True)
        writer.write_all(current_lines)
        breakpoint()
        abstract_lines = open(args.test_set_queries).read().split("\n")
        for i, ab in tqdm(enumerate(abstract_lines)):

            if i < len(current_lines):
                continue
            if len(ab.strip()) == 0:
                continue
            if ab.endswith(" <|TLDR|> ."):
                ab = ab[:-len(" <|TLDR|> .")]
            abstracts.append(ab)
            formatted_prompt = fill_prompt(ab)
            run_successful = False
            while run_successful is False:
                try:
                    fields_parsed = run_gpt(formatted_prompt)
                    run_successful = True
                except Exception as e:
                    print(e)
                    time.sleep(10)

            writer.write(fields_parsed)
        writer.close()